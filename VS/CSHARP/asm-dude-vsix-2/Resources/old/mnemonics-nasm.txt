AAA		8086	AAA 	ASCII Adjust After Addition	AAA.html
AAD		8086	AAD 	ASCII Adjust AX Before Division	AAD.html
AAD	IMM	8086	AAD IMM	ASCII Adjust AX Before Division	AAD.html
AAM		8086	AAM 	ASCII Adjust AX After Multiply	AAM.html
AAM	IMM	8086	AAM IMM	ASCII Adjust AX After Multiply	AAM.html
AAS		8086	AAS 	ASCII Adjust AL After Subtraction	AAS.html
ADC	MEM,R8	8086	ADC MEM, R8	Add with Carry	ADC.html
ADC	R8,R8	8086	ADC R8, R8	Add with Carry	ADC.html
ADC	MEM,R16	8086	ADC MEM, R16	Add with Carry	ADC.html
ADC	R16,R16	8086	ADC R16, R16	Add with Carry	ADC.html
ADC	MEM,R32	386	ADC MEM, R32	Add with Carry	ADC.html
ADC	R32,R32	386	ADC R32, R32	Add with Carry	ADC.html
ADC	MEM,R64	X64	ADC MEM, r64	Add with Carry	ADC.html
ADC	R64,R64	X64	ADC r64, r64	Add with Carry	ADC.html
ADC	R8,MEM	8086	ADC R8, MEM	Add with Carry	ADC.html
ADC	R8,R8	8086	ADC R8, R8	Add with Carry	ADC.html
ADC	R16,MEM	8086	ADC R16, MEM	Add with Carry	ADC.html
ADC	R16,R16	8086	ADC R16, R16	Add with Carry	ADC.html
ADC	R32,MEM	386	ADC R32, MEM	Add with Carry	ADC.html
ADC	R32,R32	386	ADC R32, R32	Add with Carry	ADC.html
ADC	R64,MEM	X64	ADC r64, MEM	Add with Carry	ADC.html
ADC	R64,R64	X64	ADC r64, r64	Add with Carry	ADC.html
ADC	R/M16,IMM8	8086	ADC r/m16, IMM8	Add with Carry	ADC.html
ADC	R/M32,IMM8	386	ADC R/M32, IMM8	Add with Carry	ADC.html
ADC	R/M64,IMM8	X64	ADC r/m64, IMM8	Add with Carry	ADC.html
ADC	AL,IMM	8086	ADC AL, IMM	Add with Carry	ADC.html
ADC	AX,IMM	8086	ADC AX, IMM	Add with Carry	ADC.html
ADC	EAX,IMM	386	ADC EAX, IMM	Add with Carry	ADC.html
ADC	RAX,IMM	X64	ADC RAX, IMM	Add with Carry	ADC.html
ADC	R/M8,IMM	8086	ADC r/m8, IMM	Add with Carry	ADC.html
ADC	R/M16,IMM	8086	ADC r/m16, IMM	Add with Carry	ADC.html
ADC	R/M32,IMM	386	ADC R/M32, IMM	Add with Carry	ADC.html
ADC	R/M64,IMM	X64	ADC r/m64, IMM	Add with Carry	ADC.html
ADC	MEM,IMM8	8086	ADC MEM, IMM8	Add with Carry	ADC.html
ADC	MEM,IMM16	8086	ADC MEM, IMM16	Add with Carry	ADC.html
ADC	MEM,IMM32	386	ADC MEM, IMM32	Add with Carry	ADC.html
ADC	R/M8,IMM	8086	ADC r/m8, IMM	Add with Carry	ADC.html
ADD	MEM,R8	8086	ADD MEM, R8	Add	ADD.html
ADD	R8,R8	8086	ADD R8, R8	Add	ADD.html
ADD	MEM,R16	8086	ADD MEM, R16	Add	ADD.html
ADD	R16,R16	8086	ADD R16, R16	Add	ADD.html
ADD	MEM,R32	386	ADD MEM, R32	Add	ADD.html
ADD	R32,R32	386	ADD R32, R32	Add	ADD.html
ADD	MEM,R64	X64	ADD MEM, r64	Add	ADD.html
ADD	R64,R64	X64	ADD r64, r64	Add	ADD.html
ADD	R8,MEM	8086	ADD R8, MEM	Add	ADD.html
ADD	R8,R8	8086	ADD R8, R8	Add	ADD.html
ADD	R16,MEM	8086	ADD R16, MEM	Add	ADD.html
ADD	R16,R16	8086	ADD R16, R16	Add	ADD.html
ADD	R32,MEM	386	ADD R32, MEM	Add	ADD.html
ADD	R32,R32	386	ADD R32, R32	Add	ADD.html
ADD	R64,MEM	X64	ADD r64, MEM	Add	ADD.html
ADD	R64,R64	X64	ADD r64, r64	Add	ADD.html
ADD	R/M16,IMM8	8086	ADD r/m16, IMM8	Add	ADD.html
ADD	R/M32,IMM8	386	ADD R/M32, IMM8	Add	ADD.html
ADD	R/M64,IMM8	X64	ADD r/m64, IMM8	Add	ADD.html
ADD	AL,IMM	8086	ADD AL, IMM	Add	ADD.html
ADD	AX,IMM	8086	ADD AX, IMM	Add	ADD.html
ADD	EAX,IMM	386	ADD EAX, IMM	Add	ADD.html
ADD	RAX,IMM	X64	ADD RAX, IMM	Add	ADD.html
ADD	R/M8,IMM	8086	ADD r/m8, IMM	Add	ADD.html
ADD	R/M16,IMM	8086	ADD r/m16, IMM	Add	ADD.html
ADD	R/M32,IMM	386	ADD R/M32, IMM	Add	ADD.html
ADD	R/M64,IMM	X64	ADD r/m64, IMM	Add	ADD.html
ADD	MEM,IMM8	8086	ADD MEM, IMM8	Add	ADD.html
ADD	MEM,IMM16	8086	ADD MEM, IMM16	Add	ADD.html
ADD	MEM,IMM32	386	ADD MEM, IMM32	Add	ADD.html
ADD	R/M8,IMM	8086	ADD r/m8, IMM	Add	ADD.html
AND	MEM,R8	8086	AND MEM, R8	Logical AND	AND.html
AND	R8,R8	8086	AND R8, R8	Logical AND	AND.html
AND	MEM,R16	8086	AND MEM, R16	Logical AND	AND.html
AND	R16,R16	8086	AND R16, R16	Logical AND	AND.html
AND	MEM,R32	386	AND MEM, R32	Logical AND	AND.html
AND	R32,R32	386	AND R32, R32	Logical AND	AND.html
AND	MEM,R64	X64	AND MEM, r64	Logical AND	AND.html
AND	R64,R64	X64	AND r64, r64	Logical AND	AND.html
AND	R8,MEM	8086	AND R8, MEM	Logical AND	AND.html
AND	R8,R8	8086	AND R8, R8	Logical AND	AND.html
AND	R16,MEM	8086	AND R16, MEM	Logical AND	AND.html
AND	R16,R16	8086	AND R16, R16	Logical AND	AND.html
AND	R32,MEM	386	AND R32, MEM	Logical AND	AND.html
AND	R32,R32	386	AND R32, R32	Logical AND	AND.html
AND	R64,MEM	X64	AND r64, MEM	Logical AND	AND.html
AND	R64,R64	X64	AND r64, r64	Logical AND	AND.html
AND	R/M16,IMM8	8086	AND r/m16, IMM8	Logical AND	AND.html
AND	R/M32,IMM8	386	AND R/M32, IMM8	Logical AND	AND.html
AND	R/M64,IMM8	X64	AND r/m64, IMM8	Logical AND	AND.html
AND	AL,IMM	8086	AND AL, IMM	Logical AND	AND.html
AND	AX,IMM	8086	AND AX, IMM	Logical AND	AND.html
AND	EAX,IMM	386	AND EAX, IMM	Logical AND	AND.html
AND	RAX,IMM	X64	AND RAX, IMM	Logical AND	AND.html
AND	R/M8,IMM	8086	AND r/m8, IMM	Logical AND	AND.html
AND	R/M16,IMM	8086	AND r/m16, IMM	Logical AND	AND.html
AND	R/M32,IMM	386	AND R/M32, IMM	Logical AND	AND.html
AND	R/M64,IMM	X64	AND r/m64, IMM	Logical AND	AND.html
AND	MEM,IMM8	8086	AND MEM, IMM8	Logical AND	AND.html
AND	MEM,IMM16	8086	AND MEM, IMM16	Logical AND	AND.html
AND	MEM,IMM32	386	AND MEM, IMM32	Logical AND	AND.html
AND	R/M8,IMM	8086	AND r/m8, IMM	Logical AND	AND.html
ARPL	MEM,R16	286	ARPL MEM, R16	Adjust RPL Field of Segment Selector	ARPL.html
ARPL	R16,R16	286	ARPL R16, R16	Adjust RPL Field of Segment Selector	ARPL.html
BB0_RESET		PENT,CYRIX	BB0_RESET 	TODO: PENT,CYRIX	
BB1_RESET		PENT,CYRIX	BB1_RESET 	TODO: PENT,CYRIX	
BOUND	R16,MEM	186	BOUND R16, MEM	Check Array Index Against Bounds	BOUND.html
BOUND	R32,MEM	386	BOUND R32, MEM	Check Array Index Against Bounds	BOUND.html
BSF	R16,MEM	386	BSF R16, MEM	Bit Scan Forward	BSF.html
BSF	R16,R16	386	BSF R16, R16	Bit Scan Forward	BSF.html
BSF	R32,MEM	386	BSF R32, MEM	Bit Scan Forward	BSF.html
BSF	R32,R32	386	BSF R32, R32	Bit Scan Forward	BSF.html
BSF	R64,MEM	X64	BSF r64, MEM	Bit Scan Forward	BSF.html
BSF	R64,R64	X64	BSF r64, r64	Bit Scan Forward	BSF.html
BSR	R16,MEM	386	BSR R16, MEM	Bit Scan Reverse	BSR.html
BSR	R16,R16	386	BSR R16, R16	Bit Scan Reverse	BSR.html
BSR	R32,MEM	386	BSR R32, MEM	Bit Scan Reverse	BSR.html
BSR	R32,R32	386	BSR R32, R32	Bit Scan Reverse	BSR.html
BSR	R64,MEM	X64	BSR r64, MEM	Bit Scan Reverse	BSR.html
BSR	R64,R64	X64	BSR r64, r64	Bit Scan Reverse	BSR.html
BSWAP	R32	486	BSWAP R32	Byte Swap	BSWAP.html
BSWAP	R64	X64	BSWAP r64	Byte Swap	BSWAP.html
BT	MEM,R16	386	BT MEM, R16	Bit Test	BT.html
BT	R16,R16	386	BT R16, R16	Bit Test	BT.html
BT	MEM,R32	386	BT MEM, R32	Bit Test	BT.html
BT	R32,R32	386	BT R32, R32	Bit Test	BT.html
BT	MEM,R64	X64	BT MEM, r64	Bit Test	BT.html
BT	R64,R64	X64	BT r64, r64	Bit Test	BT.html
BT	R/M16,IMM	386	BT r/m16, IMM	Bit Test	BT.html
BT	R/M32,IMM	386	BT R/M32, IMM	Bit Test	BT.html
BT	R/M64,IMM	X64	BT r/m64, IMM	Bit Test	BT.html
BTC	MEM,R16	386	BTC MEM, R16	Bit Test and Complement	BTC.html
BTC	R16,R16	386	BTC R16, R16	Bit Test and Complement	BTC.html
BTC	MEM,R32	386	BTC MEM, R32	Bit Test and Complement	BTC.html
BTC	R32,R32	386	BTC R32, R32	Bit Test and Complement	BTC.html
BTC	MEM,R64	X64	BTC MEM, r64	Bit Test and Complement	BTC.html
BTC	R64,R64	X64	BTC r64, r64	Bit Test and Complement	BTC.html
BTC	R/M16,IMM	386	BTC r/m16, IMM	Bit Test and Complement	BTC.html
BTC	R/M32,IMM	386	BTC R/M32, IMM	Bit Test and Complement	BTC.html
BTC	R/M64,IMM	X64	BTC r/m64, IMM	Bit Test and Complement	BTC.html
BTR	MEM,R16	386	BTR MEM, R16	Bit Test and Reset	BTR.html
BTR	R16,R16	386	BTR R16, R16	Bit Test and Reset	BTR.html
BTR	MEM,R32	386	BTR MEM, R32	Bit Test and Reset	BTR.html
BTR	R32,R32	386	BTR R32, R32	Bit Test and Reset	BTR.html
BTR	MEM,R64	X64	BTR MEM, r64	Bit Test and Reset	BTR.html
BTR	R64,R64	X64	BTR r64, r64	Bit Test and Reset	BTR.html
BTR	R/M16,IMM	386	BTR r/m16, IMM	Bit Test and Reset	BTR.html
BTR	R/M32,IMM	386	BTR R/M32, IMM	Bit Test and Reset	BTR.html
BTR	R/M64,IMM	X64	BTR r/m64, IMM	Bit Test and Reset	BTR.html
BTS	MEM,R16	386	BTS MEM, R16	Bit Test and Set	BTS.html
BTS	R16,R16	386	BTS R16, R16	Bit Test and Set	BTS.html
BTS	MEM,R32	386	BTS MEM, R32	Bit Test and Set	BTS.html
BTS	R32,R32	386	BTS R32, R32	Bit Test and Set	BTS.html
BTS	MEM,R64	X64	BTS MEM, r64	Bit Test and Set	BTS.html
BTS	R64,R64	X64	BTS r64, r64	Bit Test and Set	BTS.html
BTS	R/M16,IMM	386	BTS r/m16, IMM	Bit Test and Set	BTS.html
BTS	R/M32,IMM	386	BTS R/M32, IMM	Bit Test and Set	BTS.html
BTS	R/M64,IMM	X64	BTS r/m64, IMM	Bit Test and Set	BTS.html
CALL	IMM	8086,BND	CALL IMM	Call Procedure	CALL.html
CALL	IMM|NEAR	8086,BND	CALL IMM|NEAR	Call Procedure	CALL.html
CALL	IMM|far	8086	CALL IMM|far	Call Procedure	CALL.html
CALL	IMM16	8086,BND	CALL IMM16	Call Procedure	CALL.html
CALL	IMM16|NEAR	8086,BND	CALL IMM16|NEAR	Call Procedure	CALL.html
CALL	IMM16|far	8086	CALL IMM16|far	Call Procedure	CALL.html
CALL	IMM32	386,BND	CALL IMM32	Call Procedure	CALL.html
CALL	IMM32|NEAR	386,BND	CALL IMM32|NEAR	Call Procedure	CALL.html
CALL	IMM32|far	386	CALL IMM32|far	Call Procedure	CALL.html
CALL	IMM64	X64,BND	CALL IMM64	Call Procedure	CALL.html
CALL	IMM64|NEAR	X64,BND	CALL IMM64|NEAR	Call Procedure	CALL.html
CALL	IMM:IMM	8086	CALL IMM:IMM	Call Procedure	CALL.html
CALL	IMM16:IMM	8086	CALL IMM16:IMM	Call Procedure	CALL.html
CALL	IMM:IMM16	8086	CALL IMM:IMM16	Call Procedure	CALL.html
CALL	IMM32:IMM	386	CALL IMM32:IMM	Call Procedure	CALL.html
CALL	IMM:IMM32	386	CALL IMM:IMM32	Call Procedure	CALL.html
CALL	MEM|far	8086	CALL MEM|far	Call Procedure	CALL.html
CALL	MEM|far	X64	CALL MEM|far	Call Procedure	CALL.html
CALL	M16|far	8086	CALL M16|far	Call Procedure	CALL.html
CALL	M32|far	386	CALL M32|far	Call Procedure	CALL.html
CALL	M64|far	X64	CALL M64|far	Call Procedure	CALL.html
CALL	MEM|NEAR	8086,BND	CALL MEM|NEAR	Call Procedure	CALL.html
CALL	R/M16|NEAR	8086,BND	CALL r/m16|NEAR	Call Procedure	CALL.html
CALL	R/M32|NEAR	386,BND	CALL R/M32|NEAR	Call Procedure	CALL.html
CALL	R/M64|NEAR	X64,BND	CALL r/m64|NEAR	Call Procedure	CALL.html
CALL	MEM	8086,BND	CALL MEM	Call Procedure	CALL.html
CALL	R/M16	8086,BND	CALL r/m16	Call Procedure	CALL.html
CALL	R/M32	386,BND	CALL R/M32	Call Procedure	CALL.html
CALL	R/M64	X64,BND	CALL r/m64	Call Procedure	CALL.html
CBW		8086	CBW 	Convert Byte to Word	CBW:CWDE:CDQE.html
CDQ		386	CDQ 	Convert Word to Doubleword/Convert Doubleword to Quadword	CWD:CDQ:CQO.html
CDQE		X64	CDQE 	Convert Doubleword to Quadword	CBW:CWDE:CDQE.html
CLC		8086	CLC 	Clear Carry Flag	CLC.html
CLD		8086	CLD 	Clear Direction Flag	CLD.html
CLI		8086	CLI 	Clear Interrupt Flag	CLI.html
CLTS		286	CLTS 	Clear Task-Switched Flag in CR0	CLTS.html
CMC		8086	CMC 	Complement Carry Flag	CMC.html
CMP	MEM,R8	8086	CMP MEM, R8	Compare Two Operands	CMP.html
CMP	R8,R8	8086	CMP R8, R8	Compare Two Operands	CMP.html
CMP	MEM,R16	8086	CMP MEM, R16	Compare Two Operands	CMP.html
CMP	R16,R16	8086	CMP R16, R16	Compare Two Operands	CMP.html
CMP	MEM,R32	386	CMP MEM, R32	Compare Two Operands	CMP.html
CMP	R32,R32	386	CMP R32, R32	Compare Two Operands	CMP.html
CMP	MEM,R64	X64	CMP MEM, r64	Compare Two Operands	CMP.html
CMP	R64,R64	X64	CMP r64, r64	Compare Two Operands	CMP.html
CMP	R8,MEM	8086	CMP R8, MEM	Compare Two Operands	CMP.html
CMP	R8,R8	8086	CMP R8, R8	Compare Two Operands	CMP.html
CMP	R16,MEM	8086	CMP R16, MEM	Compare Two Operands	CMP.html
CMP	R16,R16	8086	CMP R16, R16	Compare Two Operands	CMP.html
CMP	R32,MEM	386	CMP R32, MEM	Compare Two Operands	CMP.html
CMP	R32,R32	386	CMP R32, R32	Compare Two Operands	CMP.html
CMP	R64,MEM	X64	CMP r64, MEM	Compare Two Operands	CMP.html
CMP	R64,R64	X64	CMP r64, r64	Compare Two Operands	CMP.html
CMP	R/M16,IMM8	8086	CMP r/m16, IMM8	Compare Two Operands	CMP.html
CMP	R/M32,IMM8	386	CMP R/M32, IMM8	Compare Two Operands	CMP.html
CMP	R/M64,IMM8	X64	CMP r/m64, IMM8	Compare Two Operands	CMP.html
CMP	AL,IMM	8086	CMP AL, IMM	Compare Two Operands	CMP.html
CMP	AX,IMM	8086	CMP AX, IMM	Compare Two Operands	CMP.html
CMP	EAX,IMM	386	CMP EAX, IMM	Compare Two Operands	CMP.html
CMP	RAX,IMM	X64	CMP RAX, IMM	Compare Two Operands	CMP.html
CMP	R/M8,IMM	8086	CMP r/m8, IMM	Compare Two Operands	CMP.html
CMP	R/M16,IMM	8086	CMP r/m16, IMM	Compare Two Operands	CMP.html
CMP	R/M32,IMM	386	CMP R/M32, IMM	Compare Two Operands	CMP.html
CMP	R/M64,IMM	X64	CMP r/m64, IMM	Compare Two Operands	CMP.html
CMP	MEM,IMM8	8086	CMP MEM, IMM8	Compare Two Operands	CMP.html
CMP	MEM,IMM16	8086	CMP MEM, IMM16	Compare Two Operands	CMP.html
CMP	MEM,IMM32	386	CMP MEM, IMM32	Compare Two Operands	CMP.html
CMP	R/M8,IMM	8086	CMP r/m8, IMM	Compare Two Operands	CMP.html
CMPSB		8086	CMPSB 	Compare String Operands	CMPS:CMPSB:CMPSW:CMPSD:CMPSQ.html
CMPSD		386	CMPSD 	Compare String Operands	CMPSD.html
CMPSD	XMM,XMM/M128,IMM8	SSE2	CMPSD XMM, XMM/M128, IMM8	Compare String Operands	CMPSD.html
CMPSQ		X64	CMPSQ 	Compare String Operands	CMPS:CMPSB:CMPSW:CMPSD:CMPSQ.html
CMPSW		8086	CMPSW 	Compare String Operands	CMPS:CMPSB:CMPSW:CMPSD:CMPSQ.html
CMPXCHG	MEM,R8	PENT	CMPXCHG MEM, R8	TODO: PENT,X64	
CMPXCHG	R8,R8	PENT	CMPXCHG R8, R8	TODO: PENT,X64	
CMPXCHG	MEM,R16	PENT	CMPXCHG MEM, R16	TODO: PENT,X64	
CMPXCHG	R16,R16	PENT	CMPXCHG R16, R16	TODO: PENT,X64	
CMPXCHG	MEM,R32	PENT	CMPXCHG MEM, R32	TODO: PENT,X64	
CMPXCHG	R32,R32	PENT	CMPXCHG R32, R32	TODO: PENT,X64	
CMPXCHG	MEM,R64	X64	CMPXCHG MEM, r64	TODO: PENT,X64	
CMPXCHG	R64,R64	X64	CMPXCHG r64, r64	TODO: PENT,X64	
CMPXCHG486	MEM,R8	486,UNDOC	CMPXCHG486 MEM, R8	TODO: 486,UNDOC	
CMPXCHG486	R8,R8	486,UNDOC	CMPXCHG486 R8, R8	TODO: 486,UNDOC	
CMPXCHG486	MEM,R16	486,UNDOC	CMPXCHG486 MEM, R16	TODO: 486,UNDOC	
CMPXCHG486	R16,R16	486,UNDOC	CMPXCHG486 R16, R16	TODO: 486,UNDOC	
CMPXCHG486	MEM,R32	486,UNDOC	CMPXCHG486 MEM, R32	TODO: 486,UNDOC	
CMPXCHG486	R32,R32	486,UNDOC	CMPXCHG486 R32, R32	TODO: 486,UNDOC	
CMPXCHG8B	MEM	PENT	CMPXCHG8B MEM	Compare EDX:EAX with m64. If equal, set ZF and load ECX:EBX into m64. Else, clear ZF and load m64 into EDX:EAX	CMPXCHG8B:CMPXCHG16B.html
CMPXCHG16B	MEM	X64	CMPXCHG16B MEM	Compare RDX:RAX with M128. If equal, set ZF and load RCX:RBX into M128. Else, clear ZF and load M128 into RDX:RAX	CMPXCHG8B:CMPXCHG16B.html
CPUID		PENT	CPUID 	CPU Identification	CPUID.html
CPU_READ		PENT,CYRIX	CPU_READ 	TODO: PENT,CYRIX	
CPU_WRITE		PENT,CYRIX	CPU_WRITE 	TODO: PENT,CYRIX	
CQO		X64	CQO 	Convert Word to Doubleword/Convert Doubleword to Quadword	CWD:CDQ:CQO.html
CWD		8086	CWD 	Convert Word to Doubleword/Convert Doubleword to Quadword	CWD:CDQ:CQO.html
CWDE		386	CWDE 	Convert Word to Doubleword	CBW:CWDE:CDQE.html
DAA		8086	DAA 	Decimal Adjust AL after Addition	DAA.html
DAS		8086	DAS 	Decimal Adjust AL after Subtraction	DAS.html
DEC	R16	8086	DEC R16	Decrement by 1	DEC.html
DEC	R32	386	DEC R32	Decrement by 1	DEC.html
DEC	R/M8	8086	DEC r/m8	Decrement by 1	DEC.html
DEC	R/M16	8086	DEC r/m16	Decrement by 1	DEC.html
DEC	R/M32	386	DEC R/M32	Decrement by 1	DEC.html
DEC	R/M64	X64	DEC r/m64	Decrement by 1	DEC.html
DIV	R/M8	8086	DIV r/m8	Unsigned Divide	DIV.html
DIV	R/M16	8086	DIV r/m16	Unsigned Divide	DIV.html
DIV	R/M32	386	DIV R/M32	Unsigned Divide	DIV.html
DIV	R/M64	X64	DIV r/m64	Unsigned Divide	DIV.html
DMINT		P6,CYRIX	DMINT 	TODO: P6,CYRIX	
EMMS		PENT,MM	EMMS 	Empty MM Technology State	EMMS.html
ENTER	IMM,IMM	186	ENTER IMM, IMM	Make Stack Frame for Procedure Parameters	ENTER.html
EQU	IMM	8086	EQU IMM	MASM: The first directive assigns numeric value of expression to name.	
EQU	IMM:IMM	8086	EQU IMM:IMM	MASM: The first directive assigns numeric value of expression to name.	
F2XM1		8086	F2XM1 	Compute 2x–1	F2XM1.html
FABS		8086	FABS 	Absolute Value	FABS.html
FADD	M32	8086	FADD M32	Add	FADD:FADDP:FIADD.html
FADD	M64	8086	FADD M64	Add	FADD:FADDP:FIADD.html
FADD	FPUREG|to	8086	FADD FPUREG|to	Add	FADD:FADDP:FIADD.html
FADD	FPUREG	8086	FADD FPUREG	Add	FADD:FADDP:FIADD.html
FADD	FPUREG0	8086	FADD FPUREG, FPU0	Add	FADD:FADDP:FIADD.html
FADD	FPU0REG	8086	FADD FPU0, FPUREG	Add	FADD:FADDP:FIADD.html
FADD		8086	FADD 	Add	FADD:FADDP:FIADD.html
FADDP	FPUREG	8086	FADDP FPUREG	Add	FADD:FADDP:FIADD.html
FADDP	FPUREG0	8086	FADDP FPUREG, FPU0	Add	FADD:FADDP:FIADD.html
FADDP		8086	FADDP 	Add	FADD:FADDP:FIADD.html
FBLD	M80	8086	FBLD M80	Load Binary Coded Decimal	FBLD.html
FBLD	MEM	8086	FBLD MEM	Load Binary Coded Decimal	FBLD.html
FBSTP	M80	8086	FBSTP M80	Store BCD Integer and Pop	FBSTP.html
FBSTP	MEM	8086	FBSTP MEM	Store BCD Integer and Pop	FBSTP.html
FCHS		8086	FCHS 	Change Sign	FCHS.html
FCLEX		8086	FCLEX 	Clear Exceptions	FCLEX:FNCLEX.html
FCMOVB	FPUREG	P6	FCMOVB FPUREG	Move Floating-Point if below (CF=1)	FCMOVcc.html
FCMOVB	FPU0REG	P6	FCMOVB FPU0, FPUREG	Move Floating-Point if below (CF=1)	FCMOVcc.html
FCMOVB		P6	FCMOVB 	Move Floating-Point if below (CF=1)	FCMOVcc.html
FCMOVBE	FPUREG	P6	FCMOVBE FPUREG	Move Floating-Point if below or equal (CF=1 OR ZF=1)	FCMOVcc.html
FCMOVBE	FPU0REG	P6	FCMOVBE FPU0, FPUREG	Move Floating-Point if below or equal (CF=1 OR ZF=1)	FCMOVcc.html
FCMOVBE		P6	FCMOVBE 	Move Floating-Point if below or equal (CF=1 OR ZF=1)	FCMOVcc.html
FCMOVE	FPUREG	P6	FCMOVE FPUREG	Move Floating-Point if equal (ZF=1)	FCMOVcc.html
FCMOVE	FPU0REG	P6	FCMOVE FPU0, FPUREG	Move Floating-Point if equal (ZF=1)	FCMOVcc.html
FCMOVE		P6	FCMOVE 	Move Floating-Point if equal (ZF=1)	FCMOVcc.html
FCMOVNB	FPUREG	P6	FCMOVNB FPUREG	Move Floating-Point if not below (CF=0)	FCMOVcc.html
FCMOVNB	FPU0REG	P6	FCMOVNB FPU0, FPUREG	Move Floating-Point if not below (CF=0)	FCMOVcc.html
FCMOVNB		P6	FCMOVNB 	Move Floating-Point if not below (CF=0)	FCMOVcc.html
FCMOVNBE	FPUREG	P6	FCMOVNBE FPUREG	Move Floating-Point if not below or equal (CF=0 AND ZF=0)	FCMOVcc.html
FCMOVNBE	FPU0REG	P6	FCMOVNBE FPU0, FPUREG	Move Floating-Point if not below or equal (CF=0 AND ZF=0)	FCMOVcc.html
FCMOVNBE		P6	FCMOVNBE 	Move Floating-Point if not below or equal (CF=0 AND ZF=0)	FCMOVcc.html
FCMOVNE	FPUREG	P6	FCMOVNE FPUREG	Move Floating-Point if not equal (ZF=0)	FCMOVcc.html
FCMOVNE	FPU0REG	P6	FCMOVNE FPU0, FPUREG	Move Floating-Point if not equal (ZF=0)	FCMOVcc.html
FCMOVNE		P6	FCMOVNE 	Move Floating-Point if not equal (ZF=0)	FCMOVcc.html
FCMOVNU	FPUREG	P6	FCMOVNU FPUREG	Move Floating-Point if not unordered (PF=0)	FCMOVcc.html
FCMOVNU	FPU0REG	P6	FCMOVNU FPU0, FPUREG	Move Floating-Point if not unordered (PF=0)	FCMOVcc.html
FCMOVNU		P6	FCMOVNU 	Move Floating-Point if not unordered (PF=0)	FCMOVcc.html
FCMOVU	FPUREG	P6	FCMOVU FPUREG	Move Floating-Point if unordered (PF=1)	FCMOVcc.html
FCMOVU	FPU0REG	P6	FCMOVU FPU0, FPUREG	Move Floating-Point if unordered (PF=1)	FCMOVcc.html
FCMOVU		P6	FCMOVU 	Move Floating-Point if unordered (PF=1)	FCMOVcc.html
FCOM	M32	8086	FCOM M32	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOM	M64	8086	FCOM M64	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOM	FPUREG	8086	FCOM FPUREG	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOM	FPU0REG	8086	FCOM FPU0, FPUREG	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOM		8086	FCOM 	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMI	FPUREG	P6	FCOMI FPUREG	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMI	FPU0REG	P6	FCOMI FPU0, FPUREG	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMI		P6	FCOMI 	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMIP	FPUREG	P6	FCOMIP FPUREG	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMIP	FPU0REG	P6	FCOMIP FPU0, FPUREG	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMIP		P6	FCOMIP 	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMP	M32	8086	FCOMP M32	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMP	M64	8086	FCOMP M64	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMP	FPUREG	8086	FCOMP FPUREG	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMP	FPU0REG	8086	FCOMP FPU0, FPUREG	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMP		8086	FCOMP 	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMPP		8086	FCOMPP 	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOS		386	FCOS 	Cosine	FCOS.html
FDECSTP		8086	FDECSTP 	Decrement Stack-Top Pointer	FDECSTP.html
FDISI		8086	FDISI 	TODO: 8086	
FDIV	M32	8086	FDIV M32	Divide	FDIV:FDIVP:FIDIV.html
FDIV	M64	8086	FDIV M64	Divide	FDIV:FDIVP:FIDIV.html
FDIV	FPUREG|to	8086	FDIV FPUREG|to	Divide	FDIV:FDIVP:FIDIV.html
FDIV	FPUREG	8086	FDIV FPUREG	Divide	FDIV:FDIVP:FIDIV.html
FDIV	FPUREG0	8086	FDIV FPUREG, FPU0	Divide	FDIV:FDIVP:FIDIV.html
FDIV	FPU0REG	8086	FDIV FPU0, FPUREG	Divide	FDIV:FDIVP:FIDIV.html
FDIV		8086	FDIV 	Divide	FDIV:FDIVP:FIDIV.html
FDIVP	FPUREG	8086	FDIVP FPUREG	Divide	FDIV:FDIVP:FIDIV.html
FDIVP	FPUREG0	8086	FDIVP FPUREG, FPU0	Divide	FDIV:FDIVP:FIDIV.html
FDIVP		8086	FDIVP 	Divide	FDIV:FDIVP:FIDIV.html
FDIVR	M32	8086	FDIVR M32	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	M64	8086	FDIVR M64	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	FPUREG|to	8086	FDIVR FPUREG|to	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	FPUREG0	8086	FDIVR FPUREG, FPU0	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	FPUREG	8086	FDIVR FPUREG	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	FPU0REG	8086	FDIVR FPU0, FPUREG	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR		8086	FDIVR 	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVRP	FPUREG	8086	FDIVRP FPUREG	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVRP	FPUREG0	8086	FDIVRP FPUREG, FPU0	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVRP		8086	FDIVRP 	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FEMMS		PENT,3DNOW	FEMMS 	TODO: PENT,3DNOW	
FENI		8086	FENI 	TODO: 8086	
FFREE	FPUREG	8086	FFREE FPUREG	Free Floating-Point Register	FFREE.html
FFREE		8086	FFREE 	Free Floating-Point Register	FFREE.html
FFREEP	FPUREG	286,UNDOC	FFREEP FPUREG	TODO: 286,UNDOC	
FFREEP		286,UNDOC	FFREEP 	TODO: 286,UNDOC	
FIADD	M32	8086	FIADD M32	Add	FADD:FADDP:FIADD.html
FIADD	M16	8086	FIADD M16	Add	FADD:FADDP:FIADD.html
FICOM	M32	8086	FICOM M32	Compare Integer	FICOM:FICOMP.html
FICOM	M16	8086	FICOM M16	Compare Integer	FICOM:FICOMP.html
FICOMP	M32	8086	FICOMP M32	Compare Integer	FICOM:FICOMP.html
FICOMP	M16	8086	FICOMP M16	Compare Integer	FICOM:FICOMP.html
FIDIV	M32	8086	FIDIV M32	Divide	FDIV:FDIVP:FIDIV.html
FIDIV	M16	8086	FIDIV M16	Divide	FDIV:FDIVP:FIDIV.html
FIDIVR	M32	8086	FIDIVR M32	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FIDIVR	M16	8086	FIDIVR M16	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FILD	M32	8086	FILD M32	Load Integer	FILD.html
FILD	M16	8086	FILD M16	Load Integer	FILD.html
FILD	M64	8086	FILD M64	Load Integer	FILD.html
FIMUL	M32	8086	FIMUL M32	Multiply	FMUL:FMULP:FIMUL.html
FIMUL	M16	8086	FIMUL M16	Multiply	FMUL:FMULP:FIMUL.html
FINCSTP		8086	FINCSTP 	Increment Stack-Top Pointer	FINCSTP.html
FINIT		8086	FINIT 	Initialize Floating-Point Unit	FINIT:FNINIT.html
FIST	M32	8086	FIST M32	Store Integer	FIST:FISTP.html
FIST	M16	8086	FIST M16	Store Integer	FIST:FISTP.html
FISTP	M32	8086	FISTP M32	Store Integer	FIST:FISTP.html
FISTP	M16	8086	FISTP M16	Store Integer	FIST:FISTP.html
FISTP	M64	8086	FISTP M64	Store Integer	FIST:FISTP.html
FISTTP	M16	PRESCOTT	FISTTP M16	Store Integer with Truncation	FISTTP.html
FISTTP	M32	PRESCOTT	FISTTP M32	Store Integer with Truncation	FISTTP.html
FISTTP	M64	PRESCOTT	FISTTP M64	Store Integer with Truncation	FISTTP.html
FISUB	M32	8086	FISUB M32	Subtract	FSUB:FSUBP:FISUB.html
FISUB	M16	8086	FISUB M16	Subtract	FSUB:FSUBP:FISUB.html
FISUBR	M32	8086	FISUBR M32	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FISUBR	M16	8086	FISUBR M16	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FLD	M32	8086	FLD M32	Load Floating Point Value	FLD.html
FLD	M64	8086	FLD M64	Load Floating Point Value	FLD.html
FLD	M80	8086	FLD M80	Load Floating Point Value	FLD.html
FLD	FPUREG	8086	FLD FPUREG	Load Floating Point Value	FLD.html
FLD		8086	FLD 	Load Floating Point Value	FLD.html
FLD1		8086	FLD1 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDCW	MEM	8086	FLDCW MEM	Load x87 FPU Control Word	FLDCW.html
FLDENV	MEM	8086	FLDENV MEM	Load x87 FPU Environment	FLDENV.html
FLDL2E		8086	FLDL2E 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDL2T		8086	FLDL2T 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDLG2		8086	FLDLG2 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDLN2		8086	FLDLN2 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDPI		8086	FLDPI 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDZ		8086	FLDZ 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FMUL	M32	8086	FMUL M32	Multiply	FMUL:FMULP:FIMUL.html
FMUL	M64	8086	FMUL M64	Multiply	FMUL:FMULP:FIMUL.html
FMUL	FPUREG|to	8086	FMUL FPUREG|to	Multiply	FMUL:FMULP:FIMUL.html
FMUL	FPUREG0	8086	FMUL FPUREG, FPU0	Multiply	FMUL:FMULP:FIMUL.html
FMUL	FPUREG	8086	FMUL FPUREG	Multiply	FMUL:FMULP:FIMUL.html
FMUL	FPU0REG	8086	FMUL FPU0, FPUREG	Multiply	FMUL:FMULP:FIMUL.html
FMUL		8086	FMUL 	Multiply	FMUL:FMULP:FIMUL.html
FMULP	FPUREG	8086	FMULP FPUREG	Multiply	FMUL:FMULP:FIMUL.html
FMULP	FPUREG0	8086	FMULP FPUREG, FPU0	Multiply	FMUL:FMULP:FIMUL.html
FMULP		8086	FMULP 	Multiply	FMUL:FMULP:FIMUL.html
FNCLEX		8086	FNCLEX 	Clear Exceptions	FCLEX:FNCLEX.html
FNDISI		8086	FNDISI 	TODO: 8086	
FNENI		8086	FNENI 	TODO: 8086	
FNINIT		8086	FNINIT 	Initialize Floating-Point Unit	FINIT:FNINIT.html
FNOP		8086	FNOP 	No Operation	FNOP.html
FNSAVE	MEM	8086	FNSAVE MEM	Store x87 FPU State	FSAVE:FNSAVE.html
FNSTCW	MEM	8086	FNSTCW MEM	Store x87 FPU Control Word	FSTCW:FNSTCW.html
FNSTENV	MEM	8086	FNSTENV MEM	Store x87 FPU Environment	FSTENV:FNSTENV.html
FNSTSW	MEM	8086	FNSTSW MEM	Store x87 FPU Status Word	FSTSW:FNSTSW.html
FNSTSW	AX	286	FNSTSW AX	Store x87 FPU Status Word	FSTSW:FNSTSW.html
FPATAN		8086	FPATAN 	Partial Arctangent	FPATAN.html
FPREM		8086	FPREM 	Partial Remainder	FPREM.html
FPREM1		386	FPREM1 	Partial Remainder	FPREM1.html
FPTAN		8086	FPTAN 	Partial Tangent	FPTAN.html
FRNDINT		8086	FRNDINT 	Round to Integer	FRNDINT.html
FRSTOR	MEM	8086	FRSTOR MEM	Restore x87 FPU State	FRSTOR.html
FSAVE	MEM	8086	FSAVE MEM	Store x87 FPU State	FSAVE:FNSAVE.html
FSCALE		8086	FSCALE 	Scale	FSCALE.html
FSETPM		286	FSETPM 	TODO: 286	
FSIN		386	FSIN 	Sine	FSIN.html
FSINCOS		386	FSINCOS 	Sine and Cosine	FSINCOS.html
FSQRT		8086	FSQRT 	Square Root	FSQRT.html
FST	M32	8086	FST M32	Store Floating Point Value	FST:FSTP.html
FST	M64	8086	FST M64	Store Floating Point Value	FST:FSTP.html
FST	FPUREG	8086	FST FPUREG	Store Floating Point Value	FST:FSTP.html
FST		8086	FST 	Store Floating Point Value	FST:FSTP.html
FSTCW	MEM	8086	FSTCW MEM	Store x87 FPU Control Word	FSTCW:FNSTCW.html
FSTENV	MEM	8086	FSTENV MEM	Store x87 FPU Environment	FSTENV:FNSTENV.html
FSTP	M32	8086	FSTP M32	Store Floating Point Value	FST:FSTP.html
FSTP	M64	8086	FSTP M64	Store Floating Point Value	FST:FSTP.html
FSTP	M80	8086	FSTP M80	Store Floating Point Value	FST:FSTP.html
FSTP	FPUREG	8086	FSTP FPUREG	Store Floating Point Value	FST:FSTP.html
FSTP		8086	FSTP 	Store Floating Point Value	FST:FSTP.html
FSTSW	MEM	8086	FSTSW MEM	Store x87 FPU Status Word	FSTSW:FNSTSW.html
FSTSW	AX	286	FSTSW AX	Store x87 FPU Status Word	FSTSW:FNSTSW.html
FSUB	M32	8086	FSUB M32	Subtract	FSUB:FSUBP:FISUB.html
FSUB	M64	8086	FSUB M64	Subtract	FSUB:FSUBP:FISUB.html
FSUB	FPUREG|to	8086	FSUB FPUREG|to	Subtract	FSUB:FSUBP:FISUB.html
FSUB	FPUREG0	8086	FSUB FPUREG, FPU0	Subtract	FSUB:FSUBP:FISUB.html
FSUB	FPUREG	8086	FSUB FPUREG	Subtract	FSUB:FSUBP:FISUB.html
FSUB	FPU0REG	8086	FSUB FPU0, FPUREG	Subtract	FSUB:FSUBP:FISUB.html
FSUB		8086	FSUB 	Subtract	FSUB:FSUBP:FISUB.html
FSUBP	FPUREG	8086	FSUBP FPUREG	Subtract	FSUB:FSUBP:FISUB.html
FSUBP	FPUREG0	8086	FSUBP FPUREG, FPU0	Subtract	FSUB:FSUBP:FISUB.html
FSUBP		8086	FSUBP 	Subtract	FSUB:FSUBP:FISUB.html
FSUBR	M32	8086	FSUBR M32	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	M64	8086	FSUBR M64	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	FPUREG|to	8086	FSUBR FPUREG|to	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	FPUREG0	8086	FSUBR FPUREG, FPU0	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	FPUREG	8086	FSUBR FPUREG	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	FPU0REG	8086	FSUBR FPU0, FPUREG	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR		8086	FSUBR 	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBRP	FPUREG	8086	FSUBRP FPUREG	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBRP	FPUREG0	8086	FSUBRP FPUREG, FPU0	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBRP		8086	FSUBRP 	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FTST		8086	FTST 	TEST	FTST.html
FUCOM	FPUREG	386	FUCOM FPUREG	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOM	FPU0REG	386	FUCOM FPU0, FPUREG	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOM		386	FUCOM 	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOMI	FPUREG	P6	FUCOMI FPUREG	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMI	FPU0REG	P6	FUCOMI FPU0, FPUREG	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMI		P6	FUCOMI 	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMIP	FPUREG	P6	FUCOMIP FPUREG	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMIP	FPU0REG	P6	FUCOMIP FPU0, FPUREG	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMIP		P6	FUCOMIP 	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMP	FPUREG	386	FUCOMP FPUREG	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOMP	FPU0REG	386	FUCOMP FPU0, FPUREG	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOMP		386	FUCOMP 	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOMPP		386	FUCOMPP 	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FXAM		8086	FXAM 	Examine ModR/M	FXAM.html
FXCH	FPUREG	8086	FXCH FPUREG	Exchange Register Contents	FXCH.html
FXCH	FPUREG0	8086	FXCH FPUREG, FPU0	Exchange Register Contents	FXCH.html
FXCH	FPU0REG	8086	FXCH FPU0, FPUREG	Exchange Register Contents	FXCH.html
FXCH		8086	FXCH 	Exchange Register Contents	FXCH.html
FXTRACT		8086	FXTRACT 	Extract Exponent and Significand	FXTRACT.html
FYL2X		8086	FYL2X 	Compute y  log2x	FYL2X.html
FYL2XP1		8086	FYL2XP1 	Compute y  log2(x +1)	FYL2XP1.html
HLT		8086	HLT 	Halt	HLT.html
IBTS	MEM,R16	386,UNDOC	IBTS MEM, R16	TODO: 386,UNDOC,SD	
IBTS	R16,R16	386,UNDOC	IBTS R16, R16	TODO: 386,UNDOC,SD	
IBTS	MEM,R32	386,SD,UNDOC	IBTS MEM, R32	TODO: 386,UNDOC,SD	
IBTS	R32,R32	386,UNDOC	IBTS R32, R32	TODO: 386,UNDOC,SD	
ICEBP		386	ICEBP 	TODO: 386	
IDIV	R/M8	8086	IDIV r/m8	Signed Divide	IDIV.html
IDIV	R/M16	8086	IDIV r/m16	Signed Divide	IDIV.html
IDIV	R/M32	386	IDIV R/M32	Signed Divide	IDIV.html
IDIV	R/M64	X64	IDIV r/m64	Signed Divide	IDIV.html
IMUL	R/M8	8086	IMUL r/m8	Signed Multiply	IMUL.html
IMUL	R/M16	8086	IMUL r/m16	Signed Multiply	IMUL.html
IMUL	R/M32	386	IMUL R/M32	Signed Multiply	IMUL.html
IMUL	R/M64	X64	IMUL r/m64	Signed Multiply	IMUL.html
IMUL	R16,MEM	386	IMUL R16, MEM	Signed Multiply	IMUL.html
IMUL	R16,R16	386	IMUL R16, R16	Signed Multiply	IMUL.html
IMUL	R32,MEM	386	IMUL R32, MEM	Signed Multiply	IMUL.html
IMUL	R32,R32	386	IMUL R32, R32	Signed Multiply	IMUL.html
IMUL	R64,MEM	X64	IMUL r64, MEM	Signed Multiply	IMUL.html
IMUL	R64,R64	X64	IMUL r64, r64	Signed Multiply	IMUL.html
IMUL	R16,MEM,IMM8	186	IMUL R16, MEM, IMM8	Signed Multiply	IMUL.html
IMUL	R16,MEM,IMM16	186	IMUL R16, MEM, IMM16	Signed Multiply	IMUL.html
IMUL	R16,MEM,IMM	186	IMUL R16, MEM, IMM	Signed Multiply	IMUL.html
IMUL	R16,R16,IMM8	186	IMUL R16, R16, IMM8	Signed Multiply	IMUL.html
IMUL	R16,R16,IMM16	186	IMUL R16, R16, IMM16	Signed Multiply	IMUL.html
IMUL	R16,R16,IMM	186	IMUL R16, R16, IMM	Signed Multiply	IMUL.html
IMUL	R32,MEM,IMM8	386	IMUL R32, MEM, IMM8	Signed Multiply	IMUL.html
IMUL	R32,MEM,IMM32	386	IMUL R32, MEM, IMM32	Signed Multiply	IMUL.html
IMUL	R32,MEM,IMM	386	IMUL R32, MEM, IMM	Signed Multiply	IMUL.html
IMUL	R32,R32,IMM8	386	IMUL R32, R32, IMM8	Signed Multiply	IMUL.html
IMUL	R32,R32,IMM32	386	IMUL R32, R32, IMM32	Signed Multiply	IMUL.html
IMUL	R32,R32,IMM	386	IMUL R32, R32, IMM	Signed Multiply	IMUL.html
IMUL	R64,MEM,IMM8	X64	IMUL r64, MEM, IMM8	Signed Multiply	IMUL.html
IMUL	R64,MEM,IMM32	X64	IMUL r64, MEM, IMM32	Signed Multiply	IMUL.html
IMUL	R64,MEM,IMM	X64	IMUL r64, MEM, IMM	Signed Multiply	IMUL.html
IMUL	R64,R64,IMM8	X64	IMUL r64, r64, IMM8	Signed Multiply	IMUL.html
IMUL	R64,R64,IMM32	X64	IMUL r64, r64, IMM32	Signed Multiply	IMUL.html
IMUL	R64,R64,IMM	X64	IMUL r64, r64, IMM	Signed Multiply	IMUL.html
IMUL	R16,IMM8	186	IMUL R16, IMM8	Signed Multiply	IMUL.html
IMUL	R16,IMM16	186	IMUL R16, IMM16	Signed Multiply	IMUL.html
IMUL	R16,IMM	186	IMUL R16, IMM	Signed Multiply	IMUL.html
IMUL	R32,IMM8	386	IMUL R32, IMM8	Signed Multiply	IMUL.html
IMUL	R32,IMM32	386	IMUL R32, IMM32	Signed Multiply	IMUL.html
IMUL	R32,IMM	386	IMUL R32, IMM	Signed Multiply	IMUL.html
IMUL	R64,IMM8	X64	IMUL r64, IMM8	Signed Multiply	IMUL.html
IMUL	R64,IMM32	X64	IMUL r64, IMM32	Signed Multiply	IMUL.html
IMUL	R64,IMM	X64	IMUL r64, IMM	Signed Multiply	IMUL.html
IN	AL,IMM	8086	IN AL, IMM	Input from Port	IN.html
IN	AX,IMM	8086	IN AX, IMM	Input from Port	IN.html
IN	EAX,IMM	386	IN EAX, IMM	Input from Port	IN.html
IN	AL,DX	8086	IN AL, DX	Input from Port	IN.html
IN	AX,DX	8086	IN AX, DX	Input from Port	IN.html
IN	EAX,DX	386	IN EAX, DX	Input from Port	IN.html
INC	R16	8086	INC R16	Increment by 1	INC.html
INC	R32	386	INC R32	Increment by 1	INC.html
INC	R/M8	8086	INC r/m8	Increment by 1	INC.html
INC	R/M16	8086	INC r/m16	Increment by 1	INC.html
INC	R/M32	386	INC R/M32	Increment by 1	INC.html
INC	R/M64	X64	INC r/m64	Increment by 1	INC.html
INSB		186	INSB 	Input from Port to String	INS:INSB:INSW:INSD.html
INSD		386	INSD 	Input from Port to String	INS:INSB:INSW:INSD.html
INSW		186	INSW 	Input from Port to String	INS:INSB:INSW:INSD.html
INT	IMM	8086	INT IMM	Call to Interrupt Procedure	INT n:INTO:INT 3.html
INTO		8086	INTO 	Call to Interrupt Procedure	INT n:INTO:INT 3.html
INVD		486	INVD 	Invalidate Internal Caches	INVD.html
INVPCID	R32,M128	FUTURE,INVPCID	INVPCID R32, M128	Invalidate Process-Context Identifier	INVPCID.html
INVPCID	R64,M128	FUTURE,INVPCID,LONG	INVPCID r64, M128	Invalidate Process-Context Identifier	INVPCID.html
INVLPG	MEM	486	INVLPG MEM	Invalidate TLB Entries	INVLPG.html
INVLPGA	AX,reg_ecx	X86_64,AMD	INVLPGA AX, ECX	TODO: X86_64,AMD,X64	
INVLPGA	EAX,reg_ecx	X86_64,AMD	INVLPGA EAX, ECX	TODO: X86_64,AMD,X64	
INVLPGA	RAX,reg_ecx	X64,AMD	INVLPGA RAX, ECX	TODO: X86_64,AMD,X64	
INVLPGA		X86_64,AMD	INVLPGA 	TODO: X86_64,AMD,X64	
IRET		8086	IRET 	Interrupt Return	IRET:IRETD.html
IRETD		386	IRETD 	Interrupt Return	IRET:IRETD.html
IRETQ		X64	IRETQ 	TODO: X64	
IRETW		8086	IRETW 	TODO: 8086	
JCXZ	IMM	8086	JCXZ IMM	Jump if CX register is 0	Jcc.html
JECXZ	IMM	386	JECXZ IMM	Jump if ECX register is 0	Jcc.html
JRCXZ	IMM	X64	JRCXZ IMM	Jump if RCX register is 0	Jcc.html
JMP	IMM|SHORT	8086	JMP IMM|SHORT	Unconditional Jump	Jcc.html
JMP	IMM	8086	JMP IMM	Unconditional Jump	Jcc.html
JMP	IMM	8086,BND	JMP IMM	Unconditional Jump	Jcc.html
JMP	IMM|NEAR	8086,BND	JMP IMM|NEAR	Unconditional Jump	Jcc.html
JMP	IMM|far	8086	JMP IMM|far	Unconditional Jump	Jcc.html
JMP	IMM16	8086,BND	JMP IMM16	Unconditional Jump	Jcc.html
JMP	IMM16|NEAR	8086,BND	JMP IMM16|NEAR	Unconditional Jump	Jcc.html
JMP	IMM16|far	8086	JMP IMM16|far	Unconditional Jump	Jcc.html
JMP	IMM32	386,BND	JMP IMM32	Unconditional Jump	Jcc.html
JMP	IMM32|NEAR	386,BND	JMP IMM32|NEAR	Unconditional Jump	Jcc.html
JMP	IMM32|far	386	JMP IMM32|far	Unconditional Jump	Jcc.html
JMP	IMM64	X64,BND	JMP IMM64	Unconditional Jump	Jcc.html
JMP	IMM64|NEAR	X64,BND	JMP IMM64|NEAR	Unconditional Jump	Jcc.html
JMP	IMM:IMM	8086	JMP IMM:IMM	Unconditional Jump	Jcc.html
JMP	IMM16:IMM	8086	JMP IMM16:IMM	Unconditional Jump	Jcc.html
JMP	IMM:IMM16	8086	JMP IMM:IMM16	Unconditional Jump	Jcc.html
JMP	IMM32:IMM	386	JMP IMM32:IMM	Unconditional Jump	Jcc.html
JMP	IMM:IMM32	386	JMP IMM:IMM32	Unconditional Jump	Jcc.html
JMP	MEM|far	8086	JMP MEM|far	Unconditional Jump	Jcc.html
JMP	MEM|far	X64	JMP MEM|far	Unconditional Jump	Jcc.html
JMP	M16|far	8086	JMP M16|far	Unconditional Jump	Jcc.html
JMP	M32|far	386	JMP M32|far	Unconditional Jump	Jcc.html
JMP	M64|far	X64	JMP M64|far	Unconditional Jump	Jcc.html
JMP	MEM|NEAR	8086,BND	JMP MEM|NEAR	Unconditional Jump	Jcc.html
JMP	R/M16|NEAR	8086,BND	JMP r/m16|NEAR	Unconditional Jump	Jcc.html
JMP	R/M32|NEAR	386,BND	JMP R/M32|NEAR	Unconditional Jump	Jcc.html
JMP	R/M64|NEAR	X64,BND	JMP r/m64|NEAR	Unconditional Jump	Jcc.html
JMP	MEM	8086,BND	JMP MEM	Unconditional Jump	Jcc.html
JMP	R/M16	8086,BND	JMP r/m16	Unconditional Jump	Jcc.html
JMP	R/M32	386,BND	JMP R/M32	Unconditional Jump	Jcc.html
JMP	R/M64	X64,BND	JMP r/m64	Unconditional Jump	Jcc.html
JMPE	IMM	IA64	JMPE IMM	TODO: IA64	
JMPE	IMM16	IA64	JMPE IMM16	TODO: IA64	
JMPE	IMM32	IA64	JMPE IMM32	TODO: IA64	
JMPE	R/M16	IA64	JMPE r/m16	TODO: IA64	
JMPE	R/M32	IA64	JMPE R/M32	TODO: IA64	
LAHF		8086	LAHF 	Load Status Flags into AH Register	LAHF.html
LAR	R16,MEM	286	LAR R16, MEM	Load Access Rights Byte	LAR.html
LAR	R16,R16	286	LAR R16, R16	Load Access Rights Byte	LAR.html
LAR	R16,R32	386	LAR R16, R32	Load Access Rights Byte	LAR.html
LAR	R16,R64	X64	LAR R16, r64	Load Access Rights Byte	LAR.html
LAR	R32,MEM	386	LAR R32, MEM	Load Access Rights Byte	LAR.html
LAR	R32,R16	386	LAR R32, R16	Load Access Rights Byte	LAR.html
LAR	R32,R32	386	LAR R32, R32	Load Access Rights Byte	LAR.html
LAR	R32,R64	X64	LAR R32, r64	Load Access Rights Byte	LAR.html
LAR	R64,MEM	X64	LAR r64, MEM	Load Access Rights Byte	LAR.html
LAR	R64,R16	X64	LAR r64, R16	Load Access Rights Byte	LAR.html
LAR	R64,R32	X64	LAR r64, R32	Load Access Rights Byte	LAR.html
LAR	R64,R64	X64	LAR r64, r64	Load Access Rights Byte	LAR.html
LDS	R16,MEM	8086	LDS R16, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LDS	R32,MEM	386	LDS R32, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LEA	R16,MEM	8086	LEA R16, MEM	Load Effective Address	LEA.html
LEA	R32,MEM	386	LEA R32, MEM	Load Effective Address	LEA.html
LEA	R64,MEM	X64	LEA r64, MEM	Load Effective Address	LEA.html
LEAVE		186	LEAVE 	High Level Procedure Exit	LEAVE.html
LES	R16,MEM	8086	LES R16, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LES	R32,MEM	386	LES R32, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LFENCE		X64,AMD	LFENCE 	Load Fence	LFENCE.html
LFENCE		SSE2	LFENCE 	Load Fence	LFENCE.html
LFS	R16,MEM	386	LFS R16, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LFS	R32,MEM	386	LFS R32, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LFS	R64,MEM	X64	LFS r64, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LGDT	MEM	286	LGDT MEM	Load Global/Interrupt Descriptor Table Register	LGDT:LIDT.html
LGS	R16,MEM	386	LGS R16, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LGS	R32,MEM	386	LGS R32, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LGS	R64,MEM	X64	LGS r64, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LIDT	MEM	286	LIDT MEM	Load Global/Interrupt Descriptor Table Register	LGDT:LIDT.html
LLDT	MEM	286	LLDT MEM	Load Local Descriptor Table Register	LLDT.html
LLDT	M16	286	LLDT M16	Load Local Descriptor Table Register	LLDT.html
LLDT	R16	286	LLDT R16	Load Local Descriptor Table Register	LLDT.html
LMSW	MEM	286	LMSW MEM	Load Machine Status Word	LMSW.html
LMSW	M16	286	LMSW M16	Load Machine Status Word	LMSW.html
LMSW	R16	286	LMSW R16	Load Machine Status Word	LMSW.html
LOADALL		386,UNDOC	LOADALL 	TODO: 386,UNDOC	
LOADALL286		286,UNDOC	LOADALL286 	TODO: 286,UNDOC	
LODSB		8086	LODSB 	Load String	LODS:LODSB:LODSW:LODSD:LODSQ.html
LODSD		386	LODSD 	Load String	LODS:LODSB:LODSW:LODSD:LODSQ.html
LODSQ		X64	LODSQ 	Load String	LODS:LODSB:LODSW:LODSD:LODSQ.html
LODSW		8086	LODSW 	Load String	LODS:LODSB:LODSW:LODSD:LODSQ.html
LOOP	IMM	8086	LOOP IMM	Loop According to ECX Counter. Jump SHORT if RCX!=0	LOOP:LOOPcc.html
LOOP	IMM,reg_cx	8086	LOOP IMM, CX	Loop According to ECX Counter. Jump SHORT if RCX!=0	LOOP:LOOPcc.html
LOOP	IMM,reg_ecx	386	LOOP IMM, ECX	Loop According to ECX Counter. Jump SHORT if RCX!=0	LOOP:LOOPcc.html
LOOP	IMM,reg_rcx	X64	LOOP IMM, RCX	Loop According to ECX Counter. Jump SHORT if RCX!=0	LOOP:LOOPcc.html
LOOPE	IMM	8086	LOOPE IMM	Loop According to ECX Counter. Jump SHORT if RCX!=0 and ZF=1	LOOP:LOOPcc.html
LOOPE	IMM,reg_cx	8086	LOOPE IMM, CX	Loop According to ECX Counter. Jump SHORT if RCX!=0 and ZF=1	LOOP:LOOPcc.html
LOOPE	IMM,reg_ecx	386	LOOPE IMM, ECX	Loop According to ECX Counter. Jump SHORT if RCX!=0 and ZF=1	LOOP:LOOPcc.html
LOOPE	IMM,reg_rcx	X64	LOOPE IMM, RCX	Loop According to ECX Counter. Jump SHORT if RCX!=0 and ZF=1	LOOP:LOOPcc.html
LOOPNE	IMM	8086	LOOPNE IMM	Loop According to ECX Counter. Jump SHORT if RCX!=0 and ZF=0	LOOP:LOOPcc.html
LOOPNE	IMM,reg_cx	8086	LOOPNE IMM, CX	Loop According to ECX Counter. Jump SHORT if RCX!=0 and ZF=0	LOOP:LOOPcc.html
LOOPNE	IMM,reg_ecx	386	LOOPNE IMM, ECX	Loop According to ECX Counter. Jump SHORT if RCX!=0 and ZF=0	LOOP:LOOPcc.html
LOOPNE	IMM,reg_rcx	X64	LOOPNE IMM, RCX	Loop According to ECX Counter. Jump SHORT if RCX!=0 and ZF=0	LOOP:LOOPcc.html
LOOPNZ	IMM	8086	LOOPNZ IMM	TODO: 8086,386,X64	
LOOPNZ	IMM,reg_cx	8086	LOOPNZ IMM, CX	TODO: 8086,386,X64	
LOOPNZ	IMM,reg_ecx	386	LOOPNZ IMM, ECX	TODO: 8086,386,X64	
LOOPNZ	IMM,reg_rcx	X64	LOOPNZ IMM, RCX	TODO: 8086,386,X64	
LOOPZ	IMM	8086	LOOPZ IMM	TODO: 8086,386,X64	
LOOPZ	IMM,reg_cx	8086	LOOPZ IMM, CX	TODO: 8086,386,X64	
LOOPZ	IMM,reg_ecx	386	LOOPZ IMM, ECX	TODO: 8086,386,X64	
LOOPZ	IMM,reg_rcx	X64	LOOPZ IMM, RCX	TODO: 8086,386,X64	
LSL	R16,MEM	286	LSL R16, MEM	Load Segment Limit	LSL.html
LSL	R16,R16	286	LSL R16, R16	Load Segment Limit	LSL.html
LSL	R16,R32	386	LSL R16, R32	Load Segment Limit	LSL.html
LSL	R16,R64	X64	LSL R16, r64	Load Segment Limit	LSL.html
LSL	R32,MEM	386	LSL R32, MEM	Load Segment Limit	LSL.html
LSL	R32,R16	386	LSL R32, R16	Load Segment Limit	LSL.html
LSL	R32,R32	386	LSL R32, R32	Load Segment Limit	LSL.html
LSL	R32,R64	X64	LSL R32, r64	Load Segment Limit	LSL.html
LSL	R64,MEM	X64	LSL r64, MEM	Load Segment Limit	LSL.html
LSL	R64,R16	X64	LSL r64, R16	Load Segment Limit	LSL.html
LSL	R64,R32	X64	LSL r64, R32	Load Segment Limit	LSL.html
LSL	R64,R64	X64	LSL r64, r64	Load Segment Limit	LSL.html
LSS	R16,MEM	386	LSS R16, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LSS	R32,MEM	386	LSS R32, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LSS	R64,MEM	X64	LSS r64, MEM	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LTR	MEM	286	LTR MEM	Load Task Register	LTR.html
LTR	M16	286	LTR M16	Load Task Register	LTR.html
LTR	R16	286	LTR R16	Load Task Register	LTR.html
MFENCE		X64,AMD	MFENCE 	Memory Fence	MFENCE.html
MFENCE		SSE2	MFENCE 	Memory Fence	MFENCE.html
MONITOR		PRESCOTT	MONITOR 	Set Up Monitor Address	MONITOR.html
MONITOR	EAX,reg_ecx,EDX	PRESCOTT	MONITOR EAX, ECX, EDX	Set Up Monitor Address	MONITOR.html
MONITOR	RAX,reg_ecx,EDX	X64	MONITOR RAX, ECX, EDX	Set Up Monitor Address	MONITOR.html
MONITORX		X64,AMD	MONITORX 	TODO: X64,AMD	
MONITORX	RAX,reg_ecx,EDX	X64,AMD	MONITORX RAX, ECX, EDX	TODO: X64,AMD	

MOV	MEM,REG_SREG	8086	MOV MEM, REG_SREG	Move 	MOV.html
MOV	R16,REG_SREG	8086	MOV R16, REG_SREG	Move	MOV.html
MOV	R32,REG_SREG	386	MOV R32, REG_SREG	Move	MOV.html
MOV	R64,REG_SREG	X64	MOV r64, REG_SREG	Move	MOV.html
MOV	R/M64,REG_SREG	X64	MOV r/m64, REG_SREG	Move	MOV.html
MOV	REG_SREG,MEM	8086	MOV REG_SREG, MEM	Move	MOV.html
MOV	REG_SREG,R16	8086	MOV REG_SREG, R16	Move	MOV.html
MOV	REG_SREG,R32	386	MOV REG_SREG, R32	Move	MOV.html
MOV	REG_SREG,R64	X64	MOV REG_SREG, r64	Move	MOV.html
MOV	REG_SREG,R16	8086	MOV REG_SREG, R16	Move	MOV.html
MOV	REG_SREG,R32	386	MOV REG_SREG, R32	Move	MOV.html
MOV	REG_SREG,R/M64	X64	MOV REG_SREG, r/m64	Move	MOV.html

MOV	AL,mem_offs	8086	MOV AL, mem_offs	Move	MOV.html
MOV	AX,mem_offs	8086	MOV AX, mem_offs	Move	MOV.html
MOV	EAX,mem_offs	386	MOV EAX, mem_offs	Move	MOV.html
MOV	RAX,mem_offs	X64	MOV RAX, mem_offs	Move	MOV.html
MOV	mem_offs,AL	8086	MOV mem_offs, AL	Move	MOV.html
MOV	mem_offs,AX	8086	MOV mem_offs, AX	Move	MOV.html
MOV	mem_offs,EAX	386	MOV mem_offs, EAX	Move	MOV.html
MOV	mem_offs,RAX	X64	MOV mem_offs, RAX	Move	MOV.html
MOV	R32,reg_creg	386	MOV R32, reg_creg	Move	MOV.html
MOV	R64,reg_creg	X64	MOV r64, reg_creg	Move	MOV.html
MOV	reg_creg,R32	386	MOV reg_creg, R32	Move	MOV.html
MOV	reg_creg,R64	X64	MOV reg_creg, r64	Move	MOV.html
MOV	R32,reg_dreg	386	MOV R32, reg_dreg	Move	MOV.html
MOV	R64,reg_dreg	X64	MOV r64, reg_dreg	Move	MOV.html
MOV	reg_dreg,R32	386	MOV reg_dreg, R32	Move	MOV.html
MOV	reg_dreg,R64	X64	MOV reg_dreg, r64	Move	MOV.html
MOV	MEM,R8	8086	MOV MEM, R8	Move	MOV.html
MOV	R8,R8	8086	MOV R8, R8	Move	MOV.html
MOV	MEM,R16	8086	MOV MEM, R16	Move	MOV.html
MOV	R16,R16	8086	MOV R16, R16	Move	MOV.html
MOV	MEM,R32	386	MOV MEM, R32	Move	MOV.html
MOV	R32,R32	386	MOV R32, R32	Move	MOV.html
MOV	MEM,R64	X64	MOV MEM, r64	Move	MOV.html
MOV	R64,R64	X64	MOV r64, r64	Move	MOV.html
MOV	R8,MEM	8086	MOV R8, MEM	Move	MOV.html
MOV	R8,R8	8086	MOV R8, R8	Move	MOV.html
MOV	R16,MEM	8086	MOV R16, MEM	Move	MOV.html
MOV	R16,R16	8086	MOV R16, R16	Move	MOV.html
MOV	R32,MEM	386	MOV R32, MEM	Move	MOV.html
MOV	R32,R32	386	MOV R32, R32	Move	MOV.html
MOV	R64,MEM	X64	MOV r64, MEM	Move	MOV.html
MOV	R64,R64	X64	MOV r64, r64	Move	MOV.html
MOV	R8,IMM	8086	MOV R8, IMM	Move	MOV.html
MOV	R16,IMM	8086	MOV R16, IMM	Move	MOV.html
MOV	R32,IMM	386	MOV R32, IMM	Move	MOV.html
MOV	R64,IMM	X64	MOV r64, IMM	Move	MOV.html
MOV	R/M8,IMM	8086	MOV r/m8, IMM	Move	MOV.html
MOV	R/M16,IMM	8086	MOV r/m16, IMM	Move	MOV.html
MOV	R/M32,IMM	386	MOV R/M32, IMM	Move	MOV.html
MOV	R/M64,IMM	X64	MOV r/m64, IMM	Move	MOV.html
MOV	R/M64,IMM32	X64	MOV r/m64, IMM32	Move	MOV.html
MOV	MEM,IMM8	8086	MOV MEM, IMM8	Move	MOV.html
MOV	MEM,IMM16	8086	MOV MEM, IMM16	Move	MOV.html
MOV	MEM,IMM32	386	MOV MEM, IMM32	Move	MOV.html
MOVD	MM,R/M32	PENT,MM,SD	MOVD MM, R/M32	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	R/M32,MM	PENT,MM,SD	MOVD R/M32, MM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	MM,R/M64	X64,MM,SX	MOVD MM, r/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	R/M64,MM	X64,MM,SX	MOVD r/m64, MM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	MEM,XMM	SSE2,SD	MOVD MEM, XMM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	XMM,MEM	SSE2,SD	MOVD XMM, MEM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	XMM,R/M32	SSE2	MOVD XMM, R/M32	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	R/M32,XMM	SSE2	MOVD R/M32, XMM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVQ	MM,MM/MEM	PENT,MM	MOVQ MM, MM/MEM	Move Quadword	MOVD:MOVQ.html
MOVQ	MM/MEM,MM	PENT,MM	MOVQ MM/MEM, MM	Move Quadword	MOVD:MOVQ.html
MOVQ	MM,R/M64	X64,MM	MOVQ MM, r/m64	Move Quadword	MOVD:MOVQ.html
MOVQ	R/M64,MM	X64,MM	MOVQ r/m64, MM	Move Quadword	MOVD:MOVQ.html
MOVQ	XMM,XMM	SSE2	MOVQ XMM, XMM	Move Quadword	MOVD:MOVQ.html
MOVQ	XMM,XMM	SSE2	MOVQ XMM, XMM	Move Quadword	MOVD:MOVQ.html
MOVQ	MEM,XMM	SSE2	MOVQ MEM, XMM	Move Quadword	MOVD:MOVQ.html
MOVQ	XMM,MEM	SSE2	MOVQ XMM, MEM	Move Quadword	MOVD:MOVQ.html
MOVQ	XMM,R/M64	X64,SSE2	MOVQ XMM, r/m64	Move Quadword	MOVD:MOVQ.html
MOVQ	R/M64,XMM	X64,SSE2	MOVQ r/m64, XMM	Move Quadword	MOVD:MOVQ.html
MOVSB		8086	MOVSB 	Move Data from String to String	MOVS:MOVSB:MOVSW:MOVSD:MOVSQ.html
MOVSD		386	MOVSD 	Move Data from String to String	MOVSD.html
MOVSD	XMM,XMM	SSE2	MOVSD XMM, XMM	Move Data from String to String	MOVSD.html
MOVSD	XMM,XMM	SSE2	MOVSD XMM, XMM	Move Data from String to String	MOVSD.html
MOVSD	M64,XMM	SSE2	MOVSD M64, XMM	Move Data from String to String	MOVSD.html
MOVSD	XMM,M64	SSE2	MOVSD XMM, M64	Move Data from String to String	MOVSD.html
MOVSQ		X64	MOVSQ 	Move Data from String to String	MOVS:MOVSB:MOVSW:MOVSD:MOVSQ.html
MOVSW		8086	MOVSW 	Move Data from String to String	MOVS:MOVSB:MOVSW:MOVSD:MOVSQ.html
MOVSX	R16,MEM	386	MOVSX R16, MEM	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	R16,R8	386	MOVSX R16, R8	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	R32,R/M8	386	MOVSX R32, r/m8	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	R32,R/M16	386	MOVSX R32, r/m16	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	R64,R/M8	X64	MOVSX r64, r/m8	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	R64,R/M16	X64	MOVSX r64, r/m16	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	R64,R/M32	X64	MOVSX r64, R/M32	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSXD	R64,R/M32	X64	MOVSXD r64, R/M32	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVZX	R16,MEM	386	MOVZX R16, MEM	Move with Zero-Extend	MOVZX.html
MOVZX	R16,R8	386	MOVZX R16, R8	Move with Zero-Extend	MOVZX.html
MOVZX	R32,R/M8	386	MOVZX R32, r/m8	Move with Zero-Extend	MOVZX.html
MOVZX	R32,R/M16	386	MOVZX R32, r/m16	Move with Zero-Extend	MOVZX.html
MOVZX	R64,R/M8	X64	MOVZX r64, r/m8	Move with Zero-Extend	MOVZX.html
MOVZX	R64,R/M16	X64	MOVZX r64, r/m16	Move with Zero-Extend	MOVZX.html
MUL	R/M8	8086	MUL r/m8	Unsigned Multiply	MUL.html
MUL	R/M16	8086	MUL r/m16	Unsigned Multiply	MUL.html
MUL	R/M32	386	MUL R/M32	Unsigned Multiply	MUL.html
MUL	R/M64	X64	MUL r/m64	Unsigned Multiply	MUL.html
MWAIT		PRESCOTT	MWAIT 	Monitor Wait	MWAIT.html
MWAIT	EAX,reg_ecx	PRESCOTT	MWAIT EAX, ECX	Monitor Wait	MWAIT.html
MWAITX		X64,AMD	MWAITX 	TODO: X64,AMD	
MWAITX	EAX,reg_ecx	X64,AMD	MWAITX EAX, ECX	TODO: X64,AMD	
NEG	R/M8	8086	NEG r/m8	Two's Complement Negation	NEG.html
NEG	R/M16	8086	NEG r/m16	Two's Complement Negation	NEG.html
NEG	R/M32	386	NEG R/M32	Two's Complement Negation	NEG.html
NEG	R/M64	X64	NEG r/m64	Two's Complement Negation	NEG.html
NOP		8086	NOP 	No Operation	NOP.html
NOP	R/M16	P6	NOP r/m16	No Operation	NOP.html
NOP	R/M32	P6	NOP R/M32	No Operation	NOP.html
NOP	R/M64	X64	NOP r/m64	No Operation	NOP.html
NOT	R/M8	8086	NOT r/m8	One's Complement Negation	NOT.html
NOT	R/M16	8086	NOT r/m16	One's Complement Negation	NOT.html
NOT	R/M32	386	NOT R/M32	One's Complement Negation	NOT.html
NOT	R/M64	X64	NOT r/m64	One's Complement Negation	NOT.html
OR	MEM,R8	8086	OR MEM, R8	Logical Inclusive OR	OR.html
OR	R8,R8	8086	OR R8, R8	Logical Inclusive OR	OR.html
OR	MEM,R16	8086	OR MEM, R16	Logical Inclusive OR	OR.html
OR	R16,R16	8086	OR R16, R16	Logical Inclusive OR	OR.html
OR	MEM,R32	386	OR MEM, R32	Logical Inclusive OR	OR.html
OR	R32,R32	386	OR R32, R32	Logical Inclusive OR	OR.html
OR	MEM,R64	X64	OR MEM, r64	Logical Inclusive OR	OR.html
OR	R64,R64	X64	OR r64, r64	Logical Inclusive OR	OR.html
OR	R8,MEM	8086	OR R8, MEM	Logical Inclusive OR	OR.html
OR	R8,R8	8086	OR R8, R8	Logical Inclusive OR	OR.html
OR	R16,MEM	8086	OR R16, MEM	Logical Inclusive OR	OR.html
OR	R16,R16	8086	OR R16, R16	Logical Inclusive OR	OR.html
OR	R32,MEM	386	OR R32, MEM	Logical Inclusive OR	OR.html
OR	R32,R32	386	OR R32, R32	Logical Inclusive OR	OR.html
OR	R64,MEM	X64	OR r64, MEM	Logical Inclusive OR	OR.html
OR	R64,R64	X64	OR r64, r64	Logical Inclusive OR	OR.html
OR	R/M16,IMM8	8086	OR r/m16, IMM8	Logical Inclusive OR	OR.html
OR	R/M32,IMM8	386	OR R/M32, IMM8	Logical Inclusive OR	OR.html
OR	R/M64,IMM8	X64	OR r/m64, IMM8	Logical Inclusive OR	OR.html
OR	AL,IMM	8086	OR AL, IMM	Logical Inclusive OR	OR.html
OR	AX,IMM	8086	OR AX, IMM	Logical Inclusive OR	OR.html
OR	EAX,IMM	386	OR EAX, IMM	Logical Inclusive OR	OR.html
OR	RAX,IMM	X64	OR RAX, IMM	Logical Inclusive OR	OR.html
OR	R/M8,IMM	8086	OR r/m8, IMM	Logical Inclusive OR	OR.html
OR	R/M16,IMM	8086	OR r/m16, IMM	Logical Inclusive OR	OR.html
OR	R/M32,IMM	386	OR R/M32, IMM	Logical Inclusive OR	OR.html
OR	R/M64,IMM	X64	OR r/m64, IMM	Logical Inclusive OR	OR.html
OR	MEM,IMM8	8086	OR MEM, IMM8	Logical Inclusive OR	OR.html
OR	MEM,IMM16	8086	OR MEM, IMM16	Logical Inclusive OR	OR.html
OR	MEM,IMM32	386	OR MEM, IMM32	Logical Inclusive OR	OR.html
OR	R/M8,IMM	8086	OR r/m8, IMM	Logical Inclusive OR	OR.html
OUT	IMM,AL	8086	OUT IMM, AL	Output to Port	OUT.html
OUT	IMM,AX	8086	OUT IMM, AX	Output to Port	OUT.html
OUT	IMM,EAX	386	OUT IMM, EAX	Output to Port	OUT.html
OUT	DX,AL	8086	OUT DX, AL	Output to Port	OUT.html
OUT	DX,AX	8086	OUT DX, AX	Output to Port	OUT.html
OUT	DX,EAX	386	OUT DX, EAX	Output to Port	OUT.html
OUTSB		186	OUTSB 	Output String to Port	OUTS:OUTSB:OUTSW:OUTSD.html
OUTSD		386	OUTSD 	Output String to Port	OUTS:OUTSB:OUTSW:OUTSD.html
OUTSW		186	OUTSW 	Output String to Port	OUTS:OUTSB:OUTSW:OUTSD.html
PACKSSDW	MM,MM/MEM	PENT,MM	PACKSSDW MM, MM/MEM	Pack Doubleword to word (signed with saturation)	PACKSSWB:PACKSSDW.html
PACKSSDW	XMM,XMM/MEM	SSE2	PACKSSDW XMM, XMM/M128	Pack Doubleword to word (signed with saturation)	PACKSSWB:PACKSSDW.html
PACKSSWB	MM,MM/MEM	PENT,MM	PACKSSWB MM, MM/MEM	Pack word to byte (signed with saturation)	PACKSSWB:PACKSSDW.html
PACKSSWB	XMM,XMM/MEM	SSE2	PACKSSWB XMM, XMM/M128	Pack word to byte (signed with saturation)	PACKSSWB:PACKSSDW.html
PACKUSWB	MM,MM/MEM	PENT,MM	PACKUSWB MM, MM/MEM	Pack with Unsigned Saturation	PACKUSWB.html
PACKUSWB	XMM,XMM/MEM	SSE2	PACKUSWB XMM, XMM/M128	Pack with Unsigned Saturation	PACKUSWB.html
PADDB	MM,MM/MEM	PENT,MM	PADDB MM, MM/MEM	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDB	XMM,XMM/MEM	SSE2	PADDB XMM, XMM/M128	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDD	MM,MM/MEM	PENT,MM	PADDD MM, MM/MEM	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDD	XMM,XMM/MEM	SSE2	PADDD XMM, XMM/M128	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDSB	MM,MM/MEM	PENT,MM	PADDSB MM, MM/MEM	Add Packed Signed Integers with Signed Saturation	PADDSB:PADDSW.html
PADDSB	XMM,XMM/MEM	SSE2	PADDSB XMM, XMM/M128	Add Packed Signed Integers with Signed Saturation	PADDSB:PADDSW.html
PADDSIW	MM,MM/MEM	PENT,MM,CYRIX	PADDSIW MM, MM/MEM	TODO: PENT,MM,CYRIX	
PADDSW	MM,MM/MEM	PENT,MM	PADDSW MM, MM/MEM	Add Packed Signed Integers with Signed Saturation	PADDSB:PADDSW.html
PADDSW	XMM,XMM/MEM	SSE2	PADDSW XMM, XMM/M128	Add Packed Signed Integers with Signed Saturation	PADDSB:PADDSW.html
PADDUSB	MM,MM/MEM	PENT,MM	PADDUSB MM, MM/MEM	Add Packed Unsigned Integers with Unsigned Saturation	PADDUSB:PADDUSW.html
PADDUSB	XMM,XMM/MEM	SSE2	PADDUSB XMM, XMM/M128	Add Packed Unsigned Integers with Unsigned Saturation	PADDUSB:PADDUSW.html
PADDUSW	MM,MM/MEM	PENT,MM	PADDUSW MM, MM/MEM	Add Packed Unsigned Integers with Unsigned Saturation	PADDUSB:PADDUSW.html
PADDUSW	XMM,XMM/MEM	SSE2	PADDUSW XMM, XMM/M128	Add Packed Unsigned Integers with Unsigned Saturation	PADDUSB:PADDUSW.html
PADDW	MM,MM/MEM	PENT,MM	PADDW MM, MM/MEM	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDW	XMM,XMM/MEM	SSE2	PADDW XMM, XMM/M128	Add Packed Integers	PADDB:PADDW:PADDD.html
PAND	MM,MM/MEM	PENT,MM	PAND MM, MM/MEM	Logical AND	PAND.html
PAND	XMM,XMM/MEM	SSE2	PAND XMM, XMM/M128	Logical AND	PAND.html
PANDN	MM,MM/MEM	PENT,MM	PANDN MM, MM/MEM	Logical AND NOT	PANDN.html
PANDN	XMM,XMM/MEM	SSE2	PANDN XMM, XMM/M128	Logical AND NOT	PANDN.html
PAUSE		8086	PAUSE 	Spin Loop Hint	PAUSE.html
PAVEB	MM,MM/MEM	PENT,MM,CYRIX	PAVEB MM, MM/MEM	TODO: PENT,MM,CYRIX	
PAVGUSB	MM,MM/MEM	PENT,3DNOW	PAVGUSB MM, MM/MEM	TODO: PENT,3DNOW	
PCMPEQB	MM,MM/MEM	PENT,MM	PCMPEQB MM, MM/MEM	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQB	XMM,XMM/MEM	SSE2	PCMPEQB XMM, XMM/M128	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQD	MM,MM/MEM	PENT,MM	PCMPEQD MM, MM/MEM	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQD	XMM,XMM/MEM	SSE2	PCMPEQD XMM, XMM/M128	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQW	MM,MM/MEM	PENT,MM	PCMPEQW MM, MM/MEM	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQW	XMM,XMM/MEM	SSE2	PCMPEQW XMM, XMM/M128	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPGTB	MM,MM/MEM	PENT,MM	PCMPGTB MM, MM/MEM	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTB	XMM,XMM/MEM	SSE2	PCMPGTB XMM, XMM/M128	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTD	MM,MM/MEM	PENT,MM	PCMPGTD MM, MM/MEM	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTD	XMM,XMM/MEM	SSE2	PCMPGTD XMM, XMM/M128	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTW	MM,MM/MEM	PENT,MM	PCMPGTW MM, MM/MEM	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTW	XMM,XMM/MEM	SSE2	PCMPGTW XMM, XMM/M128	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PDISTIB	MM,MEM	PENT,MM,CYRIX	PDISTIB MM, MEM	TODO: PENT,MM,CYRIX	
PF2ID	MM,MM/MEM	PENT,3DNOW	PF2ID MM, MM/MEM	TODO: PENT,3DNOW	
PFACC	MM,MM/MEM	PENT,3DNOW	PFACC MM, MM/MEM	TODO: PENT,3DNOW	
PFADD	MM,MM/MEM	PENT,3DNOW	PFADD MM, MM/MEM	TODO: PENT,3DNOW	
PFCMPEQ	MM,MM/MEM	PENT,3DNOW	PFCMPEQ MM, MM/MEM	TODO: PENT,3DNOW	
PFCMPGE	MM,MM/MEM	PENT,3DNOW	PFCMPGE MM, MM/MEM	TODO: PENT,3DNOW	
PFCMPGT	MM,MM/MEM	PENT,3DNOW	PFCMPGT MM, MM/MEM	TODO: PENT,3DNOW	
PFMAX	MM,MM/MEM	PENT,3DNOW	PFMAX MM, MM/MEM	TODO: PENT,3DNOW	
PFMIN	MM,MM/MEM	PENT,3DNOW	PFMIN MM, MM/MEM	TODO: PENT,3DNOW	
PFMUL	MM,MM/MEM	PENT,3DNOW	PFMUL MM, MM/MEM	TODO: PENT,3DNOW	
PFRCP	MM,MM/MEM	PENT,3DNOW	PFRCP MM, MM/MEM	TODO: PENT,3DNOW	
PFRCPIT1	MM,MM/MEM	PENT,3DNOW	PFRCPIT1 MM, MM/MEM	TODO: PENT,3DNOW	
PFRCPIT2	MM,MM/MEM	PENT,3DNOW	PFRCPIT2 MM, MM/MEM	TODO: PENT,3DNOW	
PFRSQIT1	MM,MM/MEM	PENT,3DNOW	PFRSQIT1 MM, MM/MEM	TODO: PENT,3DNOW	
PFRSQRT	MM,MM/MEM	PENT,3DNOW	PFRSQRT MM, MM/MEM	TODO: PENT,3DNOW	
PFSUB	MM,MM/MEM	PENT,3DNOW	PFSUB MM, MM/MEM	TODO: PENT,3DNOW	
PFSUBR	MM,MM/MEM	PENT,3DNOW	PFSUBR MM, MM/MEM	TODO: PENT,3DNOW	
PI2FD	MM,MM/MEM	PENT,3DNOW	PI2FD MM, MM/MEM	TODO: PENT,3DNOW	
PMACHRIW	MM,MEM	PENT,MM,CYRIX	PMACHRIW MM, MEM	TODO: PENT,MM,CYRIX	
PMADDWD	MM,MM/MEM	PENT,MM	PMADDWD MM, MM/MEM	Multiply and Add Packed Integers	PMADDWD.html
PMADDWD	XMM,XMM/MEM	SSE2	PMADDWD XMM, XMM/M128	Multiply and Add Packed Integers	PMADDWD.html
PMAGW	MM,MM/MEM	PENT,MM,CYRIX	PMAGW MM, MM/MEM	TODO: PENT,MM,CYRIX	
PMULHRIW	MM,MM/MEM	PENT,MM,CYRIX	PMULHRIW MM, MM/MEM	TODO: PENT,MM,CYRIX	
PMULHRWA	MM,MM/MEM	PENT,3DNOW	PMULHRWA MM, MM/MEM	TODO: PENT,3DNOW	
PMULHRWC	MM,MM/MEM	PENT,MM,CYRIX	PMULHRWC MM, MM/MEM	TODO: PENT,MM,CYRIX	
PMULHW	MM,MM/MEM	PENT,MM	PMULHW MM, MM/MEM	Multiply Packed Signed Integers and Store High Result	PMULHW.html
PMULHW	XMM,XMM/MEM	SSE2	PMULHW XMM, XMM/M128	Multiply Packed Signed Integers and Store High Result	PMULHW.html
PMULLW	MM,MM/MEM	PENT,MM	PMULLW MM, MM/MEM	Multiply Packed Signed Integers and Store Low Result	PMULLW.html
PMULLW	XMM,XMM/MEM	SSE2	PMULLW XMM, XMM/M128	Multiply Packed Signed Integers and Store Low Result	PMULLW.html
PMVGEZB	MM,MEM	PENT,MM,CYRIX	PMVGEZB MM, MEM	TODO: PENT,MM,CYRIX	
PMVLZB	MM,MEM	PENT,MM,CYRIX	PMVLZB MM, MEM	TODO: PENT,MM,CYRIX	
PMVNZB	MM,MEM	PENT,MM,CYRIX	PMVNZB MM, MEM	TODO: PENT,MM,CYRIX	
PMVZB	MM,MEM	PENT,MM,CYRIX	PMVZB MM, MEM	TODO: PENT,MM,CYRIX	
POP	R16	8086	POP R16	Pop a Value from the Stack	POP.html
POP	R32	386	POP R32	Pop a Value from the Stack	POP.html
POP	R64	X64	POP r64	Pop a Value from the Stack	POP.html
POP	R/M16	8086	POP r/m16	Pop a Value from the Stack	POP.html
POP	R/M32	386	POP R/M32	Pop a Value from the Stack	POP.html
POP	R/M64	X64	POP r/m64	Pop a Value from the Stack	POP.html
POP	ES	8086	POP ES	Pop a Value from the Stack	POP.html
POP	CS	8086,UNDOC	POP CS	Pop a Value from the Stack	POP.html
POP	SS	8086	POP SS	Pop a Value from the Stack	POP.html
POP	DS	8086	POP DS	Pop a Value from the Stack	POP.html
POP	FS	386	POP FS	Pop a Value from the Stack	POP.html
POP	GS	386	POP GS	Pop a Value from the Stack	POP.html
POPA		186	POPA 	Pop All General-Purpose Registers	POPA:POPAD.html
POPAD		386	POPAD 	Pop All General-Purpose Registers	POPA:POPAD.html
POPAW		186	POPAW 	TODO: 186	
POPF		8086	POPF 	Pop Stack into EFLAGS Register	POPF:POPFD:POPFQ.html
POPFD		386	POPFD 	Pop Stack into EFLAGS Register	POPF:POPFD:POPFQ.html
POPFQ		X64	POPFQ 	Pop Stack into EFLAGS Register	POPF:POPFD:POPFQ.html
POPFW		8086	POPFW 	TODO: 8086	
POR	MM,MM/MEM	PENT,MM	POR MM, MM/MEM	Bitwise Logical OR	POR.html
POR	XMM,XMM/MEM	SSE2	POR XMM, XMM/M128	Bitwise Logical OR	POR.html
PREFETCH	MEM	PENT,3DNOW	PREFETCH MEM	TODO: PENT,3DNOW	
PREFETCHW	MEM	PENT,3DNOW	PREFETCHW MEM	Prefetch Data into Caches in Anticipation of a Write	PREFETCHW.html
PSLLD	MM,MM/MEM	PENT,MM	PSLLD MM, MM/MEM	Shift Packed Word Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLD	MM,IMM	PENT,MM	PSLLD MM, IMM	Shift Packed Word Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLD	XMM,XMM/MEM	SSE2	PSLLD XMM, XMM/M128	Shift Packed Word Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLD	XMM,IMM	SSE2	PSLLD XMM, IMM	Shift Packed Word Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLQ	MM,MM/MEM	PENT,MM	PSLLQ MM, MM/MEM	Shift Packed Doubleword Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLQ	MM,IMM	PENT,MM	PSLLQ MM, IMM	Shift Packed Doubleword Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLQ	XMM,XMM/MEM	SSE2	PSLLQ XMM, XMM/M128	Shift Packed Doubleword Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLQ	XMM,IMM	SSE2	PSLLQ XMM, IMM	Shift Packed Doubleword Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLW	MM,MM/MEM	PENT,MM	PSLLW MM, MM/MEM	Shift Packed Data Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLW	MM,IMM	PENT,MM	PSLLW MM, IMM	Shift Packed Data Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLW	XMM,XMM/MEM	SSE2	PSLLW XMM, XMM/M128	Shift Packed Data Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLW	XMM,IMM	SSE2	PSLLW XMM, IMM	Shift Packed Data Left Logical	PSLLW:PSLLD:PSLLQ.html
PSRAD	MM,MM/MEM	PENT,MM	PSRAD MM, MM/MEM	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAD	MM,IMM	PENT,MM	PSRAD MM, IMM	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAD	XMM,XMM/MEM	SSE2	PSRAD XMM, XMM/M128	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAD	XMM,IMM	SSE2	PSRAD XMM, IMM	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAW	MM,MM/MEM	PENT,MM	PSRAW MM, MM/MEM	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAW	MM,IMM	PENT,MM	PSRAW MM, IMM	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAW	XMM,XMM/MEM	SSE2	PSRAW XMM, XMM/M128	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAW	XMM,IMM	SSE2	PSRAW XMM, IMM	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRLD	MM,MM/MEM	PENT,MM	PSRLD MM, MM/MEM	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLD	MM,IMM	PENT,MM	PSRLD MM, IMM	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLD	XMM,XMM/MEM	SSE2	PSRLD XMM, XMM/M128	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLD	XMM,IMM	SSE2	PSRLD XMM, IMM	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLQ	MM,MM/MEM	PENT,MM	PSRLQ MM, MM/MEM	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLQ	MM,IMM	PENT,MM	PSRLQ MM, IMM	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLQ	XMM,XMM/MEM	SSE2	PSRLQ XMM, XMM/M128	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLQ	XMM,IMM	SSE2	PSRLQ XMM, IMM	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLW	MM,MM/MEM	PENT,MM	PSRLW MM, MM/MEM	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLW	MM,IMM	PENT,MM	PSRLW MM, IMM	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLW	XMM,XMM/MEM	SSE2	PSRLW XMM, XMM/M128	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLW	XMM,IMM	SSE2	PSRLW XMM, IMM	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSUBB	MM,MM/MEM	PENT,MM	PSUBB MM, MM/MEM	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBB	XMM,XMM/MEM	SSE2	PSUBB XMM, XMM/M128	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBD	MM,MM/MEM	PENT,MM	PSUBD MM, MM/MEM	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBD	XMM,XMM/MEM	SSE2	PSUBD XMM, XMM/M128	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBSB	MM,MM/MEM	PENT,MM	PSUBSB MM, MM/MEM	Subtract Packed Signed Integers with Signed Saturation	PSUBSB:PSUBSW.html
PSUBSB	XMM,XMM/MEM	SSE2	PSUBSB XMM, XMM/M128	Subtract Packed Signed Integers with Signed Saturation	PSUBSB:PSUBSW.html
PSUBSIW	MM,MM/MEM	PENT,MM,CYRIX	PSUBSIW MM, MM/MEM	TODO: PENT,MM,CYRIX	
PSUBSW	MM,MM/MEM	PENT,MM	PSUBSW MM, MM/MEM	Subtract Packed Signed Integers with Signed Saturation	PSUBSB:PSUBSW.html
PSUBSW	XMM,XMM/MEM	SSE2	PSUBSW XMM, XMM/M128	Subtract Packed Signed Integers with Signed Saturation	PSUBSB:PSUBSW.html
PSUBUSB	MM,MM/MEM	PENT,MM	PSUBUSB MM, MM/MEM	Subtract Packed Unsigned Integers with Unsigned Saturation	PSUBUSB:PSUBUSW.html
PSUBUSB	XMM,XMM/MEM	SSE2	PSUBUSB XMM, XMM/M128	Subtract Packed Unsigned Integers with Unsigned Saturation	PSUBUSB:PSUBUSW.html
PSUBUSW	MM,MM/MEM	PENT,MM	PSUBUSW MM, MM/MEM	Subtract Packed Unsigned Integers with Unsigned Saturation	PSUBUSB:PSUBUSW.html
PSUBUSW	XMM,XMM/MEM	SSE2	PSUBUSW XMM, XMM/M128	Subtract Packed Unsigned Integers with Unsigned Saturation	PSUBUSB:PSUBUSW.html
PSUBW	MM,MM/MEM	PENT,MM	PSUBW MM, MM/MEM	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBW	XMM,XMM/MEM	SSE2	PSUBW XMM, XMM/M128	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PUNPCKHBW	MM,MM/MEM	PENT,MM	PUNPCKHBW MM, MM/MEM	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHBW	XMM,XMM/MEM	SSE2	PUNPCKHBW XMM, XMM/M128	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHDQ	MM,MM/MEM	PENT,MM	PUNPCKHDQ MM, MM/MEM	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHDQ	XMM,XMM/MEM	SSE2	PUNPCKHDQ XMM, XMM/M128	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHWD	MM,MM/MEM	PENT,MM	PUNPCKHWD MM, MM/MEM	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHWD	XMM,XMM/MEM	SSE2	PUNPCKHWD XMM, XMM/M128	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKLBW	MM,MM/MEM	PENT,MM	PUNPCKLBW MM, MM/MEM	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLBW	XMM,XMM/MEM	SSE2	PUNPCKLBW XMM, XMM/M128	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLDQ	MM,MM/MEM	PENT,MM	PUNPCKLDQ MM, MM/MEM	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLDQ	XMM,XMM/MEM	SSE2	PUNPCKLDQ XMM, XMM/M128	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLWD	MM,MM/MEM	PENT,MM	PUNPCKLWD MM, MM/MEM	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLWD	XMM,XMM/MEM	SSE2	PUNPCKLWD XMM, XMM/M128	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUSH	R16	8086	PUSH R16	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	R32	386	PUSH R32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	R64	X64	PUSH r64	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	R/M16	8086	PUSH r/m16	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	R/M32	386	PUSH R/M32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	R/M64	X64	PUSH r/m64	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	ES	8086	PUSH ES	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	CS	8086	PUSH CS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	SS	8086	PUSH SS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	DS	8086	PUSH DS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	FS	386	PUSH FS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	GS	386	PUSH GS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	IMM8	186	PUSH IMM8	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	IMM16	186,AR0,SIZE	PUSH IMM16	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	IMM32	386,AR0,SIZE	PUSH IMM32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	IMM32	386,SD	PUSH IMM32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	IMM64	X64,AR0,SIZE	PUSH IMM64	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	IMM32	X64,AR0,SIZE	PUSH IMM32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSHA		186	PUSHA 	Push All General-Purpose Registers	PUSHA:PUSHAD.html
PUSHAD		386	PUSHAD 	Push All General-Purpose Registers	PUSHA:PUSHAD.html
PUSHAW		186	PUSHAW 	TODO: 186	
PUSHF		8086	PUSHF 	Push EFLAGS Register onto the Stack	PUSHF:PUSHFD.html
PUSHFD		386	PUSHFD 	Push EFLAGS Register onto the Stack	PUSHF:PUSHFD.html
PUSHFQ		X64	PUSHFQ 	Push RFLAGS Register onto the Stack	PUSHF:PUSHFD.html
PUSHFW		8086	PUSHFW 	TODO: 8086	
PXOR	MM,MM/MEM	PENT,MM	PXOR MM, MM/MEM	Logical Exclusive OR	PXOR.html
PXOR	XMM,XMM/MEM	SSE2	PXOR XMM, XMM/M128	Logical Exclusive OR	PXOR.html
RCL	R/M8,1	8086	RCL r/m8, 1	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M8,CL	8086	RCL r/m8, CL	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M8,IMM8	186	RCL r/m8, IMM8	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M16,1	8086	RCL r/m16, 1	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M16,CL	8086	RCL r/m16, CL	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M16,IMM8	186	RCL r/m16, IMM8	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M32,1	386	RCL R/M32, 1	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M32,CL	386	RCL R/M32, CL	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M32,IMM8	386	RCL R/M32, IMM8	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M64,1	X64	RCL r/m64, 1	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M64,CL	X64	RCL r/m64, CL	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	R/M64,IMM8	X64	RCL r/m64, IMM8	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCR	R/M8,1	8086	RCR r/m8, 1	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M8,CL	8086	RCR r/m8, CL	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M8,IMM8	186	RCR r/m8, IMM8	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M16,1	8086	RCR r/m16, 1	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M16,CL	8086	RCR r/m16, CL	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M16,IMM8	186	RCR r/m16, IMM8	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M32,1	386	RCR R/M32, 1	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M32,CL	386	RCR R/M32, CL	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M32,IMM8	386	RCR R/M32, IMM8	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M64,1	X64	RCR r/m64, 1	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M64,CL	X64	RCR r/m64, CL	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	R/M64,IMM8	X64	RCR r/m64, IMM8	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RDSHR	R/M32	P6,CYRIXM	RDSHR R/M32	TODO: P6,CYRIXM	
RDMSR		PENT	RDMSR 	Read from Model Specific Register	RDMSR.html
RDPMC		P6	RDPMC 	Read Performance-Monitoring Counters	RDPMC.html
RDTSC		PENT	RDTSC 	Read Time-Stamp Counter	RDTSC.html
RDTSCP		X86_64	RDTSCP 	Read Time-Stamp Counter and Processor ID	RDTSCP.html
RET		8086,BND	RET 	Return from Procedure	RET.html
RET	IMM	8086,BND	RET IMM	Return from Procedure	RET.html
RETF		8086	RETF 	TODO: 8086	
RETF	IMM	8086	RETF IMM	TODO: 8086	
RETN		8086,BND	RETN 	TODO: 8086,BND	
RETN	IMM	8086,BND	RETN IMM	TODO: 8086,BND	
ROL	R/M8,1	8086	ROL r/m8, 1	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M8,CL	8086	ROL r/m8, CL	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M8,IMM8	186	ROL r/m8, IMM8	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M16,1	8086	ROL r/m16, 1	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M16,CL	8086	ROL r/m16, CL	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M16,IMM8	186	ROL r/m16, IMM8	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M32,1	386	ROL R/M32, 1	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M32,CL	386	ROL R/M32, CL	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M32,IMM8	386	ROL R/M32, IMM8	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M64,1	X64	ROL r/m64, 1	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M64,CL	X64	ROL r/m64, CL	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	R/M64,IMM8	X64	ROL r/m64, IMM8	Rotate Left	RCL:RCR:ROL:ROR.html
ROR	R/M8,1	8086	ROR r/m8, 1	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M8,CL	8086	ROR r/m8, CL	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M8,IMM8	186	ROR r/m8, IMM8	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M16,1	8086	ROR r/m16, 1	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M16,CL	8086	ROR r/m16, CL	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M16,IMM8	186	ROR r/m16, IMM8	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M32,1	386	ROR R/M32, 1	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M32,CL	386	ROR R/M32, CL	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M32,IMM8	386	ROR R/M32, IMM8	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M64,1	X64	ROR r/m64, 1	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M64,CL	X64	ROR r/m64, CL	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	R/M64,IMM8	X64	ROR r/m64, IMM8	Rotate Right	RCL:RCR:ROL:ROR.html
RDM		P6,CYRIX	RDM 	TODO: P6,CYRIX	
RSDC	REG_SREG,M80	486,CYRIXM	RSDC REG_SREG, M80	TODO: 486,CYRIXM	
RSLDT	M80	486,CYRIXM	RSLDT M80	TODO: 486,CYRIXM	
RSM		PENT	RSM 	Resume from System Management Mode	RSM.html
RSTS	M80	486,CYRIXM	RSTS M80	TODO: 486,CYRIXM	
SAHF		8086	SAHF 	Store AH into Flags	SAHF.html
SAL	R/M8,1	8086	SAL r/m8, 1	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M8,CL	8086	SAL r/m8, CL	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M8,IMM8	186	SAL r/m8, IMM8	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M16,1	8086	SAL r/m16, 1	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M16,CL	8086	SAL r/m16, CL	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M16,IMM8	186	SAL r/m16, IMM8	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M32,1	386	SAL R/M32, 1	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M32,CL	386	SAL R/M32, CL	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M32,IMM8	386	SAL R/M32, IMM8	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M64,1	X64	SAL r/m64, 1	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M64,CL	X64	SAL r/m64, CL	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	R/M64,IMM8	X64	SAL r/m64, IMM8	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SALC		8086,UNDOC	SALC 	TODO: 8086,UNDOC	
SAR	R/M8,1	8086	SAR r/m8, 1	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M8,CL	8086	SAR r/m8, CL	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M8,IMM8	186	SAR r/m8, IMM8	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M16,1	8086	SAR r/m16, 1	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M16,CL	8086	SAR r/m16, CL	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M16,IMM8	186	SAR r/m16, IMM8	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M32,1	386	SAR R/M32, 1	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M32,CL	386	SAR R/M32, CL	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M32,IMM8	386	SAR R/M32, IMM8	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M64,1	X64	SAR r/m64, 1	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M64,CL	X64	SAR r/m64, CL	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	R/M64,IMM8	X64	SAR r/m64, IMM8	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SBB	MEM,R8	8086	SBB MEM, R8	Integer Subtraction with Borrow	SBB.html
SBB	R8,R8	8086	SBB R8, R8	Integer Subtraction with Borrow	SBB.html
SBB	MEM,R16	8086	SBB MEM, R16	Integer Subtraction with Borrow	SBB.html
SBB	R16,R16	8086	SBB R16, R16	Integer Subtraction with Borrow	SBB.html
SBB	MEM,R32	386	SBB MEM, R32	Integer Subtraction with Borrow	SBB.html
SBB	R32,R32	386	SBB R32, R32	Integer Subtraction with Borrow	SBB.html
SBB	MEM,R64	X64	SBB MEM, r64	Integer Subtraction with Borrow	SBB.html
SBB	R64,R64	X64	SBB r64, r64	Integer Subtraction with Borrow	SBB.html
SBB	R8,MEM	8086	SBB R8, MEM	Integer Subtraction with Borrow	SBB.html
SBB	R8,R8	8086	SBB R8, R8	Integer Subtraction with Borrow	SBB.html
SBB	R16,MEM	8086	SBB R16, MEM	Integer Subtraction with Borrow	SBB.html
SBB	R16,R16	8086	SBB R16, R16	Integer Subtraction with Borrow	SBB.html
SBB	R32,MEM	386	SBB R32, MEM	Integer Subtraction with Borrow	SBB.html
SBB	R32,R32	386	SBB R32, R32	Integer Subtraction with Borrow	SBB.html
SBB	R64,MEM	X64	SBB r64, MEM	Integer Subtraction with Borrow	SBB.html
SBB	R64,R64	X64	SBB r64, r64	Integer Subtraction with Borrow	SBB.html
SBB	R/M16,IMM8	8086	SBB r/m16, IMM8	Integer Subtraction with Borrow	SBB.html
SBB	R/M32,IMM8	386	SBB R/M32, IMM8	Integer Subtraction with Borrow	SBB.html
SBB	R/M64,IMM8	X64	SBB r/m64, IMM8	Integer Subtraction with Borrow	SBB.html
SBB	AL,IMM	8086	SBB AL, IMM	Integer Subtraction with Borrow	SBB.html
SBB	AX,IMM	8086	SBB AX, IMM	Integer Subtraction with Borrow	SBB.html
SBB	EAX,IMM	386	SBB EAX, IMM	Integer Subtraction with Borrow	SBB.html
SBB	RAX,IMM	X64	SBB RAX, IMM	Integer Subtraction with Borrow	SBB.html
SBB	R/M8,IMM	8086	SBB r/m8, IMM	Integer Subtraction with Borrow	SBB.html
SBB	R/M16,IMM	8086	SBB r/m16, IMM	Integer Subtraction with Borrow	SBB.html
SBB	R/M32,IMM	386	SBB R/M32, IMM	Integer Subtraction with Borrow	SBB.html
SBB	R/M64,IMM	X64	SBB r/m64, IMM	Integer Subtraction with Borrow	SBB.html
SBB	MEM,IMM8	8086	SBB MEM, IMM8	Integer Subtraction with Borrow	SBB.html
SBB	MEM,IMM16	8086	SBB MEM, IMM16	Integer Subtraction with Borrow	SBB.html
SBB	MEM,IMM32	386	SBB MEM, IMM32	Integer Subtraction with Borrow	SBB.html
SBB	R/M8,IMM	8086	SBB r/m8, IMM	Integer Subtraction with Borrow	SBB.html
SCASB		8086	SCASB 	Scan String	SCAS:SCASB:SCASW:SCASD.html
SCASD		386	SCASD 	Scan String	SCAS:SCASB:SCASW:SCASD.html
SCASQ		X64	SCASQ 	TODO: X64	
SCASW		8086	SCASW 	Scan String	SCAS:SCASB:SCASW:SCASD.html
SFENCE		X64,AMD	SFENCE 	Store Fence	SFENCE.html
SFENCE		SSE	SFENCE 	Store Fence	SFENCE.html
SGDT	MEM	286	SGDT MEM	Store Global Descriptor Table Register	SGDT.html
SHL	R/M8,1	8086	SHL r/m8, 1	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M8,CL	8086	SHL r/m8, CL	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M8,IMM8	186	SHL r/m8, IMM8	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M16,1	8086	SHL r/m16, 1	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M16,CL	8086	SHL r/m16, CL	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M16,IMM8	186	SHL r/m16, IMM8	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M32,1	386	SHL R/M32, 1	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M32,CL	386	SHL R/M32, CL	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M32,IMM8	386	SHL R/M32, IMM8	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M64,1	X64	SHL r/m64, 1	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M64,CL	X64	SHL r/m64, CL	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	R/M64,IMM8	X64	SHL r/m64, IMM8	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHLD	MEM,R16,IMM	386	SHLD MEM, R16, IMM	Double Precision Shift Left	SHLD.html
SHLD	R16,R16,IMM	386	SHLD R16, R16, IMM	Double Precision Shift Left	SHLD.html
SHLD	MEM,R32,IMM	386	SHLD MEM, R32, IMM	Double Precision Shift Left	SHLD.html
SHLD	R32,R32,IMM	386	SHLD R32, R32, IMM	Double Precision Shift Left	SHLD.html
SHLD	MEM,R64,IMM	X64	SHLD MEM, r64, IMM	Double Precision Shift Left	SHLD.html
SHLD	R64,R64,IMM	X64	SHLD r64, r64, IMM	Double Precision Shift Left	SHLD.html
SHLD	MEM,R16,CL	386	SHLD MEM, R16, CL	Double Precision Shift Left	SHLD.html
SHLD	R16,R16,CL	386	SHLD R16, R16, CL	Double Precision Shift Left	SHLD.html
SHLD	MEM,R32,CL	386	SHLD MEM, R32, CL	Double Precision Shift Left	SHLD.html
SHLD	R32,R32,CL	386	SHLD R32, R32, CL	Double Precision Shift Left	SHLD.html
SHLD	MEM,R64,CL	X64	SHLD MEM, r64, CL	Double Precision Shift Left	SHLD.html
SHLD	R64,R64,CL	X64	SHLD r64, r64, CL	Double Precision Shift Left	SHLD.html
SHR	R/M8,1	8086	SHR r/m8, 1	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M8,CL	8086	SHR r/m8, CL	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M8,IMM8	186	SHR r/m8, IMM8	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M16,1	8086	SHR r/m16, 1	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M16,CL	8086	SHR r/m16, CL	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M16,IMM8	186	SHR r/m16, IMM8	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M32,1	386	SHR R/M32, 1	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M32,CL	386	SHR R/M32, CL	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M32,IMM8	386	SHR R/M32, IMM8	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M64,1	X64	SHR r/m64, 1	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M64,CL	X64	SHR r/m64, CL	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	R/M64,IMM8	X64	SHR r/m64, IMM8	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHRD	MEM,R16,IMM	386	SHRD MEM, R16, IMM	Double Precision Shift Right	SHRD.html
SHRD	R16,R16,IMM	386	SHRD R16, R16, IMM	Double Precision Shift Right	SHRD.html
SHRD	MEM,R32,IMM	386	SHRD MEM, R32, IMM	Double Precision Shift Right	SHRD.html
SHRD	R32,R32,IMM	386	SHRD R32, R32, IMM	Double Precision Shift Right	SHRD.html
SHRD	MEM,R64,IMM	X64	SHRD MEM, r64, IMM	Double Precision Shift Right	SHRD.html
SHRD	R64,R64,IMM	X64	SHRD r64, r64, IMM	Double Precision Shift Right	SHRD.html
SHRD	MEM,R16,CL	386	SHRD MEM, R16, CL	Double Precision Shift Right	SHRD.html
SHRD	R16,R16,CL	386	SHRD R16, R16, CL	Double Precision Shift Right	SHRD.html
SHRD	MEM,R32,CL	386	SHRD MEM, R32, CL	Double Precision Shift Right	SHRD.html
SHRD	R32,R32,CL	386	SHRD R32, R32, CL	Double Precision Shift Right	SHRD.html
SHRD	MEM,R64,CL	X64	SHRD MEM, r64, CL	Double Precision Shift Right	SHRD.html
SHRD	R64,R64,CL	X64	SHRD r64, r64, CL	Double Precision Shift Right	SHRD.html
SIDT	MEM	286	SIDT MEM	Store Interrupt Descriptor Table Register	SIDT.html
SLDT	MEM	286	SLDT MEM	Store Local Descriptor Table Register	SLDT.html
SLDT	M16	286	SLDT M16	Store Local Descriptor Table Register	SLDT.html
SLDT	R16	286	SLDT R16	Store Local Descriptor Table Register	SLDT.html
SLDT	R32	386	SLDT R32	Store Local Descriptor Table Register	SLDT.html
SLDT	R64	X64	SLDT r64	Store Local Descriptor Table Register	SLDT.html
SLDT	R64	X64	SLDT r64	Store Local Descriptor Table Register	SLDT.html
SKINIT		X64	SKINIT 	TODO: X64	
SMI		386,UNDOC	SMI 	TODO: 386,UNDOC	
SMINT		P6,CYRIX	SMINT 	TODO: P6,CYRIX	
SMINTOLD		486,CYRIX	SMINTOLD 	TODO: 486,CYRIX	
SMSW	MEM	286	SMSW MEM	Store Machine Status Word	SMSW.html
SMSW	M16	286	SMSW M16	Store Machine Status Word	SMSW.html
SMSW	R16	286	SMSW R16	Store Machine Status Word	SMSW.html
SMSW	R32	386	SMSW R32	Store Machine Status Word	SMSW.html
SMSW	R64	X64	SMSW r64	Store Machine Status Word	SMSW.html
STC		8086	STC 	Set Carry Flag	STC.html
STD		8086	STD 	Set Direction Flag	STD.html
STI		8086	STI 	Set Interrupt Flag	STI.html
STOSB		8086	STOSB 	Store String	STOS:STOSB:STOSW:STOSD:STOSQ.html
STOSD		386	STOSD 	Store String	STOS:STOSB:STOSW:STOSD:STOSQ.html
STOSQ		X64	STOSQ 	Store String	STOS:STOSB:STOSW:STOSD:STOSQ.html
STOSW		8086	STOSW 	Store String	STOS:STOSB:STOSW:STOSD:STOSQ.html
STR	MEM	286	STR MEM	Store Task Register	STR.html
STR	M16	286	STR M16	Store Task Register	STR.html
STR	R16	286	STR R16	Store Task Register	STR.html
STR	R32	386	STR R32	Store Task Register	STR.html
STR	R64	X64	STR r64	Store Task Register	STR.html
SUB	MEM,R8	8086	SUB MEM, R8	Subtract	SUB.html
SUB	R8,R8	8086	SUB R8, R8	Subtract	SUB.html
SUB	MEM,R16	8086	SUB MEM, R16	Subtract	SUB.html
SUB	R16,R16	8086	SUB R16, R16	Subtract	SUB.html
SUB	MEM,R32	386	SUB MEM, R32	Subtract	SUB.html
SUB	R32,R32	386	SUB R32, R32	Subtract	SUB.html
SUB	MEM,R64	X64	SUB MEM, r64	Subtract	SUB.html
SUB	R64,R64	X64	SUB r64, r64	Subtract	SUB.html
SUB	R8,MEM	8086	SUB R8, MEM	Subtract	SUB.html
SUB	R8,R8	8086	SUB R8, R8	Subtract	SUB.html
SUB	R16,MEM	8086	SUB R16, MEM	Subtract	SUB.html
SUB	R16,R16	8086	SUB R16, R16	Subtract	SUB.html
SUB	R32,MEM	386	SUB R32, MEM	Subtract	SUB.html
SUB	R32,R32	386	SUB R32, R32	Subtract	SUB.html
SUB	R64,MEM	X64	SUB r64, MEM	Subtract	SUB.html
SUB	R64,R64	X64	SUB r64, r64	Subtract	SUB.html
SUB	R/M16,IMM8	8086	SUB r/m16, IMM8	Subtract	SUB.html
SUB	R/M32,IMM8	386	SUB R/M32, IMM8	Subtract	SUB.html
SUB	R/M64,IMM8	X64	SUB r/m64, IMM8	Subtract	SUB.html
SUB	AL,IMM	8086	SUB AL, IMM	Subtract	SUB.html
SUB	AX,IMM	8086	SUB AX, IMM	Subtract	SUB.html
SUB	EAX,IMM	386	SUB EAX, IMM	Subtract	SUB.html
SUB	RAX,IMM	X64	SUB RAX, IMM	Subtract	SUB.html
SUB	R/M8,IMM	8086	SUB r/m8, IMM	Subtract	SUB.html
SUB	R/M16,IMM	8086	SUB r/m16, IMM	Subtract	SUB.html
SUB	R/M32,IMM	386	SUB R/M32, IMM	Subtract	SUB.html
SUB	R/M64,IMM	X64	SUB r/m64, IMM	Subtract	SUB.html
SUB	MEM,IMM8	8086	SUB MEM, IMM8	Subtract	SUB.html
SUB	MEM,IMM16	8086	SUB MEM, IMM16	Subtract	SUB.html
SUB	MEM,IMM32	386	SUB MEM, IMM32	Subtract	SUB.html
SUB	R/M8,IMM	8086	SUB r/m8, IMM	Subtract	SUB.html
SVDC	M80,REG_SREG	486,CYRIXM	SVDC M80, REG_SREG	TODO: 486,CYRIXM	
SVLDT	M80	486,CYRIXM	SVLDT M80	TODO: 486,CYRIXM	
SVTS	M80	486,CYRIXM	SVTS M80	TODO: 486,CYRIXM	
SWAPGS		X64	SWAPGS 	Swap GS Base Register	SWAPGS.html
SYSCALL		P6,AMD	SYSCALL 	Fast System Call	SYSCALL.html
SYSENTER		P6	SYSENTER 	Fast System Call	SYSENTER.html
SYSEXIT		P6	SYSEXIT 	Fast Return from Fast System Call	SYSEXIT.html
SYSRET		P6,AMD	SYSRET 	Return From Fast System Call	SYSRET.html
TEST	MEM,R8	8086	TEST MEM, R8	Logical Compare	TEST.html
TEST	R8,R8	8086	TEST R8, R8	Logical Compare	TEST.html
TEST	MEM,R16	8086	TEST MEM, R16	Logical Compare	TEST.html
TEST	R16,R16	8086	TEST R16, R16	Logical Compare	TEST.html
TEST	MEM,R32	386	TEST MEM, R32	Logical Compare	TEST.html
TEST	R32,R32	386	TEST R32, R32	Logical Compare	TEST.html
TEST	MEM,R64	X64	TEST MEM, r64	Logical Compare	TEST.html
TEST	R64,R64	X64	TEST r64, r64	Logical Compare	TEST.html
TEST	R8,MEM	8086	TEST R8, MEM	Logical Compare	TEST.html
TEST	R16,MEM	8086	TEST R16, MEM	Logical Compare	TEST.html
TEST	R32,MEM	386	TEST R32, MEM	Logical Compare	TEST.html
TEST	R64,MEM	X64	TEST r64, MEM	Logical Compare	TEST.html
TEST	AL,IMM	8086	TEST AL, IMM	Logical Compare	TEST.html
TEST	AX,IMM	8086	TEST AX, IMM	Logical Compare	TEST.html
TEST	EAX,IMM	386	TEST EAX, IMM	Logical Compare	TEST.html
TEST	RAX,IMM	X64	TEST RAX, IMM	Logical Compare	TEST.html
TEST	R/M8,IMM	8086	TEST r/m8, IMM	Logical Compare	TEST.html
TEST	R/M16,IMM	8086	TEST r/m16, IMM	Logical Compare	TEST.html
TEST	R/M32,IMM	386	TEST R/M32, IMM	Logical Compare	TEST.html
TEST	R/M64,IMM	X64	TEST r/m64, IMM	Logical Compare	TEST.html
TEST	MEM,IMM8	8086	TEST MEM, IMM8	Logical Compare	TEST.html
TEST	MEM,IMM16	8086	TEST MEM, IMM16	Logical Compare	TEST.html
TEST	MEM,IMM32	386	TEST MEM, IMM32	Logical Compare	TEST.html
UMOV	MEM,R8	386,UNDOC	UMOV MEM, R8	TODO: 386,UNDOC	
UMOV	R8,R8	386,UNDOC	UMOV R8, R8	TODO: 386,UNDOC	
UMOV	MEM,R16	386,UNDOC	UMOV MEM, R16	TODO: 386,UNDOC	
UMOV	R16,R16	386,UNDOC	UMOV R16, R16	TODO: 386,UNDOC	
UMOV	MEM,R32	386,UNDOC	UMOV MEM, R32	TODO: 386,UNDOC	
UMOV	R32,R32	386,UNDOC	UMOV R32, R32	TODO: 386,UNDOC	
UMOV	R8,MEM	386,UNDOC	UMOV R8, MEM	TODO: 386,UNDOC	
UMOV	R8,R8	386,UNDOC	UMOV R8, R8	TODO: 386,UNDOC	
UMOV	R16,MEM	386,UNDOC	UMOV R16, MEM	TODO: 386,UNDOC	
UMOV	R16,R16	386,UNDOC	UMOV R16, R16	TODO: 386,UNDOC	
UMOV	R32,MEM	386,UNDOC	UMOV R32, MEM	TODO: 386,UNDOC	
UMOV	R32,R32	386,UNDOC	UMOV R32, R32	TODO: 386,UNDOC	
VERR	MEM	286	VERR MEM	Verify a Segment for Reading or Writing	VERR:VERW.html
VERR	M16	286	VERR M16	Verify a Segment for Reading or Writing	VERR:VERW.html
VERR	R16	286	VERR R16	Verify a Segment for Reading or Writing	VERR:VERW.html
VERW	MEM	286	VERW MEM	Verify a Segment for Reading or Writing	VERR:VERW.html
VERW	M16	286	VERW M16	Verify a Segment for Reading or Writing	VERR:VERW.html
VERW	R16	286	VERW R16	Verify a Segment for Reading or Writing	VERR:VERW.html
FWAIT		8086	FWAIT 	Wait	WAIT:FWAIT.html
WBINVD		486	WBINVD 	Write Back and Invalidate Cache	WBINVD.html
WRSHR	R/M32	P6,CYRIXM	WRSHR R/M32	TODO: P6,CYRIXM	
WRMSR		PENT	WRMSR 	Write to Model Specific Register	WRMSR.html
XADD	MEM,R8	486	XADD MEM, R8	Exchange and Add	XADD.html
XADD	R8,R8	486	XADD R8, R8	Exchange and Add	XADD.html
XADD	MEM,R16	486	XADD MEM, R16	Exchange and Add	XADD.html
XADD	R16,R16	486	XADD R16, R16	Exchange and Add	XADD.html
XADD	MEM,R32	486	XADD MEM, R32	Exchange and Add	XADD.html
XADD	R32,R32	486	XADD R32, R32	Exchange and Add	XADD.html
XADD	MEM,R64	X64	XADD MEM, r64	Exchange and Add	XADD.html
XADD	R64,R64	X64	XADD r64, r64	Exchange and Add	XADD.html
XBTS	R16,MEM	386,UNDOC	XBTS R16, MEM	TODO: 386,UNDOC,SD	
XBTS	R16,R16	386,UNDOC	XBTS R16, R16	TODO: 386,UNDOC,SD	
XBTS	R32,MEM	386,SD,UNDOC	XBTS R32, MEM	TODO: 386,UNDOC,SD	
XBTS	R32,R32	386,UNDOC	XBTS R32, R32	TODO: 386,UNDOC,SD	
XCHG	AX,R16	8086	XCHG AX, R16	Exchange Register/Memory with Register	XCHG.html
XCHG	EAX,R32	386	XCHG EAX, R32	Exchange Register/Memory with Register	XCHG.html
XCHG	RAX,R64	X64	XCHG RAX, r64	Exchange Register/Memory with Register	XCHG.html
XCHG	R16,AX	8086	XCHG R16, AX	Exchange Register/Memory with Register	XCHG.html
XCHG	R32,EAX	386	XCHG R32, EAX	Exchange Register/Memory with Register	XCHG.html
XCHG	R64,RAX	X64	XCHG r64, RAX	Exchange Register/Memory with Register	XCHG.html
XCHG	EAX,EAX	386	XCHG EAX, EAX	Exchange Register/Memory with Register	XCHG.html
XCHG	R8,MEM	8086	XCHG R8, MEM	Exchange Register/Memory with Register	XCHG.html
XCHG	R8,R8	8086	XCHG R8, R8	Exchange Register/Memory with Register	XCHG.html
XCHG	R16,MEM	8086	XCHG R16, MEM	Exchange Register/Memory with Register	XCHG.html
XCHG	R16,R16	8086	XCHG R16, R16	Exchange Register/Memory with Register	XCHG.html
XCHG	R32,MEM	386	XCHG R32, MEM	Exchange Register/Memory with Register	XCHG.html
XCHG	R32,R32	386	XCHG R32, R32	Exchange Register/Memory with Register	XCHG.html
XCHG	R64,MEM	X64	XCHG r64, MEM	Exchange Register/Memory with Register	XCHG.html
XCHG	R64,R64	X64	XCHG r64, r64	Exchange Register/Memory with Register	XCHG.html
XCHG	MEM,R8	8086	XCHG MEM, R8	Exchange Register/Memory with Register	XCHG.html
XCHG	R8,R8	8086	XCHG R8, R8	Exchange Register/Memory with Register	XCHG.html
XCHG	MEM,R16	8086	XCHG MEM, R16	Exchange Register/Memory with Register	XCHG.html
XCHG	R16,R16	8086	XCHG R16, R16	Exchange Register/Memory with Register	XCHG.html
XCHG	MEM,R32	386	XCHG MEM, R32	Exchange Register/Memory with Register	XCHG.html
XCHG	R32,R32	386	XCHG R32, R32	Exchange Register/Memory with Register	XCHG.html
XCHG	MEM,R64	X64	XCHG MEM, r64	Exchange Register/Memory with Register	XCHG.html
XCHG	R64,R64	X64	XCHG r64, r64	Exchange Register/Memory with Register	XCHG.html
XLATB		8086	XLATB 	Table Look-up Translation	XLAT:XLATB.html
XLAT		8086	XLAT 	Table Look-up Translation	XLAT:XLATB.html
XOR	MEM,R8	8086	XOR MEM, R8	Logical Exclusive OR	XOR.html
XOR	R8,R8	8086	XOR R8, R8	Logical Exclusive OR	XOR.html
XOR	MEM,R16	8086	XOR MEM, R16	Logical Exclusive OR	XOR.html
XOR	R16,R16	8086	XOR R16, R16	Logical Exclusive OR	XOR.html
XOR	MEM,R32	386	XOR MEM, R32	Logical Exclusive OR	XOR.html
XOR	R32,R32	386	XOR R32, R32	Logical Exclusive OR	XOR.html
XOR	MEM,R64	X64	XOR MEM, r64	Logical Exclusive OR	XOR.html
XOR	R64,R64	X64	XOR r64, r64	Logical Exclusive OR	XOR.html
XOR	R8,MEM	8086	XOR R8, MEM	Logical Exclusive OR	XOR.html
XOR	R8,R8	8086	XOR R8, R8	Logical Exclusive OR	XOR.html
XOR	R16,MEM	8086	XOR R16, MEM	Logical Exclusive OR	XOR.html
XOR	R16,R16	8086	XOR R16, R16	Logical Exclusive OR	XOR.html
XOR	R32,MEM	386	XOR R32, MEM	Logical Exclusive OR	XOR.html
XOR	R32,R32	386	XOR R32, R32	Logical Exclusive OR	XOR.html
XOR	R64,MEM	X64	XOR r64, MEM	Logical Exclusive OR	XOR.html
XOR	R64,R64	X64	XOR r64, r64	Logical Exclusive OR	XOR.html
XOR	R/M16,IMM8	8086	XOR r/m16, IMM8	Logical Exclusive OR	XOR.html
XOR	R/M32,IMM8	386	XOR R/M32, IMM8	Logical Exclusive OR	XOR.html
XOR	R/M64,IMM8	X64	XOR r/m64, IMM8	Logical Exclusive OR	XOR.html
XOR	AL,IMM	8086	XOR AL, IMM	Logical Exclusive OR	XOR.html
XOR	AX,IMM	8086	XOR AX, IMM	Logical Exclusive OR	XOR.html
XOR	EAX,IMM	386	XOR EAX, IMM	Logical Exclusive OR	XOR.html
XOR	RAX,IMM	X64	XOR RAX, IMM	Logical Exclusive OR	XOR.html
XOR	R/M8,IMM	8086	XOR r/m8, IMM	Logical Exclusive OR	XOR.html
XOR	R/M16,IMM	8086	XOR r/m16, IMM	Logical Exclusive OR	XOR.html
XOR	R/M32,IMM	386	XOR R/M32, IMM	Logical Exclusive OR	XOR.html
XOR	R/M64,IMM	X64	XOR r/m64, IMM	Logical Exclusive OR	XOR.html
XOR	MEM,IMM8	8086	XOR MEM, IMM8	Logical Exclusive OR	XOR.html
XOR	MEM,IMM16	8086	XOR MEM, IMM16	Logical Exclusive OR	XOR.html
XOR	MEM,IMM32	386	XOR MEM, IMM32	Logical Exclusive OR	XOR.html
XOR	R/M8,IMM	8086	XOR r/m8, IMM	Logical Exclusive OR	XOR.html
;
CMOVA	R16,R/M16	P6	CMOVA R16, r/m16	Move if above (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVAE	R16,R/M16	P6	CMOVAE R16, r/m16	Move if above or equal (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVB	R16,R/M16	P6	CMOVB R16, r/m16	Move if below (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVBE	R16,R/M16	P6	CMOVBE R16, r/m16	Move if below or equal (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVE	R16,R/M16	P6	CMOVE R16, r/m16	Move if equal (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
CMOVG	R16,R/M16	P6	CMOVG R16, r/m16	Move if greater (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVGE	R16,R/M16	P6	CMOVGE R16, r/m16	Move if greater or equal (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVL	R16,R/M16	P6	CMOVL R16, r/m16	Move if less (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVLE	R16,R/M16	P6	CMOVLE R16, r/m16	Move if less or equal (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNA	R16,R/M16	P6	CMOVNA R16, r/m16	Move if not above (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVNAE	R16,R/M16	P6	CMOVNAE R16, r/m16	Move if not above or equal (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVNB	R16,R/M16	P6	CMOVNB R16, r/m16	Move if not below (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNBE	R16,R/M16	P6	CMOVNBE R16, r/m16	Move if not below or equal (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVNC	R16,R/M16	P6	CMOVNC R16, r/m16	Move if not carry (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNE	R16,R/M16	P6	CMOVNE R16, r/m16	Move if not equal (ZF=0) (CMOVNE=CMOVNZ)	CMOVcc.html
CMOVNG	R16,R/M16	P6	CMOVNG R16, r/m16	Move if not greater (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNGE	R16,R/M16	P6	CMOVNGE R16, r/m16	Move if not greater or equal (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVNL	R16,R/M16	P6	CMOVNL R16, r/m16	Move if not less (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVNLE	R16,R/M16	P6	CMOVNLE R16, r/m16	Move if not less or equal (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVNO	R16,R/M16	P6	CMOVNO R16, r/m16	Move if not overflow (OF=0)	CMOVcc.html
CMOVNP	R16,R/M16	P6	CMOVNP R16, r/m16	Move if not parity (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVNS	R16,R/M16	P6	CMOVNS R16, r/m16	Move if not sign (SF=0)	CMOVcc.html
CMOVNZ	R16,R/M16	P6	CMOVNZ R16, r/m16	Move if not zero (ZF=0 CMOVNE=CMOVNZ)	CMOVcc.html
CMOVO	R16,R/M16	P6	CMOVO R16, r/m16	Move if overflow (OF=1)	CMOVcc.html
CMOVP	R16,R/M16	P6	CMOVP R16, r/m16	Move if parity (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPE	R16,R/M16	P6	CMOVPE R16, r/m16	Move if parity even (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPO	R16,R/M16	P6	CMOVPO R16, r/m16	Move if parity odd (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVS	R16,R/M16	P6	CMOVS R16, r/m16	Move if sign (SF=1)	CMOVcc.html
CMOVZ	R16,R/M16	P6	CMOVZ R16, r/m16	Move if zero (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
;
CMOVA	R32,R/M32	P6	CMOVA R32, R/M32	Move if above (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVAE	R32,R/M32	P6	CMOVAE R32, R/M32	Move if above or equal (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVB	R32,R/M32	P6	CMOVB R32, R/M32	Move if below (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVBE	R32,R/M32	P6	CMOVBE R32, R/M32	Move if below or equal (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVE	R32,R/M32	P6	CMOVE R32, R/M32	Move if equal (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
CMOVG	R32,R/M32	P6	CMOVG R32, R/M32	Move if greater (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVGE	R32,R/M32	P6	CMOVGE R32, R/M32	Move if greater or equal (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVL	R32,R/M32	P6	CMOVL R32, R/M32	Move if less (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVLE	R32,R/M32	P6	CMOVLE R32, R/M32	Move if less or equal (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNA	R32,R/M32	P6	CMOVNA R32, R/M32	Move if not above (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVNAE	R32,R/M32	P6	CMOVNAE R32, R/M32	Move if not above or equal (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVNB	R32,R/M32	P6	CMOVNB R32, R/M32	Move if not below (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNBE	R32,R/M32	P6	CMOVNBE R32, R/M32	Move if not below or equal (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVNC	R32,R/M32	P6	CMOVNC R32, R/M32	Move if not carry (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNE	R32,R/M32	P6	CMOVNE R32, R/M32	Move if not equal (ZF=0) (CMOVNE=CMOVNZ)	CMOVcc.html
CMOVNG	R32,R/M32	P6	CMOVNG R32, R/M32	Move if not greater (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNGE	R32,R/M32	P6	CMOVNGE R32, R/M32	Move if not greater or equal (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVNL	R32,R/M32	P6	CMOVNL R32, R/M32	Move if not less (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVNLE	R32,R/M32	P6	CMOVNLE R32, R/M32	Move if not less or equal (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVNO	R32,R/M32	P6	CMOVNO R32, R/M32	Move if not overflow (OF=0)	CMOVcc.html
CMOVNP	R32,R/M32	P6	CMOVNP R32, R/M32	Move if not parity (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVNS	R32,R/M32	P6	CMOVNS R32, R/M32	Move if not sign (SF=0)	CMOVcc.html
CMOVNZ	R32,R/M32	P6	CMOVNZ R32, R/M32	Move if not zero (ZF=0 CMOVNE=CMOVNZ)	CMOVcc.html
CMOVO	R32,R/M32	P6	CMOVO R32, R/M32	Move if overflow (OF=1)	CMOVcc.html
CMOVP	R32,R/M32	P6	CMOVP R32, R/M32	Move if parity (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPE	R32,R/M32	P6	CMOVPE R32, R/M32	Move if parity even (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPO	R32,R/M32	P6	CMOVPO R32, R/M32	Move if parity odd (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVS	R32,R/M32	P6	CMOVS R32, R/M32	Move if sign (SF=1)	CMOVcc.html
CMOVZ	R32,R/M32	P6	CMOVZ R32, R/M32	Move if zero (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
;
CMOVA	R64,R/M64	X64	CMOVA r64, r/m64	Move if above (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVAE	R64,R/M64	X64	CMOVAE r64, r/m64	Move if above or equal (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVB	R64,R/M64	X64	CMOVB r64, r/m64	Move if below (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVBE	R64,R/M64	X64	CMOVBE r64, r/m64	Move if below or equal (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVE	R64,R/M64	X64	CMOVE r64, r/m64	Move if equal (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
CMOVG	R64,R/M64	X64	CMOVG r64, r/m64	Move if greater (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVGE	R64,R/M64	X64	CMOVGE r64, r/m64	Move if greater or equal (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVL	R64,R/M64	X64	CMOVL r64, r/m64	Move if less (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVLE	R64,R/M64	X64	CMOVLE r64, r/m64	Move if less or equal (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNA	R64,R/M64	X64	CMOVNA r64, r/m64	Move if not above (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVNAE	R64,R/M64	X64	CMOVNAE r64, r/m64	Move if not above or equal (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVNB	R64,R/M64	X64	CMOVNB r64, r/m64	Move if not below (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNBE	R64,R/M64	X64	CMOVNBE r64, r/m64	Move if not below or equal (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVNC	R64,R/M64	X64	CMOVNC r64, r/m64	Move if not carry (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNE	R64,R/M64	X64	CMOVNE r64, r/m64	Move if not equal (ZF=0) (CMOVNE=CMOVNZ)	CMOVcc.html
CMOVNG	R64,R/M64	X64	CMOVNG r64, r/m64	Move if not greater (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNGE	R64,R/M64	X64	CMOVNGE r64, r/m64	Move if not greater or equal (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVNL	R64,R/M64	X64	CMOVNL r64, r/m64	Move if not less (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVNLE	R64,R/M64	X64	CMOVNLE r64, r/m64	Move if not less or equal (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVNO	R64,R/M64	X64	CMOVNO r64, r/m64	Move if not overflow (OF=0)	CMOVcc.html
CMOVNP	R64,R/M64	X64	CMOVNP r64, r/m64	Move if not parity (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVNS	R64,R/M64	X64	CMOVNS r64, r/m64	Move if not sign (SF=0)	CMOVcc.html
CMOVNZ	R64,R/M64	X64	CMOVNZ r64, r/m64	Move if not zero (ZF=0 CMOVNE=CMOVNZ)	CMOVcc.html
CMOVO	R64,R/M64	X64	CMOVO r64, r/m64	Move if overflow (OF=1)	CMOVcc.html
CMOVP	R64,R/M64	X64	CMOVP r64, r/m64	Move if parity (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPE	R64,R/M64	X64	CMOVPE r64, r/m64	Move if parity even (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPO	R64,R/M64	X64	CMOVPO r64, r/m64	Move if parity odd (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVS	R64,R/M64	X64	CMOVS r64, r/m64	Move if sign (SF=1)	CMOVcc.html
CMOVZ	R64,R/M64	X64	CMOVZ r64, r/m64	Move if zero (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
;
JA	IMM|NEAR	386	JA IMM|NEAR	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	IMM|NEAR	386	JAE IMM|NEAR	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	IMM|NEAR	386	JB IMM|NEAR	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	IMM|NEAR	386	JBE IMM|NEAR	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	IMM|NEAR	386	JC IMM|NEAR	Jump if carry (CF=1)	Jcc.html
JE	IMM|NEAR	386	JE IMM|NEAR	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	IMM|NEAR	386	JG IMM|NEAR	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	IMM|NEAR	386	JGE IMM|NEAR	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	IMM|NEAR	386	JL IMM|NEAR	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	IMM|NEAR	386	JLE IMM|NEAR	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	IMM|NEAR	386	JNA IMM|NEAR	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	IMM|NEAR	386	JNAE IMM|NEAR	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	IMM|NEAR	386	JNB IMM|NEAR	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	IMM|NEAR	386	JNBE IMM|NEAR	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	IMM|NEAR	386	JNC IMM|NEAR	Jump if not carry (CF=0)	Jcc.html
JNE	IMM|NEAR	386	JNE IMM|NEAR	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	IMM|NEAR	386	JNG IMM|NEAR	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	IMM|NEAR	386	JNGE IMM|NEAR	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	IMM|NEAR	386	JNL IMM|NEAR	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	IMM|NEAR	386	JNLE IMM|NEAR	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	IMM|NEAR	386	JNO IMM|NEAR	Jump if not overflow (OF=0)	Jcc.html
JNP	IMM|NEAR	386	JNP IMM|NEAR	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	IMM|NEAR	386	JNS IMM|NEAR	Jump if not sign (SF=0)	Jcc.html
JNZ	IMM|NEAR	386	JNZ IMM|NEAR	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	IMM|NEAR	386	JO IMM|NEAR	Jump if overflow (OF=1)	Jcc.html
JP	IMM|NEAR	386	JP IMM|NEAR	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	IMM|NEAR	386	JPE IMM|NEAR	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	IMM|NEAR	386	JPO IMM|NEAR	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	IMM|NEAR	386	JS IMM|NEAR	Jump if sign (SF=1)	Jcc.html
JZ	IMM|NEAR	386	JZ IMM|NEAR	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
JA	IMM16|NEAR	386	JA IMM16|NEAR	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	IMM16|NEAR	386	JAE IMM16|NEAR	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	IMM16|NEAR	386	JB IMM16|NEAR	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	IMM16|NEAR	386	JBE IMM16|NEAR	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	IMM16|NEAR	386	JC IMM16|NEAR	Jump if carry (CF=1)	Jcc.html
JE	IMM16|NEAR	386	JE IMM16|NEAR	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	IMM16|NEAR	386	JG IMM16|NEAR	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	IMM16|NEAR	386	JGE IMM16|NEAR	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	IMM16|NEAR	386	JL IMM16|NEAR	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	IMM16|NEAR	386	JLE IMM16|NEAR	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	IMM16|NEAR	386	JNA IMM16|NEAR	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	IMM16|NEAR	386	JNAE IMM16|NEAR	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	IMM16|NEAR	386	JNB IMM16|NEAR	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	IMM16|NEAR	386	JNBE IMM16|NEAR	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	IMM16|NEAR	386	JNC IMM16|NEAR	Jump if not carry (CF=0)	Jcc.html
JNE	IMM16|NEAR	386	JNE IMM16|NEAR	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	IMM16|NEAR	386	JNG IMM16|NEAR	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	IMM16|NEAR	386	JNGE IMM16|NEAR	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	IMM16|NEAR	386	JNL IMM16|NEAR	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	IMM16|NEAR	386	JNLE IMM16|NEAR	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	IMM16|NEAR	386	JNO IMM16|NEAR	Jump if not overflow (OF=0)	Jcc.html
JNP	IMM16|NEAR	386	JNP IMM16|NEAR	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	IMM16|NEAR	386	JNS IMM16|NEAR	Jump if not sign (SF=0)	Jcc.html
JNZ	IMM16|NEAR	386	JNZ IMM16|NEAR	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	IMM16|NEAR	386	JO IMM16|NEAR	Jump if overflow (OF=1)	Jcc.html
JP	IMM16|NEAR	386	JP IMM16|NEAR	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	IMM16|NEAR	386	JPE IMM16|NEAR	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	IMM16|NEAR	386	JPO IMM16|NEAR	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	IMM16|NEAR	386	JS IMM16|NEAR	Jump if sign (SF=1)	Jcc.html
JZ	IMM16|NEAR	386	JZ IMM16|NEAR	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
JA	IMM32|NEAR	386	JA IMM32|NEAR	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	IMM32|NEAR	386	JAE IMM32|NEAR	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	IMM32|NEAR	386	JB IMM32|NEAR	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	IMM32|NEAR	386	JBE IMM32|NEAR	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	IMM32|NEAR	386	JC IMM32|NEAR	Jump if carry (CF=1)	Jcc.html
JE	IMM32|NEAR	386	JE IMM32|NEAR	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	IMM32|NEAR	386	JG IMM32|NEAR	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	IMM32|NEAR	386	JGE IMM32|NEAR	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	IMM32|NEAR	386	JL IMM32|NEAR	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	IMM32|NEAR	386	JLE IMM32|NEAR	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	IMM32|NEAR	386	JNA IMM32|NEAR	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	IMM32|NEAR	386	JNAE IMM32|NEAR	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	IMM32|NEAR	386	JNB IMM32|NEAR	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	IMM32|NEAR	386	JNBE IMM32|NEAR	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	IMM32|NEAR	386	JNC IMM32|NEAR	Jump if not carry (CF=0)	Jcc.html
JNE	IMM32|NEAR	386	JNE IMM32|NEAR	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	IMM32|NEAR	386	JNG IMM32|NEAR	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	IMM32|NEAR	386	JNGE IMM32|NEAR	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	IMM32|NEAR	386	JNL IMM32|NEAR	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	IMM32|NEAR	386	JNLE IMM32|NEAR	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	IMM32|NEAR	386	JNO IMM32|NEAR	Jump if not overflow (OF=0)	Jcc.html
JNP	IMM32|NEAR	386	JNP IMM32|NEAR	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	IMM32|NEAR	386	JNS IMM32|NEAR	Jump if not sign (SF=0)	Jcc.html
JNZ	IMM32|NEAR	386	JNZ IMM32|NEAR	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	IMM32|NEAR	386	JO IMM32|NEAR	Jump if overflow (OF=1)	Jcc.html
JP	IMM32|NEAR	386	JP IMM32|NEAR	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	IMM32|NEAR	386	JPE IMM32|NEAR	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	IMM32|NEAR	386	JPO IMM32|NEAR	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	IMM32|NEAR	386	JS IMM32|NEAR	Jump if sign (SF=1)	Jcc.html
JZ	IMM32|NEAR	386	JZ IMM32|NEAR	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
JA	IMM64|NEAR	X64	JA IMM64|NEAR	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	IMM64|NEAR	X64	JAE IMM64|NEAR	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	IMM64|NEAR	X64	JB IMM64|NEAR	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	IMM64|NEAR	X64	JBE IMM64|NEAR	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	IMM64|NEAR	X64	JC IMM64|NEAR	Jump if carry (CF=1)	Jcc.html
JE	IMM64|NEAR	X64	JE IMM64|NEAR	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	IMM64|NEAR	X64	JG IMM64|NEAR	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	IMM64|NEAR	X64	JGE IMM64|NEAR	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	IMM64|NEAR	X64	JL IMM64|NEAR	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	IMM64|NEAR	X64	JLE IMM64|NEAR	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	IMM64|NEAR	X64	JNA IMM64|NEAR	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	IMM64|NEAR	X64	JNAE IMM64|NEAR	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	IMM64|NEAR	X64	JNB IMM64|NEAR	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	IMM64|NEAR	X64	JNBE IMM64|NEAR	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	IMM64|NEAR	X64	JNC IMM64|NEAR	Jump if not carry (CF=0)	Jcc.html
JNE	IMM64|NEAR	X64	JNE IMM64|NEAR	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	IMM64|NEAR	X64	JNG IMM64|NEAR	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	IMM64|NEAR	X64	JNGE IMM64|NEAR	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	IMM64|NEAR	X64	JNL IMM64|NEAR	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	IMM64|NEAR	X64	JNLE IMM64|NEAR	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	IMM64|NEAR	X64	JNO IMM64|NEAR	Jump if not overflow (OF=0)	Jcc.html
JNP	IMM64|NEAR	X64	JNP IMM64|NEAR	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	IMM64|NEAR	X64	JNS IMM64|NEAR	Jump if not sign (SF=0)	Jcc.html
JNZ	IMM64|NEAR	X64	JNZ IMM64|NEAR	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	IMM64|NEAR	X64	JO IMM64|NEAR	Jump if overflow (OF=1)	Jcc.html
JP	IMM64|NEAR	X64	JP IMM64|NEAR	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	IMM64|NEAR	X64	JPE IMM64|NEAR	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	IMM64|NEAR	X64	JPO IMM64|NEAR	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	IMM64|NEAR	X64	JS IMM64|NEAR	Jump if sign (SF=1)	Jcc.html
JZ	IMM64|NEAR	X64	JZ IMM64|NEAR	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
JA	IMM|SHORT	8086	JA IMM|SHORT	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	IMM|SHORT	8086	JAE IMM|SHORT	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	IMM|SHORT	8086	JB IMM|SHORT	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	IMM|SHORT	8086	JBE IMM|SHORT	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	IMM|SHORT	8086	JC IMM|SHORT	Jump if carry (CF=1)	Jcc.html
JE	IMM|SHORT	8086	JE IMM|SHORT	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	IMM|SHORT	8086	JG IMM|SHORT	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	IMM|SHORT	8086	JGE IMM|SHORT	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	IMM|SHORT	8086	JL IMM|SHORT	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	IMM|SHORT	8086	JLE IMM|SHORT	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	IMM|SHORT	8086	JNA IMM|SHORT	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	IMM|SHORT	8086	JNAE IMM|SHORT	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	IMM|SHORT	8086	JNB IMM|SHORT	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	IMM|SHORT	8086	JNBE IMM|SHORT	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	IMM|SHORT	8086	JNC IMM|SHORT	Jump if not carry (CF=0)	Jcc.html
JNE	IMM|SHORT	8086	JNE IMM|SHORT	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	IMM|SHORT	8086	JNG IMM|SHORT	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	IMM|SHORT	8086	JNGE IMM|SHORT	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	IMM|SHORT	8086	JNL IMM|SHORT	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	IMM|SHORT	8086	JNLE IMM|SHORT	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	IMM|SHORT	8086	JNO IMM|SHORT	Jump if not overflow (OF=0)	Jcc.html
JNP	IMM|SHORT	8086	JNP IMM|SHORT	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	IMM|SHORT	8086	JNS IMM|SHORT	Jump if not sign (SF=0)	Jcc.html
JNZ	IMM|SHORT	8086	JNZ IMM|SHORT	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	IMM|SHORT	8086	JO IMM|SHORT	Jump if overflow (OF=1)	Jcc.html
JP	IMM|SHORT	8086	JP IMM|SHORT	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	IMM|SHORT	8086	JPE IMM|SHORT	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	IMM|SHORT	8086	JPO IMM|SHORT	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	IMM|SHORT	8086	JS IMM|SHORT	Jump if sign (SF=1)	Jcc.html
JZ	IMM|SHORT	8086	JZ IMM|SHORT	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
SETA	R/M8	386	SETA r/m8	Set byte if above (CF=0 and ZF=0) (SETA=SETNBE)	SETcc.html
SETAE	R/M8	386	SETAE r/m8	Set byte if above or equal (CF=0) (SETAE=SETNC=SETNB)	SETcc.html
SETB	R/M8	386	SETB r/m8	Set byte if below (CF=1) (SETB=SETC=SETNAE)	SETcc.html
SETBE	R/M8	386	SETBE r/m8	Set byte if below or equal (CF=1 or ZF=1) (SETBE=SETNA)	SETcc.html
SETC	R/M8	386	SETC r/m8	Set byte if carry (CF=1 SETB=SETC=SETNAE)	SETcc.html
SETE	R/M8	386	SETE r/m8	Set byte if equal (ZF=1) (SETE=SETZ)	SETcc.html
SETG	R/M8	386	SETG r/m8	Set byte if greater (ZF=0 and SF=OF) (SETG=SETNLE)	SETcc.html
SETGE	R/M8	386	SETGE r/m8	Set byte if greater or equal (SF=OF) (SETGE=SETNL)	SETcc.html
SETL	R/M8	386	SETL r/m8	Set byte if less (SF!=OF) (SETL=SETNGE)	SETcc.html
SETLE	R/M8	386	SETLE r/m8	Set byte if less or equal (ZF=1 or SF!=OF) (SETLE=SETNG)	SETcc.html
SETNA	R/M8	386	SETNA r/m8	Set byte if not above (CF=1 or ZF=1) (SETBE=SETNA)	SETcc.html
SETNAE	R/M8	386	SETNAE r/m8	Set byte if not above or equal (CF=1) (SETB=SETC=SETNAE)	SETcc.html
SETNB	R/M8	386	SETNB r/m8	Set byte if not below (CF=0) (SETAE=SETNC=SETNB)	SETcc.html
SETNBE	R/M8	386	SETNBE r/m8	Set byte if not below or equal (CF=0 and ZF=0) (SETA=SETNBE)	SETcc.html
SETNC	R/M8	386	SETNC r/m8	Set byte if not carry (CF=0) (SETAE=SETNC=SETNB)	SETcc.html
SETNE	R/M8	386	SETNE r/m8	Set byte if not equal (ZF=0) (SETNE=SETNZ)	SETcc.html
SETNG	R/M8	386	SETNG r/m8	Set byte if not greater (ZF=1 or SF!=OF) (SETLE=SETNG)	SETcc.html
SETNGE	R/M8	386	SETNGE r/m8	Set byte if not greater or equal (SF!=OF) (SETL=SETNGE)	SETcc.html
SETNL	R/M8	386	SETNL r/m8	Set byte if not less (SF=OF) (SETGE=SETNL)	SETcc.html
SETNLE	R/M8	386	SETNLE r/m8	Set byte if not less or equal (ZF=0 and SF=OF) (SETG=SETNLE)	SETcc.html
SETNO	R/M8	386	SETNO r/m8	Set byte if not overflow (OF=0)	SETcc.html
SETNP	R/M8	386	SETNP r/m8	Set byte if not parity (PF=0) (SETNP=SETPO)	SETcc.html
SETNS	R/M8	386	SETNS r/m8	Set byte if not sign (SF=0)	SETcc.html
SETNZ	R/M8	386	SETNZ r/m8	Set byte if not zero (ZF=0) (SETNE=SETNZ)	SETcc.html
SETO	R/M8	386	SETO r/m8	Set byte if overflow (OF=1)	SETcc.html
SETP	R/M8	386	SETP r/m8	Set byte if parity (PF=1) (SETP=SETPE)	SETcc.html
SETPE	R/M8	386	SETPE r/m8	Set byte if parity even (PF=1) (SETP=SETPE)	SETcc.html
SETPO	R/M8	386	SETPO r/m8	Set byte if parity odd (PF=0 SETNP=SETPO)	SETcc.html
SETS	R/M8	386	SETS r/m8	Set byte if sign (SF=1)	SETcc.html
SETZ	R/M8	386	SETZ r/m8	Set byte if zero (ZF=1) (SETE=SETZ)	SETcc.html
;
ADDPS	XMM,XMM/M128	SSE	ADDPS XMM, XMM/M128	Add Packed Single-Precision Floating-Point Values	ADDPS.html
ADDSS	XMM,XMM/M32	SSE	ADDSS XMM, XMM/m32	Add Scalar Single-Precision Floating-Point Values	ADDSS.html
ANDNPS	XMM,XMM/M128	SSE	ANDNPS XMM, XMM/M128	Bitwise Logical AND NOT of Packed Single-Precision Floating-Point Values	ANDNPS.html
ANDPS	XMM,XMM/M128	SSE	ANDPS XMM, XMM/M128	Bitwise Logical AND of Packed Single-Precision Floating-Point Values	ANDPS.html
CMPEQPS	XMM,XMM/M128	SSE	CMPEQPS XMM, XMM/M128	TODO: SSE	
CMPEQSS	XMM,XMM/M32	SSE	CMPEQSS XMM, XMM/m32	TODO: SSE	
CMPLEPS	XMM,XMM/M128	SSE	CMPLEPS XMM, XMM/M128	TODO: SSE	
CMPLESS	XMM,XMM/M32	SSE	CMPLESS XMM, XMM/m32	TODO: SSE	
CMPLTPS	XMM,XMM/M128	SSE	CMPLTPS XMM, XMM/M128	TODO: SSE	
CMPLTSS	XMM,XMM/M32	SSE	CMPLTSS XMM, XMM/m32	TODO: SSE	
CMPNEQPS	XMM,XMM/M128	SSE	CMPNEQPS XMM, XMM/M128	TODO: SSE	
CMPNEQSS	XMM,XMM/M32	SSE	CMPNEQSS XMM, XMM/m32	TODO: SSE	
CMPNLEPS	XMM,XMM/M128	SSE	CMPNLEPS XMM, XMM/M128	TODO: SSE	
CMPNLESS	XMM,XMM/M32	SSE	CMPNLESS XMM, XMM/m32	TODO: SSE	
CMPNLTPS	XMM,XMM/M128	SSE	CMPNLTPS XMM, XMM/M128	TODO: SSE	
CMPNLTSS	XMM,XMM/M32	SSE	CMPNLTSS XMM, XMM/m32	TODO: SSE	
CMPORDPS	XMM,XMM/M128	SSE	CMPORDPS XMM, XMM/M128	TODO: SSE	
CMPORDSS	XMM,XMM/M32	SSE	CMPORDSS XMM, XMM/m32	TODO: SSE	
CMPUNORDPS	XMM,XMM/M128	SSE	CMPUNORDPS XMM, XMM/M128	TODO: SSE	
CMPUNORDSS	XMM,XMM/M32	SSE	CMPUNORDSS XMM, XMM/m32	TODO: SSE	
CMPPS	XMM,MEM,IMM	SSE	CMPPS XMM, MEM, IMM	Compare Packed Single-Precision Floating-Point Values	CMPPS.html
CMPPS	XMM,XMM,IMM	SSE	CMPPS XMM, XMM, IMM	Compare Packed Single-Precision Floating-Point Values	CMPPS.html
CMPSS	XMM,MEM,IMM	SSE	CMPSS XMM, MEM, IMM	Compare Scalar Single-Precision Floating-Point Values	CMPSS.html
CMPSS	XMM,XMM,IMM	SSE	CMPSS XMM, XMM, IMM	Compare Scalar Single-Precision Floating-Point Values	CMPSS.html
COMISS	XMM,XMM/M32	SSE	COMISS XMM, XMM/m32	Compare Scalar Ordered Single-Precision Floating-Point Values and Set EFLAGS	COMISS.html
CVTPI2PS	XMM,MM/M64	SSE,MM	CVTPI2PS XMM, MM/M64	Convert Packed Dword Integers to Packed Single-Precision FP Values	CVTPI2PS.html
CVTPS2PI	MM,XMM/M64	SSE,MM	CVTPS2PI MM, XMM/m64	Convert Packed Single-Precision FP Values to Packed Dword Integers	CVTPS2PI.html
CVTSI2SS	XMM,MEM	SSE,SD	CVTSI2SS XMM, MEM	Convert Dword Integer to Scalar Single-Precision FP Value	CVTSI2SS.html
CVTSI2SS	XMM,R/M32	SSE,SD	CVTSI2SS XMM, R/M32	Convert Dword Integer to Scalar Single-Precision FP Value	CVTSI2SS.html
CVTSI2SS	XMM,R/M64	X64,SSE	CVTSI2SS XMM, r/m64	Convert Dword Integer to Scalar Single-Precision FP Value	CVTSI2SS.html
CVTSS2SI	R32,XMM	SSE,SD	CVTSS2SI R32, XMM	Convert Scalar Single-Precision FP Value to Dword Integer	CVTSS2SI.html
CVTSS2SI	R32,MEM	SSE,SD	CVTSS2SI R32, MEM	Convert Scalar Single-Precision FP Value to Dword Integer	CVTSS2SI.html
CVTSS2SI	R64,XMM	X64,SSE,SD	CVTSS2SI r64, XMM	Convert Scalar Single-Precision FP Value to Dword Integer	CVTSS2SI.html
CVTSS2SI	R64,MEM	X64,SSE,SD	CVTSS2SI r64, MEM	Convert Scalar Single-Precision FP Value to Dword Integer	CVTSS2SI.html
CVTTPS2PI	MM,XMM/MEM	SSE,MM	CVTTPS2PI MM, XMM/M128	Convert with Truncation Packed Single-Precision FP Values to Packed Dword Integers	CVTTPS2PI.html
CVTTSS2SI	R32,XMM/MEM	SSE,SD	CVTTSS2SI R32, XMM/M128	Convert with Truncation Scalar Single-Precision FP Value to Dword Integer	CVTTSS2SI.html
CVTTSS2SI	R64,XMM/MEM	X64,SSE,SD	CVTTSS2SI r64, XMM/M128	Convert with Truncation Scalar Single-Precision FP Value to Dword Integer	CVTTSS2SI.html
DIVPS	XMM,XMM/M128	SSE	DIVPS XMM, XMM/M128	Divide Packed Single-Precision Floating-Point Values	DIVPS.html
DIVSS	XMM,XMM/M32	SSE	DIVSS XMM, XMM/m32	Divide Scalar Single-Precision Floating-Point Values	DIVSS.html
LDMXCSR	M32	SSE	LDMXCSR M32	Load MXCSR Register	LDMXCSR.html
MAXPS	XMM,XMM/M128	SSE	MAXPS XMM, XMM/M128	Return Maximum Packed Single-Precision Floating-Point Values	MAXPS.html
MAXSS	XMM,XMM/M32	SSE	MAXSS XMM, XMM/m32	Return Maximum Scalar Single-Precision Floating-Point Value	MAXSS.html
MINPS	XMM,XMM/M128	SSE	MINPS XMM, XMM/M128	Return Minimum Packed Single-Precision Floating-Point Values	MINPS.html
MINSS	XMM,XMM/M32	SSE	MINSS XMM, XMM/m32	Return Minimum Scalar Single-Precision Floating-Point Value	MINSS.html
MOVAPS	XMM,XMM/M128	SSE	MOVAPS XMM, XMM/M128	Move Aligned Packed Single-Precision Floating-Point Values	MOVAPS.html
MOVAPS	XMM/M128,XMM	SSE	MOVAPS XMM/M128, XMM	Move Aligned Packed Single-Precision Floating-Point Values	MOVAPS.html
MOVHPS	XMM,M64	SSE	MOVHPS XMM, M64	Move High Packed Single-Precision Floating-Point Values	MOVHPS.html
MOVHPS	M64,XMM	SSE	MOVHPS M64, XMM	Move High Packed Single-Precision Floating-Point Values	MOVHPS.html
MOVLHPS	XMM,XMM	SSE	MOVLHPS XMM, XMM	Move Packed Single-Precision Floating-Point Values Low to High	MOVLHPS.html
MOVLPS	XMM,M64	SSE	MOVLPS XMM, M64	Move Low Packed Single-Precision Floating-Point Values	MOVLPS.html
MOVLPS	M64,XMM	SSE	MOVLPS M64, XMM	Move Low Packed Single-Precision Floating-Point Values	MOVLPS.html
MOVHLPS	XMM,XMM	SSE	MOVHLPS XMM, XMM	Move Packed Single-Precision Floating-Point Values High to Low	MOVHLPS.html
MOVMSKPS	R32,XMM	SSE	MOVMSKPS R32, XMM	Extract Packed Single-Precision Floating-Point Sign Mask	MOVMSKPS.html
MOVMSKPS	R64,XMM	X64,SSE	MOVMSKPS r64, XMM	Extract Packed Single-Precision Floating-Point Sign Mask	MOVMSKPS.html
MOVNTPS	M128,XMM	SSE	MOVNTPS M128, XMM	Store Packed Single-Precision Floating-Point Values Using Non-Temporal Hint	MOVNTPS.html
MOVSS	XMM,XMM/M32	SSE	MOVSS XMM, XMM/m32	Move Scalar Single-Precision Floating-Point Values	MOVSS.html
MOVSS	M32,XMM	SSE	MOVSS M32, XMM	Move Scalar Single-Precision Floating-Point Values	MOVSS.html
MOVSS	XMM,XMM	SSE	MOVSS XMM, XMM	Move Scalar Single-Precision Floating-Point Values	MOVSS.html
MOVUPS	XMM,XMM/M128	SSE	MOVUPS XMM, XMM/M128	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
MOVUPS	XMM/M128,XMM	SSE	MOVUPS XMM/M128, XMM	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
MULPS	XMM,XMM/M128	SSE	MULPS XMM, XMM/M128	Multiply Packed Single-Precision Floating-Point Values	MULPS.html
MULSS	XMM,XMM/M32	SSE	MULSS XMM, XMM/m32	Multiply Scalar Single-Precision Floating-Point Values	MULSS.html
ORPS	XMM,XMM/M128	SSE	ORPS XMM, XMM/M128	Bitwise Logical OR of Single-Precision Floating-Point Values	ORPS.html
RCPPS	XMM,XMM/M128	SSE	RCPPS XMM, XMM/M128	Compute Reciprocals of Packed Single-Precision Floating-Point Values	RCPPS.html
RCPSS	XMM,XMM/M32	SSE	RCPSS XMM, XMM/m32	Compute Reciprocal of Scalar Single-Precision Floating-Point Values	RCPSS.html
RSQRTPS	XMM,XMM/M128	SSE	RSQRTPS XMM, XMM/M128	Compute Reciprocals of Square Roots of Packed Single-Precision Floating-Point Values	RSQRTPS.html
RSQRTSS	XMM,XMM/M32	SSE	RSQRTSS XMM, XMM/m32	Compute Reciprocal of Square Root of Scalar Single-Precision Floating-Point Value	RSQRTSS.html
SHUFPS	XMM,XMM/M128,IMM8	SSE	SHUFPS XMM, XMM/M128, IMM8	Shuffle Packed Single-Precision Floating-Point Values	SHUFPS.html
SQRTPS	XMM,XMM/M128	SSE	SQRTPS XMM, XMM/M128	Compute Square Roots of Packed Single-Precision Floating-Point Values	SQRTPS.html
SQRTSS	XMM,XMM/M32	SSE	SQRTSS XMM, XMM/m32	Compute Square Root of Scalar Single-Precision Floating-Point Value	SQRTSS.html
STMXCSR	M32	SSE	STMXCSR M32	Store MXCSR Register State	STMXCSR.html
SUBPS	XMM,XMM/M128	SSE	SUBPS XMM, XMM/M128	Subtract Packed Single-Precision Floating-Point Values	SUBPS.html
SUBSS	XMM,XMM/M32	SSE	SUBSS XMM, XMM/m32	Subtract Scalar Single-Precision Floating-Point Values	SUBSS.html
UCOMISS	XMM,XMM/M32	SSE	UCOMISS XMM, XMM/m32	Unordered Compare Scalar Single-Precision Floating-Point Values and Set EFLAGS	UCOMISS.html
UNPCKHPS	XMM,XMM/M128	SSE	UNPCKHPS XMM, XMM/M128	Unpack and Interleave High Packed Single-Precision Floating-Point Values	UNPCKHPS.html
UNPCKLPS	XMM,XMM/M128	SSE	UNPCKLPS XMM, XMM/M128	Unpack and Interleave Low Packed Single-Precision Floating-Point Values	UNPCKLPS.html
XORPS	XMM,XMM/M128	SSE	XORPS XMM, XMM/M128	Bitwise Logical XOR for Single-Precision Floating-Point Values	XORPS.html
FXRSTOR	MEM	P6,SSE	FXRSTOR MEM	Restore x87 FPU, MM, XMM, and MXCSR State	FXRSTOR.html
FXRSTOR64	MEM	X64,SSE	FXRSTOR64 MEM	TODO: X64,SSE	
FXSAVE	MEM	P6,SSE	FXSAVE MEM	Save x87 FPU, MM Technology, and SSE State	FXSAVE.html
FXSAVE64	MEM	X64,SSE	FXSAVE64 MEM	TODO: X64,SSE	
XGETBV		NEHALEM	XGETBV 	Get Value of Extended Control Register	XGETBV.html
XSETBV		NEHALEM	XSETBV 	Set Extended Control Register	XSETBV.html
XSAVE	MEM	NEHALEM	XSAVE MEM	Save Processor Extended States	XSAVE.html
XSAVE64	MEM	LONG,NEHALEM	XSAVE64 MEM	TODO: LONG,NEHALEM	
XSAVEC	MEM	FUTURE	XSAVEC MEM	Save Processor Extended States with Compaction	XSAVEC.html
XSAVEC64	MEM	LONG,FUTURE	XSAVEC64 MEM	TODO: LONG,FUTURE	
XSAVEOPT	MEM	FUTURE	XSAVEOPT MEM	Save Processor Extended States Optimized	XSAVEOPT.html
XSAVEOPT64	MEM	LONG,FUTURE	XSAVEOPT64 MEM	TODO: LONG,FUTURE	
XSAVES	MEM	FUTURE	XSAVES MEM	Save Processor Extended States Supervisor	XSAVES.html
XSAVES64	MEM	LONG,FUTURE	XSAVES64 MEM	TODO: LONG,FUTURE	
XRSTOR	MEM	NEHALEM	XRSTOR MEM	Restore Processor Extended States	XRSTOR.html
XRSTOR64	MEM	LONG,NEHALEM	XRSTOR64 MEM	TODO: LONG,NEHALEM	
XRSTORS	MEM	FUTURE	XRSTORS MEM	Restore Processor Extended States Supervisor	XRSTORS.html
XRSTORS64	MEM	LONG,FUTURE	XRSTORS64 MEM	TODO: LONG,FUTURE	
PREFETCHNTA	M8	SSE	PREFETCHNTA M8	Move data from m8 closer to the processor using NTA hint	PREFETCHh.html
PREFETCHT0	M8	SSE	PREFETCHT0 M8	Move data from m8 closer to the processor using T0 hint	PREFETCHh.html
PREFETCHT1	M8	SSE	PREFETCHT1 M8	Move data from m8 closer to the processor using T1 hint	PREFETCHh.html
PREFETCHT2	M8	SSE	PREFETCHT2 M8	Move data from m8 closer to the processor using T2 hint	PREFETCHh.html
MASKMOVQ	MM,MM	MM	MASKMOVQ MM, MM	Store Selected Bytes of Quadword	MASKMOVQ.html
MOVNTQ	MEM,MM	MM	MOVNTQ MEM, MM	Store of Quadword Using Non-Temporal Hint	MOVNTQ.html
PAVGB	MM,MM/MEM	MM	PAVGB MM, MM/MEM	Average Packed Integers	PAVGB:PAVGW.html
PAVGB	XMM,XMM/MEM	SSE2	PAVGB XMM, XMM/M128	Average Packed Integers	PAVGB:PAVGW.html
PAVGW	MM,MM/MEM	MM	PAVGW MM, MM/MEM	Average Packed Integers	PAVGB:PAVGW.html
PAVGW	XMM,XMM/MEM	SSE2	PAVGW XMM, XMM/M128	Average Packed Integers	PAVGB:PAVGW.html
PEXTRW	R32,MM,IMM	MM	PEXTRW R32, MM, IMM	Extract Word	PEXTRW.html
PEXTRW	R32,XMM,IMM	SSE2	PEXTRW R32, XMM, IMM	Extract Word	PEXTRW.html
PEXTRW	R32,XMM,IMM	SSE41	PEXTRW R32, XMM, IMM	Extract Word	PEXTRW.html
PEXTRW	M16,XMM,IMM	SSE41	PEXTRW M16, XMM, IMM	Extract Word	PEXTRW.html
PEXTRW	R64,XMM,IMM	SSE41,X64	PEXTRW r64, XMM, IMM	Extract Word	PEXTRW.html
PINSRW	MM,MEM,IMM	MM	PINSRW MM, MEM, IMM	Insert Word	PINSRW.html
PINSRW	MM,R/M16,IMM	MM	PINSRW MM, r/m16, IMM	Insert Word	PINSRW.html
PINSRW	MM,R32,IMM	MM	PINSRW MM, R32, IMM	Insert Word	PINSRW.html
PINSRW	XMM,R16,IMM	SSE2	PINSRW XMM, R16, IMM	Insert Word	PINSRW.html
PINSRW	XMM,R32,IMM	SSE2	PINSRW XMM, R32, IMM	Insert Word	PINSRW.html
PINSRW	XMM,MEM,IMM	SSE2	PINSRW XMM, MEM, IMM	Insert Word	PINSRW.html
PINSRW	XMM,M16,IMM	SSE2	PINSRW XMM, M16, IMM	Insert Word	PINSRW.html
PMAXSW	MM,MM/MEM	MM	PMAXSW MM, MM/MEM	Maximum of Packed Signed Word Integers	PMAXSW.html
PMAXSW	XMM,XMM/MEM	SSE2	PMAXSW XMM, XMM/M128	Maximum of Packed Signed Word Integers	PMAXSW.html
PMAXUB	MM,MM/MEM	MM	PMAXUB MM, MM/MEM	Maximum of Packed Unsigned Byte Integers	PMAXUB.html
PMAXUB	XMM,XMM/MEM	SSE2	PMAXUB XMM, XMM/M128	Maximum of Packed Unsigned Byte Integers	PMAXUB.html
PMINSW	MM,MM/MEM	MM	PMINSW MM, MM/MEM	Minimum of Packed Signed Word Integers	PMINSW.html
PMINSW	XMM,XMM/MEM	SSE2	PMINSW XMM, XMM/M128	Minimum of Packed Signed Word Integers	PMINSW.html
PMINUB	MM,MM/MEM	MM	PMINUB MM, MM/MEM	Minimum of Packed Unsigned Byte Integers	PMINUB.html
PMINUB	XMM,XMM/MEM	SSE2	PMINUB XMM, XMM/M128	Minimum of Packed Unsigned Byte Integers	PMINUB.html
PMOVMSKB	R32,MM	MM	PMOVMSKB R32, MM	Move Byte Mask	PMOVMSKB.html
PMOVMSKB	R32,XMM	SSE2	PMOVMSKB R32, XMM	Move Byte Mask	PMOVMSKB.html
PMULHUW	MM,MM/MEM	MM	PMULHUW MM, MM/MEM	Multiply Packed Unsigned Integers and Store High Result	PMULHUW.html
PMULHUW	XMM,XMM/MEM	SSE2	PMULHUW XMM, XMM/M128	Multiply Packed Unsigned Integers and Store High Result	PMULHUW.html
PSADBW	MM,MM/MEM	MM	PSADBW MM, MM/MEM	Compute Sum of Absolute Differences	PSADBW.html
PSADBW	XMM,XMM/MEM	SSE2	PSADBW XMM, XMM/M128	Compute Sum of Absolute Differences	PSADBW.html
PSHUFW	MM,MM/MEM,IMM	MM	PSHUFW MM, MM/MEM, IMM	Shuffle Packed Words	PSHUFW.html
PF2IW	MM,MM/MEM	PENT,3DNOW	PF2IW MM, MM/MEM	TODO: PENT,3DNOW	
PFNACC	MM,MM/MEM	PENT,3DNOW	PFNACC MM, MM/MEM	TODO: PENT,3DNOW	
PFPNACC	MM,MM/MEM	PENT,3DNOW	PFPNACC MM, MM/MEM	TODO: PENT,3DNOW	
PI2FW	MM,MM/MEM	PENT,3DNOW	PI2FW MM, MM/MEM	TODO: PENT,3DNOW	
PSWAPD	MM,MM/MEM	PENT,3DNOW	PSWAPD MM, MM/MEM	TODO: PENT,3DNOW	
MASKMOVDQU	XMM,XMM	SSE2	MASKMOVDQU XMM, XMM	Store Selected Bytes of Double Quadword	MASKMOVDQU.html
CLFLUSH	MEM	SSE2	CLFLUSH MEM	Flush Cache Line	CLFLUSH.html
MOVNTDQ	MEM,XMM	SSE2	MOVNTDQ MEM, XMM	Store Double Quadword Using Non-Temporal Hint	MOVNTDQ.html
MOVNTI	MEM,R32	SD	MOVNTI MEM, R32	Store Doubleword Using Non-Temporal Hint	MOVNTI.html
MOVNTI	MEM,R64	X64	MOVNTI MEM, r64	Store Doubleword Using Non-Temporal Hint	MOVNTI.html
MOVNTPD	MEM,XMM	SSE2	MOVNTPD MEM, XMM	Store Packed Double-Precision Floating-Point Values Using Non-Temporal Hint	MOVNTPD.html
MOVDQA	XMM,XMM	SSE2	MOVDQA XMM, XMM	Move Aligned Double Quadword	MOVDQA.html
MOVDQA	MEM,XMM	SSE2	MOVDQA MEM, XMM	Move Aligned Double Quadword	MOVDQA.html
MOVDQA	XMM,MEM	SSE2	MOVDQA XMM, MEM	Move Aligned Double Quadword	MOVDQA.html
MOVDQA	XMM,XMM	SSE2	MOVDQA XMM, XMM	Move Aligned Double Quadword	MOVDQA.html
MOVDQU	XMM,XMM	SSE2	MOVDQU XMM, XMM	Move Unaligned Double Quadword	MOVDQU.html
MOVDQU	MEM,XMM	SSE2	MOVDQU MEM, XMM	Move Unaligned Double Quadword	MOVDQU.html
MOVDQU	XMM,MEM	SSE2	MOVDQU XMM, MEM	Move Unaligned Double Quadword	MOVDQU.html
MOVDQU	XMM,XMM	SSE2	MOVDQU XMM, XMM	Move Unaligned Double Quadword	MOVDQU.html
MOVDQ2Q	MM,XMM	SSE2	MOVDQ2Q MM, XMM	Move Quadword from XMM to MM Technology Register	MOVDQ2Q.html
MOVQ2DQ	XMM,MM	SSE2	MOVQ2DQ XMM, MM	Move Quadword from MM Technology to XMM Register	MOVQ2DQ.html
PADDQ	MM,MM/MEM	MM	PADDQ MM, MM/MEM	Add Packed Quadword Integers	PADDQ.html
PADDQ	XMM,XMM/MEM	SSE2	PADDQ XMM, XMM/M128	Add Packed Quadword Integers	PADDQ.html
PMULUDQ	MM,MM/MEM	SSE2	PMULUDQ MM, MM/MEM	Multiply Packed Unsigned Doubleword Integers	PMULUDQ.html
PMULUDQ	XMM,XMM/MEM	SSE2	PMULUDQ XMM, XMM/M128	Multiply Packed Unsigned Doubleword Integers	PMULUDQ.html
PSHUFD	XMM,XMM,IMM	SSE2	PSHUFD XMM, XMM, IMM	Shuffle Packed Doublewords	PSHUFD.html
PSHUFD	XMM,MEM,IMM	SSE2	PSHUFD XMM, MEM, IMM	Shuffle Packed Doublewords	PSHUFD.html
PSHUFHW	XMM,XMM,IMM	SSE2	PSHUFHW XMM, XMM, IMM	Shuffle Packed High Words	PSHUFHW.html
PSHUFHW	XMM,MEM,IMM	SSE2	PSHUFHW XMM, MEM, IMM	Shuffle Packed High Words	PSHUFHW.html
PSHUFLW	XMM,XMM,IMM	SSE2	PSHUFLW XMM, XMM, IMM	Shuffle Packed Low Words	PSHUFLW.html
PSHUFLW	XMM,MEM,IMM	SSE2	PSHUFLW XMM, MEM, IMM	Shuffle Packed Low Words	PSHUFLW.html
PSLLDQ	XMM,IMM	SSE2	PSLLDQ XMM, IMM	Shift Double Quadword Left Logical	PSLLDQ.html
PSRLDQ	XMM,IMM	SSE2	PSRLDQ XMM, IMM	Shift Double Quadword Right Logical	PSRLDQ.html
PSUBQ	MM,MM/MEM	SSE2	PSUBQ MM, MM/MEM	Subtract Packed Quadword Integers	PSUBQ.html
PSUBQ	XMM,XMM/MEM	SSE2	PSUBQ XMM, XMM/M128	Subtract Packed Quadword Integers	PSUBQ.html
PUNPCKHQDQ	XMM,XMM/MEM	SSE2	PUNPCKHQDQ XMM, XMM/M128	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKLQDQ	XMM,XMM/MEM	SSE2	PUNPCKLQDQ XMM, XMM/M128	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
ADDPD	XMM,XMM/MEM	SSE2	ADDPD XMM, XMM/M128	Add Packed Double-Precision Floating-Point Values	ADDPD.html
ADDSD	XMM,XMM/MEM	SSE2	ADDSD XMM, XMM/M128	Add Scalar Double-Precision Floating-Point Values	ADDSD.html
ANDNPD	XMM,XMM/MEM	SSE2	ANDNPD XMM, XMM/M128	Bitwise Logical AND NOT of Packed Double-Precision Floating-Point Values	ANDNPD.html
ANDPD	XMM,XMM/MEM	SSE2	ANDPD XMM, XMM/M128	Bitwise Logical AND of Packed Double-Precision Floating-Point Values	ANDPD.html
CMPEQPD	XMM,XMM/MEM	SSE2	CMPEQPD XMM, XMM/M128	TODO: SSE2	
CMPEQSD	XMM,XMM/MEM	SSE2	CMPEQSD XMM, XMM/M128	TODO: SSE2	
CMPLEPD	XMM,XMM/MEM	SSE2	CMPLEPD XMM, XMM/M128	TODO: SSE2	
CMPLESD	XMM,XMM/MEM	SSE2	CMPLESD XMM, XMM/M128	TODO: SSE2	
CMPLTPD	XMM,XMM/MEM	SSE2	CMPLTPD XMM, XMM/M128	TODO: SSE2	
CMPLTSD	XMM,XMM/MEM	SSE2	CMPLTSD XMM, XMM/M128	TODO: SSE2	
CMPNEQPD	XMM,XMM/MEM	SSE2	CMPNEQPD XMM, XMM/M128	TODO: SSE2	
CMPNEQSD	XMM,XMM/MEM	SSE2	CMPNEQSD XMM, XMM/M128	TODO: SSE2	
CMPNLEPD	XMM,XMM/MEM	SSE2	CMPNLEPD XMM, XMM/M128	TODO: SSE2	
CMPNLESD	XMM,XMM/MEM	SSE2	CMPNLESD XMM, XMM/M128	TODO: SSE2	
CMPNLTPD	XMM,XMM/MEM	SSE2	CMPNLTPD XMM, XMM/M128	TODO: SSE2	
CMPNLTSD	XMM,XMM/MEM	SSE2	CMPNLTSD XMM, XMM/M128	TODO: SSE2	
CMPORDPD	XMM,XMM/MEM	SSE2	CMPORDPD XMM, XMM/M128	TODO: SSE2	
CMPORDSD	XMM,XMM/MEM	SSE2	CMPORDSD XMM, XMM/M128	TODO: SSE2	
CMPUNORDPD	XMM,XMM/MEM	SSE2	CMPUNORDPD XMM, XMM/M128	TODO: SSE2	
CMPUNORDSD	XMM,XMM/MEM	SSE2	CMPUNORDSD XMM, XMM/M128	TODO: SSE2	
CMPPD	XMM,XMM/M128,IMM8	SSE2	CMPPD XMM, XMM/M128, IMM8	Compare Packed Double-Precision Floating-Point Values	CMPPD.html
COMISD	XMM,XMM/MEM	SSE2	COMISD XMM, XMM/M128	Compare Scalar Ordered Double-Precision Floating-Point Values and Set EFLAGS	COMISD.html
CVTDQ2PD	XMM,XMM/MEM	SSE2	CVTDQ2PD XMM, XMM/M128	Convert Packed Dword Integers to Packed Double-Precision FP Values	CVTDQ2PD.html
CVTDQ2PS	XMM,XMM/MEM	SSE2	CVTDQ2PS XMM, XMM/M128	Convert Packed Dword Integers to Packed Single-Precision FP Values	CVTDQ2PS.html
CVTPD2DQ	XMM,XMM/MEM	SSE2	CVTPD2DQ XMM, XMM/M128	Convert Packed Double-Precision FP Values to Packed Dword Integers	CVTPD2DQ.html
CVTPD2PI	MM,XMM/MEM	SSE2	CVTPD2PI MM, XMM/M128	Convert Packed Double-Precision FP Values to Packed Dword Integers	CVTPD2PI.html
CVTPD2PS	XMM,XMM/MEM	SSE2	CVTPD2PS XMM, XMM/M128	Convert Packed Double-Precision FP Values to Packed Single-Precision FP Values	CVTPD2PS.html
CVTPI2PD	XMM,MM/MEM	SSE2	CVTPI2PD XMM, MM/MEM	Convert Packed Dword Integers to Packed Double-Precision FP Values	CVTPI2PD.html
CVTPS2DQ	XMM,XMM/MEM	SSE2	CVTPS2DQ XMM, XMM/M128	Convert Packed Single-Precision FP Values to Packed Dword Integers	CVTPS2DQ.html
CVTPS2PD	XMM,XMM/MEM	SSE2	CVTPS2PD XMM, XMM/M128	Convert Packed Single-Precision FP Values to Packed Double-Precision FP Values	CVTPS2PD.html
CVTSD2SI	R32,XMM	SSE2	CVTSD2SI R32, XMM	Convert Scalar Double-Precision FP Value to Integer	CVTSD2SI.html
CVTSD2SI	R32,MEM	SSE2	CVTSD2SI R32, MEM	Convert Scalar Double-Precision FP Value to Integer	CVTSD2SI.html
CVTSD2SI	R64,XMM	X64,SSE2	CVTSD2SI r64, XMM	Convert Scalar Double-Precision FP Value to Integer	CVTSD2SI.html
CVTSD2SI	R64,MEM	X64,SSE2	CVTSD2SI r64, MEM	Convert Scalar Double-Precision FP Value to Integer	CVTSD2SI.html
CVTSD2SS	XMM,XMM/MEM	SSE2	CVTSD2SS XMM, XMM/M128	Convert Scalar Double-Precision FP Value to Scalar Single-Precision FP Value	CVTSD2SS.html
CVTSI2SD	XMM,MEM	SSE2,SD	CVTSI2SD XMM, MEM	Convert Dword Integer to Scalar Double-Precision FP Value	CVTSI2SD.html
CVTSI2SD	XMM,R/M32	SSE2,SD	CVTSI2SD XMM, R/M32	Convert Dword Integer to Scalar Double-Precision FP Value	CVTSI2SD.html
CVTSI2SD	XMM,R/M64	X64,SSE2	CVTSI2SD XMM, r/m64	Convert Dword Integer to Scalar Double-Precision FP Value	CVTSI2SD.html
CVTSS2SD	XMM,XMM/MEM	SSE2,SD	CVTSS2SD XMM, XMM/M128	Convert Scalar Single-Precision FP Value to Scalar Double-Precision FP Value	CVTSS2SD.html
CVTTPD2PI	MM,XMM/MEM	SSE2	CVTTPD2PI MM, XMM/M128	Convert with Truncation Packed Double-Precision FP Values to Packed Dword Integers	CVTTPD2PI.html
CVTTPD2DQ	XMM,XMM/MEM	SSE2	CVTTPD2DQ XMM, XMM/M128	Convert with Truncation Packed Double-Precision FP Values to Packed Dword Integers	CVTTPD2DQ.html
CVTTPS2DQ	XMM,XMM/MEM	SSE2	CVTTPS2DQ XMM, XMM/M128	Convert with Truncation Packed Single-Precision FP Values to Packed Dword Integers	CVTTPS2DQ.html
CVTTSD2SI	R32,XMM	SSE2	CVTTSD2SI R32, XMM	Convert with Truncation Scalar Double-Precision FP Value to Signed Integer	CVTTSD2SI.html
CVTTSD2SI	R32,MEM	SSE2	CVTTSD2SI R32, MEM	Convert with Truncation Scalar Double-Precision FP Value to Signed Integer	CVTTSD2SI.html
CVTTSD2SI	R64,XMM	X64,SSE2	CVTTSD2SI r64, XMM	Convert with Truncation Scalar Double-Precision FP Value to Signed Integer	CVTTSD2SI.html
CVTTSD2SI	R64,MEM	X64,SSE2	CVTTSD2SI r64, MEM	Convert with Truncation Scalar Double-Precision FP Value to Signed Integer	CVTTSD2SI.html
DIVPD	XMM,XMM/MEM	SSE2	DIVPD XMM, XMM/M128	Divide Packed Double-Precision Floating-Point Values	DIVPD.html
DIVSD	XMM,XMM/MEM	SSE2	DIVSD XMM, XMM/M128	Divide Scalar Double-Precision Floating-Point Values	DIVSD.html
MAXPD	XMM,XMM/MEM	SSE2	MAXPD XMM, XMM/M128	Return Maximum Packed Double-Precision Floating-Point Values	MAXPD.html
MAXSD	XMM,XMM/MEM	SSE2	MAXSD XMM, XMM/M128	Return Maximum Scalar Double-Precision Floating-Point Value	MAXSD.html
MINPD	XMM,XMM/MEM	SSE2	MINPD XMM, XMM/M128	Return Minimum Packed Double-Precision Floating-Point Values	MINPD.html
MINSD	XMM,XMM/MEM	SSE2	MINSD XMM, XMM/M128	Return Minimum Scalar Double-Precision Floating-Point Value	MINSD.html
MOVAPD	XMM,XMM	SSE2	MOVAPD XMM, XMM	Move Aligned Packed Double-Precision Floating-Point Values	MOVAPD.html
MOVAPD	XMM,XMM	SSE2	MOVAPD XMM, XMM	Move Aligned Packed Double-Precision Floating-Point Values	MOVAPD.html
MOVAPD	MEM,XMM	SSE2	MOVAPD MEM, XMM	Move Aligned Packed Double-Precision Floating-Point Values	MOVAPD.html
MOVAPD	XMM,MEM	SSE2	MOVAPD XMM, MEM	Move Aligned Packed Double-Precision Floating-Point Values	MOVAPD.html
MOVHPD	MEM,XMM	SSE2	MOVHPD MEM, XMM	Move High Packed Double-Precision Floating-Point Value	MOVHPD.html
MOVHPD	XMM,MEM	SSE2	MOVHPD XMM, MEM	Move High Packed Double-Precision Floating-Point Value	MOVHPD.html
MOVLPD	M64,XMM	SSE2	MOVLPD M64, XMM	Move Low Packed Double-Precision Floating-Point Value	MOVLPD.html
MOVLPD	XMM,M64	SSE2	MOVLPD XMM, M64	Move Low Packed Double-Precision Floating-Point Value	MOVLPD.html
MOVMSKPD	R32,XMM	SSE2	MOVMSKPD R32, XMM	Extract Packed Double-Precision Floating-Point Sign Mask	MOVMSKPD.html
MOVMSKPD	R64,XMM	X64,SSE2	MOVMSKPD r64, XMM	Extract Packed Double-Precision Floating-Point Sign Mask	MOVMSKPD.html
MOVUPD	XMM,XMM	SSE2	MOVUPD XMM, XMM	Move Unaligned Packed Double-Precision Floating-Point Values	MOVUPD.html
MOVUPD	XMM,XMM	SSE2	MOVUPD XMM, XMM	Move Unaligned Packed Double-Precision Floating-Point Values	MOVUPD.html
MOVUPD	MEM,XMM	SSE2	MOVUPD MEM, XMM	Move Unaligned Packed Double-Precision Floating-Point Values	MOVUPD.html
MOVUPD	XMM,MEM	SSE2	MOVUPD XMM, MEM	Move Unaligned Packed Double-Precision Floating-Point Values	MOVUPD.html
MULPD	XMM,XMM/MEM	SSE2	MULPD XMM, XMM/M128	Multiply Packed Double-Precision Floating-Point Values	MULPD.html
MULSD	XMM,XMM/MEM	SSE2	MULSD XMM, XMM/M128	Multiply Scalar Double-Precision Floating-Point Values	MULSD.html
ORPD	XMM,XMM/MEM	SSE2	ORPD XMM, XMM/M128	Bitwise Logical OR of Double-Precision Floating-Point Values	ORPD.html
SHUFPD	XMM,XMM,IMM	SSE2	SHUFPD XMM, XMM, IMM	Shuffle Packed Double-Precision Floating-Point Values	SHUFPD.html
SHUFPD	XMM,MEM,IMM	SSE2	SHUFPD XMM, MEM, IMM	Shuffle Packed Double-Precision Floating-Point Values	SHUFPD.html
SQRTPD	XMM,XMM/MEM	SSE2	SQRTPD XMM, XMM/M128	Compute Square Roots of Packed Double-Precision Floating-Point Values	SQRTPD.html
SQRTSD	XMM,XMM/MEM	SSE2	SQRTSD XMM, XMM/M128	Compute Square Root of Scalar Double-Precision Floating-Point Value	SQRTSD.html
SUBPD	XMM,XMM/MEM	SSE2	SUBPD XMM, XMM/M128	Subtract Packed Double-Precision Floating-Point Values	SUBPD.html
SUBSD	XMM,XMM/MEM	SSE2	SUBSD XMM, XMM/M128	Subtract Scalar Double-Precision Floating-Point Values	SUBSD.html
UCOMISD	XMM,XMM/MEM	SSE2	UCOMISD XMM, XMM/M128	Unordered Compare Scalar Double-Precision Floating-Point Values and Set EFLAGS	UCOMISD.html
UNPCKHPD	XMM,XMM/M128	SSE2	UNPCKHPD XMM, XMM/M128	Unpack and Interleave High Packed Double-Precision Floating-Point Values	UNPCKHPD.html
UNPCKLPD	XMM,XMM/M128	SSE2	UNPCKLPD XMM, XMM/M128	Unpack and Interleave Low Packed Double-Precision Floating-Point Values	UNPCKLPD.html
XORPD	XMM,XMM/M128	SSE2	XORPD XMM, XMM/M128	Bitwise Logical XOR for Double-Precision Floating-Point Values	XORPD.html
ADDSUBPD	XMM,XMM/MEM	PRESCOTT,SSE3	ADDSUBPD XMM, XMM/M128	Packed Double-FP Add/Subtract. Input: {A0,A1},{B0,B1}; Output: {A0-B0},{A1+B1}	ADDSUBPD.html
ADDSUBPS	XMM,XMM/MEM	PRESCOTT,SSE3	ADDSUBPS XMM, XMM/M128	Packed Single-FP Add/Subtract. Input: {A0,A1,A2,A3},{B0,B1,B2,B3}; Output: {A0-B0,A1+B1,A2-B2,A3+B3}	ADDSUBPS.html
HADDPD	XMM,XMM/MEM	PRESCOTT,SSE3	HADDPD XMM, XMM/M128	Packed Double-FP Horizontal Add. Input: {A0,A1},{B0,B1}; Output: {A0+A1,B0+B1}	HADDPD.html
HADDPS	XMM,XMM/MEM	PRESCOTT,SSE3	HADDPS XMM, XMM/M128	Packed Single-FP Horizontal Add. Input: {A0,A1,A2,A3},{B0,B1,B2,B3}; Output: {A0+A1,A2+A3,B0+B1,B2+B3}	HADDPS.html
HSUBPD	XMM,XMM/MEM	PRESCOTT,SSE3	HSUBPD XMM, XMM/M128	Packed Double-FP Horizontal Subtract. Input: {A0,A1},{B0,B1}; Output: {A0-A1,B0-B1}	HSUBPD.html
HSUBPS	XMM,XMM/MEM	PRESCOTT,SSE3	HSUBPS XMM, XMM/M128	Packed Single-FP Horizontal Subtract. Input: {A0,A1,A2,A3},{B0,B1,B2,B3}; Output: {A0-A1,A2-A3,B0-B1,B2-B3}	HSUBPS.html
LDDQU	XMM,MEM	PRESCOTT,SSE3	LDDQU XMM, MEM	Load Unaligned Integer 128 Bits	LDDQU.html
MOVDDUP	XMM,XMM/MEM	PRESCOTT,SSE3	MOVDDUP XMM, XMM/M128	Move One Double-FP and Duplicate	MOVDDUP.html
MOVSHDUP	XMM,XMM/MEM	PRESCOTT,SSE3	MOVSHDUP XMM, XMM/M128	Move Packed Single-FP High and Duplicate	MOVSHDUP.html
MOVSLDUP	XMM,XMM/MEM	PRESCOTT,SSE3	MOVSLDUP XMM, XMM/M128	Move Packed Single-FP Low and Duplicate	MOVSLDUP.html
CLGI		VMX,AMD	CLGI 	TODO: VMX,AMD	
STGI		VMX,AMD	STGI 	TODO: VMX,AMD	
VMCALL		VMX	VMCALL 	TODO: VMX	
VMCLEAR	MEM	VMX	VMCLEAR MEM	TODO: VMX	
VMFUNC		VMX	VMFUNC 	TODO: VMX	
VMLAUNCH		VMX	VMLAUNCH 	TODO: VMX	
VMLOAD		VMX,AMD	VMLOAD 	TODO: VMX,AMD	
VMMCALL		VMX,AMD	VMMCALL 	TODO: VMX,AMD	
VMPTRLD	MEM	VMX	VMPTRLD MEM	TODO: VMX	
VMPTRST	MEM	VMX	VMPTRST MEM	TODO: VMX	
VMREAD	R/M32,R32	VMX,SD	VMREAD R/M32, R32	TODO: VMX,SD,X64	
VMREAD	R/M64,R64	X64,VMX	VMREAD r/m64, r64	TODO: VMX,SD,X64	
VMRESUME		VMX	VMRESUME 	TODO: VMX	
VMRUN		VMX,AMD	VMRUN 	TODO: VMX,AMD	
VMSAVE		VMX,AMD	VMSAVE 	TODO: VMX,AMD	
VMWRITE	R32,R/M32	VMX,SD	VMWRITE R32, R/M32	TODO: VMX,SD,X64	
VMWRITE	R64,R/M64	X64,VMX	VMWRITE r64, r/m64	TODO: VMX,SD,X64	
VMXOFF		VMX	VMXOFF 	TODO: VMX	
VMXON	MEM	VMX	VMXON MEM	TODO: VMX	
INVEPT	R32,MEM	VMX	INVEPT R32, MEM	TODO: VMX,LONG	
INVEPT	R64,MEM	VMX,LONG	INVEPT r64, MEM	TODO: VMX,LONG	
INVVPID	R32,MEM	VMX	INVVPID R32, MEM	TODO: VMX,LONG	
INVVPID	R64,MEM	VMX,LONG	INVVPID r64, MEM	TODO: VMX,LONG	
PABSB	MM,MM/MEM	SSSE3,MM	PABSB MM, MM/MEM	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSB	XMM,XMM/MEM	SSSE3	PABSB XMM, XMM/M128	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSW	MM,MM/MEM	SSSE3,MM	PABSW MM, MM/MEM	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSW	XMM,XMM/MEM	SSSE3	PABSW XMM, XMM/M128	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSD	MM,MM/MEM	SSSE3,MM	PABSD MM, MM/MEM	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSD	XMM,XMM/MEM	SSSE3	PABSD XMM, XMM/M128	Packed Absolute Value	PABSB:PABSW:PABSD.html
PALIGNR	MM,MM/MEM,IMM	SSSE3,MM	PALIGNR MM, MM/MEM, IMM	Packed Align Right	PALIGNR.html
PALIGNR	XMM,XMM/MEM,IMM	SSSE3	PALIGNR XMM, XMM/M128, IMM	Packed Align Right	PALIGNR.html
PHADDW	MM,MM/MEM	SSSE3,MM	PHADDW MM, MM/MEM	Packed Horizontal Add	PHADDW:PHADDD.html
PHADDW	XMM,XMM/MEM	SSSE3	PHADDW XMM, XMM/M128	Packed Horizontal Add	PHADDW:PHADDD.html
PHADDD	MM,MM/MEM	SSSE3,MM	PHADDD MM, MM/MEM	Packed Horizontal Add	PHADDW:PHADDD.html
PHADDD	XMM,XMM/MEM	SSSE3	PHADDD XMM, XMM/M128	Packed Horizontal Add	PHADDW:PHADDD.html
PHADDSW	MM,MM/MEM	SSSE3,MM	PHADDSW MM, MM/MEM	Packed Horizontal Add and Saturate	PHADDSW.html
PHADDSW	XMM,XMM/MEM	SSSE3	PHADDSW XMM, XMM/M128	Packed Horizontal Add and Saturate	PHADDSW.html
PHSUBW	MM,MM/MEM	SSSE3,MM	PHSUBW MM, MM/MEM	Packed Horizontal Subtract	PHSUBW:PHSUBD.html
PHSUBW	XMM,XMM/MEM	SSSE3	PHSUBW XMM, XMM/M128	Packed Horizontal Subtract	PHSUBW:PHSUBD.html
PHSUBD	MM,MM/MEM	SSSE3,MM	PHSUBD MM, MM/MEM	Packed Horizontal Subtract	PHSUBW:PHSUBD.html
PHSUBD	XMM,XMM/MEM	SSSE3	PHSUBD XMM, XMM/M128	Packed Horizontal Subtract	PHSUBW:PHSUBD.html
PHSUBSW	MM,MM/MEM	SSSE3,MM	PHSUBSW MM, MM/MEM	Packed Horizontal Subtract and Saturate	PHSUBSW.html
PHSUBSW	XMM,XMM/MEM	SSSE3	PHSUBSW XMM, XMM/M128	Packed Horizontal Subtract and Saturate	PHSUBSW.html
PMADDUBSW	MM,MM/MEM	SSSE3,MM	PMADDUBSW MM, MM/MEM	Multiply and Add Packed Signed and Unsigned Bytes	PMADDUBSW.html
PMADDUBSW	XMM,XMM/MEM	SSSE3	PMADDUBSW XMM, XMM/M128	Multiply and Add Packed Signed and Unsigned Bytes	PMADDUBSW.html
PMULHRSW	MM,MM/MEM	SSSE3,MM	PMULHRSW MM, MM/MEM	Packed Multiply High with Round and Scale	PMULHRSW.html
PMULHRSW	XMM,XMM/MEM	SSSE3	PMULHRSW XMM, XMM/M128	Packed Multiply High with Round and Scale	PMULHRSW.html
PSHUFB	MM,MM/MEM	SSSE3,MM	PSHUFB MM, MM/MEM	Packed Shuffle Bytes	PSHUFB.html
PSHUFB	XMM,XMM/MEM	SSSE3	PSHUFB XMM, XMM/M128	Packed Shuffle Bytes	PSHUFB.html
PSIGNB	MM,MM/MEM	SSSE3,MM	PSIGNB MM, MM/MEM	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGNB	XMM,XMM/MEM	SSSE3	PSIGNB XMM, XMM/M128	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGNW	MM,MM/MEM	SSSE3,MM	PSIGNW MM, MM/MEM	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGNW	XMM,XMM/MEM	SSSE3	PSIGNW XMM, XMM/M128	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGND	MM,MM/MEM	SSSE3,MM	PSIGND MM, MM/MEM	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGND	XMM,XMM/MEM	SSSE3	PSIGND XMM, XMM/M128	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
EXTRQ	XMM,IMM,IMM	SSE4A,AMD	EXTRQ XMM, IMM, IMM	TODO: SSE4A,AMD	
EXTRQ	XMM,XMM	SSE4A,AMD	EXTRQ XMM, XMM	TODO: SSE4A,AMD	
INSERTQ	XMM,XMM,IMM,IMM	SSE4A,AMD	INSERTQ XMM, XMM, IMM, IMM	TODO: SSE4A,AMD	
INSERTQ	XMM,XMM	SSE4A,AMD	INSERTQ XMM, XMM	TODO: SSE4A,AMD	
MOVNTSD	MEM,XMM	SSE4A,AMD	MOVNTSD MEM, XMM	TODO: SSE4A,AMD	
MOVNTSS	MEM,XMM	SSE4A,AMD,SD	MOVNTSS MEM, XMM	TODO: SSE4A,AMD,SD	
LZCNT	R16,R/M16	P6,AMD	LZCNT R16, r/m16	Leading Zero Count	LZCNT.html
LZCNT	R32,R/M32	P6,AMD	LZCNT R32, R/M32	Leading Zero Count	LZCNT.html
LZCNT	R64,R/M64	X64,AMD	LZCNT r64, r/m64	Leading Zero Count	LZCNT.html
BLENDPD	XMM,XMM/MEM,IMM	SSE41	BLENDPD XMM, XMM/M128, IMM	Blend Packed Double Precision Floating-Point Values	BLENDPD.html
BLENDPS	XMM,XMM/MEM,IMM	SSE41	BLENDPS XMM, XMM/M128, IMM	Blend Packed Single Precision Floating-Point Values	BLENDPS.html
BLENDVPD	XMM,XMM/MEM,XMM_ZERO	SSE41	BLENDVPD XMM, XMM/M128, XMM_ZERO	Variable Blend Packed Double Precision Floating-Point Values	BLENDVPD.html
BLENDVPD	XMM,XMM/MEM	SSE41	BLENDVPD XMM, XMM/M128	Variable Blend Packed Double Precision Floating-Point Values	BLENDVPD.html
BLENDVPS	XMM,XMM/MEM,XMM_ZERO	SSE41	BLENDVPS XMM, XMM/M128, XMM_ZERO	Variable Blend Packed Single Precision Floating-Point Values	BLENDVPS.html
BLENDVPS	XMM,XMM/MEM	SSE41	BLENDVPS XMM, XMM/M128	Variable Blend Packed Single Precision Floating-Point Values	BLENDVPS.html
DPPD	XMM,XMM/MEM,IMM	SSE41	DPPD XMM, XMM/M128, IMM	Dot Product of Packed Double Precision Floating-Point Values	DPPD.html
DPPS	XMM,XMM/MEM,IMM	SSE41	DPPS XMM, XMM/M128, IMM	Dot Product of Packed Single Precision Floating-Point Values	DPPS.html
EXTRACTPS	R/M32,XMM,IMM	SSE41	EXTRACTPS R/M32, XMM, IMM	Extract Packed Single Precision Floating-Point Value	EXTRACTPS.html
EXTRACTPS	R64,XMM,IMM	SSE41,X64	EXTRACTPS r64, XMM, IMM	Extract Packed Single Precision Floating-Point Value	EXTRACTPS.html
INSERTPS	XMM,XMM/MEM,IMM	SSE41,SD	INSERTPS XMM, XMM/M128, IMM	Insert Packed Single Precision Floating-Point Value	INSERTPS.html
MOVNTDQA	XMM,M128	SSE41	MOVNTDQA XMM, M128	Load Double Quadword Non-Temporal Aligned Hint	MOVNTDQA.html
MPSADBW	XMM,XMM/MEM,IMM	SSE41	MPSADBW XMM, XMM/M128, IMM	Compute Multiple Packed Sums of Absolute Difference	MPSADBW.html
PACKUSDW	XMM,XMM/MEM	SSE41	PACKUSDW XMM, XMM/M128	Pack with Unsigned Saturation	PACKUSDW.html
PBLENDVB	XMM,XMM/MEM,XMM_ZERO	SSE41	PBLENDVB XMM, XMM/M128, XMM_ZERO	Variable Blend Packed Bytes	PBLENDVB.html
PBLENDVB	XMM,XMM/MEM	SSE41	PBLENDVB XMM, XMM/M128	Variable Blend Packed Bytes	PBLENDVB.html
PBLENDW	XMM,XMM/MEM,IMM	SSE41	PBLENDW XMM, XMM/M128, IMM	Blend Packed Words	PBLENDW.html
PCMPEQQ	XMM,XMM/MEM	SSE41	PCMPEQQ XMM, XMM/M128	Compare Packed Qword Data for Equal	PCMPEQQ.html
PEXTRB	R32,XMM,IMM	SSE41	PEXTRB R32, XMM, IMM	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PEXTRB	M8,XMM,IMM	SSE41	PEXTRB M8, XMM, IMM	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PEXTRB	R64,XMM,IMM	SSE41,X64	PEXTRB r64, XMM, IMM	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PEXTRD	R/M32,XMM,IMM	SSE41	PEXTRD R/M32, XMM, IMM	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PEXTRQ	R/M64,XMM,IMM	SSE41,X64	PEXTRQ r/m64, XMM, IMM	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PHMINPOSUW	XMM,XMM/MEM	SSE41	PHMINPOSUW XMM, XMM/M128	Packed Horizontal Word Minimum	PHMINPOSUW.html
PINSRB	XMM,MEM,IMM	SSE41	PINSRB XMM, MEM, IMM	Insert Byte	PINSRB:PINSRD:PINSRQ.html
PINSRB	XMM,R/M8,IMM	SSE41	PINSRB XMM, r/m8, IMM	Insert Byte	PINSRB:PINSRD:PINSRQ.html
PINSRB	XMM,R32,IMM	SSE41	PINSRB XMM, R32, IMM	Insert Byte	PINSRB:PINSRD:PINSRQ.html
PINSRD	XMM,MEM,IMM	SSE41	PINSRD XMM, MEM, IMM	Insert Dword	PINSRB:PINSRD:PINSRQ.html
PINSRD	XMM,R/M32,IMM	SSE41	PINSRD XMM, R/M32, IMM	Insert Dword	PINSRB:PINSRD:PINSRQ.html
PINSRQ	XMM,MEM,IMM	SSE41,X64	PINSRQ XMM, MEM, IMM	Insert Qword	PINSRB:PINSRD:PINSRQ.html
PINSRQ	XMM,R/M64,IMM	SSE41,X64	PINSRQ XMM, r/m64, IMM	Insert Qword	PINSRB:PINSRD:PINSRQ.html
PMAXSB	XMM,XMM/MEM	SSE41	PMAXSB XMM, XMM/M128	Maximum of Packed Signed Byte Integers	PMAXSB.html
PMAXSD	XMM,XMM/MEM	SSE41	PMAXSD XMM, XMM/M128	Maximum of Packed Signed Dword Integers	PMAXSD.html
PMAXUD	XMM,XMM/MEM	SSE41	PMAXUD XMM, XMM/M128	Maximum of Packed Unsigned Dword Integers	PMAXUD.html
PMAXUW	XMM,XMM/MEM	SSE41	PMAXUW XMM, XMM/M128	Maximum of Packed Word Integers	PMAXUW.html
PMINSB	XMM,XMM/MEM	SSE41	PMINSB XMM, XMM/M128	Minimum of Packed Signed Byte Integers	PMINSB.html
PMINSD	XMM,XMM/MEM	SSE41	PMINSD XMM, XMM/M128	Minimum of Packed Dword Integers	PMINSD.html
PMINUD	XMM,XMM/MEM	SSE41	PMINUD XMM, XMM/M128	Minimum of Packed Dword Integers	PMINUD.html
PMINUW	XMM,XMM/MEM	SSE41	PMINUW XMM, XMM/M128	Minimum of Packed Word Integers	PMINUW.html
PMOVSXBW	XMM,XMM/MEM	SSE41	PMOVSXBW XMM, XMM/M128	PMOVSXBW xmm1, xmm2/m64: Sign extend 8 packed signed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed signed 16-bit integers in xmm1	PMOVSX.html
PMOVSXBD	XMM,XMM/MEM	SSE41,SD	PMOVSXBD XMM, XMM/M128	PMOVSXBD xmm1, xmm2/m32: Sign extend 4 packed signed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed signed 32-bit integers in xmm1	PMOVSX.html
PMOVSXBQ	XMM,XMM/MEM	SSE41	PMOVSXBQ XMM, XMM/M128	PMOVSXWD xmm1, xmm2/m64: Sign extend 4 packed signed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed signed 32-bit integers in xmm1	PMOVSX.html
PMOVSXWD	XMM,XMM/MEM	SSE41	PMOVSXWD XMM, XMM/M128	PMOVSXWD xmm1, xmm2/m64: Sign extend 4 packed signed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed signed 32-bit integers in xmm1	PMOVSX.html
PMOVSXWQ	XMM,XMM/MEM	SSE41,SD	PMOVSXWQ XMM, XMM/M128	PMOVSXWQ xmm1, xmm2/m32: Sign extend 2 packed signed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed signed 64-bit integers in xmm1	PMOVSX.html
PMOVSXDQ	XMM,XMM/MEM	SSE41	PMOVSXDQ XMM, XMM/M128	PMOVSXDQ xmm1, xmm2/m64: Sign extend 2 packed signed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed signed 64-bit integers in xmm1	PMOVSX.html
PMOVZXBW	XMM,XMM/MEM	SSE41	PMOVZXBW XMM, XMM/M128	PMOVZXBW xmm1, xmm2/m64: Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1	PMOVZX.html
PMOVZXBD	XMM,XMM/MEM	SSE41,SD	PMOVZXBD XMM, XMM/M128	PMOVZXBD xmm1, xmm2/m32: Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1	PMOVZX.html
PMOVZXBQ	XMM,XMM/MEM	SSE41	PMOVZXBQ XMM, XMM/M128	PMOVZXBQ xmm1, xmm2/m16: Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1	PMOVZX.html
PMOVZXWD	XMM,XMM/MEM	SSE41	PMOVZXWD XMM, XMM/M128	PMOVZXWD xmm1, xmm2/m64: Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1	PMOVZX.html
PMOVZXWQ	XMM,XMM/MEM	SSE41,SD	PMOVZXWQ XMM, XMM/M128	PMOVZXWQ xmm1, xmm2/m32: Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1	PMOVZX.html
PMOVZXDQ	XMM,XMM/MEM	SSE41	PMOVZXDQ XMM, XMM/M128	PMOVZXDQ xmm1, xmm2/m64: Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1	PMOVZX.html
PMULDQ	XMM,XMM/MEM	SSE41	PMULDQ XMM, XMM/M128	Multiply Packed Signed Dword Integers	PMULDQ.html
PMULLD	XMM,XMM/MEM	SSE41	PMULLD XMM, XMM/M128	Multiply Packed Signed Dword Integers and Store Low Result	PMULLD.html
PTEST	XMM,XMM/MEM	SSE41	PTEST XMM, XMM/M128	Logical Compare	PTEST.html
ROUNDPD	XMM,XMM/MEM,IMM	SSE41	ROUNDPD XMM, XMM/M128, IMM	Round Packed Double Precision Floating-Point Values	ROUNDPD.html
ROUNDPS	XMM,XMM/MEM,IMM	SSE41	ROUNDPS XMM, XMM/M128, IMM	Round Packed Single Precision Floating-Point Values	ROUNDPS.html
ROUNDSD	XMM,XMM/MEM,IMM	SSE41	ROUNDSD XMM, XMM/M128, IMM	Round Scalar Double Precision Floating-Point Values	ROUNDSD.html
ROUNDSS	XMM,XMM/MEM,IMM	SSE41	ROUNDSS XMM, XMM/M128, IMM	Round Scalar Single Precision Floating-Point Values	ROUNDSS.html
CRC32	R32,R/M8	SSE42	CRC32 R32, r/m8	Accumulate CRC32 Value	CRC32.html
CRC32	R32,R/M16	SSE42	CRC32 R32, r/m16	Accumulate CRC32 Value	CRC32.html
CRC32	R32,R/M32	SSE42	CRC32 R32, R/M32	Accumulate CRC32 Value	CRC32.html
CRC32	R64,R/M8	SSE42,X64	CRC32 r64, r/m8	Accumulate CRC32 Value	CRC32.html
CRC32	R64,R/M64	SSE42,X64	CRC32 r64, r/m64	Accumulate CRC32 Value	CRC32.html
PCMPESTRI	XMM,XMM/MEM,IMM	SSE42	PCMPESTRI XMM, XMM/M128, IMM	Packed Compare Explicit Length Strings, Return Index	PCMPESTRI.html
PCMPESTRM	XMM,XMM/MEM,IMM	SSE42	PCMPESTRM XMM, XMM/M128, IMM	Packed Compare Explicit Length Strings, Return Mask	PCMPESTRM.html
PCMPISTRI	XMM,XMM/MEM,IMM	SSE42	PCMPISTRI XMM, XMM/M128, IMM	Packed Compare Implicit Length Strings, Return Index	PCMPISTRI.html
PCMPISTRM	XMM,XMM/MEM,IMM	SSE42	PCMPISTRM XMM, XMM/M128, IMM	Packed Compare Implicit Length Strings, Return Mask	PCMPISTRM.html
PCMPGTQ	XMM,XMM/MEM	SSE42	PCMPGTQ XMM, XMM/M128	Compare Packed Data for Greater Than	PCMPGTQ.html
POPCNT	R16,R/M16	NEHALEM	POPCNT R16, r/m16	Return the Count of Number of Bits Set to 1	POPCNT.html
POPCNT	R32,R/M32	NEHALEM,SD	POPCNT R32, R/M32	Return the Count of Number of Bits Set to 1	POPCNT.html
POPCNT	R64,R/M64	NEHALEM,X64	POPCNT r64, r/m64	Return the Count of Number of Bits Set to 1	POPCNT.html
GETSEC		SSE	GETSEC 	TODO: SSE	
PFRCPV	MM,MM/MEM	PENT,3DNOW,CYRIX	PFRCPV MM, MM/MEM	TODO: PENT,3DNOW,CYRIX	
PFRSQRTV	MM,MM/MEM	PENT,3DNOW,CYRIX	PFRSQRTV MM, MM/MEM	TODO: PENT,3DNOW,CYRIX	
MOVBE	R16,M16	NEHALEM	MOVBE R16, M16	Move Data After Swapping Bytes	MOVBE.html
MOVBE	R32,M32	NEHALEM	MOVBE R32, M32	Move Data After Swapping Bytes	MOVBE.html
MOVBE	R64,M64	NEHALEM	MOVBE r64, M64	Move Data After Swapping Bytes	MOVBE.html
MOVBE	M16,R16	NEHALEM	MOVBE M16, R16	Move Data After Swapping Bytes	MOVBE.html
MOVBE	M32,R32	NEHALEM	MOVBE M32, R32	Move Data After Swapping Bytes	MOVBE.html
MOVBE	M64,R64	NEHALEM	MOVBE M64, r64	Move Data After Swapping Bytes	MOVBE.html
AESENC	XMM,XMM/M128	SSE,WESTMERE	AESENC XMM, XMM/M128	Perform One Round of an AES Encryption Flow	AESENC.html
AESENCLAST	XMM,XMM/M128	SSE,WESTMERE	AESENCLAST XMM, XMM/M128	Perform Last Round of an AES Encryption Flow	AESENCLAST.html
AESDEC	XMM,XMM/M128	SSE,WESTMERE	AESDEC XMM, XMM/M128	Perform One Round of an AES Decryption Flow	AESDEC.html
AESDECLAST	XMM,XMM/M128	SSE,WESTMERE	AESDECLAST XMM, XMM/M128	Perform Last Round of an AES Decryption Flow	AESDECLAST.html
AESIMC	XMM,XMM/M128	SSE,WESTMERE	AESIMC XMM, XMM/M128	Perform the AES InvMixColumn Transformation	AESIMC.html
AESKEYGENASSIST	XMM,XMM/M128,IMM8	SSE,WESTMERE	AESKEYGENASSIST XMM, XMM/M128, IMM8	AES Round Key Generation Assist	AESKEYGENASSIST.html
VAESENC	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VAESENC XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VAESENCLAST	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VAESENCLAST XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VAESDEC	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VAESDEC XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VAESDECLAST	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VAESDECLAST XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VAESIMC	XMM,XMM/M128	AVX,SANDYBRIDGE	VAESIMC XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VAESKEYGENASSIST	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VAESKEYGENASSIST XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VADDPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VADDPD XMM, XMM, XMM/M128	Add Float64 Vectors	
VADDPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VADDPD YMM, YMM, YMM/m256	Add Float64 Vectors	
VADDPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VADDPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Add Float64 Vectors	
VADDPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VADDPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Add Float64 Vectors	
VADDPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VADDPD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Add Float64 Vectors	
VADDPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VADDPS XMM, XMM, XMM/M128	Add Float32 Vectors	
VADDPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VADDPS YMM, YMM, YMM/m256	Add Float32 Vectors	
VADDPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VADDPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Add Float32 Vectors	
VADDPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VADDPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Add Float32 Vectors	
VADDPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VADDPS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Add Float32 Vectors	
VADDSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VADDSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VADDSD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VADDSD XMM{K}{Z}, XMM, XMM/m64{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VADDSS	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VADDSS XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VADDSS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VADDSS XMM{K}{Z}, XMM, XMM/m32{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VADDSUBPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VADDSUBPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VADDSUBPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VADDSUBPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VADDSUBPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VADDSUBPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VADDSUBPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VADDSUBPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VANDPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VANDPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VANDPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VANDPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VANDPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512DQ,FUTURE	VANDPD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VANDPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VANDPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512DQ,FUTURE	VANDPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512DQ,FUTURE	VANDPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512DQ,FUTURE	VANDPS zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VANDNPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VANDNPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VANDNPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VANDNPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512DQ,FUTURE	VANDNPD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VANDNPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VANDNPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512DQ,FUTURE	VANDNPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512DQ,FUTURE	VANDNPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512DQ,FUTURE	VANDNPS zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VBLENDPD	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VBLENDPD XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VBLENDPD	YMM,YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VBLENDPD YMM, YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE	
VBLENDPS	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VBLENDPS XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VBLENDPS	YMM,YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VBLENDPS YMM, YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE	
VBLENDVPD	XMM,XMM,XMM/M128,XMM	AVX,SANDYBRIDGE	VBLENDVPD XMM, XMM, XMM/M128, XMM	TODO: AVX,SANDYBRIDGE	
VBLENDVPD	YMM,YMM,YMM/M256,YMM	AVX,SANDYBRIDGE	VBLENDVPD YMM, YMM, YMM/m256, YMM	TODO: AVX,SANDYBRIDGE	
VBLENDVPS	XMM,XMM,XMM/M128,XMM	AVX,SANDYBRIDGE	VBLENDVPS XMM, XMM, XMM/M128, XMM	TODO: AVX,SANDYBRIDGE	
VBLENDVPS	YMM,YMM,YMM/M256,YMM	AVX,SANDYBRIDGE	VBLENDVPS YMM, YMM, YMM/m256, YMM	TODO: AVX,SANDYBRIDGE	
VBROADCASTSS	XMM,M32	AVX,SANDYBRIDGE	VBROADCASTSS XMM, M32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	YMM,M32	AVX,SANDYBRIDGE	VBROADCASTSS YMM, M32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	XMM,XMM	FUTURE,AVX2	VBROADCASTSS XMM, XMM	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	YMM,XMM	FUTURE,AVX2	VBROADCASTSS YMM, XMM	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	XMM{K}{Z},M32	AVX512VL,AVX512,FUTURE	VBROADCASTSS XMM{K}{Z}, M32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	YMM{K}{Z},M32	AVX512VL,AVX512,FUTURE	VBROADCASTSS YMM{K}{Z}, M32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	ZMM{K}{Z},M32	AVX512,FUTURE	VBROADCASTSS zmm{K}{Z}, M32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VBROADCASTSS XMM{K}{Z}, XMM	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	YMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VBROADCASTSS YMM{K}{Z}, XMM	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	ZMM{K}{Z},XMM	AVX512,FUTURE	VBROADCASTSS zmm{K}{Z}, XMM	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSD	YMM,M64	AVX,SANDYBRIDGE	VBROADCASTSD YMM, M64	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	YMM,XMM	FUTURE,AVX2	VBROADCASTSD YMM, XMM	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	YMM{K}{Z},M64	AVX512VL,AVX512,FUTURE	VBROADCASTSD YMM{K}{Z}, M64	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	ZMM{K}{Z},M64	AVX512,FUTURE	VBROADCASTSD zmm{K}{Z}, M64	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	YMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VBROADCASTSD YMM{K}{Z}, XMM	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	ZMM{K}{Z},XMM	AVX512,FUTURE	VBROADCASTSD zmm{K}{Z}, XMM	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTF128	YMM,M128	AVX,SANDYBRIDGE	VBROADCASTF128 YMM, M128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQ_OSPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQ_OSPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQ_OSPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQ_OSPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLT_OSPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLT_OSPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLTPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLTPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLTPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLTPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLE_OSPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLE_OSPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLEPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLEPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLEPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLEPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPUNORD_QPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPUNORD_QPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORDPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPUNORDPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPUNORDPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPUNORDPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQ_UQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQ_UQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLT_USPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLT_USPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLTPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLTPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLTPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLTPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLE_USPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLE_USPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLEPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLEPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLEPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLEPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPORD_QPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPORD_QPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPORD_QPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPORD_QPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPORDPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPORDPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPORDPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPORDPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQ_UQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQ_UQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGE_USPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGE_USPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGEPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGEPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGEPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGEPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGT_USPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGT_USPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGTPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGTPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGTPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGTPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPFALSE_OQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPFALSE_OQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSEPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPFALSEPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPFALSEPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPFALSEPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQ_OQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQ_OQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGE_OSPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGE_OSPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGEPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGEPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGEPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGEPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGT_OSPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGT_OSPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGTPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGTPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGTPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGTPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPTRUE_UQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPTRUE_UQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUEPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPTRUEPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPTRUEPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPTRUEPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLT_OQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLT_OQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLE_OQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLE_OQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPUNORD_SPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPUNORD_SPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQ_USPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQ_USPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLT_UQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLT_UQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLE_UQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLE_UQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPORD_SPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPORD_SPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPORD_SPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPORD_SPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQ_USPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQ_USPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGE_UQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGE_UQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGT_UQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGT_UQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPFALSE_OSPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPFALSE_OSPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQ_OSPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQ_OSPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGE_OQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGE_OQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGT_OQPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGT_OQPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPTRUE_USPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPTRUE_USPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPPD	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VCMPPD XMM, XMM, XMM/M128, IMM8	Compare Float64 Vectors and Set Vector Mask	
VCMPPD	YMM,YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VCMPPD YMM, YMM, YMM/m256, IMM8	Compare Float64 Vectors and Set Vector Mask	
VCMPPD	K{K},XMM,XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VCMPPD K{K}, XMM, XMM/M128/M32BCST, IMM8	Compare Float64 Vectors and Set Vector Mask	
VCMPPD	K{K},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VCMPPD K{K}, YMM, YMM/m256/M32BCST, IMM8	Compare Float64 Vectors and Set Vector Mask	
VCMPPD	K{K},ZMM,ZMM/M512/M64BCST{SAE},IMM8	AVX512,FUTURE	VCMPPD K{K}, zmm, zmm/m512/M32BCST{SAE}, IMM8	Compare Float64 Vectors and Set Vector Mask	
VCMPEQ_OSPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQ_OSPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQ_OSPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQ_OSPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQ_OSPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLT_OSPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLT_OSPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLTPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLTPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLTPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLTPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLE_OSPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLE_OSPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLEPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLEPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLEPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLEPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPUNORD_QPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPUNORD_QPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORDPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPUNORDPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPUNORDPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPUNORDPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQ_UQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQ_UQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLT_USPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLT_USPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLTPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLTPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLTPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLTPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLE_USPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLE_USPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLEPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLEPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLEPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLEPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPORD_QPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPORD_QPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPORD_QPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPORD_QPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPORDPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPORDPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPORDPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPORDPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQ_UQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQ_UQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGE_USPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGE_USPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGEPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGEPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGEPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGEPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGT_USPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGT_USPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGTPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGTPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGTPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGTPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPFALSE_OQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPFALSE_OQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSEPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPFALSEPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPFALSEPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPFALSEPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQ_OQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQ_OQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGE_OSPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGE_OSPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGEPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGEPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGEPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGEPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGT_OSPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGT_OSPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGTPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGTPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGTPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGTPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPTRUE_UQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPTRUE_UQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUEPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPTRUEPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPTRUEPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPTRUEPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLT_OQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLT_OQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPLE_OQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPLE_OQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPUNORD_SPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPUNORD_SPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQ_USPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQ_USPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLT_UQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLT_UQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNLE_UQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNLE_UQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPORD_SPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPORD_SPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPORD_SPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPORD_SPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPEQ_USPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPEQ_USPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGE_UQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGE_UQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNGT_UQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNGT_UQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPFALSE_OSPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPFALSE_OSPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPNEQ_OSPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPNEQ_OSPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGE_OQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGE_OQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPGT_OQPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPGT_OQPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VCMPTRUE_USPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VCMPTRUE_USPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VCMPPS	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VCMPPS XMM, XMM, XMM/M128, IMM8	Compare Float32 Vectors and Set Vector Mask	
VCMPPS	YMM,YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VCMPPS YMM, YMM, YMM/m256, IMM8	Compare Float32 Vectors and Set Vector Mask	
VCMPPS	K{K},XMM,XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VCMPPS K{K}, XMM, XMM/M128/M32BCST, IMM8	Compare Float32 Vectors and Set Vector Mask	
VCMPPS	K{K},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VCMPPS K{K}, YMM, YMM/m256/M32BCST, IMM8	Compare Float32 Vectors and Set Vector Mask	
VCMPPS	K{K},ZMM,ZMM/M512/M32BCST{SAE},IMM8	AVX512,FUTURE	VCMPPS K{K}, zmm, zmm/m512/M32BCST{SAE}, IMM8	Compare Float32 Vectors and Set Vector Mask	
VCMPEQ_OSSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQ_OSSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQ_OSSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLT_OSSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLTSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLTSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLE_OSSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLESD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLESD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPUNORD_QSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORDSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPUNORDSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQ_UQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLT_USSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLTSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLTSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLE_USSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLESD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLESD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPORD_QSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPORD_QSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPORDSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPORDSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQ_UQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGE_USSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGESD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGESD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGT_USSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGTSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGTSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPFALSE_OQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSESD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPFALSESD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQ_OQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGE_OSSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGESD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGESD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGT_OSSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGTSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGTSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPTRUE_UQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUESD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPTRUESD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLT_OQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLE_OQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPUNORD_SSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQ_USSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLT_UQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLE_UQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPORD_SSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPORD_SSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQ_USSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGE_UQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGT_UQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPFALSE_OSSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQ_OSSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGE_OQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGT_OQSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPTRUE_USSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPSD	XMM,XMM,XMM/M64,IMM8	AVX,SANDYBRIDGE	VCMPSD XMM, XMM, XMM/m64, IMM8	Compare Scalar Double-Precision Floating-Point Values	CMPSD.html
VCMPSD	K{K},XMM,XMM/M64{SAE},IMM8	AVX512,FUTURE	VCMPSD K{K}, XMM, XMM/m64{SAE}, IMM8	Compare Scalar Double-Precision Floating-Point Values	CMPSD.html
VCMPEQ_OSSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQ_OSSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQ_OSSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLT_OSSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLTSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLTSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLE_OSSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLESS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLESS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPUNORD_QSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORDSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPUNORDSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQ_UQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLT_USSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLTSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLTSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLE_USSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLESS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLESS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPORD_QSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPORD_QSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPORDSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPORDSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQ_UQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGE_USSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGESS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGESS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGT_USSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGTSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGTSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPFALSE_OQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSESS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPFALSESS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQ_OQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGE_OSSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGESS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGESS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGT_OSSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGTSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGTSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPTRUE_UQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUESS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPTRUESS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLT_OQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPLE_OQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPUNORD_SSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQ_USSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLT_UQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNLE_UQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPORD_SSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPORD_SSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPEQ_USSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGE_UQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNGT_UQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPFALSE_OSSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPNEQ_OSSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGE_OQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPGT_OQSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USSS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCMPTRUE_USSS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE	
VCMPSS	XMM,XMM,XMM/M64,IMM8	AVX,SANDYBRIDGE	VCMPSS XMM, XMM, XMM/m64, IMM8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCMPSS	K{K},XMM,XMM/M32{SAE},IMM8	AVX512,FUTURE	VCMPSS K{K}, XMM, XMM/m32{SAE}, IMM8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCOMISD	XMM,XMM/M64	AVX,SANDYBRIDGE	VCOMISD XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCOMISD	XMM,XMM/M64{SAE}	AVX512,FUTURE	VCOMISD XMM, XMM/m64{SAE}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCOMISS	XMM,XMM/M32	AVX,SANDYBRIDGE	VCOMISS XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCOMISS	XMM,XMM/M32{SAE}	AVX512,FUTURE	VCOMISS XMM, XMM/m32{SAE}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTDQ2PD	XMM,XMM/M64	AVX,SANDYBRIDGE	VCVTDQ2PD XMM, XMM/m64	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PD	YMM,XMM/M128	AVX,SANDYBRIDGE	VCVTDQ2PD YMM, XMM/M128	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PD	XMM{K}{Z},XMM/M64/M32BCST	AVX512VL,AVX512,FUTURE	VCVTDQ2PD XMM{K}{Z}, XMM/m64/M32BCST	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PD	YMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VCVTDQ2PD YMM{K}{Z}, XMM/M128/M32BCST	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PD	ZMM{K}{Z},YMM/M256/M32BCST{ER}	AVX512,FUTURE	VCVTDQ2PD zmm{K}{Z}, YMM/m256/M32BCST{ER}	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PS	XMM,XMM/M128	AVX,SANDYBRIDGE	VCVTDQ2PS XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTDQ2PS	YMM,YMM/M256	AVX,SANDYBRIDGE	VCVTDQ2PS YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTDQ2PS	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VCVTDQ2PS XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTDQ2PS	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VCVTDQ2PS YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTDQ2PS	ZMM{K}{Z},ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VCVTDQ2PS zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	XMM,XMM	AVX,SANDYBRIDGE	VCVTPD2DQ XMM, XMM	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	XMM,M128	AVX,SANDYBRIDGE	VCVTPD2DQ XMM, M128	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	XMM,YMM	AVX,SANDYBRIDGE	VCVTPD2DQ XMM, YMM	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	XMM,M256	AVX,SANDYBRIDGE,SY	VCVTPD2DQ XMM, M256	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VCVTPD2DQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	XMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VCVTPD2DQ XMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	YMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VCVTPD2DQ YMM{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2PS	XMM,XMM	AVX,SANDYBRIDGE	VCVTPD2PS XMM, XMM	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	XMM,M128	AVX,SANDYBRIDGE	VCVTPD2PS XMM, M128	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	XMM,YMM	AVX,SANDYBRIDGE	VCVTPD2PS XMM, YMM	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	XMM,M256	AVX,SANDYBRIDGE,SY	VCVTPD2PS XMM, M256	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VCVTPD2PS XMM{K}{Z}, XMM/M128/M32BCST	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	XMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VCVTPD2PS XMM{K}{Z}, YMM/m256/M32BCST	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	YMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VCVTPD2PS YMM{K}{Z}, zmm/m512/M32BCST{ER}	Convert Float64 Vector to Float32 Vector	
VCVTPS2DQ	XMM,XMM/M128	AVX,SANDYBRIDGE	VCVTPS2DQ XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2DQ	YMM,YMM/M256	AVX,SANDYBRIDGE	VCVTPS2DQ YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2DQ	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VCVTPS2DQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2DQ	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VCVTPS2DQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2DQ	ZMM{K}{Z},ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VCVTPS2DQ zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2PD	XMM,XMM/M64	AVX,SANDYBRIDGE	VCVTPS2PD XMM, XMM/m64	Convert Float32 Vector to Float64 Vector	
VCVTPS2PD	YMM,XMM/M128	AVX,SANDYBRIDGE	VCVTPS2PD YMM, XMM/M128	Convert Float32 Vector to Float64 Vector	
VCVTPS2PD	XMM{K}{Z},XMM/M64/M32BCST	AVX512VL,AVX512,FUTURE	VCVTPS2PD XMM{K}{Z}, XMM/m64/M32BCST	Convert Float32 Vector to Float64 Vector	
VCVTPS2PD	YMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VCVTPS2PD YMM{K}{Z}, XMM/M128/M32BCST	Convert Float32 Vector to Float64 Vector	
VCVTPS2PD	ZMM{K}{Z},YMM/M256/M32BCST{SAE}	AVX512,FUTURE	VCVTPS2PD zmm{K}{Z}, YMM/m256/M32BCST{SAE}	Convert Float32 Vector to Float64 Vector	
VCVTSD2SI	R32,XMM/M64	AVX,SANDYBRIDGE	VCVTSD2SI R32, XMM/m64	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSD2SI	R64,XMM/M64	AVX,SANDYBRIDGE,LONG	VCVTSD2SI r64, XMM/m64	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSD2SI	R32,XMM/M64{ER}	AVX512,FUTURE	VCVTSD2SI R32, XMM/m64{ER}	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSD2SI	R64,XMM/M64{ER}	AVX512,FUTURE	VCVTSD2SI r64, XMM/m64{ER}	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSD2SS	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VCVTSD2SS XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTSD2SS	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VCVTSD2SS XMM{K}{Z}, XMM, XMM/m64{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTSI2SD	XMM,XMM,R/M32	AVX,SANDYBRIDGE,SD	VCVTSI2SD XMM, XMM, R/M32	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSI2SD	XMM,XMM,M32	AVX,SANDYBRIDGE,SD	VCVTSI2SD XMM, XMM, M32	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSI2SD	XMM,XMM,R/M64	AVX,SANDYBRIDGE,LONG	VCVTSI2SD XMM, XMM, r/m64	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSI2SD	XMM,XMM{ER},R/M32	AVX512,FUTURE	VCVTSI2SD XMM, XMM{ER}, R/M32	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSI2SD	XMM,XMM{ER},R/M64	AVX512,FUTURE	VCVTSI2SD XMM, XMM{ER}, r/m64	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSI2SS	XMM,XMM,R/M32	AVX,SANDYBRIDGE,SD	VCVTSI2SS XMM, XMM, R/M32	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSI2SS	XMM,XMM,M32	AVX,SANDYBRIDGE,SD	VCVTSI2SS XMM, XMM, M32	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSI2SS	XMM,XMM,R/M64	AVX,SANDYBRIDGE,LONG	VCVTSI2SS XMM, XMM, r/m64	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSI2SS	XMM,XMM{ER},R/M32	AVX512,FUTURE	VCVTSI2SS XMM, XMM{ER}, R/M32	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSI2SS	XMM,XMM{ER},R/M64	AVX512,FUTURE	VCVTSI2SS XMM, XMM{ER}, r/m64	TODO: AVX,SANDYBRIDGE,SD,LONG,AVX512,FUTURE	
VCVTSS2SD	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VCVTSS2SD XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTSS2SD	XMM{K}{Z},XMM,XMM/M32{SAE}	AVX512,FUTURE	VCVTSS2SD XMM{K}{Z}, XMM, XMM/m32{SAE}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTSS2SI	R32,XMM/M32	AVX,SANDYBRIDGE	VCVTSS2SI R32, XMM/m32	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSS2SI	R64,XMM/M32	AVX,SANDYBRIDGE,LONG	VCVTSS2SI r64, XMM/m32	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSS2SI	R32,XMM/M32{ER}	AVX512,FUTURE	VCVTSS2SI R32, XMM/m32{ER}	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSS2SI	R64,XMM/M32{ER}	AVX512,FUTURE	VCVTSS2SI r64, XMM/m32{ER}	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTPD2DQ	XMM,XMM	AVX,SANDYBRIDGE	VCVTTPD2DQ XMM, XMM	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	XMM,M128	AVX,SANDYBRIDGE	VCVTTPD2DQ XMM, M128	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	XMM,YMM	AVX,SANDYBRIDGE	VCVTTPD2DQ XMM, YMM	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	XMM,M256	AVX,SANDYBRIDGE,SY	VCVTTPD2DQ XMM, M256	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VCVTTPD2DQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	XMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VCVTTPD2DQ XMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	YMM{K}{Z},ZMM/M512/M64BCST{SAE}	AVX512,FUTURE	VCVTTPD2DQ YMM{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX,SANDYBRIDGE,SY,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	XMM,XMM/M128	AVX,SANDYBRIDGE	VCVTTPS2DQ XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	YMM,YMM/M256	AVX,SANDYBRIDGE	VCVTTPS2DQ YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VCVTTPS2DQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VCVTTPS2DQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	ZMM{K}{Z},ZMM/M512/M32BCST{SAE}	AVX512,FUTURE	VCVTTPS2DQ zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTSD2SI	R32,XMM/M64	AVX,SANDYBRIDGE	VCVTTSD2SI R32, XMM/m64	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSD2SI	R64,XMM/M64	AVX,SANDYBRIDGE,LONG	VCVTTSD2SI r64, XMM/m64	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSD2SI	R32,XMM/M64{SAE}	AVX512,FUTURE	VCVTTSD2SI R32, XMM/m64{SAE}	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSD2SI	R64,XMM/M64{SAE}	AVX512,FUTURE	VCVTTSD2SI r64, XMM/m64{SAE}	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSS2SI	R32,XMM/M32	AVX,SANDYBRIDGE	VCVTTSS2SI R32, XMM/m32	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSS2SI	R64,XMM/M32	AVX,SANDYBRIDGE,LONG	VCVTTSS2SI r64, XMM/m32	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSS2SI	R32,XMM/M32{SAE}	AVX512,FUTURE	VCVTTSS2SI R32, XMM/m32{SAE}	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSS2SI	R64,XMM/M32{SAE}	AVX512,FUTURE	VCVTTSS2SI r64, XMM/m32{SAE}	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VDIVPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VDIVPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VDIVPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VDIVPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VDIVPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VDIVPD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VDIVPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VDIVPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VDIVPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VDIVPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VDIVPS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VDIVSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VDIVSD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VDIVSD XMM{K}{Z}, XMM, XMM/m64{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VDIVSS	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VDIVSS XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VDIVSS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VDIVSS XMM{K}{Z}, XMM, XMM/m32{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VDPPD	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VDPPD XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VDPPS	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VDPPS XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VDPPS	YMM,YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VDPPS YMM, YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE	
VEXTRACTF128	XMM/M128,YMM,IMM8	AVX,SANDYBRIDGE	VEXTRACTF128 XMM/M128, YMM, IMM8	Extract Packed Floating-Point Values	VEXTRACTF128.html
VEXTRACTPS	R/M32,XMM,IMM8	AVX,SANDYBRIDGE	VEXTRACTPS R/M32, XMM, IMM8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VEXTRACTPS	R32,XMM,IMM8	AVX512,FUTURE	VEXTRACTPS R32, XMM, IMM8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VEXTRACTPS	R64,XMM,IMM8	AVX512,FUTURE	VEXTRACTPS r64, XMM, IMM8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VEXTRACTPS	M32,XMM,IMM8	AVX512,FUTURE	VEXTRACTPS M32, XMM, IMM8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VHADDPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VHADDPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VHADDPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VHADDPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VHADDPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VHADDPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VHADDPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VHADDPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VHSUBPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VHSUBPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VHSUBPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VHSUBPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VHSUBPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VHSUBPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VHSUBPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VHSUBPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VINSERTF128	YMM,YMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VINSERTF128 YMM, YMM, XMM/M128, IMM8	Insert Packed Floating-Point Values	VINSERTF128.html
VINSERTPS	XMM,XMM,XMM/M32,IMM8	AVX,SANDYBRIDGE	VINSERTPS XMM, XMM, XMM/m32, IMM8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VINSERTPS	XMM,XMM,XMM/M32,IMM8	AVX512,FUTURE	VINSERTPS XMM, XMM, XMM/m32, IMM8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VLDDQU	XMM,M128	AVX,SANDYBRIDGE	VLDDQU XMM, M128	TODO: AVX,SANDYBRIDGE	
VLDDQU	YMM,M256	AVX,SANDYBRIDGE	VLDDQU YMM, M256	TODO: AVX,SANDYBRIDGE	
VLDQQU	YMM,M256	AVX,SANDYBRIDGE	VLDQQU YMM, M256	TODO: AVX,SANDYBRIDGE	
VLDMXCSR	M32	AVX,SANDYBRIDGE	VLDMXCSR M32	TODO: AVX,SANDYBRIDGE	
VMASKMOVDQU	XMM,XMM	AVX,SANDYBRIDGE	VMASKMOVDQU XMM, XMM	TODO: AVX,SANDYBRIDGE	
VMASKMOVPS	XMM,XMM,M128	AVX,SANDYBRIDGE	VMASKMOVPS XMM, XMM, M128	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPS	YMM,YMM,M256	AVX,SANDYBRIDGE	VMASKMOVPS YMM, YMM, M256	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPS	M128,XMM,XMM	AVX,SANDYBRIDGE	VMASKMOVPS M128, XMM, XMM	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPS	M256,YMM,YMM	AVX,SANDYBRIDGE,SY	VMASKMOVPS M256, YMM, YMM	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPD	XMM,XMM,M128	AVX,SANDYBRIDGE	VMASKMOVPD XMM, XMM, M128	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPD	YMM,YMM,M256	AVX,SANDYBRIDGE	VMASKMOVPD YMM, YMM, M256	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPD	M128,XMM,XMM	AVX,SANDYBRIDGE	VMASKMOVPD M128, XMM, XMM	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPD	M256,YMM,YMM	AVX,SANDYBRIDGE	VMASKMOVPD M256, YMM, YMM	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMAXPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VMAXPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VMAXPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VMAXPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VMAXPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{SAE}	AVX512,FUTURE	VMAXPD zmm{K}{Z}, zmm, zmm/m512/M32BCST{SAE}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VMAXPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VMAXPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VMAXPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VMAXPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{SAE}	AVX512,FUTURE	VMAXPS zmm{K}{Z}, zmm, zmm/m512/M32BCST{SAE}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VMAXSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMAXSD	XMM{K}{Z},XMM,XMM/M64{SAE}	AVX512,FUTURE	VMAXSD XMM{K}{Z}, XMM, XMM/m64{SAE}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMAXSS	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VMAXSS XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMAXSS	XMM{K}{Z},XMM,XMM/M32{SAE}	AVX512,FUTURE	VMAXSS XMM{K}{Z}, XMM, XMM/m32{SAE}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMINPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VMINPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VMINPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VMINPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VMINPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{SAE}	AVX512,FUTURE	VMINPD zmm{K}{Z}, zmm, zmm/m512/M32BCST{SAE}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VMINPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VMINPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VMINPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VMINPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{SAE}	AVX512,FUTURE	VMINPS zmm{K}{Z}, zmm, zmm/m512/M32BCST{SAE}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VMINSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMINSD	XMM{K}{Z},XMM,XMM/M64{SAE}	AVX512,FUTURE	VMINSD XMM{K}{Z}, XMM, XMM/m64{SAE}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMINSS	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VMINSS XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMINSS	XMM{K}{Z},XMM,XMM/M32{SAE}	AVX512,FUTURE	VMINSS XMM{K}{Z}, XMM, XMM/m32{SAE}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVAPD	XMM,XMM/M128	AVX,SANDYBRIDGE	VMOVAPD XMM, XMM/M128	Move Aligned Float64 Vector	
VMOVAPD	XMM/M128,XMM	AVX,SANDYBRIDGE	VMOVAPD XMM/M128, XMM	Move Aligned Float64 Vector	
VMOVAPD	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVAPD YMM, YMM/m256	Move Aligned Float64 Vector	
VMOVAPD	YMM/M256,YMM	AVX,SANDYBRIDGE	VMOVAPD YMM/m256, YMM	Move Aligned Float64 Vector	
VMOVAPD	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVAPD XMM{K}{Z}, XMM/M128	Move Aligned Float64 Vector	
VMOVAPD	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVAPD YMM{K}{Z}, YMM/m256	Move Aligned Float64 Vector	
VMOVAPD	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVAPD zmm{K}{Z}, zmm/m512	Move Aligned Float64 Vector	
VMOVAPD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VMOVAPD XMM{K}{Z}, XMM	Move Aligned Float64 Vector	
VMOVAPD	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VMOVAPD YMM{K}{Z}, YMM	Move Aligned Float64 Vector	
VMOVAPD	ZMM{K}{Z},ZMM	AVX512,FUTURE	VMOVAPD zmm{K}{Z}, zmm	Move Aligned Float64 Vector	
VMOVAPD	M128{K},XMM	AVX512VL,AVX512,FUTURE	VMOVAPD M128{K}, XMM	Move Aligned Float64 Vector	
VMOVAPD	M256{K},YMM	AVX512VL,AVX512,FUTURE	VMOVAPD M256{K}, YMM	Move Aligned Float64 Vector	
VMOVAPD	M512{K},ZMM	AVX512,FUTURE	VMOVAPD M512{K}, zmm	Move Aligned Float64 Vector	
VMOVAPS	XMM,XMM/M128	AVX,SANDYBRIDGE	VMOVAPS XMM, XMM/M128	Move Aligned Float32 Vector	
VMOVAPS	XMM/M128,XMM	AVX,SANDYBRIDGE	VMOVAPS XMM/M128, XMM	Move Aligned Float32 Vector	
VMOVAPS	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVAPS YMM, YMM/m256	Move Aligned Float32 Vector	
VMOVAPS	YMM/M256,YMM	AVX,SANDYBRIDGE	VMOVAPS YMM/m256, YMM	Move Aligned Float32 Vector	
VMOVAPS	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVAPS XMM{K}{Z}, XMM/M128	Move Aligned Float32 Vector	
VMOVAPS	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVAPS YMM{K}{Z}, YMM/m256	Move Aligned Float32 Vector	
VMOVAPS	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVAPS zmm{K}{Z}, zmm/m512	Move Aligned Float32 Vector	
VMOVAPS	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VMOVAPS XMM{K}{Z}, XMM	Move Aligned Float32 Vector	
VMOVAPS	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VMOVAPS YMM{K}{Z}, YMM	Move Aligned Float32 Vector	
VMOVAPS	ZMM{K}{Z},ZMM	AVX512,FUTURE	VMOVAPS zmm{K}{Z}, zmm	Move Aligned Float32 Vector	
VMOVAPS	M128{K},XMM	AVX512VL,AVX512,FUTURE	VMOVAPS M128{K}, XMM	Move Aligned Float32 Vector	
VMOVAPS	M256{K},YMM	AVX512VL,AVX512,FUTURE	VMOVAPS M256{K}, YMM	Move Aligned Float32 Vector	
VMOVAPS	M512{K},ZMM	AVX512,FUTURE	VMOVAPS M512{K}, zmm	Move Aligned Float32 Vector	
VMOVD	XMM,R/M32	AVX,SANDYBRIDGE	VMOVD XMM, R/M32	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVD	R/M32,XMM	AVX,SANDYBRIDGE	VMOVD R/M32, XMM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVD	XMM,R/M32	AVX512,FUTURE	VMOVD XMM, R/M32	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVD	R/M32,XMM	AVX512,FUTURE	VMOVD R/M32, XMM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	XMM,XMM/M64	AVX,SANDYBRIDGE	VMOVQ XMM, XMM/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	XMM/M64,XMM	AVX,SANDYBRIDGE	VMOVQ XMM/m64, XMM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	XMM,R/M64	AVX,SANDYBRIDGE,LONG	VMOVQ XMM, r/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	R/M64,XMM	AVX,SANDYBRIDGE,LONG	VMOVQ r/m64, XMM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	XMM,R/M64	AVX512,FUTURE	VMOVQ XMM, r/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	R/M64,XMM	AVX512,FUTURE	VMOVQ r/m64, XMM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	XMM,XMM/M64	AVX512,FUTURE	VMOVQ XMM, XMM/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	XMM/M64,XMM	AVX512,FUTURE	VMOVQ XMM/m64, XMM	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVDDUP	XMM,XMM/M64	AVX,SANDYBRIDGE	VMOVDDUP XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDDUP	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVDDUP YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDDUP	XMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VMOVDDUP XMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDDUP	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVDDUP YMM{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDDUP	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVDDUP zmm{K}{Z}, zmm/m512	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDQA	XMM,XMM/M128	AVX,SANDYBRIDGE	VMOVDQA XMM, XMM/M128	Move Aligned Double Quadword	MOVDQA.html
VMOVDQA	XMM/M128,XMM	AVX,SANDYBRIDGE	VMOVDQA XMM/M128, XMM	Move Aligned Double Quadword	MOVDQA.html
VMOVDQA	YMM,ymmrm	AVX,SANDYBRIDGE	VMOVDQA YMM, YMM/m256	Move Aligned Double Quadword	MOVDQA.html
VMOVDQA	YMM/M256,YMM	AVX,SANDYBRIDGE	VMOVDQA YMM/m256, YMM	Move Aligned Double Quadword	MOVDQA.html
VMOVQQA	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVQQA YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VMOVQQA	YMM/M256,YMM	AVX,SANDYBRIDGE	VMOVQQA YMM/m256, YMM	TODO: AVX,SANDYBRIDGE	
VMOVDQU	XMM,XMM/M128	AVX,SANDYBRIDGE	VMOVDQU XMM, XMM/M128	Move Unaligned Double Quadword	MOVDQU.html
VMOVDQU	XMM/M128,XMM	AVX,SANDYBRIDGE	VMOVDQU XMM/M128, XMM	Move Unaligned Double Quadword	MOVDQU.html
VMOVDQU	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVDQU YMM, YMM/m256	Move Unaligned Double Quadword	MOVDQU.html
VMOVDQU	YMM/M256,YMM	AVX,SANDYBRIDGE	VMOVDQU YMM/m256, YMM	Move Unaligned Double Quadword	MOVDQU.html
VMOVQQU	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVQQU YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VMOVQQU	YMM/M256,YMM	AVX,SANDYBRIDGE	VMOVQQU YMM/m256, YMM	TODO: AVX,SANDYBRIDGE	
VMOVHLPS	XMM,XMM,XMM	AVX,SANDYBRIDGE	VMOVHLPS XMM, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHLPS	XMM,XMM,XMM	AVX512,FUTURE	VMOVHLPS XMM, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPD	XMM,XMM,M64	AVX,SANDYBRIDGE	VMOVHPD XMM, XMM, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPD	M64,XMM	AVX,SANDYBRIDGE	VMOVHPD M64, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPD	XMM,XMM,M64	AVX512,FUTURE	VMOVHPD XMM, XMM, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPD	M64,XMM	AVX512,FUTURE	VMOVHPD M64, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPS	XMM,XMM,M64	AVX,SANDYBRIDGE	VMOVHPS XMM, XMM, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPS	M64,XMM	AVX,SANDYBRIDGE	VMOVHPS M64, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPS	XMM,XMM,M64	AVX512,FUTURE	VMOVHPS XMM, XMM, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPS	M64,XMM	AVX512,FUTURE	VMOVHPS M64, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLHPS	XMM,XMM,XMM	AVX,SANDYBRIDGE	VMOVLHPS XMM, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLHPS	XMM,XMM,XMM	AVX512,FUTURE	VMOVLHPS XMM, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPD	XMM,XMM,M64	AVX,SANDYBRIDGE	VMOVLPD XMM, XMM, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPD	M64,XMM	AVX,SANDYBRIDGE	VMOVLPD M64, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPD	XMM,XMM,M64	AVX512,FUTURE	VMOVLPD XMM, XMM, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPD	M64,XMM	AVX512,FUTURE	VMOVLPD M64, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPS	XMM,XMM,M64	AVX,SANDYBRIDGE	VMOVLPS XMM, XMM, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPS	M64,XMM	AVX,SANDYBRIDGE	VMOVLPS M64, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPS	XMM,XMM,M64	AVX512,FUTURE	VMOVLPS XMM, XMM, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPS	M64,XMM	AVX512,FUTURE	VMOVLPS M64, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVMSKPD	R64,XMM	AVX,SANDYBRIDGE,LONG	VMOVMSKPD r64, XMM	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPD	R32,XMM	AVX,SANDYBRIDGE	VMOVMSKPD R32, XMM	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPD	R64,YMM	AVX,SANDYBRIDGE,LONG	VMOVMSKPD r64, YMM	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPD	R32,YMM	AVX,SANDYBRIDGE	VMOVMSKPD R32, YMM	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPS	R64,XMM	AVX,SANDYBRIDGE,LONG	VMOVMSKPS r64, XMM	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPS	R32,XMM	AVX,SANDYBRIDGE	VMOVMSKPS R32, XMM	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPS	R64,YMM	AVX,SANDYBRIDGE,LONG	VMOVMSKPS r64, YMM	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPS	R32,YMM	AVX,SANDYBRIDGE	VMOVMSKPS R32, YMM	TODO: AVX,SANDYBRIDGE,LONG	
VMOVNTDQ	M128,XMM	AVX,SANDYBRIDGE	VMOVNTDQ M128, XMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTDQ	M256,YMM	AVX,SANDYBRIDGE	VMOVNTDQ M256, YMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTDQ	M128,XMM	AVX512VL,AVX512,FUTURE	VMOVNTDQ M128, XMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTDQ	M256,YMM	AVX512VL,AVX512,FUTURE	VMOVNTDQ M256, YMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTDQ	M512,ZMM	AVX512,FUTURE	VMOVNTDQ M512, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTQQ	M256,YMM	AVX,SANDYBRIDGE	VMOVNTQQ M256, YMM	TODO: AVX,SANDYBRIDGE	
VMOVNTDQA	XMM,M128	AVX,SANDYBRIDGE	VMOVNTDQA XMM, M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTDQA	YMM,M256	FUTURE,AVX2	VMOVNTDQA YMM, M256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTDQA	XMM,M128	AVX512VL,AVX512,FUTURE	VMOVNTDQA XMM, M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTDQA	YMM,M256	AVX512VL,AVX512,FUTURE	VMOVNTDQA YMM, M256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTDQA	ZMM,M512	AVX512,FUTURE	VMOVNTDQA zmm, M512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTPD	M128,XMM	AVX,SANDYBRIDGE	VMOVNTPD M128, XMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPD	M256,YMM	AVX,SANDYBRIDGE	VMOVNTPD M256, YMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPD	M128,XMM	AVX512VL,AVX512,FUTURE	VMOVNTPD M128, XMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPD	M256,YMM	AVX512VL,AVX512,FUTURE	VMOVNTPD M256, YMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPD	M512,ZMM	AVX512,FUTURE	VMOVNTPD M512, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	M128,XMM	AVX,SANDYBRIDGE	VMOVNTPS M128, XMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	M256,YMM	AVX,SANDYBRIDGE	VMOVNTPS M256, YMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	M128,XMM	AVX512VL,AVX512,FUTURE	VMOVNTPS M128, XMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	M256,YMM	AVX512VL,AVX512,FUTURE	VMOVNTPS M256, YMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	M512,ZMM	AVX512,FUTURE	VMOVNTPS M512, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSD	XMM,XMM,XMM	AVX,SANDYBRIDGE	VMOVSD XMM, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	XMM,M64	AVX,SANDYBRIDGE	VMOVSD XMM, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	XMM,XMM,XMM	AVX,SANDYBRIDGE	VMOVSD XMM, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	M64,XMM	AVX,SANDYBRIDGE	VMOVSD M64, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	XMM{K}{Z},M64	AVX512,FUTURE	VMOVSD XMM{K}{Z}, M64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	M64{K},XMM	AVX512,FUTURE	VMOVSD M64{K}, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	XMM{K}{Z},XMM,XMM	AVX512,FUTURE	VMOVSD XMM{K}{Z}, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	XMM{K}{Z},XMM,XMM	AVX512,FUTURE	VMOVSD XMM{K}{Z}, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSHDUP	XMM,XMM/M128	AVX,SANDYBRIDGE	VMOVSHDUP XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSHDUP	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVSHDUP YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSHDUP	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVSHDUP XMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSHDUP	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVSHDUP YMM{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSHDUP	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVSHDUP zmm{K}{Z}, zmm/m512	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	XMM,XMM/M128	AVX,SANDYBRIDGE	VMOVSLDUP XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVSLDUP YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVSLDUP XMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVSLDUP YMM{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVSLDUP zmm{K}{Z}, zmm/m512	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSS	XMM,XMM,XMM	AVX,SANDYBRIDGE	VMOVSS XMM, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	XMM,M32	AVX,SANDYBRIDGE	VMOVSS XMM, M32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	XMM,XMM,XMM	AVX,SANDYBRIDGE	VMOVSS XMM, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	M32,XMM	AVX,SANDYBRIDGE	VMOVSS M32, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	XMM{K}{Z},M32	AVX512,FUTURE	VMOVSS XMM{K}{Z}, M32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	M32{K},XMM	AVX512,FUTURE	VMOVSS M32{K}, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	XMM{K}{Z},XMM,XMM	AVX512,FUTURE	VMOVSS XMM{K}{Z}, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	XMM{K}{Z},XMM,XMM	AVX512,FUTURE	VMOVSS XMM{K}{Z}, XMM, XMM	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVUPD	XMM,XMM/M128	AVX,SANDYBRIDGE	VMOVUPD XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	XMM/M128,XMM	AVX,SANDYBRIDGE	VMOVUPD XMM/M128, XMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVUPD YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	YMM/M256,YMM	AVX,SANDYBRIDGE	VMOVUPD YMM/m256, YMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVUPD XMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVUPD YMM{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVUPD zmm{K}{Z}, zmm/m512	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VMOVUPD XMM{K}{Z}, XMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VMOVUPD YMM{K}{Z}, YMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	ZMM{K}{Z},ZMM	AVX512,FUTURE	VMOVUPD zmm{K}{Z}, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	M128{K},XMM	AVX512VL,AVX512,FUTURE	VMOVUPD M128{K}, XMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	M256{K},YMM	AVX512VL,AVX512,FUTURE	VMOVUPD M256{K}, YMM	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	M512{K},ZMM	AVX512,FUTURE	VMOVUPD M512{K}, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPS	XMM,XMM/M128	AVX,SANDYBRIDGE	VMOVUPS XMM, XMM/M128	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	XMM/M128,XMM	AVX,SANDYBRIDGE	VMOVUPS XMM/M128, XMM	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	YMM,YMM/M256	AVX,SANDYBRIDGE	VMOVUPS YMM, YMM/m256	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	YMM/M256,YMM	AVX,SANDYBRIDGE	VMOVUPS YMM/m256, YMM	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVUPS XMM{K}{Z}, XMM/M128	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVUPS YMM{K}{Z}, YMM/m256	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVUPS zmm{K}{Z}, zmm/m512	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VMOVUPS XMM{K}{Z}, XMM	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VMOVUPS YMM{K}{Z}, YMM	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	ZMM{K}{Z},ZMM	AVX512,FUTURE	VMOVUPS zmm{K}{Z}, zmm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	M128{K},XMM	AVX512VL,AVX512,FUTURE	VMOVUPS M128{K}, XMM	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	M256{K},YMM	AVX512VL,AVX512,FUTURE	VMOVUPS M256{K}, YMM	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	M512{K},ZMM	AVX512,FUTURE	VMOVUPS M512{K}, zmm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMPSADBW	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VMPSADBW XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VMPSADBW	YMM,YMM,YMM/M256,IMM8	FUTURE,AVX2	VMPSADBW YMM, YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VMULPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VMULPD XMM, XMM, XMM/M128	Multiply Float64 Vectors	
VMULPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VMULPD YMM, YMM, YMM/m256	Multiply Float64 Vectors	
VMULPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VMULPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Float64 Vectors	
VMULPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VMULPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Float64 Vectors	
VMULPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VMULPD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Float64 Vectors	
VMULPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VMULPS XMM, XMM, XMM/M128	Multiply Float32 Vectors	
VMULPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VMULPS YMM, YMM, YMM/m256	Multiply Float32 Vectors	
VMULPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VMULPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Float32 Vectors	
VMULPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VMULPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Float32 Vectors	
VMULPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VMULPS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Float32 Vectors	
VMULSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VMULSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMULSD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VMULSD XMM{K}{Z}, XMM, XMM/m64{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMULSS	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VMULSS XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMULSS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VMULSS XMM{K}{Z}, XMM, XMM/m32{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VORPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VORPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VORPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VORPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VORPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512DQ,FUTURE	VORPD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VORPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VORPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512DQ,FUTURE	VORPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512DQ,FUTURE	VORPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512DQ,FUTURE	VORPS zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VPABSB	XMM,XMM/M128	AVX,SANDYBRIDGE	VPABSB XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSB	YMM,YMM/M256	FUTURE,AVX2	VPABSB YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSB	XMM{K}{Z},XMM/M128	AVX512VL,AVX512BW,FUTURE	VPABSB XMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSB	YMM{K}{Z},YMM/M256	AVX512VL,AVX512BW,FUTURE	VPABSB YMM{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSB	ZMM{K}{Z},ZMM/M512	AVX512BW,FUTURE	VPABSB zmm{K}{Z}, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	XMM,XMM/M128	AVX,SANDYBRIDGE	VPABSW XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	YMM,YMM/M256	FUTURE,AVX2	VPABSW YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	XMM{K}{Z},XMM/M128	AVX512VL,AVX512BW,FUTURE	VPABSW XMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	YMM{K}{Z},YMM/M256	AVX512VL,AVX512BW,FUTURE	VPABSW YMM{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	ZMM{K}{Z},ZMM/M512	AVX512BW,FUTURE	VPABSW zmm{K}{Z}, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSD	XMM,XMM/M128	AVX,SANDYBRIDGE	VPABSD XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPABSD	YMM,YMM/M256	FUTURE,AVX2	VPABSD YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPABSD	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPABSD XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPABSD	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPABSD YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPABSD	ZMM{K}{Z},ZMM/M512/M32BCST	AVX512,FUTURE	VPABSD zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPACKSSWB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPACKSSWB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSWB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPACKSSWB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSWB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPACKSSWB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSWB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPACKSSWB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSWB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPACKSSWB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPACKSSDW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPACKSSDW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512BW,FUTURE	VPACKSSDW XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512BW,FUTURE	VPACKSSDW YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512BW,FUTURE	VPACKSSDW zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPACKUSWB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPACKUSWB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPACKUSWB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPACKUSWB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPACKUSWB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPACKUSDW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPACKUSDW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512BW,FUTURE	VPACKUSDW XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512BW,FUTURE	VPACKUSDW YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512BW,FUTURE	VPACKUSDW zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPADDB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPADDB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPADDB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPADDB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPADDB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPADDW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPADDW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPADDW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPADDW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPADDW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPADDD XMM, XMM, XMM/M128	Add Int32 Vectors	
VPADDD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPADDD YMM, YMM, YMM/m256	Add Int32 Vectors	
VPADDD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPADDD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Add Int32 Vectors	
VPADDD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPADDD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Add Int32 Vectors	
VPADDD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPADDD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Add Int32 Vectors	
VPADDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPADDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPADDQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPADDQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPADDQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPADDQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDSB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPADDSB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPADDSB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPADDSB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPADDSB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPADDSB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPADDSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPADDSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPADDSW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPADDSW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPADDSW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPADDUSB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPADDUSB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPADDUSB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPADDUSB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPADDUSB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPADDUSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPADDUSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPADDUSW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPADDUSW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPADDUSW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPALIGNR XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	YMM,YMM,YMM/M256,IMM8	FUTURE,AVX2	VPALIGNR YMM, YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	XMM{K}{Z},XMM,XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPALIGNR XMM{K}{Z}, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	YMM{K}{Z},YMM,YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPALIGNR YMM{K}{Z}, YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	ZMM{K}{Z},ZMM,ZMM/M512,IMM8	AVX512BW,FUTURE	VPALIGNR zmm{K}{Z}, zmm, zmm/m512, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAND	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPAND XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPAND	YMM,YMM,YMM/M256	FUTURE,AVX2	VPAND YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPANDN	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPANDN XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPANDN	YMM,YMM,YMM/M256	FUTURE,AVX2	VPANDN YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPAVGB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPAVGB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPAVGB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPAVGB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPAVGB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPAVGB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPAVGW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPAVGW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPAVGW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPAVGW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPAVGW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPBLENDVB	XMM,XMM,XMM/M128,XMM	AVX,SANDYBRIDGE	VPBLENDVB XMM, XMM, XMM/M128, XMM	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPBLENDVB	YMM,YMM,YMM/M256,YMM	FUTURE,AVX2	VPBLENDVB YMM, YMM, YMM/m256, YMM	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPBLENDW	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPBLENDW XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPBLENDW	YMM,YMM,YMM/M256,IMM8	FUTURE,AVX2	VPBLENDW YMM, YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPCMPESTRI	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPCMPESTRI XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VPCMPESTRM	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPCMPESTRM XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VPCMPISTRI	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPCMPISTRI XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VPCMPISTRM	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPCMPISTRM XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VPCMPEQB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCMPEQB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPCMPEQB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQB	K{K},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPCMPEQB K{K}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQB	K{K},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPCMPEQB K{K}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQB	K{K},ZMM,ZMM/M512	AVX512BW,FUTURE	VPCMPEQB K{K}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCMPEQW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPCMPEQW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	K{K},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPCMPEQW K{K}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	K{K},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPCMPEQW K{K}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	K{K},ZMM,ZMM/M512	AVX512BW,FUTURE	VPCMPEQW K{K}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCMPEQD XMM, XMM, XMM/M128	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPCMPEQD YMM, YMM, YMM/m256	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQD	K{K},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPCMPEQD K{K}, XMM, XMM/M128/M32BCST	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQD	K{K},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPCMPEQD K{K}, YMM, YMM/m256/M32BCST	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQD	K{K},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPCMPEQD K{K}, zmm, zmm/m512/M32BCST	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCMPEQQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPEQQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPCMPEQQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPEQQ	K{K},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPCMPEQQ K{K}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPEQQ	K{K},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPCMPEQQ K{K}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPEQQ	K{K},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPCMPEQQ K{K}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCMPGTB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPCMPGTB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTB	K{K},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPCMPGTB K{K}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTB	K{K},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPCMPGTB K{K}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTB	K{K},ZMM,ZMM/M512	AVX512BW,FUTURE	VPCMPGTB K{K}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCMPGTW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPCMPGTW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	K{K},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPCMPGTW K{K}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	K{K},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPCMPGTW K{K}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	K{K},ZMM,ZMM/M512	AVX512BW,FUTURE	VPCMPGTW K{K}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCMPGTD XMM, XMM, XMM/M128	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPCMPGTD YMM, YMM, YMM/m256	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTD	K{K},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPCMPGTD K{K}, XMM, XMM/M128/M32BCST	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTD	K{K},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPCMPGTD K{K}, YMM, YMM/m256/M32BCST	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTD	K{K},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPCMPGTD K{K}, zmm, zmm/m512/M32BCST	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCMPGTQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPCMPGTQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTQ	K{K},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPCMPGTQ K{K}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTQ	K{K},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPCMPGTQ K{K}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTQ	K{K},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPCMPGTQ K{K}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPERMILPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPERMILPD XMM, XMM, XMM/M128	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VPERMILPD YMM, YMM, YMM/m256	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPERMILPD XMM, XMM/M128, IMM8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VPERMILPD YMM, YMM/m256, IMM8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	XMM{K}{Z},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPERMILPD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPERMILPD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	ZMM{K}{Z},ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPERMILPD zmm{K}{Z}, zmm/m512/M32BCST, IMM8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPERMILPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPERMILPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPERMILPD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPERMILPS XMM, XMM, XMM/M128	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VPERMILPS YMM, YMM, YMM/m256	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPERMILPS XMM, XMM/M128, IMM8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VPERMILPS YMM, YMM/m256, IMM8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPERMILPS XMM{K}{Z}, XMM/M128/M32BCST, IMM8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPERMILPS YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	ZMM{K}{Z},ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPERMILPS zmm{K}{Z}, zmm/m512/M32BCST, IMM8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPERMILPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPERMILPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPERMILPS zmm{K}{Z}, zmm, zmm/m512/M32BCST	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERM2F128	YMM,YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VPERM2F128 YMM, YMM, YMM/m256, IMM8	Permute Floating-Point Values	VPERM2F128.html
VPEXTRB	R64,XMM,IMM8	AVX,SANDYBRIDGE,LONG	VPEXTRB r64, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	R32,XMM,IMM8	AVX,SANDYBRIDGE	VPEXTRB R32, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	M8,XMM,IMM8	AVX,SANDYBRIDGE	VPEXTRB M8, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	R8,XMM,IMM8	AVX512BW,FUTURE	VPEXTRB R8, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	R16,XMM,IMM8	AVX512BW,FUTURE	VPEXTRB R16, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	R32,XMM,IMM8	AVX512BW,FUTURE	VPEXTRB R32, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	R64,XMM,IMM8	AVX512BW,FUTURE	VPEXTRB r64, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	M8,XMM,IMM8	AVX512BW,FUTURE	VPEXTRB M8, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRW	R64,XMM,IMM8	AVX,SANDYBRIDGE,LONG	VPEXTRW r64, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	R32,XMM,IMM8	AVX,SANDYBRIDGE	VPEXTRW R32, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	R64,XMM,IMM8	AVX,SANDYBRIDGE,LONG	VPEXTRW r64, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	R32,XMM,IMM8	AVX,SANDYBRIDGE	VPEXTRW R32, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	M16,XMM,IMM8	AVX,SANDYBRIDGE	VPEXTRW M16, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	R16,XMM,IMM8	AVX512BW,FUTURE	VPEXTRW R16, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	R32,XMM,IMM8	AVX512BW,FUTURE	VPEXTRW R32, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	R64,XMM,IMM8	AVX512BW,FUTURE	VPEXTRW r64, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	M16,XMM,IMM8	AVX512BW,FUTURE	VPEXTRW M16, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	R16,XMM,IMM8	AVX512BW,FUTURE	VPEXTRW R16, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	R32,XMM,IMM8	AVX512BW,FUTURE	VPEXTRW R32, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRW	R64,XMM,IMM8	AVX512BW,FUTURE	VPEXTRW r64, XMM, IMM8	Extract Word	PEXTRW.html
VPEXTRD	R64,XMM,IMM8	AVX,SANDYBRIDGE,LONG	VPEXTRD r64, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRD	R/M32,XMM,IMM8	AVX,SANDYBRIDGE	VPEXTRD R/M32, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRD	R/M32,XMM,IMM8	AVX512DQ,FUTURE	VPEXTRD R/M32, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRQ	R/M64,XMM,IMM8	AVX,SANDYBRIDGE,LONG	VPEXTRQ r/m64, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRQ	R/M64,XMM,IMM8	AVX512DQ,FUTURE	VPEXTRQ r/m64, XMM, IMM8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPHADDW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPHADDW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPHADDW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPHADDD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPHADDD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPHADDSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPHADDSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHMINPOSUW	XMM,XMM/M128	AVX,SANDYBRIDGE	VPHMINPOSUW XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VPHSUBW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPHSUBW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPHSUBW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPHSUBD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPHSUBD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPHSUBSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPHSUBSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPINSRB	XMM,XMM,M8,IMM8	AVX,SANDYBRIDGE	VPINSRB XMM, XMM, M8, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRB	XMM,XMM,R/M8,IMM8	AVX,SANDYBRIDGE	VPINSRB XMM, XMM, r/m8, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRB	XMM,XMM,R32,IMM8	AVX,SANDYBRIDGE	VPINSRB XMM, XMM, R32, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRB	XMM,XMM,R32,IMM8	AVX512BW,FUTURE	VPINSRB XMM, XMM, R32, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRB	XMM,XMM,M8,IMM8	AVX512BW,FUTURE	VPINSRB XMM, XMM, M8, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	XMM,XMM,M16,IMM8	AVX,SANDYBRIDGE	VPINSRW XMM, XMM, M16, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	XMM,XMM,R/M16,IMM8	AVX,SANDYBRIDGE	VPINSRW XMM, XMM, r/m16, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	XMM,XMM,R32,IMM8	AVX,SANDYBRIDGE	VPINSRW XMM, XMM, R32, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	XMM,XMM,R32,IMM8	AVX512BW,FUTURE	VPINSRW XMM, XMM, R32, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	XMM,XMM,M16,IMM8	AVX512BW,FUTURE	VPINSRW XMM, XMM, M16, IMM8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRD	XMM,XMM,M32,IMM8	AVX,SANDYBRIDGE	VPINSRD XMM, XMM, M32, IMM8	TODO: AVX,SANDYBRIDGE,AVX512DQ,FUTURE	
VPINSRD	XMM,XMM,R/M32,IMM8	AVX,SANDYBRIDGE	VPINSRD XMM, XMM, R/M32, IMM8	TODO: AVX,SANDYBRIDGE,AVX512DQ,FUTURE	
VPINSRD	XMM,XMM,R/M32,IMM8	AVX512DQ,FUTURE	VPINSRD XMM, XMM, R/M32, IMM8	TODO: AVX,SANDYBRIDGE,AVX512DQ,FUTURE	
VPINSRQ	XMM,XMM,M64,IMM8	AVX,SANDYBRIDGE,LONG	VPINSRQ XMM, XMM, M64, IMM8	TODO: AVX,SANDYBRIDGE,LONG,AVX512DQ,FUTURE	
VPINSRQ	XMM,XMM,R/M64,IMM8	AVX,SANDYBRIDGE,LONG	VPINSRQ XMM, XMM, r/m64, IMM8	TODO: AVX,SANDYBRIDGE,LONG,AVX512DQ,FUTURE	
VPINSRQ	XMM,XMM,R/M64,IMM8	AVX512DQ,FUTURE	VPINSRQ XMM, XMM, r/m64, IMM8	TODO: AVX,SANDYBRIDGE,LONG,AVX512DQ,FUTURE	
VPMADDWD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMADDWD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDWD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMADDWD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDWD	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMADDWD XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDWD	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMADDWD YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDWD	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMADDWD zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMADDUBSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMADDUBSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMADDUBSW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMADDUBSW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMADDUBSW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMAXSB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMAXSB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMAXSB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMAXSB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMAXSB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMAXSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMAXSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMAXSW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMAXSW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMAXSW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMAXSD XMM, XMM, XMM/M128	Maximum of Int32 Vectors	
VPMAXSD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMAXSD YMM, YMM, YMM/m256	Maximum of Int32 Vectors	
VPMAXSD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPMAXSD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Maximum of Int32 Vectors	
VPMAXSD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPMAXSD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Maximum of Int32 Vectors	
VPMAXSD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPMAXSD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Maximum of Int32 Vectors	
VPMAXUB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMAXUB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMAXUB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMAXUB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMAXUB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMAXUB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMAXUW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMAXUW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMAXUW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMAXUW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMAXUW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMAXUD XMM, XMM, XMM/M128	Maximum of Uint32 Vectors	
VPMAXUD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMAXUD YMM, YMM, YMM/m256	Maximum of Uint32 Vectors	
VPMAXUD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPMAXUD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Maximum of Uint32 Vectors	
VPMAXUD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPMAXUD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Maximum of Uint32 Vectors	
VPMAXUD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPMAXUD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Maximum of Uint32 Vectors	
VPMINSB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMINSB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMINSB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMINSB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMINSB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMINSB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMINSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMINSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMINSW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMINSW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMINSW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMINSD XMM, XMM, XMM/M128	Minimum of Int32 Vectors	
VPMINSD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMINSD YMM, YMM, YMM/m256	Minimum of Int32 Vectors	
VPMINSD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPMINSD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Minimum of Int32 Vectors	
VPMINSD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPMINSD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Minimum of Int32 Vectors	
VPMINSD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPMINSD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Minimum of Int32 Vectors	
VPMINUB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMINUB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMINUB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMINUB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMINUB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMINUB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMINUW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMINUW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMINUW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMINUW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMINUW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMINUD XMM, XMM, XMM/M128	Minimum of Uint32 Vectors	
VPMINUD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMINUD YMM, YMM, YMM/m256	Minimum of Uint32 Vectors	
VPMINUD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPMINUD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Minimum of Uint32 Vectors	
VPMINUD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPMINUD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Minimum of Uint32 Vectors	
VPMINUD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPMINUD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Minimum of Uint32 Vectors	
VPMOVMSKB	R64,XMM	AVX,SANDYBRIDGE,LONG	VPMOVMSKB r64, XMM	TODO: AVX,SANDYBRIDGE,LONG,FUTURE,AVX2	
VPMOVMSKB	R32,XMM	AVX,SANDYBRIDGE	VPMOVMSKB R32, XMM	TODO: AVX,SANDYBRIDGE,LONG,FUTURE,AVX2	
VPMOVMSKB	R32,YMM	FUTURE,AVX2	VPMOVMSKB R32, YMM	TODO: AVX,SANDYBRIDGE,LONG,FUTURE,AVX2	
VPMOVMSKB	R64,YMM	FUTURE,AVX2	VPMOVMSKB r64, YMM	TODO: AVX,SANDYBRIDGE,LONG,FUTURE,AVX2	
VPMOVSXBW	XMM,XMM/M64	AVX,SANDYBRIDGE	VPMOVSXBW XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBW	YMM,XMM/M128	FUTURE,AVX2	VPMOVSXBW YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBW	XMM{K}{Z},XMM/M64	AVX512VL,AVX512BW,FUTURE	VPMOVSXBW XMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBW	YMM{K}{Z},XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMOVSXBW YMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBW	ZMM{K}{Z},YMM/M256	AVX512BW,FUTURE	VPMOVSXBW zmm{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBD	XMM,XMM/M32	AVX,SANDYBRIDGE	VPMOVSXBD XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	YMM,M64	FUTURE,AVX2	VPMOVSXBD YMM, M64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	YMM,XMM	FUTURE,AVX2	VPMOVSXBD YMM, XMM	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	XMM{K}{Z},XMM/M32	AVX512VL,AVX512,FUTURE	VPMOVSXBD XMM{K}{Z}, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	YMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VPMOVSXBD YMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	ZMM{K}{Z},XMM/M128	AVX512,FUTURE	VPMOVSXBD zmm{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	XMM,xmmrm16	AVX,SANDYBRIDGE	VPMOVSXBQ XMM, XMM/m16	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	YMM,M32	FUTURE,AVX2	VPMOVSXBQ YMM, M32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	YMM,XMM	FUTURE,AVX2	VPMOVSXBQ YMM, XMM	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	XMM{K}{Z},xmmrm16	AVX512VL,AVX512,FUTURE	VPMOVSXBQ XMM{K}{Z}, XMM/m16	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	YMM{K}{Z},XMM/M32	AVX512VL,AVX512,FUTURE	VPMOVSXBQ YMM{K}{Z}, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	ZMM{K}{Z},XMM/M64	AVX512,FUTURE	VPMOVSXBQ zmm{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	XMM,XMM/M64	AVX,SANDYBRIDGE	VPMOVSXWD XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	YMM,XMM/M128	FUTURE,AVX2	VPMOVSXWD YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	XMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VPMOVSXWD XMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	YMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VPMOVSXWD YMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	ZMM{K}{Z},YMM/M256	AVX512,FUTURE	VPMOVSXWD zmm{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	XMM,XMM/M32	AVX,SANDYBRIDGE	VPMOVSXWQ XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	YMM,M64	FUTURE,AVX2	VPMOVSXWQ YMM, M64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	YMM,XMM	FUTURE,AVX2	VPMOVSXWQ YMM, XMM	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	XMM{K}{Z},XMM/M32	AVX512VL,AVX512,FUTURE	VPMOVSXWQ XMM{K}{Z}, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	YMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VPMOVSXWQ YMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	ZMM{K}{Z},XMM/M128	AVX512,FUTURE	VPMOVSXWQ zmm{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	XMM,XMM/M64	AVX,SANDYBRIDGE	VPMOVSXDQ XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	YMM,XMM/M128	FUTURE,AVX2	VPMOVSXDQ YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	XMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VPMOVSXDQ XMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	YMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VPMOVSXDQ YMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	ZMM{K}{Z},YMM/M256	AVX512,FUTURE	VPMOVSXDQ zmm{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBW	XMM,XMM/M64	AVX,SANDYBRIDGE	VPMOVZXBW XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBW	YMM,XMM/M128	FUTURE,AVX2	VPMOVZXBW YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBW	XMM{K}{Z},XMM/M64	AVX512VL,AVX512BW,FUTURE	VPMOVZXBW XMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBW	YMM{K}{Z},XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMOVZXBW YMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBW	ZMM{K}{Z},YMM/M256	AVX512BW,FUTURE	VPMOVZXBW zmm{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBD	XMM,XMM/M32	AVX,SANDYBRIDGE	VPMOVZXBD XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	YMM,M64	FUTURE,AVX2	VPMOVZXBD YMM, M64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	YMM,XMM	FUTURE,AVX2	VPMOVZXBD YMM, XMM	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	XMM{K}{Z},XMM/M32	AVX512VL,AVX512,FUTURE	VPMOVZXBD XMM{K}{Z}, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	YMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VPMOVZXBD YMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	ZMM{K}{Z},XMM/M128	AVX512,FUTURE	VPMOVZXBD zmm{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	XMM,xmmrm16	AVX,SANDYBRIDGE	VPMOVZXBQ XMM, XMM/m16	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	YMM,M32	FUTURE,AVX2	VPMOVZXBQ YMM, M32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	YMM,XMM	FUTURE,AVX2	VPMOVZXBQ YMM, XMM	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	XMM{K}{Z},xmmrm16	AVX512VL,AVX512,FUTURE	VPMOVZXBQ XMM{K}{Z}, XMM/m16	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	YMM{K}{Z},XMM/M32	AVX512VL,AVX512,FUTURE	VPMOVZXBQ YMM{K}{Z}, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	ZMM{K}{Z},XMM/M64	AVX512,FUTURE	VPMOVZXBQ zmm{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	XMM,XMM/M64	AVX,SANDYBRIDGE	VPMOVZXWD XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	YMM,XMM/M128	FUTURE,AVX2	VPMOVZXWD YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	XMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VPMOVZXWD XMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	YMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VPMOVZXWD YMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	ZMM{K}{Z},YMM/M256	AVX512,FUTURE	VPMOVZXWD zmm{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	XMM,XMM/M32	AVX,SANDYBRIDGE	VPMOVZXWQ XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	YMM,M64	FUTURE,AVX2	VPMOVZXWQ YMM, M64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	YMM,XMM	FUTURE,AVX2	VPMOVZXWQ YMM, XMM	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	XMM{K}{Z},XMM/M32	AVX512VL,AVX512,FUTURE	VPMOVZXWQ XMM{K}{Z}, XMM/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	YMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VPMOVZXWQ YMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	ZMM{K}{Z},XMM/M128	AVX512,FUTURE	VPMOVZXWQ zmm{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	XMM,XMM/M64	AVX,SANDYBRIDGE	VPMOVZXDQ XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	YMM,XMM/M128	FUTURE,AVX2	VPMOVZXDQ YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	XMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VPMOVZXDQ XMM{K}{Z}, XMM/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	YMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VPMOVZXDQ YMM{K}{Z}, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	ZMM{K}{Z},YMM/M256	AVX512,FUTURE	VPMOVZXDQ zmm{K}{Z}, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULHUW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMULHUW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHUW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMULHUW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHUW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMULHUW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHUW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMULHUW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHUW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMULHUW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMULHRSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMULHRSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMULHRSW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMULHRSW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMULHRSW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMULHW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMULHW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMULHW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMULHW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMULHW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMULLW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMULLW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPMULLW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPMULLW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPMULLW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMULLD XMM, XMM, XMM/M128	Multiply Int32 Vectors And Store Low Result	
VPMULLD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMULLD YMM, YMM, YMM/m256	Multiply Int32 Vectors And Store Low Result	
VPMULLD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPMULLD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Int32 Vectors And Store Low Result	
VPMULLD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPMULLD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Int32 Vectors And Store Low Result	
VPMULLD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPMULLD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Multiply Int32 Vectors And Store Low Result	
VPMULUDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMULUDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULUDQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMULUDQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULUDQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPMULUDQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULUDQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPMULUDQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULUDQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPMULUDQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPMULDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPMULDQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPMULDQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPMULDQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPMULDQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPOR	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPOR XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPOR	YMM,YMM,YMM/M256	FUTURE,AVX2	VPOR YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSADBW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSADBW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSADBW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSADBW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSADBW	XMM,XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSADBW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSADBW	YMM,YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSADBW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSADBW	ZMM,ZMM,ZMM/M512	AVX512BW,FUTURE	VPSADBW zmm, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSHUFB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSHUFB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSHUFB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSHUFB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSHUFB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFD	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPSHUFD XMM, XMM/M128, IMM8	Shuf?le Vector Doublewords	
VPSHUFD	YMM,YMM/M256,IMM8	FUTURE,AVX2	VPSHUFD YMM, YMM/m256, IMM8	Shuf?le Vector Doublewords	
VPSHUFD	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSHUFD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	Shuf?le Vector Doublewords	
VPSHUFD	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSHUFD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Shuf?le Vector Doublewords	
VPSHUFD	ZMM{K}{Z},ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPSHUFD zmm{K}{Z}, zmm/m512/M32BCST, IMM8	Shuf?le Vector Doublewords	
VPSHUFHW	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPSHUFHW XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFHW	YMM,YMM/M256,IMM8	FUTURE,AVX2	VPSHUFHW YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFHW	XMM{K}{Z},XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPSHUFHW XMM{K}{Z}, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFHW	YMM{K}{Z},YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPSHUFHW YMM{K}{Z}, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFHW	ZMM{K}{Z},ZMM/M512,IMM8	AVX512BW,FUTURE	VPSHUFHW zmm{K}{Z}, zmm/m512, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPSHUFLW XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	YMM,YMM/M256,IMM8	FUTURE,AVX2	VPSHUFLW YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	XMM{K}{Z},XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPSHUFLW XMM{K}{Z}, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	YMM{K}{Z},YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPSHUFLW YMM{K}{Z}, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	ZMM{K}{Z},ZMM/M512,IMM8	AVX512BW,FUTURE	VPSHUFLW zmm{K}{Z}, zmm/m512, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSIGNB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSIGNB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGNB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSIGNB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGNW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSIGNW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGNW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSIGNW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGND	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSIGND XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGND	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSIGND YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSLLDQ	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSLLDQ XMM, XMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLDQ	YMM,YMM,IMM8	FUTURE,AVX2	VPSLLDQ YMM, YMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLDQ	XMM,XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPSLLDQ XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLDQ	YMM,YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPSLLDQ YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLDQ	ZMM,ZMM/M512,IMM8	AVX512BW,FUTURE	VPSLLDQ zmm, zmm/m512, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSRLDQ XMM, XMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	YMM,YMM,IMM8	FUTURE,AVX2	VPSRLDQ YMM, YMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	XMM,XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPSRLDQ XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	YMM,YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPSRLDQ YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	ZMM,ZMM/M512,IMM8	AVX512BW,FUTURE	VPSRLDQ zmm, zmm/m512, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSLLW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSLLW XMM, XMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	YMM,YMM,XMM/M128	FUTURE,AVX2	VPSLLW YMM, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	YMM,YMM,IMM8	FUTURE,AVX2	VPSLLW YMM, YMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSLLW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	YMM{K}{Z},YMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSLLW YMM{K}{Z}, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	ZMM{K}{Z},ZMM,XMM/M128	AVX512BW,FUTURE	VPSLLW zmm{K}{Z}, zmm, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	XMM{K}{Z},XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPSLLW XMM{K}{Z}, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	YMM{K}{Z},YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPSLLW YMM{K}{Z}, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	ZMM{K}{Z},ZMM/M512,IMM8	AVX512BW,FUTURE	VPSLLW zmm{K}{Z}, zmm/m512, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSLLD XMM, XMM, XMM/M128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSLLD XMM, XMM, IMM8	Shift Int32 Vector Immediate Left Logical	
VPSLLD	YMM,YMM,XMM/M128	FUTURE,AVX2	VPSLLD YMM, YMM, XMM/M128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	YMM,YMM,IMM8	FUTURE,AVX2	VPSLLD YMM, YMM, IMM8	Shift Int32 Vector Immediate Left Logical	
VPSLLD	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSLLD XMM{K}{Z}, XMM, XMM/M128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	YMM{K}{Z},YMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSLLD YMM{K}{Z}, YMM, XMM/M128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	ZMM{K}{Z},ZMM,XMM/M128	AVX512,FUTURE	VPSLLD zmm{K}{Z}, zmm, XMM/M128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSLLD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	Shift Int32 Vector Immediate Left Logical	
VPSLLD	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSLLD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Shift Int32 Vector Immediate Left Logical	
VPSLLD	ZMM{K}{Z},ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPSLLD zmm{K}{Z}, zmm/m512/M32BCST, IMM8	Shift Int32 Vector Immediate Left Logical	
VPSLLQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSLLQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSLLQ XMM, XMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	YMM,YMM,XMM/M128	FUTURE,AVX2	VPSLLQ YMM, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	YMM,YMM,IMM8	FUTURE,AVX2	VPSLLQ YMM, YMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSLLQ XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	YMM{K}{Z},YMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSLLQ YMM{K}{Z}, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	ZMM{K}{Z},ZMM,XMM/M128	AVX512,FUTURE	VPSLLQ zmm{K}{Z}, zmm, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	XMM{K}{Z},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSLLQ XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSLLQ YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	ZMM{K}{Z},ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPSLLQ zmm{K}{Z}, zmm/m512/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRAW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSRAW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSRAW XMM, XMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	YMM,YMM,XMM/M128	FUTURE,AVX2	VPSRAW YMM, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	YMM,YMM,IMM8	FUTURE,AVX2	VPSRAW YMM, YMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSRAW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	YMM{K}{Z},YMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSRAW YMM{K}{Z}, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	ZMM{K}{Z},ZMM,XMM/M128	AVX512BW,FUTURE	VPSRAW zmm{K}{Z}, zmm, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	XMM{K}{Z},XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPSRAW XMM{K}{Z}, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	YMM{K}{Z},YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPSRAW YMM{K}{Z}, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	ZMM{K}{Z},ZMM/M512,IMM8	AVX512BW,FUTURE	VPSRAW zmm{K}{Z}, zmm/m512, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSRAD XMM, XMM, XMM/M128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSRAD XMM, XMM, IMM8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	YMM,YMM,XMM/M128	FUTURE,AVX2	VPSRAD YMM, YMM, XMM/M128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	YMM,YMM,IMM8	FUTURE,AVX2	VPSRAD YMM, YMM, IMM8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSRAD XMM{K}{Z}, XMM, XMM/M128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	YMM{K}{Z},YMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSRAD YMM{K}{Z}, YMM, XMM/M128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	ZMM{K}{Z},ZMM,XMM/M128	AVX512,FUTURE	VPSRAD zmm{K}{Z}, zmm, XMM/M128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSRAD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSRAD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	ZMM{K}{Z},ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPSRAD zmm{K}{Z}, zmm/m512/M32BCST, IMM8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRLW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSRLW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSRLW XMM, XMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	YMM,YMM,XMM/M128	FUTURE,AVX2	VPSRLW YMM, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	YMM,YMM,IMM8	FUTURE,AVX2	VPSRLW YMM, YMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSRLW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	YMM{K}{Z},YMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSRLW YMM{K}{Z}, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	ZMM{K}{Z},ZMM,XMM/M128	AVX512BW,FUTURE	VPSRLW zmm{K}{Z}, zmm, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	XMM{K}{Z},XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPSRLW XMM{K}{Z}, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	YMM{K}{Z},YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPSRLW YMM{K}{Z}, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	ZMM{K}{Z},ZMM/M512,IMM8	AVX512BW,FUTURE	VPSRLW zmm{K}{Z}, zmm/m512, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSRLD XMM, XMM, XMM/M128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSRLD XMM, XMM, IMM8	Shift Int32 Vector Immediate Right Logical	
VPSRLD	YMM,YMM,XMM/M128	FUTURE,AVX2	VPSRLD YMM, YMM, XMM/M128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	YMM,YMM,IMM8	FUTURE,AVX2	VPSRLD YMM, YMM, IMM8	Shift Int32 Vector Immediate Right Logical	
VPSRLD	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSRLD XMM{K}{Z}, XMM, XMM/M128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	YMM{K}{Z},YMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSRLD YMM{K}{Z}, YMM, XMM/M128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	ZMM{K}{Z},ZMM,XMM/M128	AVX512,FUTURE	VPSRLD zmm{K}{Z}, zmm, XMM/M128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSRLD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	Shift Int32 Vector Immediate Right Logical	
VPSRLD	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSRLD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Shift Int32 Vector Immediate Right Logical	
VPSRLD	ZMM{K}{Z},ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPSRLD zmm{K}{Z}, zmm/m512/M32BCST, IMM8	Shift Int32 Vector Immediate Right Logical	
VPSRLQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSRLQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	XMM,XMM,IMM8	AVX,SANDYBRIDGE	VPSRLQ XMM, XMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	YMM,YMM,XMM/M128	FUTURE,AVX2	VPSRLQ YMM, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	YMM,YMM,IMM8	FUTURE,AVX2	VPSRLQ YMM, YMM, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSRLQ XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	YMM{K}{Z},YMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSRLQ YMM{K}{Z}, YMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	ZMM{K}{Z},ZMM,XMM/M128	AVX512,FUTURE	VPSRLQ zmm{K}{Z}, zmm, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	XMM{K}{Z},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSRLQ XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSRLQ YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	ZMM{K}{Z},ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPSRLQ zmm{K}{Z}, zmm/m512/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPTEST	XMM,XMM/M128	AVX,SANDYBRIDGE	VPTEST XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VPTEST	YMM,YMM/M256	AVX,SANDYBRIDGE	VPTEST YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VPSUBB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSUBB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSUBB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSUBB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSUBB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSUBB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSUBW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSUBW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSUBW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSUBW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSUBW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSUBD XMM, XMM, XMM/M128	Subtract Int32 Vectors	
VPSUBD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSUBD YMM, YMM, YMM/m256	Subtract Int32 Vectors	
VPSUBD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPSUBD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Subtract Int32 Vectors	
VPSUBD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPSUBD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Subtract Int32 Vectors	
VPSUBD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPSUBD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Subtract Int32 Vectors	
VPSUBQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSUBQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSUBQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPSUBQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPSUBQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPSUBQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBSB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSUBSB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSUBSB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSUBSB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSUBSB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSUBSB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSUBSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSUBSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSUBSW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSUBSW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSUBSW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSUBUSB XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSUBUSB YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSUBUSB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSUBUSB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSUBUSB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPSUBUSW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSUBUSW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSUBUSW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSUBUSW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSUBUSW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPUNPCKHBW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPUNPCKHBW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPUNPCKHBW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPUNPCKHBW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPUNPCKHBW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPUNPCKHWD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPUNPCKHWD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPUNPCKHWD XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPUNPCKHWD YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPUNPCKHWD zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPUNPCKHDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHDQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPUNPCKHDQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHDQ	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPUNPCKHDQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHDQ	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPUNPCKHDQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHDQ	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPUNPCKHDQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPUNPCKHQDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPUNPCKHQDQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPUNPCKHQDQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPUNPCKHQDQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPUNPCKHQDQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLBW	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPUNPCKLBW XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLBW	YMM,YMM,YMM/M256	FUTURE,AVX2	VPUNPCKLBW YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLBW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPUNPCKLBW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLBW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPUNPCKLBW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLBW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPUNPCKLBW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPUNPCKLWD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPUNPCKLWD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPUNPCKLWD XMM{K}{Z}, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPUNPCKLWD YMM{K}{Z}, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPUNPCKLWD zmm{K}{Z}, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPUNPCKLDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLDQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPUNPCKLDQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLDQ	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPUNPCKLDQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLDQ	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPUNPCKLDQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLDQ	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPUNPCKLDQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPUNPCKLQDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPUNPCKLQDQ YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPUNPCKLQDQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPUNPCKLQDQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPUNPCKLQDQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPXOR	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPXOR XMM, XMM, XMM/M128	Logical Exclusive OR	PXOR.html
VPXOR	YMM,YMM,YMM/M256	FUTURE,AVX2	VPXOR YMM, YMM, YMM/m256	Logical Exclusive OR	PXOR.html
VRCPPS	XMM,XMM/M128	AVX,SANDYBRIDGE	VRCPPS XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VRCPPS	YMM,YMM/M256	AVX,SANDYBRIDGE	VRCPPS YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VRCPSS	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VRCPSS XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE	
VRSQRTPS	XMM,XMM/M128	AVX,SANDYBRIDGE	VRSQRTPS XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VRSQRTPS	YMM,YMM/M256	AVX,SANDYBRIDGE	VRSQRTPS YMM, YMM/m256	TODO: AVX,SANDYBRIDGE	
VRSQRTSS	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VRSQRTSS XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE	
VROUNDPD	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VROUNDPD XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VROUNDPD	YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VROUNDPD YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE	
VROUNDPS	XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VROUNDPS XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VROUNDPS	YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VROUNDPS YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE	
VROUNDSD	XMM,XMM,XMM/M64,IMM8	AVX,SANDYBRIDGE	VROUNDSD XMM, XMM, XMM/m64, IMM8	TODO: AVX,SANDYBRIDGE	
VROUNDSS	XMM,XMM,XMM/M32,IMM8	AVX,SANDYBRIDGE	VROUNDSS XMM, XMM, XMM/m32, IMM8	TODO: AVX,SANDYBRIDGE	
VSHUFPD	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VSHUFPD XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPD	YMM,YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VSHUFPD YMM, YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPD	XMM{K}{Z},XMM,XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VSHUFPD XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPD	YMM{K}{Z},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VSHUFPD YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VSHUFPD zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VSHUFPS XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	YMM,YMM,YMM/M256,IMM8	AVX,SANDYBRIDGE	VSHUFPS YMM, YMM, YMM/m256, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	XMM{K}{Z},XMM,XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VSHUFPS XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	YMM{K}{Z},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VSHUFPS YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VSHUFPS zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	XMM,XMM/M128	AVX,SANDYBRIDGE	VSQRTPD XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	YMM,YMM/M256	AVX,SANDYBRIDGE	VSQRTPD YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VSQRTPD XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VSQRTPD YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	ZMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VSQRTPD zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	XMM,XMM/M128	AVX,SANDYBRIDGE	VSQRTPS XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	YMM,YMM/M256	AVX,SANDYBRIDGE	VSQRTPS YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VSQRTPS XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VSQRTPS YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	ZMM{K}{Z},ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VSQRTPS zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VSQRTSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSQRTSD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VSQRTSD XMM{K}{Z}, XMM, XMM/m64{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSQRTSS	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VSQRTSS XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSQRTSS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VSQRTSS XMM{K}{Z}, XMM, XMM/m32{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSTMXCSR	M32	AVX,SANDYBRIDGE	VSTMXCSR M32	Store MXCSR Register State	STMXCSR.html
VSUBPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VSUBPD XMM, XMM, XMM/M128	Subtract Float64 Vectors	
VSUBPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VSUBPD YMM, YMM, YMM/m256	Subtract Float64 Vectors	
VSUBPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VSUBPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Subtract Float64 Vectors	
VSUBPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VSUBPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Subtract Float64 Vectors	
VSUBPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VSUBPD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Subtract Float64 Vectors	
VSUBPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VSUBPS XMM, XMM, XMM/M128	Subtract Float32 Vectors	
VSUBPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VSUBPS YMM, YMM, YMM/m256	Subtract Float32 Vectors	
VSUBPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VSUBPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Subtract Float32 Vectors	
VSUBPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VSUBPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Subtract Float32 Vectors	
VSUBPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VSUBPS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Subtract Float32 Vectors	
VSUBSD	XMM,XMM,XMM/M64	AVX,SANDYBRIDGE	VSUBSD XMM, XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSUBSD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VSUBSD XMM{K}{Z}, XMM, XMM/m64{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSUBSS	XMM,XMM,XMM/M32	AVX,SANDYBRIDGE	VSUBSS XMM, XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSUBSS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VSUBSS XMM{K}{Z}, XMM, XMM/m32{ER}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VTESTPS	XMM,XMM/M128	AVX,SANDYBRIDGE	VTESTPS XMM, XMM/M128	Packed Bit Test	VTESTPD:VTESTPS.html
VTESTPS	YMM,YMM/M256	AVX,SANDYBRIDGE	VTESTPS YMM, YMM/m256	Packed Bit Test	VTESTPD:VTESTPS.html
VTESTPD	XMM,XMM/M128	AVX,SANDYBRIDGE	VTESTPD XMM, XMM/M128	Packed Bit Test	VTESTPD:VTESTPS.html
VTESTPD	YMM,YMM/M256	AVX,SANDYBRIDGE	VTESTPD YMM, YMM/m256	Packed Bit Test	VTESTPD:VTESTPS.html
VUCOMISD	XMM,XMM/M64	AVX,SANDYBRIDGE	VUCOMISD XMM, XMM/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VUCOMISD	XMM,XMM/M64{SAE}	AVX512,FUTURE	VUCOMISD XMM, XMM/m64{SAE}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VUCOMISS	XMM,XMM/M32	AVX,SANDYBRIDGE	VUCOMISS XMM, XMM/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VUCOMISS	XMM,XMM/M32{SAE}	AVX512,FUTURE	VUCOMISS XMM, XMM/m32{SAE}	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VUNPCKHPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VUNPCKHPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VUNPCKHPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VUNPCKHPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VUNPCKHPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VUNPCKHPD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VUNPCKHPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VUNPCKHPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VUNPCKHPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VUNPCKHPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VUNPCKHPS zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VUNPCKLPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VUNPCKLPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VUNPCKLPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VUNPCKLPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VUNPCKLPD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VUNPCKLPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VUNPCKLPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VUNPCKLPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VUNPCKLPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VUNPCKLPS zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VXORPD	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VXORPD XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPD	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VXORPD YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VXORPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VXORPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512DQ,FUTURE	VXORPD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VXORPS XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	YMM,YMM,YMM/M256	AVX,SANDYBRIDGE	VXORPS YMM, YMM, YMM/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512DQ,FUTURE	VXORPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512DQ,FUTURE	VXORPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512DQ,FUTURE	VXORPS zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VZEROALL		AVX,SANDYBRIDGE	VZEROALL 	Zero All YMM Registers	VZEROALL.html
VZEROUPPER		AVX,SANDYBRIDGE	VZEROUPPER 	Zero Upper Bits of YMM Registers	VZEROUPPER.html
PCLMULLQLQDQ	XMM,XMM/M128	SSE,WESTMERE	PCLMULLQLQDQ XMM, XMM/M128	TODO: SSE,WESTMERE	
PCLMULHQLQDQ	XMM,XMM/M128	SSE,WESTMERE	PCLMULHQLQDQ XMM, XMM/M128	TODO: SSE,WESTMERE	
PCLMULLQHQDQ	XMM,XMM/M128	SSE,WESTMERE	PCLMULLQHQDQ XMM, XMM/M128	TODO: SSE,WESTMERE	
PCLMULHQHQDQ	XMM,XMM/M128	SSE,WESTMERE	PCLMULHQHQDQ XMM, XMM/M128	TODO: SSE,WESTMERE	
PCLMULQDQ	XMM,XMM/M128,IMM8	SSE,WESTMERE	PCLMULQDQ XMM, XMM/M128, IMM8	Carry-Less Multiplication Quadword	PCLMULQDQ.html
VPCLMULLQLQDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCLMULLQLQDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VPCLMULHQLQDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCLMULHQLQDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VPCLMULLQHQDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCLMULLQHQDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VPCLMULHQHQDQ	XMM,XMM,XMM/M128	AVX,SANDYBRIDGE	VPCLMULHQHQDQ XMM, XMM, XMM/M128	TODO: AVX,SANDYBRIDGE	
VPCLMULQDQ	XMM,XMM,XMM/M128,IMM8	AVX,SANDYBRIDGE	VPCLMULQDQ XMM, XMM, XMM/M128, IMM8	TODO: AVX,SANDYBRIDGE	
VFMADD132PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD132PS XMM, XMM, XMM/M128	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD132PS YMM, YMM, YMM/m256	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMADD132PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMADD132PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMADD132PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD132PD XMM, XMM, XMM/M128	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD132PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD132PD YMM, YMM, YMM/m256	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD132PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMADD132PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD132PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMADD132PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD132PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMADD132PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD312PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD312PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADD312PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD312PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADD312PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD312PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADD312PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD312PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADD213PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD213PS XMM, XMM, XMM/M128	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD213PS YMM, YMM, YMM/m256	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMADD213PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMADD213PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMADD213PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD213PD XMM, XMM, XMM/M128	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD213PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD213PD YMM, YMM, YMM/m256	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD213PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMADD213PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD213PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMADD213PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD213PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMADD213PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD123PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD123PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADD123PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD123PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADD123PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD123PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADD123PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD123PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADD231PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD231PS XMM, XMM, XMM/M128	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD231PS YMM, YMM, YMM/m256	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMADD231PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMADD231PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMADD231PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD231PD XMM, XMM, XMM/M128	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD231PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD231PD YMM, YMM, YMM/m256	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD231PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMADD231PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD231PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMADD231PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD231PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMADD231PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD321PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD321PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADD321PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD321PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADD321PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADD321PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADD321PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADD321PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADDSUB132PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB132PS XMM, XMM, XMM/M128	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB132PS YMM, YMM, YMM/m256	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB132PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB132PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMADDSUB132PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB132PD XMM, XMM, XMM/M128	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB132PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB132PD YMM, YMM, YMM/m256	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB132PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB132PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB132PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB132PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB132PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMADDSUB132PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB312PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB312PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADDSUB312PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB312PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADDSUB312PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB312PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADDSUB312PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB312PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADDSUB213PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB213PS XMM, XMM, XMM/M128	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB213PS YMM, YMM, YMM/m256	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB213PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB213PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMADDSUB213PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB213PD XMM, XMM, XMM/M128	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB213PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB213PD YMM, YMM, YMM/m256	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB213PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB213PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB213PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB213PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB213PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMADDSUB213PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB123PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB123PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADDSUB123PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB123PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADDSUB123PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB123PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADDSUB123PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB123PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADDSUB231PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB231PS XMM, XMM, XMM/M128	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB231PS YMM, YMM, YMM/m256	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB231PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB231PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMADDSUB231PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB231PD XMM, XMM, XMM/M128	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB231PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB231PD YMM, YMM, YMM/m256	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB231PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB231PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB231PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMADDSUB231PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB231PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMADDSUB231PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB321PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB321PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADDSUB321PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB321PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADDSUB321PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMADDSUB321PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMADDSUB321PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMADDSUB321PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUB132PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB132PS XMM, XMM, XMM/M128	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB132PS YMM, YMM, YMM/m256	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUB132PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUB132PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMSUB132PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB132PD XMM, XMM, XMM/M128	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB132PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB132PD YMM, YMM, YMM/m256	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB132PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUB132PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB132PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUB132PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB132PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMSUB132PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB312PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB312PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUB312PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB312PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUB312PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB312PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUB312PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB312PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUB213PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB213PS XMM, XMM, XMM/M128	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB213PS YMM, YMM, YMM/m256	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUB213PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUB213PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMSUB213PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB213PD XMM, XMM, XMM/M128	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB213PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB213PD YMM, YMM, YMM/m256	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB213PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUB213PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB213PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUB213PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB213PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMSUB213PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB123PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB123PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUB123PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB123PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUB123PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB123PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUB123PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB123PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUB231PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB231PS XMM, XMM, XMM/M128	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB231PS YMM, YMM, YMM/m256	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUB231PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUB231PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMSUB231PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB231PD XMM, XMM, XMM/M128	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB231PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB231PD YMM, YMM, YMM/m256	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB231PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUB231PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB231PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUB231PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB231PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMSUB231PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB321PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB321PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUB321PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB321PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUB321PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUB321PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUB321PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUB321PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUBADD132PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD132PS XMM, XMM, XMM/M128	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD132PS YMM, YMM, YMM/m256	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD132PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD132PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMSUBADD132PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD132PD XMM, XMM, XMM/M128	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD132PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD132PD YMM, YMM, YMM/m256	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD132PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD132PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD132PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD132PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD132PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMSUBADD132PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD312PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD312PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUBADD312PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD312PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUBADD312PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD312PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUBADD312PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD312PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUBADD213PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD213PS XMM, XMM, XMM/M128	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD213PS YMM, YMM, YMM/m256	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD213PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD213PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMSUBADD213PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD213PD XMM, XMM, XMM/M128	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD213PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD213PD YMM, YMM, YMM/m256	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD213PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD213PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD213PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD213PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD213PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMSUBADD213PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD123PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD123PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUBADD123PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD123PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUBADD123PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD123PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUBADD123PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD123PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUBADD231PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD231PS XMM, XMM, XMM/M128	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD231PS YMM, YMM, YMM/m256	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD231PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD231PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFMSUBADD231PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD231PD XMM, XMM, XMM/M128	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD231PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD231PD YMM, YMM, YMM/m256	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD231PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD231PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD231PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFMSUBADD231PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD231PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFMSUBADD231PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD321PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD321PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUBADD321PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD321PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMSUBADD321PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFMSUBADD321PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFMSUBADD321PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFMSUBADD321PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMADD132PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD132PS XMM, XMM, XMM/M128	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD132PS YMM, YMM, YMM/m256	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFNMADD132PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFNMADD132PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFNMADD132PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD132PD XMM, XMM, XMM/M128	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD132PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD132PD YMM, YMM, YMM/m256	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD132PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFNMADD132PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD132PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFNMADD132PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD132PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFNMADD132PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD312PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD312PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMADD312PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD312PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMADD312PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD312PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMADD312PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD312PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMADD213PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD213PS XMM, XMM, XMM/M128	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD213PS YMM, YMM, YMM/m256	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFNMADD213PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFNMADD213PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFNMADD213PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD213PD XMM, XMM, XMM/M128	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD213PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD213PD YMM, YMM, YMM/m256	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD213PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFNMADD213PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD213PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFNMADD213PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD213PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFNMADD213PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD123PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD123PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMADD123PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD123PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMADD123PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD123PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMADD123PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD123PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMADD231PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD231PS XMM, XMM, XMM/M128	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD231PS YMM, YMM, YMM/m256	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFNMADD231PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFNMADD231PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFNMADD231PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD231PD XMM, XMM, XMM/M128	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD231PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD231PD YMM, YMM, YMM/m256	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD231PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFNMADD231PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD231PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFNMADD231PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD231PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFNMADD231PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD321PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD321PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMADD321PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD321PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMADD321PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMADD321PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMADD321PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMADD321PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMSUB132PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB132PS XMM, XMM, XMM/M128	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB132PS YMM, YMM, YMM/m256	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFNMSUB132PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFNMSUB132PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFNMSUB132PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB132PD XMM, XMM, XMM/M128	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB132PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB132PD YMM, YMM, YMM/m256	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB132PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFNMSUB132PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB132PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFNMSUB132PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB132PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFNMSUB132PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB312PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB312PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMSUB312PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB312PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMSUB312PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB312PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMSUB312PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB312PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMSUB213PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB213PS XMM, XMM, XMM/M128	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB213PS YMM, YMM, YMM/m256	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFNMSUB213PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFNMSUB213PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFNMSUB213PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB213PD XMM, XMM, XMM/M128	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB213PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB213PD YMM, YMM, YMM/m256	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB213PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFNMSUB213PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB213PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFNMSUB213PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB213PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFNMSUB213PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB123PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB123PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMSUB123PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB123PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMSUB123PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB123PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMSUB123PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB123PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMSUB231PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB231PS XMM, XMM, XMM/M128	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB231PS YMM, YMM, YMM/m256	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VFNMSUB231PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VFNMSUB231PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VFNMSUB231PS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB231PD XMM, XMM, XMM/M128	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB231PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB231PD YMM, YMM, YMM/m256	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB231PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VFNMSUB231PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB231PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VFNMSUB231PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB231PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VFNMSUB231PD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB321PS	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB321PS XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMSUB321PS	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB321PS YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFNMSUB321PD	XMM,XMM,XMM/M128	FMA,FUTURE	VFNMSUB321PD XMM, XMM, XMM/M128	TODO: FMA,FUTURE	
VFNMSUB321PD	YMM,YMM,YMM/M256	FMA,FUTURE	VFNMSUB321PD YMM, YMM, YMM/m256	TODO: FMA,FUTURE	
VFMADD132SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMADD132SS XMM, XMM, XMM/m32	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD132SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFMADD132SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD132SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMADD132SD XMM, XMM, XMM/m64	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD132SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFMADD132SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD312SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMADD312SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFMADD312SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMADD312SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFMADD213SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMADD213SS XMM, XMM, XMM/m32	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD213SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFMADD213SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD213SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMADD213SD XMM, XMM, XMM/m64	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD213SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFMADD213SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD123SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMADD123SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFMADD123SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMADD123SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFMADD231SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMADD231SS XMM, XMM, XMM/m32	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD231SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFMADD231SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD231SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMADD231SD XMM, XMM, XMM/m64	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD231SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFMADD231SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD321SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMADD321SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFMADD321SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMADD321SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFMSUB132SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMSUB132SS XMM, XMM, XMM/m32	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB132SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFMSUB132SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB132SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMSUB132SD XMM, XMM, XMM/m64	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB132SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFMSUB132SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB312SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMSUB312SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFMSUB312SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMSUB312SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFMSUB213SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMSUB213SS XMM, XMM, XMM/m32	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB213SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFMSUB213SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB213SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMSUB213SD XMM, XMM, XMM/m64	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB213SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFMSUB213SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB123SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMSUB123SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFMSUB123SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMSUB123SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFMSUB231SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMSUB231SS XMM, XMM, XMM/m32	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB231SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFMSUB231SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB231SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMSUB231SD XMM, XMM, XMM/m64	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB231SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFMSUB231SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB321SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFMSUB321SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFMSUB321SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFMSUB321SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFNMADD132SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMADD132SS XMM, XMM, XMM/m32	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD132SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFNMADD132SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD132SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMADD132SD XMM, XMM, XMM/m64	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD132SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFNMADD132SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD312SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMADD312SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFNMADD312SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMADD312SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFNMADD213SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMADD213SS XMM, XMM, XMM/m32	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD213SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFNMADD213SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD213SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMADD213SD XMM, XMM, XMM/m64	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD213SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFNMADD213SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD123SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMADD123SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFNMADD123SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMADD123SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFNMADD231SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMADD231SS XMM, XMM, XMM/m32	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD231SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFNMADD231SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD231SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMADD231SD XMM, XMM, XMM/m64	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD231SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFNMADD231SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD321SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMADD321SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFNMADD321SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMADD321SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFNMSUB132SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMSUB132SS XMM, XMM, XMM/m32	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB132SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFNMSUB132SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB132SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMSUB132SD XMM, XMM, XMM/m64	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB132SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFNMSUB132SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB312SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMSUB312SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFNMSUB312SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMSUB312SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFNMSUB213SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMSUB213SS XMM, XMM, XMM/m32	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB213SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFNMSUB213SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB213SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMSUB213SD XMM, XMM, XMM/m64	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB213SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFNMSUB213SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB123SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMSUB123SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFNMSUB123SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMSUB123SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
VFNMSUB231SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMSUB231SS XMM, XMM, XMM/m32	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB231SS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VFNMSUB231SS XMM{K}{Z}, XMM, XMM/m32{ER}	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB231SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMSUB231SD XMM, XMM, XMM/m64	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB231SD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VFNMSUB231SD XMM{K}{Z}, XMM, XMM/m64{ER}	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB321SS	XMM,XMM,XMM/M32	FMA,FUTURE	VFNMSUB321SS XMM, XMM, XMM/m32	TODO: FMA,FUTURE	
VFNMSUB321SD	XMM,XMM,XMM/M64	FMA,FUTURE	VFNMSUB321SD XMM, XMM, XMM/m64	TODO: FMA,FUTURE	
RDFSBASE	R32	LONG,FUTURE	RDFSBASE R32	Read FS/GS Segment Base	RDFSBASE:RDGSBASE.html
RDFSBASE	R64	LONG,FUTURE	RDFSBASE r64	Read FS/GS Segment Base	RDFSBASE:RDGSBASE.html
RDGSBASE	R32	LONG,FUTURE	RDGSBASE R32	Read FS/GS Segment Base	RDFSBASE:RDGSBASE.html
RDGSBASE	R64	LONG,FUTURE	RDGSBASE r64	Read FS/GS Segment Base	RDFSBASE:RDGSBASE.html
RDRAND	R16	FUTURE	RDRAND R16	Read Random Number	RDRAND.html
RDRAND	R32	FUTURE	RDRAND R32	Read Random Number	RDRAND.html
RDRAND	R64	LONG,FUTURE	RDRAND r64	Read Random Number	RDRAND.html
WRFSBASE	R32	LONG,FUTURE	WRFSBASE R32	Write FS/GS Segment Base	WRFSBASE:WRGSBASE.html
WRFSBASE	R64	LONG,FUTURE	WRFSBASE r64	Write FS/GS Segment Base	WRFSBASE:WRGSBASE.html
WRGSBASE	R32	LONG,FUTURE	WRGSBASE R32	Write FS/GS Segment Base	WRFSBASE:WRGSBASE.html
WRGSBASE	R64	LONG,FUTURE	WRGSBASE r64	Write FS/GS Segment Base	WRFSBASE:WRGSBASE.html
VCVTPH2PS	YMM,XMM/M128	AVX,FUTURE	VCVTPH2PS YMM, XMM/M128	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPH2PS	XMM,XMM/M64	AVX,FUTURE	VCVTPH2PS XMM, XMM/m64	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPH2PS	XMM{K}{Z},XMM/M64	AVX512VL,AVX512,FUTURE	VCVTPH2PS XMM{K}{Z}, XMM/m64	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPH2PS	YMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VCVTPH2PS YMM{K}{Z}, XMM/M128	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPH2PS	ZMM{K}{Z},YMM/M256{SAE}	AVX512,FUTURE	VCVTPH2PS zmm{K}{Z}, YMM/m256{SAE}	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPS2PH	XMM/M128,YMM,IMM8	AVX,FUTURE	VCVTPS2PH XMM/M128, YMM, IMM8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	XMM/M64,XMM,IMM8	AVX,FUTURE	VCVTPS2PH XMM/m64, XMM, IMM8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	XMM{K}{Z},XMM,IMM8	AVX512VL,AVX512,FUTURE	VCVTPS2PH XMM{K}{Z}, XMM, IMM8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	XMM{K}{Z},YMM,IMM8	AVX512VL,AVX512,FUTURE	VCVTPS2PH XMM{K}{Z}, YMM, IMM8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	YMM{K}{Z},ZMM{SAE},IMM8	AVX512,FUTURE	VCVTPS2PH YMM{K}{Z}, zmm{SAE}, IMM8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	M64{K},XMM,IMM8	AVX512VL,AVX512,FUTURE	VCVTPS2PH M64{K}, XMM, IMM8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	M128{K},YMM,IMM8	AVX512VL,AVX512,FUTURE	VCVTPS2PH M128{K}, YMM, IMM8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	M256{K},ZMM{SAE},IMM8	AVX512,FUTURE	VCVTPS2PH M256{K}, zmm{SAE}, IMM8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
ADCX	R32,R/M32	FUTURE	ADCX R32, R/M32	Unsigned Integer Addition of Two Operands with Carry Flag	ADCX.html
ADCX	R64,R/M64	LONG,FUTURE	ADCX r64, r/m64	Unsigned Integer Addition of Two Operands with Carry Flag	ADCX.html
ADOX	R32,R/M32	FUTURE	ADOX R32, R/M32	Unsigned Integer Addition of Two Operands with Overflow Flag	ADOX.html
ADOX	R64,R/M64	LONG,FUTURE	ADOX r64, r/m64	Unsigned Integer Addition of Two Operands with Overflow Flag	ADOX.html
RDSEED	R16	FUTURE	RDSEED R16	Read Random SEED	RDSEED.html
RDSEED	R32	FUTURE	RDSEED R32	Read Random SEED	RDSEED.html
RDSEED	R64	LONG,FUTURE	RDSEED r64	Read Random SEED	RDSEED.html
CLAC		PRIV,FUTURE	CLAC 	Clear AC Flag in EFLAGS Register	CLAC.html
STAC		PRIV,FUTURE	STAC 	Set AC Flag in EFLAGS Register	STAC.html
XSTORE		PENT,CYRIX	XSTORE 	TODO: PENT,CYRIX	
XCRYPTECB		PENT,CYRIX	XCRYPTECB 	TODO: PENT,CYRIX	
XCRYPTCBC		PENT,CYRIX	XCRYPTCBC 	TODO: PENT,CYRIX	
XCRYPTCTR		PENT,CYRIX	XCRYPTCTR 	TODO: PENT,CYRIX	
XCRYPTCFB		PENT,CYRIX	XCRYPTCFB 	TODO: PENT,CYRIX	
XCRYPTOFB		PENT,CYRIX	XCRYPTOFB 	TODO: PENT,CYRIX	
MONTMUL		PENT,CYRIX	MONTMUL 	TODO: PENT,CYRIX	
XSHA1		PENT,CYRIX	XSHA1 	TODO: PENT,CYRIX	
XSHA256		PENT,CYRIX	XSHA256 	TODO: PENT,CYRIX	
LLWPCB	R32	AMD,386	LLWPCB R32	TODO: AMD,386,X64	
LLWPCB	R64	AMD,X64	LLWPCB r64	TODO: AMD,386,X64	
SLWPCB	R32	AMD,386	SLWPCB R32	TODO: AMD,386,X64	
SLWPCB	R64	AMD,X64	SLWPCB r64	TODO: AMD,386,X64	
LWPVAL	R32,R/M32,IMM32	AMD,386	LWPVAL R32, R/M32, IMM32	TODO: AMD,386,X64	
LWPVAL	R64,R/M32,IMM32	AMD,X64	LWPVAL r64, R/M32, IMM32	TODO: AMD,386,X64	
LWPINS	R32,R/M32,IMM32	AMD,386	LWPINS R32, R/M32, IMM32	TODO: AMD,386,X64	
LWPINS	R64,R/M32,IMM32	AMD,X64	LWPINS r64, R/M32, IMM32	TODO: AMD,386,X64	
VFMADDPD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFMADDPD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFMADDPD	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFMADDPD YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFMADDPD	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFMADDPD XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFMADDPD	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFMADDPD YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFMADDPS	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFMADDPS XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFMADDPS	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFMADDPS YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFMADDPS	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFMADDPS XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFMADDPS	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFMADDPS YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFMADDSD	XMM,XMM,XMM/M64,XMM	AMD,SSE5	VFMADDSD XMM, XMM, XMM/m64, XMM	TODO: AMD,SSE5	
VFMADDSD	XMM,XMM,XMM,XMM/M64	AMD,SSE5	VFMADDSD XMM, XMM, XMM, XMM/m64	TODO: AMD,SSE5	
VFMADDSS	XMM,XMM,XMM/M32,XMM	AMD,SSE5	VFMADDSS XMM, XMM, XMM/m32, XMM	TODO: AMD,SSE5	
VFMADDSS	XMM,XMM,XMM,XMM/M32	AMD,SSE5	VFMADDSS XMM, XMM, XMM, XMM/m32	TODO: AMD,SSE5	
VFMADDSUBPD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFMADDSUBPD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFMADDSUBPD	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFMADDSUBPD YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFMADDSUBPD	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFMADDSUBPD XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFMADDSUBPD	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFMADDSUBPD YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFMADDSUBPS	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFMADDSUBPS XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFMADDSUBPS	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFMADDSUBPS YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFMADDSUBPS	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFMADDSUBPS XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFMADDSUBPS	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFMADDSUBPS YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFMSUBADDPD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFMSUBADDPD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFMSUBADDPD	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFMSUBADDPD YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFMSUBADDPD	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFMSUBADDPD XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFMSUBADDPD	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFMSUBADDPD YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFMSUBADDPS	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFMSUBADDPS XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFMSUBADDPS	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFMSUBADDPS YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFMSUBADDPS	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFMSUBADDPS XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFMSUBADDPS	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFMSUBADDPS YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFMSUBPD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFMSUBPD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFMSUBPD	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFMSUBPD YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFMSUBPD	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFMSUBPD XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFMSUBPD	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFMSUBPD YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFMSUBPS	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFMSUBPS XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFMSUBPS	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFMSUBPS YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFMSUBPS	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFMSUBPS XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFMSUBPS	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFMSUBPS YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFMSUBSD	XMM,XMM,XMM/M64,XMM	AMD,SSE5	VFMSUBSD XMM, XMM, XMM/m64, XMM	TODO: AMD,SSE5	
VFMSUBSD	XMM,XMM,XMM,XMM/M64	AMD,SSE5	VFMSUBSD XMM, XMM, XMM, XMM/m64	TODO: AMD,SSE5	
VFMSUBSS	XMM,XMM,XMM/M32,XMM	AMD,SSE5	VFMSUBSS XMM, XMM, XMM/m32, XMM	TODO: AMD,SSE5	
VFMSUBSS	XMM,XMM,XMM,XMM/M32	AMD,SSE5	VFMSUBSS XMM, XMM, XMM, XMM/m32	TODO: AMD,SSE5	
VFNMADDPD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFNMADDPD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFNMADDPD	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFNMADDPD YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFNMADDPD	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFNMADDPD XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFNMADDPD	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFNMADDPD YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFNMADDPS	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFNMADDPS XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFNMADDPS	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFNMADDPS YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFNMADDPS	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFNMADDPS XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFNMADDPS	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFNMADDPS YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFNMADDSD	XMM,XMM,XMM/M64,XMM	AMD,SSE5	VFNMADDSD XMM, XMM, XMM/m64, XMM	TODO: AMD,SSE5	
VFNMADDSD	XMM,XMM,XMM,XMM/M64	AMD,SSE5	VFNMADDSD XMM, XMM, XMM, XMM/m64	TODO: AMD,SSE5	
VFNMADDSS	XMM,XMM,XMM/M32,XMM	AMD,SSE5	VFNMADDSS XMM, XMM, XMM/m32, XMM	TODO: AMD,SSE5	
VFNMADDSS	XMM,XMM,XMM,XMM/M32	AMD,SSE5	VFNMADDSS XMM, XMM, XMM, XMM/m32	TODO: AMD,SSE5	
VFNMSUBPD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFNMSUBPD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFNMSUBPD	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFNMSUBPD YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFNMSUBPD	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFNMSUBPD XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFNMSUBPD	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFNMSUBPD YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFNMSUBPS	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VFNMSUBPS XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VFNMSUBPS	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VFNMSUBPS YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VFNMSUBPS	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VFNMSUBPS XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VFNMSUBPS	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VFNMSUBPS YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VFNMSUBSD	XMM,XMM,XMM/M64,XMM	AMD,SSE5	VFNMSUBSD XMM, XMM, XMM/m64, XMM	TODO: AMD,SSE5	
VFNMSUBSD	XMM,XMM,XMM,XMM/M64	AMD,SSE5	VFNMSUBSD XMM, XMM, XMM, XMM/m64	TODO: AMD,SSE5	
VFNMSUBSS	XMM,XMM,XMM/M32,XMM	AMD,SSE5	VFNMSUBSS XMM, XMM, XMM/m32, XMM	TODO: AMD,SSE5	
VFNMSUBSS	XMM,XMM,XMM,XMM/M32	AMD,SSE5	VFNMSUBSS XMM, XMM, XMM, XMM/m32	TODO: AMD,SSE5	
VFRCZPD	XMM,XMM/M128	AMD,SSE5	VFRCZPD XMM, XMM/M128	TODO: AMD,SSE5	
VFRCZPD	YMM,YMM/M256	AMD,SSE5	VFRCZPD YMM, YMM/m256	TODO: AMD,SSE5	
VFRCZPS	XMM,XMM/M128	AMD,SSE5	VFRCZPS XMM, XMM/M128	TODO: AMD,SSE5	
VFRCZPS	YMM,YMM/M256	AMD,SSE5	VFRCZPS YMM, YMM/m256	TODO: AMD,SSE5	
VFRCZSD	XMM,XMM/M64	AMD,SSE5	VFRCZSD XMM, XMM/m64	TODO: AMD,SSE5	
VFRCZSS	XMM,XMM/M32	AMD,SSE5	VFRCZSS XMM, XMM/m32	TODO: AMD,SSE5	
VPCMOV	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPCMOV XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPCMOV	YMM,YMM,YMM/M256,YMM	AMD,SSE5	VPCMOV YMM, YMM, YMM/m256, YMM	TODO: AMD,SSE5	
VPCMOV	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VPCMOV XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPCMOV	YMM,YMM,YMM,YMM/M256	AMD,SSE5	VPCMOV YMM, YMM, YMM, YMM/m256	TODO: AMD,SSE5	
VPCOMB	XMM,XMM,XMM/M128,IMM8	AMD,SSE5	VPCOMB XMM, XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPCOMD	XMM,XMM,XMM/M128,IMM8	AMD,SSE5	VPCOMD XMM, XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPCOMQ	XMM,XMM,XMM/M128,IMM8	AMD,SSE5	VPCOMQ XMM, XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPCOMUB	XMM,XMM,XMM/M128,IMM8	AMD,SSE5	VPCOMUB XMM, XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPCOMUD	XMM,XMM,XMM/M128,IMM8	AMD,SSE5	VPCOMUD XMM, XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPCOMUQ	XMM,XMM,XMM/M128,IMM8	AMD,SSE5	VPCOMUQ XMM, XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPCOMUW	XMM,XMM,XMM/M128,IMM8	AMD,SSE5	VPCOMUW XMM, XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPCOMW	XMM,XMM,XMM/M128,IMM8	AMD,SSE5	VPCOMW XMM, XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPHADDBD	XMM,XMM/M128	AMD,SSE5	VPHADDBD XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDBQ	XMM,XMM/M128	AMD,SSE5	VPHADDBQ XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDBW	XMM,XMM/M128	AMD,SSE5	VPHADDBW XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDDQ	XMM,XMM/M128	AMD,SSE5	VPHADDDQ XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDUBD	XMM,XMM/M128	AMD,SSE5	VPHADDUBD XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDUBQ	XMM,XMM/M128	AMD,SSE5	VPHADDUBQ XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDUBW	XMM,XMM/M128	AMD,SSE5	VPHADDUBW XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDUDQ	XMM,XMM/M128	AMD,SSE5	VPHADDUDQ XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDUWD	XMM,XMM/M128	AMD,SSE5	VPHADDUWD XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDUWQ	XMM,XMM/M128	AMD,SSE5	VPHADDUWQ XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDWD	XMM,XMM/M128	AMD,SSE5	VPHADDWD XMM, XMM/M128	TODO: AMD,SSE5	
VPHADDWQ	XMM,XMM/M128	AMD,SSE5	VPHADDWQ XMM, XMM/M128	TODO: AMD,SSE5	
VPHSUBBW	XMM,XMM/M128	AMD,SSE5	VPHSUBBW XMM, XMM/M128	TODO: AMD,SSE5	
VPHSUBDQ	XMM,XMM/M128	AMD,SSE5	VPHSUBDQ XMM, XMM/M128	TODO: AMD,SSE5	
VPHSUBWD	XMM,XMM/M128	AMD,SSE5	VPHSUBWD XMM, XMM/M128	TODO: AMD,SSE5	
VPMACSDD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSDD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMACSDQH	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSDQH XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMACSDQL	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSDQL XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMACSSDD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSSDD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMACSSDQH	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSSDQH XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMACSSDQL	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSSDQL XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMACSSWD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSSWD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMACSSWW	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSSWW XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMACSWD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSWD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMACSWW	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMACSWW XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMADCSSWD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMADCSSWD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPMADCSWD	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPMADCSWD XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPPERM	XMM,XMM,XMM,XMM/M128	AMD,SSE5	VPPERM XMM, XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPPERM	XMM,XMM,XMM/M128,XMM	AMD,SSE5	VPPERM XMM, XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPROTB	XMM,XMM/M128,XMM	AMD,SSE5	VPROTB XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPROTB	XMM,XMM,XMM/M128	AMD,SSE5	VPROTB XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPROTB	XMM,XMM/M128,IMM8	AMD,SSE5	VPROTB XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPROTD	XMM,XMM/M128,XMM	AMD,SSE5	VPROTD XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPROTD	XMM,XMM,XMM/M128	AMD,SSE5	VPROTD XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPROTD	XMM,XMM/M128,IMM8	AMD,SSE5	VPROTD XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPROTQ	XMM,XMM/M128,XMM	AMD,SSE5	VPROTQ XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPROTQ	XMM,XMM,XMM/M128	AMD,SSE5	VPROTQ XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPROTQ	XMM,XMM/M128,IMM8	AMD,SSE5	VPROTQ XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPROTW	XMM,XMM/M128,XMM	AMD,SSE5	VPROTW XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPROTW	XMM,XMM,XMM/M128	AMD,SSE5	VPROTW XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPROTW	XMM,XMM/M128,IMM8	AMD,SSE5	VPROTW XMM, XMM/M128, IMM8	TODO: AMD,SSE5	
VPSHAB	XMM,XMM/M128,XMM	AMD,SSE5	VPSHAB XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPSHAB	XMM,XMM,XMM/M128	AMD,SSE5	VPSHAB XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPSHAD	XMM,XMM/M128,XMM	AMD,SSE5	VPSHAD XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPSHAD	XMM,XMM,XMM/M128	AMD,SSE5	VPSHAD XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPSHAQ	XMM,XMM/M128,XMM	AMD,SSE5	VPSHAQ XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPSHAQ	XMM,XMM,XMM/M128	AMD,SSE5	VPSHAQ XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPSHAW	XMM,XMM/M128,XMM	AMD,SSE5	VPSHAW XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPSHAW	XMM,XMM,XMM/M128	AMD,SSE5	VPSHAW XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPSHLB	XMM,XMM/M128,XMM	AMD,SSE5	VPSHLB XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPSHLB	XMM,XMM,XMM/M128	AMD,SSE5	VPSHLB XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPSHLD	XMM,XMM/M128,XMM	AMD,SSE5	VPSHLD XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPSHLD	XMM,XMM,XMM/M128	AMD,SSE5	VPSHLD XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPSHLQ	XMM,XMM/M128,XMM	AMD,SSE5	VPSHLQ XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPSHLQ	XMM,XMM,XMM/M128	AMD,SSE5	VPSHLQ XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VPSHLW	XMM,XMM/M128,XMM	AMD,SSE5	VPSHLW XMM, XMM/M128, XMM	TODO: AMD,SSE5	
VPSHLW	XMM,XMM,XMM/M128	AMD,SSE5	VPSHLW XMM, XMM, XMM/M128	TODO: AMD,SSE5	
VBROADCASTI128	YMM,M128	FUTURE,AVX2	VBROADCASTI128 YMM, M128	Copy a 128-bit memory operand to all elements of a YMM vector Register	VPBROADCAST.html
VPBLENDD	XMM,XMM,XMM/M128,IMM8	FUTURE,AVX2	VPBLENDD XMM, XMM, XMM/M128, IMM8	Blend Packed Dwords	VPBLENDD.html
VPBLENDD	YMM,YMM,YMM/M256,IMM8	FUTURE,AVX2	VPBLENDD YMM, YMM, YMM/m256, IMM8	Blend Packed Dwords	VPBLENDD.html
VPBROADCASTB	XMM,M8	FUTURE,AVX2	VPBROADCASTB XMM, M8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	XMM,XMM	FUTURE,AVX2	VPBROADCASTB XMM, XMM	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	YMM,M8	FUTURE,AVX2	VPBROADCASTB YMM, M8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	YMM,XMM	FUTURE,AVX2	VPBROADCASTB YMM, XMM	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	XMM{K}{Z},xmmrm8	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB XMM{K}{Z}, XMM/m8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	YMM{K}{Z},xmmrm8	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB YMM{K}{Z}, XMM/m8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ZMM{K}{Z},xmmrm8	AVX512BW,FUTURE	VPBROADCASTB zmm{K}{Z}, XMM/m8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	XMM{K}{Z},R8	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB XMM{K}{Z}, R8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	XMM{K}{Z},R16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB XMM{K}{Z}, R16	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	XMM{K}{Z},R32	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB XMM{K}{Z}, R32	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	XMM{K}{Z},R64	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB XMM{K}{Z}, r64	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	YMM{K}{Z},R8	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB YMM{K}{Z}, R8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	YMM{K}{Z},R16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB YMM{K}{Z}, R16	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	YMM{K}{Z},R32	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB YMM{K}{Z}, R32	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	YMM{K}{Z},R64	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB YMM{K}{Z}, r64	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ZMM{K}{Z},R8	AVX512BW,FUTURE	VPBROADCASTB zmm{K}{Z}, R8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ZMM{K}{Z},R16	AVX512BW,FUTURE	VPBROADCASTB zmm{K}{Z}, R16	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ZMM{K}{Z},R32	AVX512BW,FUTURE	VPBROADCASTB zmm{K}{Z}, R32	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ZMM{K}{Z},R64	AVX512BW,FUTURE	VPBROADCASTB zmm{K}{Z}, r64	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	XMM,M16	FUTURE,AVX2	VPBROADCASTW XMM, M16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	XMM,XMM	FUTURE,AVX2	VPBROADCASTW XMM, XMM	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	YMM,M16	FUTURE,AVX2	VPBROADCASTW YMM, M16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	YMM,XMM	FUTURE,AVX2	VPBROADCASTW YMM, XMM	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	XMM{K}{Z},xmmrm16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW XMM{K}{Z}, XMM/m16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	YMM{K}{Z},xmmrm16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW YMM{K}{Z}, XMM/m16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ZMM{K}{Z},xmmrm16	AVX512BW,FUTURE	VPBROADCASTW zmm{K}{Z}, XMM/m16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	XMM{K}{Z},R16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW XMM{K}{Z}, R16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	XMM{K}{Z},R32	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW XMM{K}{Z}, R32	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	XMM{K}{Z},R64	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW XMM{K}{Z}, r64	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	YMM{K}{Z},R16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW YMM{K}{Z}, R16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	YMM{K}{Z},R32	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW YMM{K}{Z}, R32	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	YMM{K}{Z},R64	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW YMM{K}{Z}, r64	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ZMM{K}{Z},R16	AVX512BW,FUTURE	VPBROADCASTW zmm{K}{Z}, R16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ZMM{K}{Z},R32	AVX512BW,FUTURE	VPBROADCASTW zmm{K}{Z}, R32	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ZMM{K}{Z},R64	AVX512BW,FUTURE	VPBROADCASTW zmm{K}{Z}, r64	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTD	XMM,M32	FUTURE,AVX2	VPBROADCASTD XMM, M32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	XMM,XMM	FUTURE,AVX2	VPBROADCASTD XMM, XMM	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	YMM,M32	FUTURE,AVX2	VPBROADCASTD YMM, M32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	YMM,XMM	FUTURE,AVX2	VPBROADCASTD YMM, XMM	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	XMM{K}{Z},M32	AVX512VL,AVX512,FUTURE	VPBROADCASTD XMM{K}{Z}, M32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	YMM{K}{Z},M32	AVX512VL,AVX512,FUTURE	VPBROADCASTD YMM{K}{Z}, M32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	ZMM{K}{Z},M32	AVX512,FUTURE	VPBROADCASTD zmm{K}{Z}, M32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPBROADCASTD XMM{K}{Z}, XMM	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	YMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPBROADCASTD YMM{K}{Z}, XMM	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	ZMM{K}{Z},XMM	AVX512,FUTURE	VPBROADCASTD zmm{K}{Z}, XMM	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	XMM{K}{Z},R32	AVX512VL,AVX512,FUTURE	VPBROADCASTD XMM{K}{Z}, R32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	YMM{K}{Z},R32	AVX512VL,AVX512,FUTURE	VPBROADCASTD YMM{K}{Z}, R32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	ZMM{K}{Z},R32	AVX512,FUTURE	VPBROADCASTD zmm{K}{Z}, R32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTQ	XMM,M64	FUTURE,AVX2	VPBROADCASTQ XMM, M64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	XMM,XMM	FUTURE,AVX2	VPBROADCASTQ XMM, XMM	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	YMM,M64	FUTURE,AVX2	VPBROADCASTQ YMM, M64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	YMM,XMM	FUTURE,AVX2	VPBROADCASTQ YMM, XMM	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	XMM{K}{Z},M64	AVX512VL,AVX512,FUTURE	VPBROADCASTQ XMM{K}{Z}, M64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	YMM{K}{Z},M64	AVX512VL,AVX512,FUTURE	VPBROADCASTQ YMM{K}{Z}, M64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	ZMM{K}{Z},M64	AVX512,FUTURE	VPBROADCASTQ zmm{K}{Z}, M64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPBROADCASTQ XMM{K}{Z}, XMM	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	YMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPBROADCASTQ YMM{K}{Z}, XMM	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	ZMM{K}{Z},XMM	AVX512,FUTURE	VPBROADCASTQ zmm{K}{Z}, XMM	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	XMM{K}{Z},R64	AVX512VL,AVX512,FUTURE	VPBROADCASTQ XMM{K}{Z}, r64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	YMM{K}{Z},R64	AVX512VL,AVX512,FUTURE	VPBROADCASTQ YMM{K}{Z}, r64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	ZMM{K}{Z},R64	AVX512,FUTURE	VPBROADCASTQ zmm{K}{Z}, r64	Broadcast Int64 Vector	VPBROADCAST.html
VPERMD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPERMD YMM, YMM, YMM/m256	Permutes Int32 Vectors	VPERMD.html
VPERMD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPERMD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Permutes Int32 Vectors	VPERMD.html
VPERMD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPERMD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Permutes Int32 Vectors	VPERMD.html
VPERMPD	YMM,YMM/M256,IMM8	FUTURE,AVX2	VPERMPD YMM, YMM/m256, IMM8	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPD	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPERMPD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPD	ZMM{K}{Z},ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPERMPD zmm{K}{Z}, zmm/m512/M32BCST, IMM8	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPERMPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPERMPD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPS	YMM,YMM,YMM/M256	FUTURE,AVX2	VPERMPS YMM, YMM, YMM/m256	Permute Single-Precision Floating-Point Elements	VPERMPS.html
VPERMPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPERMPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Permute Single-Precision Floating-Point Elements	VPERMPS.html
VPERMPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPERMPS zmm{K}{Z}, zmm, zmm/m512/M32BCST	Permute Single-Precision Floating-Point Elements	VPERMPS.html
VPERMQ	YMM,YMM/M256,IMM8	FUTURE,AVX2	VPERMQ YMM, YMM/m256, IMM8	Qwords Element Permutation	VPERMQ.html
VPERMQ	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPERMQ YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Qwords Element Permutation	VPERMQ.html
VPERMQ	ZMM{K}{Z},ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPERMQ zmm{K}{Z}, zmm/m512/M32BCST, IMM8	Qwords Element Permutation	VPERMQ.html
VPERMQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPERMQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	Qwords Element Permutation	VPERMQ.html
VPERMQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPERMQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	Qwords Element Permutation	VPERMQ.html
VPERM2I128	YMM,YMM,YMM/M256,IMM8	FUTURE,AVX2	VPERM2I128 YMM, YMM, YMM/m256, IMM8	Permute Integer Values	VPERM2I128.html
VEXTRACTI128	XMM/M128,YMM,IMM8	FUTURE,AVX2	VEXTRACTI128 XMM/M128, YMM, IMM8	Extract packed Integer Values	VEXTRACTI128.html
VINSERTI128	YMM,YMM,XMM/M128,IMM8	FUTURE,AVX2	VINSERTI128 YMM, YMM, XMM/M128, IMM8	Insert Packed Integer Values	VINSERTI128.html
VPMASKMOVD	XMM,XMM,M128	FUTURE,AVX2	VPMASKMOVD XMM, XMM, M128	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVD	YMM,YMM,M256	FUTURE,AVX2	VPMASKMOVD YMM, YMM, M256	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVD	M128,XMM,XMM	FUTURE,AVX2	VPMASKMOVD M128, XMM, XMM	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVD	M256,YMM,YMM	FUTURE,AVX2	VPMASKMOVD M256, YMM, YMM	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVQ	XMM,XMM,M128	FUTURE,AVX2	VPMASKMOVQ XMM, XMM, M128	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVQ	YMM,YMM,M256	FUTURE,AVX2	VPMASKMOVQ YMM, YMM, M256	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVQ	M128,XMM,XMM	FUTURE,AVX2	VPMASKMOVQ M128, XMM, XMM	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVQ	M256,YMM,YMM	FUTURE,AVX2	VPMASKMOVQ M256, YMM, YMM	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPSLLVD	XMM,XMM,XMM/M128	FUTURE,AVX2	VPSLLVD XMM, XMM, XMM/M128	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSLLVD YMM, YMM, YMM/m256	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPSLLVD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPSLLVD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPSLLVD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	XMM,XMM,XMM/M128	FUTURE,AVX2	VPSLLVQ XMM, XMM, XMM/M128	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSLLVQ YMM, YMM, YMM/m256	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPSLLVQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPSLLVQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPSLLVQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSRAVD	XMM,XMM,XMM/M128	FUTURE,AVX2	VPSRAVD XMM, XMM, XMM/M128	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRAVD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSRAVD YMM, YMM, YMM/m256	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRAVD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPSRAVD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRAVD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPSRAVD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRAVD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPSRAVD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRLVD	XMM,XMM,XMM/M128	FUTURE,AVX2	VPSRLVD XMM, XMM, XMM/M128	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVD	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSRLVD YMM, YMM, YMM/m256	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPSRLVD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPSRLVD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPSRLVD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	XMM,XMM,XMM/M128	FUTURE,AVX2	VPSRLVQ XMM, XMM, XMM/M128	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	YMM,YMM,YMM/M256	FUTURE,AVX2	VPSRLVQ YMM, YMM, YMM/m256	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPSRLVQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPSRLVQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPSRLVQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VGATHERDPD	XMM,xmem64,XMM	FUTURE,AVX2	VGATHERDPD XMM, xmem64, XMM	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPD	YMM,xmem64,YMM	FUTURE,AVX2	VGATHERDPD YMM, xmem64, YMM	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPD	XMM{K},xmem64	AVX512VL,AVX512,FUTURE	VGATHERDPD XMM{K}, xmem64	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPD	YMM{K},xmem64	AVX512VL,AVX512,FUTURE	VGATHERDPD YMM{K}, xmem64	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPD	ZMM{K},ymem64	AVX512,FUTURE	VGATHERDPD zmm{K}, ymem64	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	XMM,xmem64,XMM	FUTURE,AVX2	VGATHERQPD XMM, xmem64, XMM	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	YMM,ymem64,YMM	FUTURE,AVX2	VGATHERQPD YMM, ymem64, YMM	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	XMM{K},xmem64	AVX512VL,AVX512,FUTURE	VGATHERQPD XMM{K}, xmem64	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	YMM{K},ymem64	AVX512VL,AVX512,FUTURE	VGATHERQPD YMM{K}, ymem64	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	ZMM{K},zmem64	AVX512,FUTURE	VGATHERQPD zmm{K}, zmem64	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPS	XMM,VM32X,XMM	FUTURE,AVX2	VGATHERDPS XMM, VM32X, XMM	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERDPS	YMM,ymem32,YMM	FUTURE,AVX2	VGATHERDPS YMM, ymem32, YMM	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERDPS	XMM{K},VM32X	AVX512VL,AVX512,FUTURE	VGATHERDPS XMM{K}, VM32X	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERDPS	YMM{K},ymem32	AVX512VL,AVX512,FUTURE	VGATHERDPS YMM{K}, ymem32	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERDPS	ZMM{K},zmem32	AVX512,FUTURE	VGATHERDPS zmm{K}, zmem32	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	XMM,VM32X,XMM	FUTURE,AVX2	VGATHERQPS XMM, VM32X, XMM	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	XMM,ymem32,XMM	FUTURE,AVX2	VGATHERQPS XMM, ymem32, XMM	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	XMM{K},VM32X	AVX512VL,AVX512,FUTURE	VGATHERQPS XMM{K}, VM32X	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	XMM{K},ymem32	AVX512VL,AVX512,FUTURE	VGATHERQPS XMM{K}, ymem32	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	YMM{K},zmem32	AVX512,FUTURE	VGATHERQPS YMM{K}, zmem32	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VPGATHERDD	XMM,VM32X,XMM	FUTURE,AVX2	VPGATHERDD XMM, VM32X, XMM	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDD	YMM,ymem32,YMM	FUTURE,AVX2	VPGATHERDD YMM, ymem32, YMM	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDD	XMM{K},VM32X	AVX512VL,AVX512,FUTURE	VPGATHERDD XMM{K}, VM32X	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDD	YMM{K},ymem32	AVX512VL,AVX512,FUTURE	VPGATHERDD YMM{K}, ymem32	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDD	ZMM{K},zmem32	AVX512,FUTURE	VPGATHERDD zmm{K}, zmem32	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	XMM,VM32X,XMM	FUTURE,AVX2	VPGATHERQD XMM, VM32X, XMM	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	XMM,ymem32,XMM	FUTURE,AVX2	VPGATHERQD XMM, ymem32, XMM	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	XMM{K},VM32X	AVX512VL,AVX512,FUTURE	VPGATHERQD XMM{K}, VM32X	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	XMM{K},ymem32	AVX512VL,AVX512,FUTURE	VPGATHERQD XMM{K}, ymem32	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	YMM{K},zmem32	AVX512,FUTURE	VPGATHERQD YMM{K}, zmem32	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDQ	XMM,xmem64,XMM	FUTURE,AVX2	VPGATHERDQ XMM, xmem64, XMM	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERDQ	YMM,xmem64,YMM	FUTURE,AVX2	VPGATHERDQ YMM, xmem64, YMM	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERDQ	XMM{K},xmem64	AVX512VL,AVX512,FUTURE	VPGATHERDQ XMM{K}, xmem64	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERDQ	YMM{K},xmem64	AVX512VL,AVX512,FUTURE	VPGATHERDQ YMM{K}, xmem64	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERDQ	ZMM{K},ymem64	AVX512,FUTURE	VPGATHERDQ zmm{K}, ymem64	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	XMM,xmem64,XMM	FUTURE,AVX2	VPGATHERQQ XMM, xmem64, XMM	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	YMM,ymem64,YMM	FUTURE,AVX2	VPGATHERQQ YMM, ymem64, YMM	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	XMM{K},xmem64	AVX512VL,AVX512,FUTURE	VPGATHERQQ XMM{K}, xmem64	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	YMM{K},ymem64	AVX512VL,AVX512,FUTURE	VPGATHERQQ YMM{K}, ymem64	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	ZMM{K},zmem64	AVX512,FUTURE	VPGATHERQQ zmm{K}, zmem64	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
XABORT	IMM	FUTURE,RTM	XABORT IMM	Transactional Abort	XABORT.html
XABORT	IMM8	FUTURE,RTM	XABORT IMM8	Transactional Abort	XABORT.html
XBEGIN	IMM	FUTURE,RTM	XBEGIN IMM	Transactional Begin	XBEGIN.html
XBEGIN	IMM|NEAR	FUTURE,RTM	XBEGIN IMM|NEAR	Transactional Begin	XBEGIN.html
XBEGIN	IMM16	FUTURE,RTM	XBEGIN IMM16	Transactional Begin	XBEGIN.html
XBEGIN	IMM16|NEAR	FUTURE,RTM	XBEGIN IMM16|NEAR	Transactional Begin	XBEGIN.html
XBEGIN	IMM32	FUTURE,RTM	XBEGIN IMM32	Transactional Begin	XBEGIN.html
XBEGIN	IMM32|NEAR	FUTURE,RTM	XBEGIN IMM32|NEAR	Transactional Begin	XBEGIN.html
XBEGIN	IMM64	FUTURE,RTM,LONG	XBEGIN IMM64	Transactional Begin	XBEGIN.html
XBEGIN	IMM64|NEAR	FUTURE,RTM,LONG	XBEGIN IMM64|NEAR	Transactional Begin	XBEGIN.html
XEND		FUTURE,RTM	XEND 	Transactional End	XEND.html
XTEST		FUTURE,HLE,RTM	XTEST 	Test If In Transactional Execution	XTEST.html
ANDN	R32,R32,R/M32	FUTURE,BMI1	ANDN R32, R32, R/M32	Logical AND NOT	ANDN.html
ANDN	R64,R64,R/M64	LONG,FUTURE,BMI1	ANDN r64, r64, r/m64	Logical AND NOT	ANDN.html
BEXTR	R32,R/M32,R32	FUTURE,BMI1	BEXTR R32, R/M32, R32	Bit Field Extract	BEXTR.html
BEXTR	R64,R/M64,R64	LONG,FUTURE,BMI1	BEXTR r64, r/m64, r64	Bit Field Extract	BEXTR.html
BEXTR	R32,R/M32,IMM32	FUTURE,TBM	BEXTR R32, R/M32, IMM32	Bit Field Extract	BEXTR.html
BEXTR	R64,R/M64,IMM32	LONG,FUTURE,TBM	BEXTR r64, r/m64, IMM32	Bit Field Extract	BEXTR.html
BLCI	R32,R/M32	FUTURE,TBM	BLCI R32, R/M32	TODO: FUTURE,TBM,LONG	
BLCI	R64,R/M64	LONG,FUTURE,TBM	BLCI r64, r/m64	TODO: FUTURE,TBM,LONG	
BLCIC	R32,R/M32	FUTURE,TBM	BLCIC R32, R/M32	TODO: FUTURE,TBM,LONG	
BLCIC	R64,R/M64	LONG,FUTURE,TBM	BLCIC r64, r/m64	TODO: FUTURE,TBM,LONG	
BLSI	R32,R/M32	FUTURE,BMI1	BLSI R32, R/M32	Extract Lowest Set Isolated Bit	BLSI.html
BLSI	R64,R/M64	LONG,FUTURE,BMI1	BLSI r64, r/m64	Extract Lowest Set Isolated Bit	BLSI.html
BLSIC	R32,R/M32	FUTURE,TBM	BLSIC R32, R/M32	TODO: FUTURE,TBM,LONG	
BLSIC	R64,R/M64	LONG,FUTURE,TBM	BLSIC r64, r/m64	TODO: FUTURE,TBM,LONG	
BLCFILL	R32,R/M32	FUTURE,TBM	BLCFILL R32, R/M32	TODO: FUTURE,TBM,LONG	
BLCFILL	R64,R/M64	LONG,FUTURE,TBM	BLCFILL r64, r/m64	TODO: FUTURE,TBM,LONG	
BLSFILL	R32,R/M32	FUTURE,TBM	BLSFILL R32, R/M32	TODO: FUTURE,TBM,LONG	
BLSFILL	R64,R/M64	LONG,FUTURE,TBM	BLSFILL r64, r/m64	TODO: FUTURE,TBM,LONG	
BLCMSK	R32,R/M32	FUTURE,TBM	BLCMSK R32, R/M32	TODO: FUTURE,TBM,LONG	
BLCMSK	R64,R/M64	LONG,FUTURE,TBM	BLCMSK r64, r/m64	TODO: FUTURE,TBM,LONG	
BLSMSK	R32,R/M32	FUTURE,BMI1	BLSMSK R32, R/M32	Get Mask Up to Lowest Set Bit	BLSMSK.html
BLSMSK	R64,R/M64	LONG,FUTURE,BMI1	BLSMSK r64, r/m64	Get Mask Up to Lowest Set Bit	BLSMSK.html
BLSR	R32,R/M32	FUTURE,BMI1	BLSR R32, R/M32	Reset Lowest Set Bit	BLSR.html
BLSR	R64,R/M64	LONG,FUTURE,BMI1	BLSR r64, r/m64	Reset Lowest Set Bit	BLSR.html
BLCS	R32,R/M32	FUTURE,TBM	BLCS R32, R/M32	TODO: FUTURE,TBM,LONG	
BLCS	R64,R/M64	LONG,FUTURE,TBM	BLCS r64, r/m64	TODO: FUTURE,TBM,LONG	
BZHI	R32,R/M32,R32	FUTURE,BMI2	BZHI R32, R/M32, R32	Zero High Bits Starting with Specified Bit Position	BZHI.html
BZHI	R64,R/M64,R64	LONG,FUTURE,BMI2	BZHI r64, r/m64, r64	Zero High Bits Starting with Specified Bit Position	BZHI.html
MULX	R32,R32,R/M32	FUTURE,BMI2	MULX R32, R32, R/M32	Unsigned Multiply Without Affecting Flags	MULX.html
MULX	R64,R64,R/M64	LONG,FUTURE,BMI2	MULX r64, r64, r/m64	Unsigned Multiply Without Affecting Flags	MULX.html
PDEP	R32,R32,R/M32	FUTURE,BMI2	PDEP R32, R32, R/M32	Parallel Bits Deposit	PDEP.html
PDEP	R64,R64,R/M64	LONG,FUTURE,BMI2	PDEP r64, r64, r/m64	Parallel Bits Deposit	PDEP.html
PEXT	R32,R32,R/M32	FUTURE,BMI2	PEXT R32, R32, R/M32	Parallel Bits Extract	PEXT.html
PEXT	R64,R64,R/M64	LONG,FUTURE,BMI2	PEXT r64, r64, r/m64	Parallel Bits Extract	PEXT.html
RORX	R32,R/M32,IMM8	FUTURE,BMI2	RORX R32, R/M32, IMM8	Rotate Right Logical Without Affecting Flags	RORX.html
RORX	R64,R/M64,IMM8	LONG,FUTURE,BMI2	RORX r64, r/m64, IMM8	Rotate Right Logical Without Affecting Flags	RORX.html
SARX	R32,R/M32,R32	FUTURE,BMI2	SARX R32, R/M32, R32	Shift Arithmetic Right Without Affecting Flags	SARX:SHLX:SHRX.html
SARX	R64,R/M64,R64	LONG,FUTURE,BMI2	SARX r64, r/m64, r64	Shift Arithmetic Right Without Affecting Flags	SARX:SHLX:SHRX.html
SHLX	R32,R/M32,R32	FUTURE,BMI2	SHLX R32, R/M32, R32	Shift Logical Left Without Affecting Flags	SARX:SHLX:SHRX.html
SHLX	R64,R/M64,R64	LONG,FUTURE,BMI2	SHLX r64, r/m64, r64	Shift Logical Left Without Affecting Flags	SARX:SHLX:SHRX.html
SHRX	R32,R/M32,R32	FUTURE,BMI2	SHRX R32, R/M32, R32	Shift Logical Right Without Affecting Flags	SARX:SHLX:SHRX.html
SHRX	R64,R/M64,R64	LONG,FUTURE,BMI2	SHRX r64, r/m64, r64	Shift Logical Right Without Affecting Flags	SARX:SHLX:SHRX.html
TZCNT	R16,R/M16	FUTURE,BMI1	TZCNT R16, r/m16	Trailing Zero Count	TZCNT.html
TZCNT	R32,R/M32	FUTURE,BMI1	TZCNT R32, R/M32	Trailing Zero Count	TZCNT.html
TZCNT	R64,R/M64	LONG,FUTURE,BMI1	TZCNT r64, r/m64	Trailing Zero Count	TZCNT.html
TZMSK	R32,R/M32	FUTURE,TBM	TZMSK R32, R/M32	TODO: FUTURE,TBM,LONG	
TZMSK	R64,R/M64	LONG,FUTURE,TBM	TZMSK r64, r/m64	TODO: FUTURE,TBM,LONG	
T1MSKC	R32,R/M32	FUTURE,TBM	T1MSKC R32, R/M32	TODO: FUTURE,TBM,LONG	
T1MSKC	R64,R/M64	LONG,FUTURE,TBM	T1MSKC r64, r/m64	TODO: FUTURE,TBM,LONG	
PREFETCHWT1	M8	PREFETCHWT1,FUTURE	PREFETCHWT1 M8	Prefetch Vector Data Into Caches with Intent to Write and T1 Hint	PREFETCHWT1.html

BNDMK	bndreg,MEM	MPX,MIB,FUTURE	BNDMK b, m	Create LowerBound (LB) and UpperBound (UB) in the bounds register b	

BNDCL	bndreg,MEM	MPX,FUTURE	BNDCL b, MEM	 Checks the address of a memory reference or address in r against the lower bound 	
BNDCL	bndreg,R32	MPX,FUTURE	BNDCL b, R32	 Checks the address of a memory reference or address in r against the lower bound 	
BNDCL	bndreg,R64	MPX,LONG,FUTURE	BNDCL b, r64	 Checks the address of a memory reference or address in r against the lower bound 	

BNDCU	bndreg,MEM	MPX,FUTURE	BNDCU bndreg, MEM	Checks the address of a memory reference or address in r against the upper bound in 1's complement form	
BNDCU	bndreg,R32	MPX,FUTURE	BNDCU bndreg, R32	Checks the address of a memory reference or address in r against the upper bound in 1's complement form	
BNDCU	bndreg,R64	MPX,LONG,FUTURE	BNDCU bndreg, r64	Checks the address of a memory reference or address in r against the upper bound in 1's complement form	
BNDCN	bndreg,MEM	MPX,FUTURE	BNDCN bndreg, MEM	Checks the address of a memory reference or address in r against the upper bound in 1's complement formChecks the address of a memory reference or address in r against the upper bound not in 1's complement form	
BNDCN	bndreg,R32	MPX,FUTURE	BNDCN bndreg, R32	Checks the address of a memory reference or address in r against the upper bound in 1's complement formChecks the address of a memory reference or address in r against the upper bound not in 1's complement form	
BNDCN	bndreg,R64	MPX,LONG,FUTURE	BNDCN bndreg, r64	Checks the address of a memory reference or address in r against the upper bound in 1's complement formChecks the address of a memory reference or address in r against the upper bound not in 1's complement form	

BNDMOV	bndreg,bndreg	MPX,FUTURE	BNDMOV bndreg, bndreg	Copy/load LB and UB bounds from memory or a bounds register	
BNDMOV	bndreg,MEM	MPX,FUTURE	BNDMOV bndreg, MEM	Copy/load LB and UB bounds from memory or a bounds register	
BNDMOV	MEM,bndreg	MPX,FUTURE	BNDMOV MEM, bndreg	Store LB and UB bounds in a bounds register to memory or another register	

BNDLDX	bndreg,MEM	MPX,MIB,FUTURE	BNDLDX bndreg, MEM	Load bounds using address translation using an sib-addressing expression mib	
BNDLDX	bndreg,MEM,R32	MPX,MIB,FUTURE	BNDLDX bndreg, MEM, R32	Load bounds using address translation using an sib-addressing expression mib	
BNDLDX	bndreg,MEM,R64	MPX,MIB,LONG,FUTURE	BNDLDX bndreg, MEM, r64	Load bounds using address translation using an sib-addressing expression mib	
BNDSTX	MEM,bndreg	MPX,MIB,FUTURE	BNDSTX MEM, bndreg	Store bounds using address translation using an sib-addressing expression mib	
BNDSTX	MEM,R32,bndreg	MPX,MIB,FUTURE	BNDSTX MEM, R32, bndreg	Store bounds using address translation using an sib-addressing expression mib	
BNDSTX	MEM,R64,bndreg	MPX,MIB,LONG,FUTURE	BNDSTX MEM, r64, bndreg	Store bounds using address translation using an sib-addressing expression mib	
BNDSTX	MEM,bndreg,R32	MPX,MIB,FUTURE	BNDSTX MEM, bndreg, R32	Store bounds using address translation using an sib-addressing expression mib	
BNDSTX	MEM,bndreg,R64	MPX,MIB,LONG,FUTURE	BNDSTX MEM, bndreg, r64	Store bounds using address translation using an sib-addressing expression mib	

KADDB	K,K,K	FUTURE	KADDB K, K, K	TODO: FUTURE	
KADDD	K,K,K	FUTURE	KADDD K, K, K	TODO: FUTURE	
KADDQ	K,K,K	FUTURE	KADDQ K, K, K	TODO: FUTURE	
KADDW	K,K,K	FUTURE	KADDW K, K, K	TODO: FUTURE	
KANDB	K,K,K	FUTURE	KANDB K, K, K	TODO: FUTURE	
KANDD	K,K,K	FUTURE	KANDD K, K, K	TODO: FUTURE	
KANDNB	K,K,K	FUTURE	KANDNB K, K, K	TODO: FUTURE	
KANDND	K,K,K	FUTURE	KANDND K, K, K	TODO: FUTURE	
KANDNQ	K,K,K	FUTURE	KANDNQ K, K, K	TODO: FUTURE	
KANDNW	K,K,K	FUTURE	KANDNW K, K, K	TODO: FUTURE	
KANDQ	K,K,K	FUTURE	KANDQ K, K, K	TODO: FUTURE	
KANDW	K,K,K	FUTURE	KANDW K, K, K	TODO: FUTURE	
KMOVB	K,K/M8	FUTURE	KMOVB K, K/M8	TODO: FUTURE	
KMOVB	M8,K	FUTURE	KMOVB M8, K	TODO: FUTURE	
KMOVB	K,R32	FUTURE	KMOVB K, R32	TODO: FUTURE	
KMOVB	R32,K	FUTURE	KMOVB R32, K	TODO: FUTURE	
KMOVD	K,K/M32	FUTURE	KMOVD K, K/M32	TODO: FUTURE	
KMOVD	M32,K	FUTURE	KMOVD M32, K	TODO: FUTURE	
KMOVD	K,R32	FUTURE	KMOVD K, R32	TODO: FUTURE	
KMOVD	R32,K	FUTURE	KMOVD R32, K	TODO: FUTURE	
KMOVQ	K,K/M64	FUTURE	KMOVQ K, K/M64	TODO: FUTURE	
KMOVQ	M64,K	FUTURE	KMOVQ M64, K	TODO: FUTURE	
KMOVQ	K,R64	FUTURE	KMOVQ K, r64	TODO: FUTURE	
KMOVQ	R64,K	FUTURE	KMOVQ r64, K	TODO: FUTURE	
KMOVW	K,K/M16	FUTURE	KMOVW K, K/M16	TODO: FUTURE	
KMOVW	M16,K	FUTURE	KMOVW M16, K	TODO: FUTURE	
KMOVW	K,R32	FUTURE	KMOVW K, R32	TODO: FUTURE	
KMOVW	R32,K	FUTURE	KMOVW R32, K	TODO: FUTURE	
KNOTB	K,K	FUTURE	KNOTB K, K	TODO: FUTURE	
KNOTD	K,K	FUTURE	KNOTD K, K	TODO: FUTURE	
KNOTQ	K,K	FUTURE	KNOTQ K, K	TODO: FUTURE	
KNOTW	K,K	FUTURE	KNOTW K, K	TODO: FUTURE	
KORB	K,K,K	FUTURE	KORB K, K, K	TODO: FUTURE	
KORD	K,K,K	FUTURE	KORD K, K, K	TODO: FUTURE	
KORQ	K,K,K	FUTURE	KORQ K, K, K	TODO: FUTURE	
KORTESTB	K,K	FUTURE	KORTESTB K, K	TODO: FUTURE	
KORTESTD	K,K	FUTURE	KORTESTD K, K	TODO: FUTURE	
KORTESTQ	K,K	FUTURE	KORTESTQ K, K	TODO: FUTURE	
KORTESTW	K,K	FUTURE	KORTESTW K, K	TODO: FUTURE	
KORW	K,K,K	FUTURE	KORW K, K, K	TODO: FUTURE	
KSHIFTLB	K,K,IMM8	FUTURE	KSHIFTLB K, K, IMM8	TODO: FUTURE	
KSHIFTLD	K,K,IMM8	FUTURE	KSHIFTLD K, K, IMM8	TODO: FUTURE	
KSHIFTLQ	K,K,IMM8	FUTURE	KSHIFTLQ K, K, IMM8	TODO: FUTURE	
KSHIFTLW	K,K,IMM8	FUTURE	KSHIFTLW K, K, IMM8	TODO: FUTURE	
KSHIFTRB	K,K,IMM8	FUTURE	KSHIFTRB K, K, IMM8	TODO: FUTURE	
KSHIFTRD	K,K,IMM8	FUTURE	KSHIFTRD K, K, IMM8	TODO: FUTURE	
KSHIFTRQ	K,K,IMM8	FUTURE	KSHIFTRQ K, K, IMM8	TODO: FUTURE	
KSHIFTRW	K,K,IMM8	FUTURE	KSHIFTRW K, K, IMM8	TODO: FUTURE	
KTESTB	K,K	FUTURE	KTESTB K, K	TODO: FUTURE	
KTESTD	K,K	FUTURE	KTESTD K, K	TODO: FUTURE	
KTESTQ	K,K	FUTURE	KTESTQ K, K	TODO: FUTURE	
KTESTW	K,K	FUTURE	KTESTW K, K	TODO: FUTURE	
KUNPCKBW	K,K,K	FUTURE	KUNPCKBW K, K, K	TODO: FUTURE	
KUNPCKDQ	K,K,K	FUTURE	KUNPCKDQ K, K, K	TODO: FUTURE	
KUNPCKWD	K,K,K	FUTURE	KUNPCKWD K, K, K	TODO: FUTURE	
KXNORB	K,K,K	FUTURE	KXNORB K, K, K	TODO: FUTURE	
KXNORD	K,K,K	FUTURE	KXNORD K, K, K	TODO: FUTURE	
KXNORQ	K,K,K	FUTURE	KXNORQ K, K, K	TODO: FUTURE	
KXNORW	K,K,K	FUTURE	KXNORW K, K, K	TODO: FUTURE	
KXORB	K,K,K	FUTURE	KXORB K, K, K	TODO: FUTURE	
KXORD	K,K,K	FUTURE	KXORD K, K, K	TODO: FUTURE	
KXORQ	K,K,K	FUTURE	KXORQ K, K, K	TODO: FUTURE	
KXORW	K,K,K	FUTURE	KXORW K, K, K	TODO: FUTURE	
SHA1MSG1	XMM,XMM/M128	SHA,FUTURE	SHA1MSG1 XMM, XMM/M128	TODO: SHA,FUTURE	
SHA1MSG2	XMM,XMM/M128	SHA,FUTURE	SHA1MSG2 XMM, XMM/M128	TODO: SHA,FUTURE	
SHA1NEXTE	XMM,XMM/M128	SHA,FUTURE	SHA1NEXTE XMM, XMM/M128	TODO: SHA,FUTURE	
SHA1RNDS4	XMM,XMM/M128,IMM8	SHA,FUTURE	SHA1RNDS4 XMM, XMM/M128, IMM8	TODO: SHA,FUTURE	
SHA256MSG1	XMM,XMM/M128	SHA,FUTURE	SHA256MSG1 XMM, XMM/M128	TODO: SHA,FUTURE	
SHA256MSG2	XMM,XMM/M128	SHA,FUTURE	SHA256MSG2 XMM, XMM/M128	TODO: SHA,FUTURE	
SHA256RNDS2	XMM,XMM/M128,XMM_ZERO	SHA,FUTURE	SHA256RNDS2 XMM, XMM/M128, XMM_ZERO	TODO: SHA,FUTURE	
VALIGND	XMM{K}{Z},XMM,XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VALIGND XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	Align Doubleword Vectors	
VALIGND	YMM{K}{Z},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VALIGND YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	Align Doubleword Vectors	
VALIGND	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VALIGND zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	Align Doubleword Vectors	
VALIGNQ	XMM{K}{Z},XMM,XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VALIGNQ XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VALIGNQ	YMM{K}{Z},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VALIGNQ YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VALIGNQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VALIGNQ zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VBLENDMPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VBLENDMPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Blend Float64 Vectors using the Instruction Mask	
VBLENDMPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VBLENDMPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Blend Float64 Vectors using the Instruction Mask	
VBLENDMPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VBLENDMPD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Blend Float64 Vectors using the Instruction Mask	
VBLENDMPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VBLENDMPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	Blend Float32 Vectors using the Instruction Mask	
VBLENDMPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VBLENDMPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	Blend Float32 Vectors using the Instruction Mask	
VBLENDMPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VBLENDMPS zmm{K}{Z}, zmm, zmm/m512/M32BCST	Blend Float32 Vectors using the Instruction Mask	
VBROADCASTF32X2	YMM{K}{Z},XMM/M64	AVX512VL,AVX512DQ,FUTURE	VBROADCASTF32X2 YMM{K}{Z}, XMM/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTF32X2	ZMM{K}{Z},XMM/M64	AVX512DQ,FUTURE	VBROADCASTF32X2 zmm{K}{Z}, XMM/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTF32X4	YMM{K}{Z},M128	AVX512VL,AVX512,FUTURE	VBROADCASTF32X4 YMM{K}{Z}, M128	Broadcast 4xFloat32 Vector	
VBROADCASTF32X4	ZMM{K}{Z},M128	AVX512,FUTURE	VBROADCASTF32X4 zmm{K}{Z}, M128	Broadcast 4xFloat32 Vector	
VBROADCASTF32X8	ZMM{K}{Z},M256	AVX512DQ,FUTURE	VBROADCASTF32X8 zmm{K}{Z}, M256	TODO: AVX512DQ,FUTURE	
VBROADCASTF64X2	YMM{K}{Z},M128	AVX512VL,AVX512DQ,FUTURE	VBROADCASTF64X2 YMM{K}{Z}, M128	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTF64X2	ZMM{K}{Z},M128	AVX512DQ,FUTURE	VBROADCASTF64X2 zmm{K}{Z}, M128	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTF64X4	ZMM{K}{Z},M256	AVX512,FUTURE	VBROADCASTF64X4 zmm{K}{Z}, M256	Broadcast 4xFloat64 Vector	
VBROADCASTI32X2	XMM{K}{Z},XMM/M64	AVX512VL,AVX512DQ,FUTURE	VBROADCASTI32X2 XMM{K}{Z}, XMM/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI32X2	YMM{K}{Z},XMM/M64	AVX512VL,AVX512DQ,FUTURE	VBROADCASTI32X2 YMM{K}{Z}, XMM/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI32X2	ZMM{K}{Z},XMM/M64	AVX512DQ,FUTURE	VBROADCASTI32X2 zmm{K}{Z}, XMM/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI32X4	YMM{K}{Z},M128	AVX512VL,AVX512,FUTURE	VBROADCASTI32X4 YMM{K}{Z}, M128	Broadcast 4xInt32 Vector	
VBROADCASTI32X4	ZMM{K}{Z},M128	AVX512,FUTURE	VBROADCASTI32X4 zmm{K}{Z}, M128	Broadcast 4xInt32 Vector	
VBROADCASTI32X8	ZMM{K}{Z},M256	AVX512DQ,FUTURE	VBROADCASTI32X8 zmm{K}{Z}, M256	TODO: AVX512DQ,FUTURE	
VBROADCASTI64X2	YMM{K}{Z},M128	AVX512VL,AVX512DQ,FUTURE	VBROADCASTI64X2 YMM{K}{Z}, M128	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI64X2	ZMM{K}{Z},M128	AVX512DQ,FUTURE	VBROADCASTI64X2 zmm{K}{Z}, M128	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI64X4	ZMM{K}{Z},M256	AVX512,FUTURE	VBROADCASTI64X4 zmm{K}{Z}, M256	Broadcast 4xInt64 Vector	
VCOMPRESSPD	M128{K},XMM	AVX512VL,AVX512,FUTURE	VCOMPRESSPD M128{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	M256{K},YMM	AVX512VL,AVX512,FUTURE	VCOMPRESSPD M256{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	M512{K},ZMM	AVX512,FUTURE	VCOMPRESSPD M512{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VCOMPRESSPD XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VCOMPRESSPD YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	ZMM{K}{Z},ZMM	AVX512,FUTURE	VCOMPRESSPD zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	M128{K},XMM	AVX512VL,AVX512,FUTURE	VCOMPRESSPS M128{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	M256{K},YMM	AVX512VL,AVX512,FUTURE	VCOMPRESSPS M256{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	M512{K},ZMM	AVX512,FUTURE	VCOMPRESSPS M512{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VCOMPRESSPS XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VCOMPRESSPS YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	ZMM{K}{Z},ZMM	AVX512,FUTURE	VCOMPRESSPS zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VCVTPD2QQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTPD2QQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2QQ	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTPD2QQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2QQ	ZMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512DQ,FUTURE	VCVTPD2QQ zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2UDQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VCVTPD2UDQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTPD2UDQ	XMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VCVTPD2UDQ XMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTPD2UDQ	YMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VCVTPD2UDQ YMM{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512,FUTURE	
VCVTPD2UQQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTPD2UQQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2UQQ	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTPD2UQQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2UQQ	ZMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512DQ,FUTURE	VCVTPD2UQQ zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2QQ	XMM{K}{Z},XMM/M64/M32BCST	AVX512VL,AVX512DQ,FUTURE	VCVTPS2QQ XMM{K}{Z}, XMM/m64/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2QQ	YMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512DQ,FUTURE	VCVTPS2QQ YMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2QQ	ZMM{K}{Z},YMM/M256/M32BCST{ER}	AVX512DQ,FUTURE	VCVTPS2QQ zmm{K}{Z}, YMM/m256/M32BCST{ER}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2UDQ	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VCVTPS2UDQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTPS2UDQ	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VCVTPS2UDQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTPS2UDQ	ZMM{K}{Z},ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VCVTPS2UDQ zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512,FUTURE	
VCVTPS2UQQ	XMM{K}{Z},XMM/M64/M32BCST	AVX512VL,AVX512DQ,FUTURE	VCVTPS2UQQ XMM{K}{Z}, XMM/m64/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2UQQ	YMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512DQ,FUTURE	VCVTPS2UQQ YMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2UQQ	ZMM{K}{Z},YMM/M256/M32BCST{ER}	AVX512DQ,FUTURE	VCVTPS2UQQ zmm{K}{Z}, YMM/m256/M32BCST{ER}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PD	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTQQ2PD XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PD	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTQQ2PD YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PD	ZMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512DQ,FUTURE	VCVTQQ2PD zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PS	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTQQ2PS XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PS	XMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTQQ2PS XMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PS	YMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512DQ,FUTURE	VCVTQQ2PS YMM{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTSD2USI	R32,XMM/M64{ER}	AVX512,FUTURE	VCVTSD2USI R32, XMM/m64{ER}	TODO: AVX512,FUTURE	
VCVTSD2USI	R64,XMM/M64{ER}	AVX512,FUTURE	VCVTSD2USI r64, XMM/m64{ER}	TODO: AVX512,FUTURE	
VCVTSS2USI	R32,XMM/M32{ER}	AVX512,FUTURE	VCVTSS2USI R32, XMM/m32{ER}	TODO: AVX512,FUTURE	
VCVTSS2USI	R64,XMM/M32{ER}	AVX512,FUTURE	VCVTSS2USI r64, XMM/m32{ER}	TODO: AVX512,FUTURE	
VCVTTPD2QQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTTPD2QQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2QQ	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTTPD2QQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2QQ	ZMM{K}{Z},ZMM/M512/M64BCST{SAE}	AVX512DQ,FUTURE	VCVTTPD2QQ zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2UDQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VCVTTPD2UDQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPD2UDQ	XMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VCVTTPD2UDQ XMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPD2UDQ	YMM{K}{Z},ZMM/M512/M64BCST{SAE}	AVX512,FUTURE	VCVTTPD2UDQ YMM{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPD2UQQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTTPD2UQQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2UQQ	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTTPD2UQQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2UQQ	ZMM{K}{Z},ZMM/M512/M64BCST{SAE}	AVX512DQ,FUTURE	VCVTTPD2UQQ zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2QQ	XMM{K}{Z},XMM/M64/M32BCST	AVX512VL,AVX512DQ,FUTURE	VCVTTPS2QQ XMM{K}{Z}, XMM/m64/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2QQ	YMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512DQ,FUTURE	VCVTTPS2QQ YMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2QQ	ZMM{K}{Z},YMM/M256/M32BCST{SAE}	AVX512DQ,FUTURE	VCVTTPS2QQ zmm{K}{Z}, YMM/m256/M32BCST{SAE}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2UDQ	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VCVTTPS2UDQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPS2UDQ	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VCVTTPS2UDQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPS2UDQ	ZMM{K}{Z},ZMM/M512/M32BCST{SAE}	AVX512,FUTURE	VCVTTPS2UDQ zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPS2UQQ	XMM{K}{Z},XMM/M64/M32BCST	AVX512VL,AVX512DQ,FUTURE	VCVTTPS2UQQ XMM{K}{Z}, XMM/m64/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2UQQ	YMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512DQ,FUTURE	VCVTTPS2UQQ YMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2UQQ	ZMM{K}{Z},YMM/M256/M32BCST{SAE}	AVX512DQ,FUTURE	VCVTTPS2UQQ zmm{K}{Z}, YMM/m256/M32BCST{SAE}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTSD2USI	R32,XMM/M64{SAE}	AVX512,FUTURE	VCVTTSD2USI R32, XMM/m64{SAE}	TODO: AVX512,FUTURE	
VCVTTSD2USI	R64,XMM/M64{SAE}	AVX512,FUTURE	VCVTTSD2USI r64, XMM/m64{SAE}	TODO: AVX512,FUTURE	
VCVTTSS2USI	R32,XMM/M32{SAE}	AVX512,FUTURE	VCVTTSS2USI R32, XMM/m32{SAE}	TODO: AVX512,FUTURE	
VCVTTSS2USI	R64,XMM/M32{SAE}	AVX512,FUTURE	VCVTTSS2USI r64, XMM/m32{SAE}	TODO: AVX512,FUTURE	
VCVTUDQ2PD	XMM{K}{Z},XMM/M64/M32BCST	AVX512VL,AVX512,FUTURE	VCVTUDQ2PD XMM{K}{Z}, XMM/m64/M32BCST	Convert Uint32 Vector to Float64 Vector	
VCVTUDQ2PD	YMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VCVTUDQ2PD YMM{K}{Z}, XMM/M128/M32BCST	Convert Uint32 Vector to Float64 Vector	
VCVTUDQ2PD	ZMM{K}{Z},YMM/M256/M32BCST{ER}	AVX512,FUTURE	VCVTUDQ2PD zmm{K}{Z}, YMM/m256/M32BCST{ER}	Convert Uint32 Vector to Float64 Vector	
VCVTUDQ2PS	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VCVTUDQ2PS XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTUDQ2PS	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VCVTUDQ2PS YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VCVTUDQ2PS	ZMM{K}{Z},ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VCVTUDQ2PS zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512,FUTURE	
VCVTUQQ2PD	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTUQQ2PD XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PD	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTUQQ2PD YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PD	ZMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512DQ,FUTURE	VCVTUQQ2PD zmm{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PS	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTUQQ2PS XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PS	XMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VCVTUQQ2PS XMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PS	YMM{K}{Z},ZMM/M512/M64BCST{ER}	AVX512DQ,FUTURE	VCVTUQQ2PS YMM{K}{Z}, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUSI2SD	XMM,XMM{ER},R/M32	AVX512,FUTURE	VCVTUSI2SD XMM, XMM{ER}, R/M32	TODO: AVX512,FUTURE	
VCVTUSI2SD	XMM,XMM{ER},R/M64	AVX512,FUTURE	VCVTUSI2SD XMM, XMM{ER}, r/m64	TODO: AVX512,FUTURE	
VCVTUSI2SS	XMM,XMM{ER},R/M32	AVX512,FUTURE	VCVTUSI2SS XMM, XMM{ER}, R/M32	TODO: AVX512,FUTURE	
VCVTUSI2SS	XMM,XMM{ER},R/M64	AVX512,FUTURE	VCVTUSI2SS XMM, XMM{ER}, r/m64	TODO: AVX512,FUTURE	
VDBPSADBW	XMM{K}{Z},XMM,XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VDBPSADBW XMM{K}{Z}, XMM, XMM/M128, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VDBPSADBW	YMM{K}{Z},YMM,YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VDBPSADBW YMM{K}{Z}, YMM, YMM/m256, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VDBPSADBW	ZMM{K}{Z},ZMM,ZMM/M512,IMM8	AVX512BW,FUTURE	VDBPSADBW zmm{K}{Z}, zmm, zmm/m512, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VEXP2PD	ZMM{K}{Z},ZMM/M512/M64BCST{SAE}	AVX512ER,FUTURE	VEXP2PD zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512ER,FUTURE	
VEXP2PS	ZMM{K}{Z},ZMM/M512/M32BCST{SAE}	AVX512ER,FUTURE	VEXP2PS zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512ER,FUTURE	
VEXPANDPD	XMM{K}{Z},M128	AVX512VL,AVX512,FUTURE	VEXPANDPD XMM{K}{Z}, M128	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	YMM{K}{Z},M256	AVX512VL,AVX512,FUTURE	VEXPANDPD YMM{K}{Z}, M256	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	ZMM{K}{Z},M512	AVX512,FUTURE	VEXPANDPD zmm{K}{Z}, M512	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VEXPANDPD XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VEXPANDPD YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	ZMM{K}{Z},ZMM	AVX512,FUTURE	VEXPANDPD zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	XMM{K}{Z},M128	AVX512VL,AVX512,FUTURE	VEXPANDPS XMM{K}{Z}, M128	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	YMM{K}{Z},M256	AVX512VL,AVX512,FUTURE	VEXPANDPS YMM{K}{Z}, M256	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	ZMM{K}{Z},M512	AVX512,FUTURE	VEXPANDPS zmm{K}{Z}, M512	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VEXPANDPS XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VEXPANDPS YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	ZMM{K}{Z},ZMM	AVX512,FUTURE	VEXPANDPS zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X4	XMM{K}{Z},YMM,IMM8	AVX512VL,AVX512,FUTURE	VEXTRACTF32X4 XMM{K}{Z}, YMM, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X4	XMM{K}{Z},ZMM,IMM8	AVX512,FUTURE	VEXTRACTF32X4 XMM{K}{Z}, zmm, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X4	M128{K},YMM,IMM8	AVX512VL,AVX512,FUTURE	VEXTRACTF32X4 M128{K}, YMM, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X4	M128{K},ZMM,IMM8	AVX512,FUTURE	VEXTRACTF32X4 M128{K}, zmm, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X8	YMM{K}{Z},ZMM,IMM8	AVX512DQ,FUTURE	VEXTRACTF32X8 YMM{K}{Z}, zmm, IMM8	TODO: AVX512DQ,FUTURE	
VEXTRACTF32X8	M256{K},ZMM,IMM8	AVX512DQ,FUTURE	VEXTRACTF32X8 M256{K}, zmm, IMM8	TODO: AVX512DQ,FUTURE	
VEXTRACTF64X2	XMM{K}{Z},YMM,IMM8	AVX512VL,AVX512DQ,FUTURE	VEXTRACTF64X2 XMM{K}{Z}, YMM, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTF64X2	XMM{K}{Z},ZMM,IMM8	AVX512DQ,FUTURE	VEXTRACTF64X2 XMM{K}{Z}, zmm, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTF64X2	M128{K},YMM,IMM8	AVX512VL,AVX512DQ,FUTURE	VEXTRACTF64X2 M128{K}, YMM, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTF64X2	M128{K},ZMM,IMM8	AVX512DQ,FUTURE	VEXTRACTF64X2 M128{K}, zmm, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTF64X4	YMM{K}{Z},ZMM,IMM8	AVX512,FUTURE	VEXTRACTF64X4 YMM{K}{Z}, zmm, IMM8	TODO: AVX512,FUTURE	
VEXTRACTF64X4	M256{K},ZMM,IMM8	AVX512,FUTURE	VEXTRACTF64X4 M256{K}, zmm, IMM8	TODO: AVX512,FUTURE	
VEXTRACTI32X4	XMM{K}{Z},YMM,IMM8	AVX512VL,AVX512,FUTURE	VEXTRACTI32X4 XMM{K}{Z}, YMM, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTI32X4	XMM{K}{Z},ZMM,IMM8	AVX512,FUTURE	VEXTRACTI32X4 XMM{K}{Z}, zmm, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTI32X4	M128{K},YMM,IMM8	AVX512VL,AVX512,FUTURE	VEXTRACTI32X4 M128{K}, YMM, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTI32X4	M128{K},ZMM,IMM8	AVX512,FUTURE	VEXTRACTI32X4 M128{K}, zmm, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTI32X8	YMM{K}{Z},ZMM,IMM8	AVX512DQ,FUTURE	VEXTRACTI32X8 YMM{K}{Z}, zmm, IMM8	TODO: AVX512DQ,FUTURE	
VEXTRACTI32X8	M256{K},ZMM,IMM8	AVX512DQ,FUTURE	VEXTRACTI32X8 M256{K}, zmm, IMM8	TODO: AVX512DQ,FUTURE	
VEXTRACTI64X2	XMM{K}{Z},YMM,IMM8	AVX512VL,AVX512DQ,FUTURE	VEXTRACTI64X2 XMM{K}{Z}, YMM, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTI64X2	XMM{K}{Z},ZMM,IMM8	AVX512DQ,FUTURE	VEXTRACTI64X2 XMM{K}{Z}, zmm, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTI64X2	M128{K},YMM,IMM8	AVX512VL,AVX512DQ,FUTURE	VEXTRACTI64X2 M128{K}, YMM, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTI64X2	M128{K},ZMM,IMM8	AVX512DQ,FUTURE	VEXTRACTI64X2 M128{K}, zmm, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTI64X4	YMM{K}{Z},ZMM,IMM8	AVX512,FUTURE	VEXTRACTI64X4 YMM{K}{Z}, zmm, IMM8	TODO: AVX512,FUTURE	
VEXTRACTI64X4	M256{K},ZMM,IMM8	AVX512,FUTURE	VEXTRACTI64X4 M256{K}, zmm, IMM8	TODO: AVX512,FUTURE	
VFIXUPIMMPD	XMM{K}{Z},XMM,XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VFIXUPIMMPD XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPD	YMM{K}{Z},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VFIXUPIMMPD YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{SAE},IMM8	AVX512,FUTURE	VFIXUPIMMPD zmm{K}{Z}, zmm, zmm/m512/M32BCST{SAE}, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPS	XMM{K}{Z},XMM,XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VFIXUPIMMPS XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPS	YMM{K}{Z},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VFIXUPIMMPS YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{SAE},IMM8	AVX512,FUTURE	VFIXUPIMMPS zmm{K}{Z}, zmm, zmm/m512/M32BCST{SAE}, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMSD	XMM{K}{Z},XMM,XMM/M64{SAE},IMM8	AVX512,FUTURE	VFIXUPIMMSD XMM{K}{Z}, XMM, XMM/m64{SAE}, IMM8	TODO: AVX512,FUTURE	
VFIXUPIMMSS	XMM{K}{Z},XMM,XMM/M32{SAE},IMM8	AVX512,FUTURE	VFIXUPIMMSS XMM{K}{Z}, XMM, XMM/m32{SAE}, IMM8	TODO: AVX512,FUTURE	
VFPCLASSPD	K{K},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VFPCLASSPD K{K}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPD	K{K},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VFPCLASSPD K{K}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPD	K{K},ZMM/M512/M64BCST,IMM8	AVX512DQ,FUTURE	VFPCLASSPD K{K}, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPS	K{K},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VFPCLASSPS K{K}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPS	K{K},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VFPCLASSPS K{K}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPS	K{K},ZMM/M512/M32BCST,IMM8	AVX512DQ,FUTURE	VFPCLASSPS K{K}, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSSD	K{K},XMM/M64,IMM8	AVX512DQ,FUTURE	VFPCLASSSD K{K}, XMM/m64, IMM8	TODO: AVX512DQ,FUTURE	
VFPCLASSSS	K{K},XMM/M32,IMM8	AVX512DQ,FUTURE	VFPCLASSSS K{K}, XMM/m32, IMM8	TODO: AVX512DQ,FUTURE	
VGATHERPF0DPD	VM64Y{K}	AVX512PF,FUTURE	VGATHERPF0DPD VM64Y{K}	TODO: AVX512PF,FUTURE	
VGATHERPF0DPS	VM32Z{K}	AVX512PF,FUTURE	VGATHERPF0DPS VM32Z{K}	Gather Prefetch Float32 Vector With Signed Dword Indices Into L1	
VGATHERPF0QPD	VM64Z{K}	AVX512PF,FUTURE	VGATHERPF0QPD VM64Z{K}	TODO: AVX512PF,FUTURE	
VGATHERPF0QPS	VM32Z{K}	AVX512PF,FUTURE	VGATHERPF0QPS VM32Z{K}	TODO: AVX512PF,FUTURE	
VGATHERPF1DPD	VM64Y{K}	AVX512PF,FUTURE	VGATHERPF1DPD VM64Y{K}	TODO: AVX512PF,FUTURE	
VGATHERPF1DPS	VM32Z{K}	AVX512PF,FUTURE	VGATHERPF1DPS VM32Z{K}	Gather Prefetch Float32 Vector With Signed Dword Indices Into L2	
VGATHERPF1QPD	VM64Z{K}	AVX512PF,FUTURE	VGATHERPF1QPD VM64Z{K}	TODO: AVX512PF,FUTURE	
VGATHERPF1QPS	VM32Z{K}	AVX512PF,FUTURE	VGATHERPF1QPS VM32Z{K}	TODO: AVX512PF,FUTURE	
VGETEXPPD	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VGETEXPPD XMM{K}{Z}, XMM/M128/M32BCST	Extract Float64 Vector of Exponents from Float64 Vector	
VGETEXPPD	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VGETEXPPD YMM{K}{Z}, YMM/m256/M32BCST	Extract Float64 Vector of Exponents from Float64 Vector	
VGETEXPPD	ZMM{K}{Z},ZMM/M512/M64BCST{SAE}	AVX512,FUTURE	VGETEXPPD zmm{K}{Z}, zmm/m512/M32BCST{SAE}	Extract Float64 Vector of Exponents from Float64 Vector	
VGETEXPPS	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VGETEXPPS XMM{K}{Z}, XMM/M128/M32BCST	Extract Float32 Vector of Exponents from Float32 Vector	
VGETEXPPS	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VGETEXPPS YMM{K}{Z}, YMM/m256/M32BCST	Extract Float32 Vector of Exponents from Float32 Vector	
VGETEXPPS	ZMM{K}{Z},ZMM/M512/M32BCST{SAE}	AVX512,FUTURE	VGETEXPPS zmm{K}{Z}, zmm/m512/M32BCST{SAE}	Extract Float32 Vector of Exponents from Float32 Vector	
VGETEXPSD	XMM{K}{Z},XMM,XMM/M64{SAE}	AVX512,FUTURE	VGETEXPSD XMM{K}{Z}, XMM, XMM/m64{SAE}	TODO: AVX512,FUTURE	
VGETEXPSS	XMM{K}{Z},XMM,XMM/M32{SAE}	AVX512,FUTURE	VGETEXPSS XMM{K}{Z}, XMM, XMM/m32{SAE}	TODO: AVX512,FUTURE	
VGETMANTPD	XMM{K}{Z},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VGETMANTPD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	Extract Float64 Vector of Normalized Mantissas from Float64 Vector	
VGETMANTPD	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VGETMANTPD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Extract Float64 Vector of Normalized Mantissas from Float64 Vector	
VGETMANTPD	ZMM{K}{Z},ZMM/M512/M64BCST{SAE},IMM8	AVX512,FUTURE	VGETMANTPD zmm{K}{Z}, zmm/m512/M32BCST{SAE}, IMM8	Extract Float64 Vector of Normalized Mantissas from Float64 Vector	
VGETMANTPS	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VGETMANTPS XMM{K}{Z}, XMM/M128/M32BCST, IMM8	Extract Float32 Vector of Normalized Mantissas from Float32 Vector	
VGETMANTPS	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VGETMANTPS YMM{K}{Z}, YMM/m256/M32BCST, IMM8	Extract Float32 Vector of Normalized Mantissas from Float32 Vector	
VGETMANTPS	ZMM{K}{Z},ZMM/M512/M32BCST{SAE},IMM8	AVX512,FUTURE	VGETMANTPS zmm{K}{Z}, zmm/m512/M32BCST{SAE}, IMM8	Extract Float32 Vector of Normalized Mantissas from Float32 Vector	
VGETMANTSD	XMM{K}{Z},XMM,XMM/M64{SAE},IMM8	AVX512,FUTURE	VGETMANTSD XMM{K}{Z}, XMM, XMM/m64{SAE}, IMM8	TODO: AVX512,FUTURE	
VGETMANTSS	XMM{K}{Z},XMM,XMM/M32{SAE},IMM8	AVX512,FUTURE	VGETMANTSS XMM{K}{Z}, XMM, XMM/m32{SAE}, IMM8	TODO: AVX512,FUTURE	
VINSERTF32X4	YMM{K}{Z},YMM,XMM/M128,IMM8	AVX512VL,AVX512,FUTURE	VINSERTF32X4 YMM{K}{Z}, YMM, XMM/M128, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VINSERTF32X4	ZMM{K}{Z},ZMM,XMM/M128,IMM8	AVX512,FUTURE	VINSERTF32X4 zmm{K}{Z}, zmm, XMM/M128, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VINSERTF32X8	ZMM{K}{Z},ZMM,YMM/M256,IMM8	AVX512DQ,FUTURE	VINSERTF32X8 zmm{K}{Z}, zmm, YMM/m256, IMM8	TODO: AVX512DQ,FUTURE	
VINSERTF64X2	YMM{K}{Z},YMM,XMM/M128,IMM8	AVX512VL,AVX512DQ,FUTURE	VINSERTF64X2 YMM{K}{Z}, YMM, XMM/M128, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VINSERTF64X2	ZMM{K}{Z},ZMM,XMM/M128,IMM8	AVX512DQ,FUTURE	VINSERTF64X2 zmm{K}{Z}, zmm, XMM/M128, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VINSERTF64X4	ZMM{K}{Z},ZMM,YMM/M256,IMM8	AVX512,FUTURE	VINSERTF64X4 zmm{K}{Z}, zmm, YMM/m256, IMM8	TODO: AVX512,FUTURE	
VINSERTI32X4	YMM{K}{Z},YMM,XMM/M128,IMM8	AVX512VL,AVX512,FUTURE	VINSERTI32X4 YMM{K}{Z}, YMM, XMM/M128, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VINSERTI32X4	ZMM{K}{Z},ZMM,XMM/M128,IMM8	AVX512,FUTURE	VINSERTI32X4 zmm{K}{Z}, zmm, XMM/M128, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VINSERTI32X8	ZMM{K}{Z},ZMM,YMM/M256,IMM8	AVX512DQ,FUTURE	VINSERTI32X8 zmm{K}{Z}, zmm, YMM/m256, IMM8	TODO: AVX512DQ,FUTURE	
VINSERTI64X2	YMM{K}{Z},YMM,XMM/M128,IMM8	AVX512VL,AVX512DQ,FUTURE	VINSERTI64X2 YMM{K}{Z}, YMM, XMM/M128, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VINSERTI64X2	ZMM{K}{Z},ZMM,XMM/M128,IMM8	AVX512DQ,FUTURE	VINSERTI64X2 zmm{K}{Z}, zmm, XMM/M128, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VINSERTI64X4	ZMM{K}{Z},ZMM,YMM/M256,IMM8	AVX512,FUTURE	VINSERTI64X4 zmm{K}{Z}, zmm, YMM/m256, IMM8	TODO: AVX512,FUTURE	
VMOVDQA32	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVDQA32 XMM{K}{Z}, XMM/M128	Move Aligned Int32 Vector	
VMOVDQA32	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVDQA32 YMM{K}{Z}, YMM/m256	Move Aligned Int32 Vector	
VMOVDQA32	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVDQA32 zmm{K}{Z}, zmm/m512	Move Aligned Int32 Vector	
VMOVDQA32	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VMOVDQA32 XMM{K}{Z}, XMM	Move Aligned Int32 Vector	
VMOVDQA32	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VMOVDQA32 YMM{K}{Z}, YMM	Move Aligned Int32 Vector	
VMOVDQA32	ZMM{K}{Z},ZMM	AVX512,FUTURE	VMOVDQA32 zmm{K}{Z}, zmm	Move Aligned Int32 Vector	
VMOVDQA32	M128{K},XMM	AVX512VL,AVX512,FUTURE	VMOVDQA32 M128{K}, XMM	Move Aligned Int32 Vector	
VMOVDQA32	M256{K},YMM	AVX512VL,AVX512,FUTURE	VMOVDQA32 M256{K}, YMM	Move Aligned Int32 Vector	
VMOVDQA32	M512{K},ZMM	AVX512,FUTURE	VMOVDQA32 M512{K}, zmm	Move Aligned Int32 Vector	
VMOVDQA64	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVDQA64 XMM{K}{Z}, XMM/M128	Move Aligned Int64 Vector	
VMOVDQA64	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVDQA64 YMM{K}{Z}, YMM/m256	Move Aligned Int64 Vector	
VMOVDQA64	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVDQA64 zmm{K}{Z}, zmm/m512	Move Aligned Int64 Vector	
VMOVDQA64	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VMOVDQA64 XMM{K}{Z}, XMM	Move Aligned Int64 Vector	
VMOVDQA64	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VMOVDQA64 YMM{K}{Z}, YMM	Move Aligned Int64 Vector	
VMOVDQA64	ZMM{K}{Z},ZMM	AVX512,FUTURE	VMOVDQA64 zmm{K}{Z}, zmm	Move Aligned Int64 Vector	
VMOVDQA64	M128{K},XMM	AVX512VL,AVX512,FUTURE	VMOVDQA64 M128{K}, XMM	Move Aligned Int64 Vector	
VMOVDQA64	M256{K},YMM	AVX512VL,AVX512,FUTURE	VMOVDQA64 M256{K}, YMM	Move Aligned Int64 Vector	
VMOVDQA64	M512{K},ZMM	AVX512,FUTURE	VMOVDQA64 M512{K}, zmm	Move Aligned Int64 Vector	
VMOVDQU16	XMM{K}{Z},XMM/M128	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 XMM{K}{Z}, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	YMM{K}{Z},YMM/M256	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 YMM{K}{Z}, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	ZMM{K}{Z},ZMM/M512	AVX512BW,FUTURE	VMOVDQU16 zmm{K}{Z}, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	XMM{K}{Z},XMM	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	YMM{K}{Z},YMM	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	ZMM{K}{Z},ZMM	AVX512BW,FUTURE	VMOVDQU16 zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	M128{K},XMM	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 M128{K}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	M256{K},YMM	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 M256{K}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	M512{K},ZMM	AVX512BW,FUTURE	VMOVDQU16 M512{K}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU32	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVDQU32 XMM{K}{Z}, XMM/M128	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVDQU32 YMM{K}{Z}, YMM/m256	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVDQU32 zmm{K}{Z}, zmm/m512	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VMOVDQU32 XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VMOVDQU32 YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	ZMM{K}{Z},ZMM	AVX512,FUTURE	VMOVDQU32 zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	M128{K},XMM	AVX512VL,AVX512,FUTURE	VMOVDQU32 M128{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	M256{K},YMM	AVX512VL,AVX512,FUTURE	VMOVDQU32 M256{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	M512{K},ZMM	AVX512,FUTURE	VMOVDQU32 M512{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	XMM{K}{Z},XMM/M128	AVX512VL,AVX512,FUTURE	VMOVDQU64 XMM{K}{Z}, XMM/M128	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	YMM{K}{Z},YMM/M256	AVX512VL,AVX512,FUTURE	VMOVDQU64 YMM{K}{Z}, YMM/m256	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	ZMM{K}{Z},ZMM/M512	AVX512,FUTURE	VMOVDQU64 zmm{K}{Z}, zmm/m512	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VMOVDQU64 XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VMOVDQU64 YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	ZMM{K}{Z},ZMM	AVX512,FUTURE	VMOVDQU64 zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	M128{K},XMM	AVX512VL,AVX512,FUTURE	VMOVDQU64 M128{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	M256{K},YMM	AVX512VL,AVX512,FUTURE	VMOVDQU64 M256{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	M512{K},ZMM	AVX512,FUTURE	VMOVDQU64 M512{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU8	XMM{K}{Z},XMM/M128	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 XMM{K}{Z}, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	YMM{K}{Z},YMM/M256	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 YMM{K}{Z}, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	ZMM{K}{Z},ZMM/M512	AVX512BW,FUTURE	VMOVDQU8 zmm{K}{Z}, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	XMM{K}{Z},XMM	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	YMM{K}{Z},YMM	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	ZMM{K}{Z},ZMM	AVX512BW,FUTURE	VMOVDQU8 zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	M128{K},XMM	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 M128{K}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	M256{K},YMM	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 M256{K}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	M512{K},ZMM	AVX512BW,FUTURE	VMOVDQU8 M512{K}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPABSQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPABSQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPABSQ	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPABSQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPABSQ	ZMM{K}{Z},ZMM/M512/M64BCST	AVX512,FUTURE	VPABSQ zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPANDD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPANDD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Bitwise AND Int32 Vectors	
VPANDD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPANDD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Bitwise AND Int32 Vectors	
VPANDD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPANDD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Bitwise AND Int32 Vectors	
VPANDND	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPANDND XMM{K}{Z}, XMM, XMM/M128/M32BCST	Bitwise AND NOT Int32 Vectors	
VPANDND	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPANDND YMM{K}{Z}, YMM, YMM/m256/M32BCST	Bitwise AND NOT Int32 Vectors	
VPANDND	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPANDND zmm{K}{Z}, zmm, zmm/m512/M32BCST	Bitwise AND NOT Int32 Vectors	
VPANDNQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPANDNQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	Bitwise AND NOT Int64 Vectors	
VPANDNQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPANDNQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	Bitwise AND NOT Int64 Vectors	
VPANDNQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPANDNQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	Bitwise AND NOT Int64 Vectors	
VPANDQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPANDQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	Bitwise AND Int64 Vectors	
VPANDQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPANDQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	Bitwise AND Int64 Vectors	
VPANDQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPANDQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	Bitwise AND Int64 Vectors	
VPBLENDMB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPBLENDMB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPBLENDMB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPBLENDMB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPBLENDMD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Blend Int32 Vectors using the Instruction Mask	
VPBLENDMD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPBLENDMD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Blend Int32 Vectors using the Instruction Mask	
VPBLENDMD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPBLENDMD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Blend Int32 Vectors using the Instruction Mask	
VPBLENDMQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPBLENDMQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	Blend Int64 Vectors using the Instruction Mask	
VPBLENDMQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPBLENDMQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	Blend Int64 Vectors using the Instruction Mask	
VPBLENDMQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPBLENDMQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	Blend Int64 Vectors using the Instruction Mask	
VPBLENDMW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPBLENDMW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPBLENDMW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPBLENDMW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPBROADCASTMB2Q	XMM,K	AVX512VL,AVX512CD,FUTURE	VPBROADCASTMB2Q XMM, K	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMB2Q	YMM,K	AVX512VL,AVX512CD,FUTURE	VPBROADCASTMB2Q YMM, K	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMB2Q	ZMM,K	AVX512CD,FUTURE	VPBROADCASTMB2Q zmm, K	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMW2D	XMM,K	AVX512VL,AVX512CD,FUTURE	VPBROADCASTMW2D XMM, K	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMW2D	YMM,K	AVX512VL,AVX512CD,FUTURE	VPBROADCASTMW2D YMM, K	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMW2D	ZMM,K	AVX512CD,FUTURE	VPBROADCASTMW2D zmm, K	TODO: AVX512VL,AVX512CD,FUTURE	
VPCMPB	K{K},XMM,XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPCMPB K{K}, XMM, XMM/M128, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPB	K{K},YMM,YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPCMPB K{K}, YMM, YMM/m256, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPB	K{K},ZMM,ZMM/M512,IMM8	AVX512BW,FUTURE	VPCMPB K{K}, zmm, zmm/m512, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPD	K{K},XMM,XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPCMPD K{K}, XMM, XMM/M128/M32BCST, IMM8	Compare Int32 Vectors and Set Vector Mask	
VPCMPD	K{K},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPCMPD K{K}, YMM, YMM/m256/M32BCST, IMM8	Compare Int32 Vectors and Set Vector Mask	
VPCMPD	K{K},ZMM,ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPCMPD K{K}, zmm, zmm/m512/M32BCST, IMM8	Compare Int32 Vectors and Set Vector Mask	
VPCMPQ	K{K},XMM,XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPCMPQ K{K}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPQ	K{K},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPCMPQ K{K}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPQ	K{K},ZMM,ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPCMPQ K{K}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPUB	K{K},XMM,XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPCMPUB K{K}, XMM, XMM/M128, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUB	K{K},YMM,YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPCMPUB K{K}, YMM, YMM/m256, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUB	K{K},ZMM,ZMM/M512,IMM8	AVX512BW,FUTURE	VPCMPUB K{K}, zmm, zmm/m512, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUD	K{K},XMM,XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPCMPUD K{K}, XMM, XMM/M128/M32BCST, IMM8	Compare Uint32 Vectors and Set Vector Mask	
VPCMPUD	K{K},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPCMPUD K{K}, YMM, YMM/m256/M32BCST, IMM8	Compare Uint32 Vectors and Set Vector Mask	
VPCMPUD	K{K},ZMM,ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPCMPUD K{K}, zmm, zmm/m512/M32BCST, IMM8	Compare Uint32 Vectors and Set Vector Mask	
VPCMPUQ	K{K},XMM,XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPCMPUQ K{K}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPUQ	K{K},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPCMPUQ K{K}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPUQ	K{K},ZMM,ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPCMPUQ K{K}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPUW	K{K},XMM,XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPCMPUW K{K}, XMM, XMM/M128, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUW	K{K},YMM,YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPCMPUW K{K}, YMM, YMM/m256, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUW	K{K},ZMM,ZMM/M512,IMM8	AVX512BW,FUTURE	VPCMPUW K{K}, zmm, zmm/m512, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPW	K{K},XMM,XMM/M128,IMM8	AVX512VL,AVX512BW,FUTURE	VPCMPW K{K}, XMM, XMM/M128, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPW	K{K},YMM,YMM/M256,IMM8	AVX512VL,AVX512BW,FUTURE	VPCMPW K{K}, YMM, YMM/m256, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPW	K{K},ZMM,ZMM/M512,IMM8	AVX512BW,FUTURE	VPCMPW K{K}, zmm, zmm/m512, IMM8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCOMPRESSD	M128{K},XMM	AVX512VL,AVX512,FUTURE	VPCOMPRESSD M128{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	M256{K},YMM	AVX512VL,AVX512,FUTURE	VPCOMPRESSD M256{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	M512{K},ZMM	AVX512,FUTURE	VPCOMPRESSD M512{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPCOMPRESSD XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPCOMPRESSD YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	ZMM{K}{Z},ZMM	AVX512,FUTURE	VPCOMPRESSD zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	M128{K},XMM	AVX512VL,AVX512,FUTURE	VPCOMPRESSQ M128{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	M256{K},YMM	AVX512VL,AVX512,FUTURE	VPCOMPRESSQ M256{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	M512{K},ZMM	AVX512,FUTURE	VPCOMPRESSQ M512{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPCOMPRESSQ XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPCOMPRESSQ YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	ZMM{K}{Z},ZMM	AVX512,FUTURE	VPCOMPRESSQ zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPCONFLICTD	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512CD,FUTURE	VPCONFLICTD XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTD	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512CD,FUTURE	VPCONFLICTD YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTD	ZMM{K}{Z},ZMM/M512/M32BCST	AVX512CD,FUTURE	VPCONFLICTD zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512CD,FUTURE	VPCONFLICTQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTQ	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512CD,FUTURE	VPCONFLICTQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTQ	ZMM{K}{Z},ZMM/M512/M64BCST	AVX512CD,FUTURE	VPCONFLICTQ zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPERMB	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512VBMI,FUTURE	VPERMB XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMB	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512VBMI,FUTURE	VPERMB YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMB	ZMM{K}{Z},ZMM,ZMM/M512	AVX512VBMI,FUTURE	VPERMB zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMI2B	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512VBMI,FUTURE	VPERMI2B XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMI2B	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512VBMI,FUTURE	VPERMI2B YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMI2B	ZMM{K}{Z},ZMM,ZMM/M512	AVX512VBMI,FUTURE	VPERMI2B zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMI2D	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPERMI2D XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2D	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPERMI2D YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2D	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPERMI2D zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPERMI2PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPERMI2PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPERMI2PD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPERMI2PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPERMI2PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPERMI2PS zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2Q	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPERMI2Q XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2Q	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPERMI2Q YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2Q	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPERMI2Q zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2W	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPERMI2W XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMI2W	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPERMI2W YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMI2W	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPERMI2W zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMT2B	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512VBMI,FUTURE	VPERMT2B XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMT2B	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512VBMI,FUTURE	VPERMT2B YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMT2B	ZMM{K}{Z},ZMM,ZMM/M512	AVX512VBMI,FUTURE	VPERMT2B zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMT2D	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPERMT2D XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2D	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPERMT2D YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2D	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPERMT2D zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPERMT2PD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPERMT2PD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPERMT2PD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPERMT2PS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPERMT2PS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPERMT2PS zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2Q	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPERMT2Q XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2Q	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPERMT2Q YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2Q	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPERMT2Q zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2W	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPERMT2W XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMT2W	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPERMT2W YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMT2W	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPERMT2W zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPERMW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPERMW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPERMW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPEXPANDD	XMM{K}{Z},M128	AVX512VL,AVX512,FUTURE	VPEXPANDD XMM{K}{Z}, M128	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	YMM{K}{Z},M256	AVX512VL,AVX512,FUTURE	VPEXPANDD YMM{K}{Z}, M256	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	ZMM{K}{Z},M512	AVX512,FUTURE	VPEXPANDD zmm{K}{Z}, M512	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPEXPANDD XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPEXPANDD YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	ZMM{K}{Z},ZMM	AVX512,FUTURE	VPEXPANDD zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	XMM{K}{Z},M128	AVX512VL,AVX512,FUTURE	VPEXPANDQ XMM{K}{Z}, M128	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	YMM{K}{Z},M256	AVX512VL,AVX512,FUTURE	VPEXPANDQ YMM{K}{Z}, M256	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	ZMM{K}{Z},M512	AVX512,FUTURE	VPEXPANDQ zmm{K}{Z}, M512	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPEXPANDQ XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	YMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPEXPANDQ YMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	ZMM{K}{Z},ZMM	AVX512,FUTURE	VPEXPANDQ zmm{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPLZCNTD	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512CD,FUTURE	VPLZCNTD XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTD	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512CD,FUTURE	VPLZCNTD YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTD	ZMM{K}{Z},ZMM/M512/M32BCST	AVX512CD,FUTURE	VPLZCNTD zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTQ	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512CD,FUTURE	VPLZCNTQ XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTQ	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512CD,FUTURE	VPLZCNTQ YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTQ	ZMM{K}{Z},ZMM/M512/M64BCST	AVX512CD,FUTURE	VPLZCNTQ zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX512VL,AVX512CD,FUTURE	
VPMADD52HUQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512IFMA,FUTURE	VPMADD52HUQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52HUQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512IFMA,FUTURE	VPMADD52HUQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52HUQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512IFMA,FUTURE	VPMADD52HUQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52LUQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512IFMA,FUTURE	VPMADD52LUQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52LUQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512IFMA,FUTURE	VPMADD52LUQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52LUQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512IFMA,FUTURE	VPMADD52LUQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMAXSQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPMAXSQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMAXSQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPMAXSQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMAXSQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPMAXSQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMAXUQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPMAXUQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMAXUQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPMAXUQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMAXUQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPMAXUQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMINSQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPMINSQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMINSQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPMINSQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMINSQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPMINSQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMINUQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPMINUQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMINUQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPMINUQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMINUQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPMINUQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPMOVB2M	K,XMM	AVX512VL,AVX512BW,FUTURE	VPMOVB2M K, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVB2M	K,YMM	AVX512VL,AVX512BW,FUTURE	VPMOVB2M K, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVB2M	K,ZMM	AVX512BW,FUTURE	VPMOVB2M K, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVD2M	K,XMM	AVX512VL,AVX512DQ,FUTURE	VPMOVD2M K, XMM	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVD2M	K,YMM	AVX512VL,AVX512DQ,FUTURE	VPMOVD2M K, YMM	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVD2M	K,ZMM	AVX512DQ,FUTURE	VPMOVD2M K, zmm	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVDB	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVDB XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVDB XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	XMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVDB XMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	M32{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVDB M32{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	M64{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVDB M64{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	M128{K},ZMM	AVX512,FUTURE	VPMOVDB M128{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVDW XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVDW XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	YMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVDW YMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	M64{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVDW M64{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	M128{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVDW M128{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	M256{K},ZMM	AVX512,FUTURE	VPMOVDW M256{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVM2B	XMM,K	AVX512VL,AVX512BW,FUTURE	VPMOVM2B XMM, K	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2B	YMM,K	AVX512VL,AVX512BW,FUTURE	VPMOVM2B YMM, K	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2B	ZMM,K	AVX512BW,FUTURE	VPMOVM2B zmm, K	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2D	XMM,K	AVX512VL,AVX512DQ,FUTURE	VPMOVM2D XMM, K	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2D	YMM,K	AVX512VL,AVX512DQ,FUTURE	VPMOVM2D YMM, K	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2D	ZMM,K	AVX512DQ,FUTURE	VPMOVM2D zmm, K	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2Q	XMM,K	AVX512VL,AVX512DQ,FUTURE	VPMOVM2Q XMM, K	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2Q	YMM,K	AVX512VL,AVX512DQ,FUTURE	VPMOVM2Q YMM, K	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2Q	ZMM,K	AVX512DQ,FUTURE	VPMOVM2Q zmm, K	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2W	XMM,K	AVX512VL,AVX512BW,FUTURE	VPMOVM2W XMM, K	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2W	YMM,K	AVX512VL,AVX512BW,FUTURE	VPMOVM2W YMM, K	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2W	ZMM,K	AVX512BW,FUTURE	VPMOVM2W zmm, K	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVQ2M	K,XMM	AVX512VL,AVX512DQ,FUTURE	VPMOVQ2M K, XMM	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVQ2M	K,YMM	AVX512VL,AVX512DQ,FUTURE	VPMOVQ2M K, YMM	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVQ2M	K,ZMM	AVX512DQ,FUTURE	VPMOVQ2M K, zmm	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVQB	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVQB XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVQB XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	XMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVQB XMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	M16{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVQB M16{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	M32{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVQB M32{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	M64{K},ZMM	AVX512,FUTURE	VPMOVQB M64{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVQD XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVQD XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	YMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVQD YMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	M64{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVQD M64{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	M128{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVQD M128{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	M256{K},ZMM	AVX512,FUTURE	VPMOVQD M256{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVQW XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVQW XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	XMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVQW XMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	M32{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVQW M32{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	M64{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVQW M64{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	M128{K},ZMM	AVX512,FUTURE	VPMOVQW M128{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVSDB XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVSDB XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	XMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVSDB XMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	M32{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVSDB M32{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	M64{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVSDB M64{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	M128{K},ZMM	AVX512,FUTURE	VPMOVSDB M128{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVSDW XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVSDW XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	YMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVSDW YMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	M64{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVSDW M64{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	M128{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVSDW M128{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	M256{K},ZMM	AVX512,FUTURE	VPMOVSDW M256{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVSQB XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVSQB XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	XMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVSQB XMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	M16{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVSQB M16{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	M32{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVSQB M32{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	M64{K},ZMM	AVX512,FUTURE	VPMOVSQB M64{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVSQD XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVSQD XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	YMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVSQD YMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	M64{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVSQD M64{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	M128{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVSQD M128{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	M256{K},ZMM	AVX512,FUTURE	VPMOVSQD M256{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVSQW XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVSQW XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	XMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVSQW XMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	M32{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVSQW M32{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	M64{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVSQW M64{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	M128{K},ZMM	AVX512,FUTURE	VPMOVSQW M128{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSWB	XMM{K}{Z},XMM	AVX512VL,AVX512BW,FUTURE	VPMOVSWB XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	XMM{K}{Z},YMM	AVX512VL,AVX512BW,FUTURE	VPMOVSWB XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	YMM{K}{Z},ZMM	AVX512BW,FUTURE	VPMOVSWB YMM{K}{Z}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	M64{K},XMM	AVX512VL,AVX512BW,FUTURE	VPMOVSWB M64{K}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	M128{K},YMM	AVX512VL,AVX512BW,FUTURE	VPMOVSWB M128{K}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	M256{K},ZMM	AVX512BW,FUTURE	VPMOVSWB M256{K}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSDB	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSDB XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSDB XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	XMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVUSDB XMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	M32{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSDB M32{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	M64{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSDB M64{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	M128{K},ZMM	AVX512,FUTURE	VPMOVUSDB M128{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSDW XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSDW XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	YMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVUSDW YMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	M64{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSDW M64{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	M128{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSDW M128{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	M256{K},ZMM	AVX512,FUTURE	VPMOVUSDW M256{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSQB XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSQB XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	XMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVUSQB XMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	M16{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSQB M16{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	M32{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSQB M32{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	M64{K},ZMM	AVX512,FUTURE	VPMOVUSQB M64{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSQD XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSQD XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	YMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVUSQD YMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	M64{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSQD M64{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	M128{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSQD M128{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	M256{K},ZMM	AVX512,FUTURE	VPMOVUSQD M256{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	XMM{K}{Z},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSQW XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	XMM{K}{Z},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSQW XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	XMM{K}{Z},ZMM	AVX512,FUTURE	VPMOVUSQW XMM{K}{Z}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	M32{K},XMM	AVX512VL,AVX512,FUTURE	VPMOVUSQW M32{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	M64{K},YMM	AVX512VL,AVX512,FUTURE	VPMOVUSQW M64{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	M128{K},ZMM	AVX512,FUTURE	VPMOVUSQW M128{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSWB	XMM{K}{Z},XMM	AVX512VL,AVX512BW,FUTURE	VPMOVUSWB XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	XMM{K}{Z},YMM	AVX512VL,AVX512BW,FUTURE	VPMOVUSWB XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	YMM{K}{Z},ZMM	AVX512BW,FUTURE	VPMOVUSWB YMM{K}{Z}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	M64{K},XMM	AVX512VL,AVX512BW,FUTURE	VPMOVUSWB M64{K}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	M128{K},YMM	AVX512VL,AVX512BW,FUTURE	VPMOVUSWB M128{K}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	M256{K},ZMM	AVX512BW,FUTURE	VPMOVUSWB M256{K}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVW2M	K,XMM	AVX512VL,AVX512BW,FUTURE	VPMOVW2M K, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVW2M	K,YMM	AVX512VL,AVX512BW,FUTURE	VPMOVW2M K, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVW2M	K,ZMM	AVX512BW,FUTURE	VPMOVW2M K, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	XMM{K}{Z},XMM	AVX512VL,AVX512BW,FUTURE	VPMOVWB XMM{K}{Z}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	XMM{K}{Z},YMM	AVX512VL,AVX512BW,FUTURE	VPMOVWB XMM{K}{Z}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	YMM{K}{Z},ZMM	AVX512BW,FUTURE	VPMOVWB YMM{K}{Z}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	M64{K},XMM	AVX512VL,AVX512BW,FUTURE	VPMOVWB M64{K}, XMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	M128{K},YMM	AVX512VL,AVX512BW,FUTURE	VPMOVWB M128{K}, YMM	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	M256{K},ZMM	AVX512BW,FUTURE	VPMOVWB M256{K}, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMULLQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512DQ,FUTURE	VPMULLQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMULLQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512DQ,FUTURE	VPMULLQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMULLQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512DQ,FUTURE	VPMULLQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMULTISHIFTQB	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512VBMI,FUTURE	VPMULTISHIFTQB XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPMULTISHIFTQB	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512VBMI,FUTURE	VPMULTISHIFTQB YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPMULTISHIFTQB	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512VBMI,FUTURE	VPMULTISHIFTQB zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPORD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPORD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Bitwise OR Int32 Vectors	
VPORD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPORD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Bitwise OR Int32 Vectors	
VPORD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPORD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Bitwise OR Int32 Vectors	
VPORQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPORQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	Bitwise OR Int64 Vectors	
VPORQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPORQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	Bitwise OR Int64 Vectors	
VPORQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPORQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	Bitwise OR Int64 Vectors	
VPROLD	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPROLD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPROLD	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPROLD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPROLD	ZMM{K}{Z},ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPROLD zmm{K}{Z}, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPROLQ	XMM{K}{Z},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPROLQ XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPROLQ	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPROLQ YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPROLQ	ZMM{K}{Z},ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPROLQ zmm{K}{Z}, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPROLVD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPROLVD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPROLVD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPROLVD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPROLVD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPROLVD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPROLVQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPROLVQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPROLVQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPROLVQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPROLVQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPROLVQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPRORD	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPRORD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPRORD	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPRORD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPRORD	ZMM{K}{Z},ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPRORD zmm{K}{Z}, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPRORQ	XMM{K}{Z},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPRORQ XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPRORQ	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPRORQ YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPRORQ	ZMM{K}{Z},ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPRORQ zmm{K}{Z}, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPRORVD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPRORVD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPRORVD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPRORVD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPRORVD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPRORVD zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPRORVQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPRORVQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPRORVQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPRORVQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPRORVQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPRORVQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERDD	VM32X{K},XMM	AVX512VL,AVX512,FUTURE	VPSCATTERDD VM32X{K}, XMM	Scatter Int32 Vector With Signed Dword Indices	
VPSCATTERDD	VM32Y{K},YMM	AVX512VL,AVX512,FUTURE	VPSCATTERDD VM32Y{K}, YMM	Scatter Int32 Vector With Signed Dword Indices	
VPSCATTERDD	VM32Z{K},ZMM	AVX512,FUTURE	VPSCATTERDD VM32Z{K}, zmm	Scatter Int32 Vector With Signed Dword Indices	
VPSCATTERDQ	VM64X{K},XMM	AVX512VL,AVX512,FUTURE	VPSCATTERDQ VM64X{K}, XMM	Scatter Int64 Vector With Signed Dword Indices	
VPSCATTERDQ	VM64X{K},YMM	AVX512VL,AVX512,FUTURE	VPSCATTERDQ VM64X{K}, YMM	Scatter Int64 Vector With Signed Dword Indices	
VPSCATTERDQ	VM64Y{K},ZMM	AVX512,FUTURE	VPSCATTERDQ VM64Y{K}, zmm	Scatter Int64 Vector With Signed Dword Indices	
VPSCATTERQD	VM32X{K},XMM	AVX512VL,AVX512,FUTURE	VPSCATTERQD VM32X{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQD	VM32Y{K},XMM	AVX512VL,AVX512,FUTURE	VPSCATTERQD VM32Y{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQD	VM32Z{K},YMM	AVX512,FUTURE	VPSCATTERQD VM32Z{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQQ	VM64X{K},XMM	AVX512VL,AVX512,FUTURE	VPSCATTERQQ VM64X{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQQ	VM64Y{K},YMM	AVX512VL,AVX512,FUTURE	VPSCATTERQQ VM64Y{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQQ	VM64Z{K},ZMM	AVX512,FUTURE	VPSCATTERQQ VM64Z{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPSLLVW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSLLVW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPSLLVW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSLLVW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPSLLVW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSLLVW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRAQ	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSRAQ XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	YMM{K}{Z},YMM,XMM/M128	AVX512VL,AVX512,FUTURE	VPSRAQ YMM{K}{Z}, YMM, XMM/M128	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	ZMM{K}{Z},ZMM,XMM/M128	AVX512,FUTURE	VPSRAQ zmm{K}{Z}, zmm, XMM/M128	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	XMM{K}{Z},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSRAQ XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPSRAQ YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	ZMM{K}{Z},ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPSRAQ zmm{K}{Z}, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPSRAVQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPSRAVQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPSRAVQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPSRAVQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPSRAVQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPSRAVQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPSRAVW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSRAVW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRAVW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSRAVW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRAVW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSRAVW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRLVW	XMM{K}{Z},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPSRLVW XMM{K}{Z}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRLVW	YMM{K}{Z},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPSRLVW YMM{K}{Z}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRLVW	ZMM{K}{Z},ZMM,ZMM/M512	AVX512BW,FUTURE	VPSRLVW zmm{K}{Z}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPTERNLOGD	XMM{K}{Z},XMM,XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPTERNLOGD XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGD	YMM{K}{Z},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VPTERNLOGD YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VPTERNLOGD zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGQ	XMM{K}{Z},XMM,XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPTERNLOGQ XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGQ	YMM{K}{Z},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VPTERNLOGQ YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VPTERNLOGQ zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VPTESTMB	K{K},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPTESTMB K{K}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMB	K{K},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPTESTMB K{K}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMB	K{K},ZMM,ZMM/M512	AVX512BW,FUTURE	VPTESTMB K{K}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMD	K{K},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPTESTMD K{K}, XMM, XMM/M128/M32BCST	Logical AND Int32 Vectors and Set Vector Mask	
VPTESTMD	K{K},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPTESTMD K{K}, YMM, YMM/m256/M32BCST	Logical AND Int32 Vectors and Set Vector Mask	
VPTESTMD	K{K},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPTESTMD K{K}, zmm, zmm/m512/M32BCST	Logical AND Int32 Vectors and Set Vector Mask	
VPTESTMQ	K{K},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPTESTMQ K{K}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPTESTMQ	K{K},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPTESTMQ K{K}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPTESTMQ	K{K},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPTESTMQ K{K}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPTESTMW	K{K},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPTESTMW K{K}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMW	K{K},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPTESTMW K{K}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMW	K{K},ZMM,ZMM/M512	AVX512BW,FUTURE	VPTESTMW K{K}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMB	K{K},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPTESTNMB K{K}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMB	K{K},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPTESTNMB K{K}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMB	K{K},ZMM,ZMM/M512	AVX512BW,FUTURE	VPTESTNMB K{K}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMD	K{K},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPTESTNMD K{K}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMD	K{K},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPTESTNMD K{K}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMD	K{K},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPTESTNMD K{K}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMQ	K{K},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPTESTNMQ K{K}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMQ	K{K},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPTESTNMQ K{K}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMQ	K{K},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPTESTNMQ K{K}, zmm, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMW	K{K},XMM,XMM/M128	AVX512VL,AVX512BW,FUTURE	VPTESTNMW K{K}, XMM, XMM/M128	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMW	K{K},YMM,YMM/M256	AVX512VL,AVX512BW,FUTURE	VPTESTNMW K{K}, YMM, YMM/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMW	K{K},ZMM,ZMM/M512	AVX512BW,FUTURE	VPTESTNMW K{K}, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPXORD	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VPXORD XMM{K}{Z}, XMM, XMM/M128/M32BCST	Bitwise XOR Int32 Vectors	
VPXORD	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VPXORD YMM{K}{Z}, YMM, YMM/m256/M32BCST	Bitwise XOR Int32 Vectors	
VPXORD	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST	AVX512,FUTURE	VPXORD zmm{K}{Z}, zmm, zmm/m512/M32BCST	Bitwise XOR Int32 Vectors	
VPXORQ	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VPXORQ XMM{K}{Z}, XMM, XMM/M128/M32BCST	Bitwise XOR Int64 Vectors	
VPXORQ	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VPXORQ YMM{K}{Z}, YMM, YMM/m256/M32BCST	Bitwise XOR Int64 Vectors	
VPXORQ	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST	AVX512,FUTURE	VPXORQ zmm{K}{Z}, zmm, zmm/m512/M32BCST	Bitwise XOR Int64 Vectors	
VRANGEPD	XMM{K}{Z},XMM,XMM/M128/M64BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VRANGEPD XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPD	YMM{K}{Z},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VRANGEPD YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{SAE},IMM8	AVX512DQ,FUTURE	VRANGEPD zmm{K}{Z}, zmm, zmm/m512/M32BCST{SAE}, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPS	XMM{K}{Z},XMM,XMM/M128/M32BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VRANGEPS XMM{K}{Z}, XMM, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPS	YMM{K}{Z},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VRANGEPS YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{SAE},IMM8	AVX512DQ,FUTURE	VRANGEPS zmm{K}{Z}, zmm, zmm/m512/M32BCST{SAE}, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGESD	XMM{K}{Z},XMM,XMM/M64{SAE},IMM8	AVX512DQ,FUTURE	VRANGESD XMM{K}{Z}, XMM, XMM/m64{SAE}, IMM8	TODO: AVX512DQ,FUTURE	
VRANGESS	XMM{K}{Z},XMM,XMM/M32{SAE},IMM8	AVX512DQ,FUTURE	VRANGESS XMM{K}{Z}, XMM, XMM/m32{SAE}, IMM8	TODO: AVX512DQ,FUTURE	
VRCP14PD	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VRCP14PD XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PD	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VRCP14PD YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PD	ZMM{K}{Z},ZMM/M512/M64BCST	AVX512,FUTURE	VRCP14PD zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PS	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VRCP14PS XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PS	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VRCP14PS YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PS	ZMM{K}{Z},ZMM/M512/M32BCST	AVX512,FUTURE	VRCP14PS zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRCP14SD	XMM{K}{Z},XMM,XMM/M64	AVX512,FUTURE	VRCP14SD XMM{K}{Z}, XMM, XMM/m64	TODO: AVX512,FUTURE	
VRCP14SS	XMM{K}{Z},XMM,XMM/M32	AVX512,FUTURE	VRCP14SS XMM{K}{Z}, XMM, XMM/m32	TODO: AVX512,FUTURE	
VRCP28PD	ZMM{K}{Z},ZMM/M512/M64BCST{SAE}	AVX512ER,FUTURE	VRCP28PD zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512ER,FUTURE	
VRCP28PS	ZMM{K}{Z},ZMM/M512/M32BCST{SAE}	AVX512ER,FUTURE	VRCP28PS zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512ER,FUTURE	
VRCP28SD	XMM{K}{Z},XMM,XMM/M64{SAE}	AVX512ER,FUTURE	VRCP28SD XMM{K}{Z}, XMM, XMM/m64{SAE}	TODO: AVX512ER,FUTURE	
VRCP28SS	XMM{K}{Z},XMM,XMM/M32{SAE}	AVX512ER,FUTURE	VRCP28SS XMM{K}{Z}, XMM, XMM/m32{SAE}	TODO: AVX512ER,FUTURE	
VREDUCEPD	XMM{K}{Z},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VREDUCEPD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPD	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VREDUCEPD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPD	ZMM{K}{Z},ZMM/M512/M64BCST{SAE},IMM8	AVX512DQ,FUTURE	VREDUCEPD zmm{K}{Z}, zmm/m512/M32BCST{SAE}, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPS	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VREDUCEPS XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPS	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512DQ,FUTURE	VREDUCEPS YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPS	ZMM{K}{Z},ZMM/M512/M32BCST{SAE},IMM8	AVX512DQ,FUTURE	VREDUCEPS zmm{K}{Z}, zmm/m512/M32BCST{SAE}, IMM8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCESD	XMM{K}{Z},XMM,XMM/M64{SAE},IMM8	AVX512DQ,FUTURE	VREDUCESD XMM{K}{Z}, XMM, XMM/m64{SAE}, IMM8	TODO: AVX512DQ,FUTURE	
VREDUCESS	XMM{K}{Z},XMM,XMM/M32{SAE},IMM8	AVX512DQ,FUTURE	VREDUCESS XMM{K}{Z}, XMM, XMM/m32{SAE}, IMM8	TODO: AVX512DQ,FUTURE	
VRNDSCALEPD	XMM{K}{Z},XMM/M128/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VRNDSCALEPD XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPD	YMM{K}{Z},YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VRNDSCALEPD YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPD	ZMM{K}{Z},ZMM/M512/M64BCST{SAE},IMM8	AVX512,FUTURE	VRNDSCALEPD zmm{K}{Z}, zmm/m512/M32BCST{SAE}, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPS	XMM{K}{Z},XMM/M128/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VRNDSCALEPS XMM{K}{Z}, XMM/M128/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPS	YMM{K}{Z},YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VRNDSCALEPS YMM{K}{Z}, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPS	ZMM{K}{Z},ZMM/M512/M32BCST{SAE},IMM8	AVX512,FUTURE	VRNDSCALEPS zmm{K}{Z}, zmm/m512/M32BCST{SAE}, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALESD	XMM{K}{Z},XMM,XMM/M64{SAE},IMM8	AVX512,FUTURE	VRNDSCALESD XMM{K}{Z}, XMM, XMM/m64{SAE}, IMM8	TODO: AVX512,FUTURE	
VRNDSCALESS	XMM{K}{Z},XMM,XMM/M32{SAE},IMM8	AVX512,FUTURE	VRNDSCALESS XMM{K}{Z}, XMM, XMM/m32{SAE}, IMM8	TODO: AVX512,FUTURE	
VRSQRT14PD	XMM{K}{Z},XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VRSQRT14PD XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PD	YMM{K}{Z},YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VRSQRT14PD YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PD	ZMM{K}{Z},ZMM/M512/M64BCST	AVX512,FUTURE	VRSQRT14PD zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PS	XMM{K}{Z},XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VRSQRT14PS XMM{K}{Z}, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PS	YMM{K}{Z},YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VRSQRT14PS YMM{K}{Z}, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PS	ZMM{K}{Z},ZMM/M512/M32BCST	AVX512,FUTURE	VRSQRT14PS zmm{K}{Z}, zmm/m512/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14SD	XMM{K}{Z},XMM,XMM/M64	AVX512,FUTURE	VRSQRT14SD XMM{K}{Z}, XMM, XMM/m64	TODO: AVX512,FUTURE	
VRSQRT14SS	XMM{K}{Z},XMM,XMM/M32	AVX512,FUTURE	VRSQRT14SS XMM{K}{Z}, XMM, XMM/m32	TODO: AVX512,FUTURE	
VRSQRT28PD	ZMM{K}{Z},ZMM/M512/M64BCST{SAE}	AVX512ER,FUTURE	VRSQRT28PD zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512ER,FUTURE	
VRSQRT28PS	ZMM{K}{Z},ZMM/M512/M32BCST{SAE}	AVX512ER,FUTURE	VRSQRT28PS zmm{K}{Z}, zmm/m512/M32BCST{SAE}	TODO: AVX512ER,FUTURE	
VRSQRT28SD	XMM{K}{Z},XMM,XMM/M64{SAE}	AVX512ER,FUTURE	VRSQRT28SD XMM{K}{Z}, XMM, XMM/m64{SAE}	TODO: AVX512ER,FUTURE	
VRSQRT28SS	XMM{K}{Z},XMM,XMM/M32{SAE}	AVX512ER,FUTURE	VRSQRT28SS XMM{K}{Z}, XMM, XMM/m32{SAE}	TODO: AVX512ER,FUTURE	
VSCALEFPD	XMM{K}{Z},XMM,XMM/M128/M64BCST	AVX512VL,AVX512,FUTURE	VSCALEFPD XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPD	YMM{K}{Z},YMM,YMM/M256/M64BCST	AVX512VL,AVX512,FUTURE	VSCALEFPD YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPD	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST{ER}	AVX512,FUTURE	VSCALEFPD zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPS	XMM{K}{Z},XMM,XMM/M128/M32BCST	AVX512VL,AVX512,FUTURE	VSCALEFPS XMM{K}{Z}, XMM, XMM/M128/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPS	YMM{K}{Z},YMM,YMM/M256/M32BCST	AVX512VL,AVX512,FUTURE	VSCALEFPS YMM{K}{Z}, YMM, YMM/m256/M32BCST	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPS	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST{ER}	AVX512,FUTURE	VSCALEFPS zmm{K}{Z}, zmm, zmm/m512/M32BCST{ER}	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFSD	XMM{K}{Z},XMM,XMM/M64{ER}	AVX512,FUTURE	VSCALEFSD XMM{K}{Z}, XMM, XMM/m64{ER}	TODO: AVX512,FUTURE	
VSCALEFSS	XMM{K}{Z},XMM,XMM/M32{ER}	AVX512,FUTURE	VSCALEFSS XMM{K}{Z}, XMM, XMM/m32{ER}	TODO: AVX512,FUTURE	
VSCATTERDPD	VM64X{K},XMM	AVX512VL,AVX512,FUTURE	VSCATTERDPD VM64X{K}, XMM	Scatter Float64 Vector With Signed Dword Indices	
VSCATTERDPD	VM64X{K},YMM	AVX512VL,AVX512,FUTURE	VSCATTERDPD VM64X{K}, YMM	Scatter Float64 Vector With Signed Dword Indices	
VSCATTERDPD	VM64Y{K},ZMM	AVX512,FUTURE	VSCATTERDPD VM64Y{K}, zmm	Scatter Float64 Vector With Signed Dword Indices	
VSCATTERDPS	VM32X{K},XMM	AVX512VL,AVX512,FUTURE	VSCATTERDPS VM32X{K}, XMM	Scatter Float32 Vector With Signed Dword Indices	
VSCATTERDPS	VM32Y{K},YMM	AVX512VL,AVX512,FUTURE	VSCATTERDPS VM32Y{K}, YMM	Scatter Float32 Vector With Signed Dword Indices	
VSCATTERDPS	VM32Z{K},ZMM	AVX512,FUTURE	VSCATTERDPS VM32Z{K}, zmm	Scatter Float32 Vector With Signed Dword Indices	
VSCATTERPF0DPD	VM64Y{K}	AVX512PF,FUTURE	VSCATTERPF0DPD VM64Y{K}	TODO: AVX512PF,FUTURE	
VSCATTERPF0DPS	VM32Z{K}	AVX512PF,FUTURE	VSCATTERPF0DPS VM32Z{K}	Scatter Prefetch Float32 Vector With Signed Dword Indices Into L1	
VSCATTERPF0QPD	VM64Z{K}	AVX512PF,FUTURE	VSCATTERPF0QPD VM64Z{K}	TODO: AVX512PF,FUTURE	
VSCATTERPF0QPS	VM32Z{K}	AVX512PF,FUTURE	VSCATTERPF0QPS VM32Z{K}	TODO: AVX512PF,FUTURE	
VSCATTERPF1DPD	VM64Y{K}	AVX512PF,FUTURE	VSCATTERPF1DPD VM64Y{K}	TODO: AVX512PF,FUTURE	
VSCATTERPF1DPS	VM32Z{K}	AVX512PF,FUTURE	VSCATTERPF1DPS VM32Z{K}	Scatter Prefetch Float32 Vector With Signed Dword Indices Into L2	
VSCATTERPF1QPD	VM64Z{K}	AVX512PF,FUTURE	VSCATTERPF1QPD VM64Z{K}	TODO: AVX512PF,FUTURE	
VSCATTERPF1QPS	VM32Z{K}	AVX512PF,FUTURE	VSCATTERPF1QPS VM32Z{K}	TODO: AVX512PF,FUTURE	
VSCATTERQPD	VM64X{K},XMM	AVX512VL,AVX512,FUTURE	VSCATTERQPD VM64X{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPD	VM64Y{K},YMM	AVX512VL,AVX512,FUTURE	VSCATTERQPD VM64Y{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPD	VM64Z{K},ZMM	AVX512,FUTURE	VSCATTERQPD VM64Z{K}, zmm	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPS	VM32X{K},XMM	AVX512VL,AVX512,FUTURE	VSCATTERQPS VM32X{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPS	VM32Y{K},XMM	AVX512VL,AVX512,FUTURE	VSCATTERQPS VM32Y{K}, XMM	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPS	VM32Z{K},YMM	AVX512,FUTURE	VSCATTERQPS VM32Z{K}, YMM	TODO: AVX512VL,AVX512,FUTURE	
VSHUFF32X4	YMM{K}{Z},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VSHUFF32X4 YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFF32X4	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VSHUFF32X4 zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFF64X2	YMM{K}{Z},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VSHUFF64X2 YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFF64X2	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VSHUFF64X2 zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFI32X4	YMM{K}{Z},YMM,YMM/M256/M32BCST,IMM8	AVX512VL,AVX512,FUTURE	VSHUFI32X4 YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFI32X4	ZMM{K}{Z},ZMM,ZMM/M512/M32BCST,IMM8	AVX512,FUTURE	VSHUFI32X4 zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFI64X2	YMM{K}{Z},YMM,YMM/M256/M64BCST,IMM8	AVX512VL,AVX512,FUTURE	VSHUFI64X2 YMM{K}{Z}, YMM, YMM/m256/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFI64X2	ZMM{K}{Z},ZMM,ZMM/M512/M64BCST,IMM8	AVX512,FUTURE	VSHUFI64X2 zmm{K}{Z}, zmm, zmm/m512/M32BCST, IMM8	TODO: AVX512VL,AVX512,FUTURE	
RDPKRU		X64,FUTURE	RDPKRU 	TODO: X64,FUTURE	
WRPKRU		X64,FUTURE	WRPKRU 	TODO: X64,FUTURE	
CLFLUSHOPT	MEM	FUTURE	CLFLUSHOPT MEM	TODO: FUTURE	
CLZERO		X64,FUTURE,AMD	CLZERO 	TODO: X64,FUTURE,AMD
