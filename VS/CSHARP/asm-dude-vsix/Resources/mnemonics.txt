AAA	none	8086,NOLONG	AAA 	ASCII Adjust After Addition	AAA.html
AAD	none	8086,NOLONG	AAD 	ASCII Adjust AX Before Division	AAD.html
AAD	imm	8086,NOLONG	AAD imm	ASCII Adjust AX Before Division	AAD.html
AAM	none	8086,NOLONG	AAM 	ASCII Adjust AX After Multiply	AAM.html
AAM	imm	8086,NOLONG	AAM imm	ASCII Adjust AX After Multiply	AAM.html
AAS	none	8086,NOLONG	AAS 	ASCII Adjust AL After Subtraction	AAS.html
ADC	mem,reg8	8086,LOCK	ADC mem, r8	Add with Carry	ADC.html
ADC	reg8,reg8	8086	ADC r8, r8	Add with Carry	ADC.html
ADC	mem,reg16	8086,LOCK	ADC mem, r16	Add with Carry	ADC.html
ADC	reg16,reg16	8086	ADC r16, r16	Add with Carry	ADC.html
ADC	mem,reg32	386,LOCK	ADC mem, r32	Add with Carry	ADC.html
ADC	reg32,reg32	386	ADC r32, r32	Add with Carry	ADC.html
ADC	mem,reg64	X64,LOCK	ADC mem, r64	Add with Carry	ADC.html
ADC	reg64,reg64	X64	ADC r64, r64	Add with Carry	ADC.html
ADC	reg8,mem	8086	ADC r8, mem	Add with Carry	ADC.html
ADC	reg8,reg8	8086	ADC r8, r8	Add with Carry	ADC.html
ADC	reg16,mem	8086	ADC r16, mem	Add with Carry	ADC.html
ADC	reg16,reg16	8086	ADC r16, r16	Add with Carry	ADC.html
ADC	reg32,mem	386	ADC r32, mem	Add with Carry	ADC.html
ADC	reg32,reg32	386	ADC r32, r32	Add with Carry	ADC.html
ADC	reg64,mem	X64	ADC r64, mem	Add with Carry	ADC.html
ADC	reg64,reg64	X64	ADC r64, r64	Add with Carry	ADC.html
ADC	rm16,imm8	8086,LOCK	ADC r/m16, imm8	Add with Carry	ADC.html
ADC	rm32,imm8	386,LOCK	ADC r/m32, imm8	Add with Carry	ADC.html
ADC	rm64,imm8	X64,LOCK	ADC r/m64, imm8	Add with Carry	ADC.html
ADC	reg_al,imm	8086	ADC AL, imm	Add with Carry	ADC.html
ADC	reg_ax,imm	8086	ADC AX, imm	Add with Carry	ADC.html
ADC	reg_eax,imm	386	ADC EAX, imm	Add with Carry	ADC.html
ADC	reg_rax,imm	X64	ADC RAX, imm	Add with Carry	ADC.html
ADC	rm8,imm	8086,LOCK	ADC r/m8, imm	Add with Carry	ADC.html
ADC	rm16,imm	8086,LOCK	ADC r/m16, imm	Add with Carry	ADC.html
ADC	rm32,imm	386,LOCK	ADC r/m32, imm	Add with Carry	ADC.html
ADC	rm64,imm	X64,LOCK	ADC r/m64, imm	Add with Carry	ADC.html
ADC	mem,imm8	8086,LOCK,ND	ADC mem, imm8	Add with Carry	ADC.html
ADC	mem,imm16	8086,LOCK	ADC mem, imm16	Add with Carry	ADC.html
ADC	mem,imm32	386,LOCK	ADC mem, imm32	Add with Carry	ADC.html
ADC	rm8,imm	8086,LOCK,ND,NOLONG	ADC r/m8, imm	Add with Carry	ADC.html
ADD	mem,reg8	8086,LOCK	ADD mem, r8	Add	ADD.html
ADD	reg8,reg8	8086	ADD r8, r8	Add	ADD.html
ADD	mem,reg16	8086,LOCK	ADD mem, r16	Add	ADD.html
ADD	reg16,reg16	8086	ADD r16, r16	Add	ADD.html
ADD	mem,reg32	386,LOCK	ADD mem, r32	Add	ADD.html
ADD	reg32,reg32	386	ADD r32, r32	Add	ADD.html
ADD	mem,reg64	X64,LOCK	ADD mem, r64	Add	ADD.html
ADD	reg64,reg64	X64	ADD r64, r64	Add	ADD.html
ADD	reg8,mem	8086	ADD r8, mem	Add	ADD.html
ADD	reg8,reg8	8086	ADD r8, r8	Add	ADD.html
ADD	reg16,mem	8086	ADD r16, mem	Add	ADD.html
ADD	reg16,reg16	8086	ADD r16, r16	Add	ADD.html
ADD	reg32,mem	386	ADD r32, mem	Add	ADD.html
ADD	reg32,reg32	386	ADD r32, r32	Add	ADD.html
ADD	reg64,mem	X64	ADD r64, mem	Add	ADD.html
ADD	reg64,reg64	X64	ADD r64, r64	Add	ADD.html
ADD	rm16,imm8	8086,LOCK	ADD r/m16, imm8	Add	ADD.html
ADD	rm32,imm8	386,LOCK	ADD r/m32, imm8	Add	ADD.html
ADD	rm64,imm8	X64,LOCK	ADD r/m64, imm8	Add	ADD.html
ADD	reg_al,imm	8086	ADD AL, imm	Add	ADD.html
ADD	reg_ax,imm	8086	ADD AX, imm	Add	ADD.html
ADD	reg_eax,imm	386	ADD EAX, imm	Add	ADD.html
ADD	reg_rax,imm	X64	ADD RAX, imm	Add	ADD.html
ADD	rm8,imm	8086,LOCK	ADD r/m8, imm	Add	ADD.html
ADD	rm16,imm	8086,LOCK	ADD r/m16, imm	Add	ADD.html
ADD	rm32,imm	386,LOCK	ADD r/m32, imm	Add	ADD.html
ADD	rm64,imm	X64,LOCK	ADD r/m64, imm	Add	ADD.html
ADD	mem,imm8	8086,LOCK	ADD mem, imm8	Add	ADD.html
ADD	mem,imm16	8086,LOCK	ADD mem, imm16	Add	ADD.html
ADD	mem,imm32	386,LOCK	ADD mem, imm32	Add	ADD.html
ADD	rm8,imm	8086,LOCK,ND,NOLONG	ADD r/m8, imm	Add	ADD.html
AND	mem,reg8	8086,LOCK	AND mem, r8	Logical AND	AND.html
AND	reg8,reg8	8086	AND r8, r8	Logical AND	AND.html
AND	mem,reg16	8086,LOCK	AND mem, r16	Logical AND	AND.html
AND	reg16,reg16	8086	AND r16, r16	Logical AND	AND.html
AND	mem,reg32	386,LOCK	AND mem, r32	Logical AND	AND.html
AND	reg32,reg32	386	AND r32, r32	Logical AND	AND.html
AND	mem,reg64	X64,LOCK	AND mem, r64	Logical AND	AND.html
AND	reg64,reg64	X64	AND r64, r64	Logical AND	AND.html
AND	reg8,mem	8086	AND r8, mem	Logical AND	AND.html
AND	reg8,reg8	8086	AND r8, r8	Logical AND	AND.html
AND	reg16,mem	8086	AND r16, mem	Logical AND	AND.html
AND	reg16,reg16	8086	AND r16, r16	Logical AND	AND.html
AND	reg32,mem	386	AND r32, mem	Logical AND	AND.html
AND	reg32,reg32	386	AND r32, r32	Logical AND	AND.html
AND	reg64,mem	X64	AND r64, mem	Logical AND	AND.html
AND	reg64,reg64	X64	AND r64, r64	Logical AND	AND.html
AND	rm16,imm8	8086,LOCK	AND r/m16, imm8	Logical AND	AND.html
AND	rm32,imm8	386,LOCK	AND r/m32, imm8	Logical AND	AND.html
AND	rm64,imm8	X64,LOCK	AND r/m64, imm8	Logical AND	AND.html
AND	reg_al,imm	8086	AND AL, imm	Logical AND	AND.html
AND	reg_ax,imm	8086	AND AX, imm	Logical AND	AND.html
AND	reg_eax,imm	386	AND EAX, imm	Logical AND	AND.html
AND	reg_rax,imm	X64	AND RAX, imm	Logical AND	AND.html
AND	rm8,imm	8086,LOCK	AND r/m8, imm	Logical AND	AND.html
AND	rm16,imm	8086,LOCK	AND r/m16, imm	Logical AND	AND.html
AND	rm32,imm	386,LOCK	AND r/m32, imm	Logical AND	AND.html
AND	rm64,imm	X64,LOCK	AND r/m64, imm	Logical AND	AND.html
AND	mem,imm8	8086,LOCK	AND mem, imm8	Logical AND	AND.html
AND	mem,imm16	8086,LOCK	AND mem, imm16	Logical AND	AND.html
AND	mem,imm32	386,LOCK	AND mem, imm32	Logical AND	AND.html
AND	rm8,imm	8086,LOCK,ND,NOLONG	AND r/m8, imm	Logical AND	AND.html
ARPL	mem,reg16	286,PROT,NOLONG	ARPL mem, r16	Adjust RPL Field of Segment Selector	ARPL.html
ARPL	reg16,reg16	286,PROT,NOLONG	ARPL r16, r16	Adjust RPL Field of Segment Selector	ARPL.html
BB0_RESET	none	PENT,CYRIX,ND	BB0_RESET 	TODO: PENT,CYRIX,ND	
BB1_RESET	none	PENT,CYRIX,ND	BB1_RESET 	TODO: PENT,CYRIX,ND	
BOUND	reg16,mem	186,NOLONG	BOUND r16, mem	Check Array Index Against Bounds	BOUND.html
BOUND	reg32,mem	386,NOLONG	BOUND r32, mem	Check Array Index Against Bounds	BOUND.html
BSF	reg16,mem	386	BSF r16, mem	Bit Scan Forward	BSF.html
BSF	reg16,reg16	386	BSF r16, r16	Bit Scan Forward	BSF.html
BSF	reg32,mem	386	BSF r32, mem	Bit Scan Forward	BSF.html
BSF	reg32,reg32	386	BSF r32, r32	Bit Scan Forward	BSF.html
BSF	reg64,mem	X64	BSF r64, mem	Bit Scan Forward	BSF.html
BSF	reg64,reg64	X64	BSF r64, r64	Bit Scan Forward	BSF.html
BSR	reg16,mem	386	BSR r16, mem	Bit Scan Reverse	BSR.html
BSR	reg16,reg16	386	BSR r16, r16	Bit Scan Reverse	BSR.html
BSR	reg32,mem	386	BSR r32, mem	Bit Scan Reverse	BSR.html
BSR	reg32,reg32	386	BSR r32, r32	Bit Scan Reverse	BSR.html
BSR	reg64,mem	X64	BSR r64, mem	Bit Scan Reverse	BSR.html
BSR	reg64,reg64	X64	BSR r64, r64	Bit Scan Reverse	BSR.html
BSWAP	reg32	486	BSWAP r32	Byte Swap	BSWAP.html
BSWAP	reg64	X64	BSWAP r64	Byte Swap	BSWAP.html
BT	mem,reg16	386	BT mem, r16	Bit Test	BT.html
BT	reg16,reg16	386	BT r16, r16	Bit Test	BT.html
BT	mem,reg32	386	BT mem, r32	Bit Test	BT.html
BT	reg32,reg32	386	BT r32, r32	Bit Test	BT.html
BT	mem,reg64	X64	BT mem, r64	Bit Test	BT.html
BT	reg64,reg64	X64	BT r64, r64	Bit Test	BT.html
BT	rm16,imm	386	BT r/m16, imm	Bit Test	BT.html
BT	rm32,imm	386	BT r/m32, imm	Bit Test	BT.html
BT	rm64,imm	X64	BT r/m64, imm	Bit Test	BT.html
BTC	mem,reg16	386,LOCK	BTC mem, r16	Bit Test and Complement	BTC.html
BTC	reg16,reg16	386	BTC r16, r16	Bit Test and Complement	BTC.html
BTC	mem,reg32	386,LOCK	BTC mem, r32	Bit Test and Complement	BTC.html
BTC	reg32,reg32	386	BTC r32, r32	Bit Test and Complement	BTC.html
BTC	mem,reg64	X64,LOCK	BTC mem, r64	Bit Test and Complement	BTC.html
BTC	reg64,reg64	X64	BTC r64, r64	Bit Test and Complement	BTC.html
BTC	rm16,imm	386,LOCK	BTC r/m16, imm	Bit Test and Complement	BTC.html
BTC	rm32,imm	386,LOCK	BTC r/m32, imm	Bit Test and Complement	BTC.html
BTC	rm64,imm	X64,LOCK	BTC r/m64, imm	Bit Test and Complement	BTC.html
BTR	mem,reg16	386,LOCK	BTR mem, r16	Bit Test and Reset	BTR.html
BTR	reg16,reg16	386	BTR r16, r16	Bit Test and Reset	BTR.html
BTR	mem,reg32	386,LOCK	BTR mem, r32	Bit Test and Reset	BTR.html
BTR	reg32,reg32	386	BTR r32, r32	Bit Test and Reset	BTR.html
BTR	mem,reg64	X64,LOCK	BTR mem, r64	Bit Test and Reset	BTR.html
BTR	reg64,reg64	X64	BTR r64, r64	Bit Test and Reset	BTR.html
BTR	rm16,imm	386,LOCK	BTR r/m16, imm	Bit Test and Reset	BTR.html
BTR	rm32,imm	386,LOCK	BTR r/m32, imm	Bit Test and Reset	BTR.html
BTR	rm64,imm	X64,LOCK	BTR r/m64, imm	Bit Test and Reset	BTR.html
BTS	mem,reg16	386,LOCK	BTS mem, r16	Bit Test and Set	BTS.html
BTS	reg16,reg16	386	BTS r16, r16	Bit Test and Set	BTS.html
BTS	mem,reg32	386,LOCK	BTS mem, r32	Bit Test and Set	BTS.html
BTS	reg32,reg32	386	BTS r32, r32	Bit Test and Set	BTS.html
BTS	mem,reg64	X64,LOCK	BTS mem, r64	Bit Test and Set	BTS.html
BTS	reg64,reg64	X64	BTS r64, r64	Bit Test and Set	BTS.html
BTS	rm16,imm	386,LOCK	BTS r/m16, imm	Bit Test and Set	BTS.html
BTS	rm32,imm	386,LOCK	BTS r/m32, imm	Bit Test and Set	BTS.html
BTS	rm64,imm	X64,LOCK	BTS r/m64, imm	Bit Test and Set	BTS.html
CALL	imm	8086,BND	CALL imm	Call Procedure	CALL.html
CALL	imm|near	8086,ND,BND	CALL imm|near	Call Procedure	CALL.html
CALL	imm|far	8086,ND,NOLONG	CALL imm|far	Call Procedure	CALL.html
CALL	imm16	8086,NOLONG,BND	CALL imm16	Call Procedure	CALL.html
CALL	imm16|near	8086,ND,NOLONG,BND	CALL imm16|near	Call Procedure	CALL.html
CALL	imm16|far	8086,ND,NOLONG	CALL imm16|far	Call Procedure	CALL.html
CALL	imm32	386,NOLONG,BND	CALL imm32	Call Procedure	CALL.html
CALL	imm32|near	386,ND,NOLONG,BND	CALL imm32|near	Call Procedure	CALL.html
CALL	imm32|far	386,ND,NOLONG	CALL imm32|far	Call Procedure	CALL.html
CALL	imm64	X64,BND	CALL imm64	Call Procedure	CALL.html
CALL	imm64|near	X64,ND,BND	CALL imm64|near	Call Procedure	CALL.html
CALL	imm:imm	8086,NOLONG	CALL imm:imm	Call Procedure	CALL.html
CALL	imm16:imm	8086,NOLONG	CALL imm16:imm	Call Procedure	CALL.html
CALL	imm:imm16	8086,NOLONG	CALL imm:imm16	Call Procedure	CALL.html
CALL	imm32:imm	386,NOLONG	CALL imm32:imm	Call Procedure	CALL.html
CALL	imm:imm32	386,NOLONG	CALL imm:imm32	Call Procedure	CALL.html
CALL	mem|far	8086,NOLONG	CALL mem|far	Call Procedure	CALL.html
CALL	mem|far	X64	CALL mem|far	Call Procedure	CALL.html
CALL	mem16|far	8086	CALL mem16|far	Call Procedure	CALL.html
CALL	mem32|far	386	CALL mem32|far	Call Procedure	CALL.html
CALL	mem64|far	X64	CALL mem64|far	Call Procedure	CALL.html
CALL	mem|near	8086,ND,BND	CALL mem|near	Call Procedure	CALL.html
CALL	rm16|near	8086,NOLONG,ND,BND	CALL r/m16|near	Call Procedure	CALL.html
CALL	rm32|near	386,NOLONG,ND,BND	CALL r/m32|near	Call Procedure	CALL.html
CALL	rm64|near	X64,ND,BND	CALL r/m64|near	Call Procedure	CALL.html
CALL	mem	8086,BND	CALL mem	Call Procedure	CALL.html
CALL	rm16	8086,NOLONG,BND	CALL r/m16	Call Procedure	CALL.html
CALL	rm32	386,NOLONG,BND	CALL r/m32	Call Procedure	CALL.html
CALL	rm64	X64,BND	CALL r/m64	Call Procedure	CALL.html
CBW	none	8086	CBW 	Convert Byte to Word	CBW:CWDE:CDQE.html
CDQ	none	386	CDQ 	Convert Word to Doubleword/Convert Doubleword to Quadword	CWD:CDQ:CQO.html
CDQE	none	X64	CDQE 	Convert Doubleword to Quadword	CBW:CWDE:CDQE.html
CLC	none	8086	CLC 	Clear Carry Flag	CLC.html
CLD	none	8086	CLD 	Clear Direction Flag	CLD.html
CLI	none	8086	CLI 	Clear Interrupt Flag	CLI.html
CLTS	none	286,PRIV	CLTS 	Clear Task-Switched Flag in CR0	CLTS.html
CMC	none	8086	CMC 	Complement Carry Flag	CMC.html
CMP	mem,reg8	8086	CMP mem, r8	Compare Two Operands	CMP.html
CMP	reg8,reg8	8086	CMP r8, r8	Compare Two Operands	CMP.html
CMP	mem,reg16	8086	CMP mem, r16	Compare Two Operands	CMP.html
CMP	reg16,reg16	8086	CMP r16, r16	Compare Two Operands	CMP.html
CMP	mem,reg32	386	CMP mem, r32	Compare Two Operands	CMP.html
CMP	reg32,reg32	386	CMP r32, r32	Compare Two Operands	CMP.html
CMP	mem,reg64	X64	CMP mem, r64	Compare Two Operands	CMP.html
CMP	reg64,reg64	X64	CMP r64, r64	Compare Two Operands	CMP.html
CMP	reg8,mem	8086	CMP r8, mem	Compare Two Operands	CMP.html
CMP	reg8,reg8	8086	CMP r8, r8	Compare Two Operands	CMP.html
CMP	reg16,mem	8086	CMP r16, mem	Compare Two Operands	CMP.html
CMP	reg16,reg16	8086	CMP r16, r16	Compare Two Operands	CMP.html
CMP	reg32,mem	386	CMP r32, mem	Compare Two Operands	CMP.html
CMP	reg32,reg32	386	CMP r32, r32	Compare Two Operands	CMP.html
CMP	reg64,mem	X64	CMP r64, mem	Compare Two Operands	CMP.html
CMP	reg64,reg64	X64	CMP r64, r64	Compare Two Operands	CMP.html
CMP	rm16,imm8	8086	CMP r/m16, imm8	Compare Two Operands	CMP.html
CMP	rm32,imm8	386	CMP r/m32, imm8	Compare Two Operands	CMP.html
CMP	rm64,imm8	X64	CMP r/m64, imm8	Compare Two Operands	CMP.html
CMP	reg_al,imm	8086	CMP AL, imm	Compare Two Operands	CMP.html
CMP	reg_ax,imm	8086	CMP AX, imm	Compare Two Operands	CMP.html
CMP	reg_eax,imm	386	CMP EAX, imm	Compare Two Operands	CMP.html
CMP	reg_rax,imm	X64	CMP RAX, imm	Compare Two Operands	CMP.html
CMP	rm8,imm	8086	CMP r/m8, imm	Compare Two Operands	CMP.html
CMP	rm16,imm	8086	CMP r/m16, imm	Compare Two Operands	CMP.html
CMP	rm32,imm	386	CMP r/m32, imm	Compare Two Operands	CMP.html
CMP	rm64,imm	X64	CMP r/m64, imm	Compare Two Operands	CMP.html
CMP	mem,imm8	8086	CMP mem, imm8	Compare Two Operands	CMP.html
CMP	mem,imm16	8086	CMP mem, imm16	Compare Two Operands	CMP.html
CMP	mem,imm32	386	CMP mem, imm32	Compare Two Operands	CMP.html
CMP	rm8,imm	8086,ND,NOLONG	CMP r/m8, imm	Compare Two Operands	CMP.html
CMPSB	none	8086	CMPSB 	Compare String Operands	CMPS:CMPSB:CMPSW:CMPSD:CMPSQ.html
CMPSD	none	386	CMPSD 	Compare String Operands	CMPSD.html
CMPSD	xmmreg,xmmrm128,imm8	WILLAMETTE,SSE2	CMPSD xmm, xmm/m128, imm8	Compare String Operands	CMPSD.html
CMPSQ	none	X64	CMPSQ 	Compare String Operands	CMPS:CMPSB:CMPSW:CMPSD:CMPSQ.html
CMPSW	none	8086	CMPSW 	Compare String Operands	CMPS:CMPSB:CMPSW:CMPSD:CMPSQ.html
CMPXCHG	mem,reg8	PENT,LOCK	CMPXCHG mem, r8	TODO: PENT,LOCK,X64	
CMPXCHG	reg8,reg8	PENT	CMPXCHG r8, r8	TODO: PENT,LOCK,X64	
CMPXCHG	mem,reg16	PENT,LOCK	CMPXCHG mem, r16	TODO: PENT,LOCK,X64	
CMPXCHG	reg16,reg16	PENT	CMPXCHG r16, r16	TODO: PENT,LOCK,X64	
CMPXCHG	mem,reg32	PENT,LOCK	CMPXCHG mem, r32	TODO: PENT,LOCK,X64	
CMPXCHG	reg32,reg32	PENT	CMPXCHG r32, r32	TODO: PENT,LOCK,X64	
CMPXCHG	mem,reg64	X64,LOCK	CMPXCHG mem, r64	TODO: PENT,LOCK,X64	
CMPXCHG	reg64,reg64	X64	CMPXCHG r64, r64	TODO: PENT,LOCK,X64	
CMPXCHG486	mem,reg8	486,UNDOC,ND,LOCK	CMPXCHG486 mem, r8	TODO: 486,UNDOC,ND,LOCK	
CMPXCHG486	reg8,reg8	486,UNDOC,ND	CMPXCHG486 r8, r8	TODO: 486,UNDOC,ND,LOCK	
CMPXCHG486	mem,reg16	486,UNDOC,ND,LOCK	CMPXCHG486 mem, r16	TODO: 486,UNDOC,ND,LOCK	
CMPXCHG486	reg16,reg16	486,UNDOC,ND	CMPXCHG486 r16, r16	TODO: 486,UNDOC,ND,LOCK	
CMPXCHG486	mem,reg32	486,UNDOC,ND,LOCK	CMPXCHG486 mem, r32	TODO: 486,UNDOC,ND,LOCK	
CMPXCHG486	reg32,reg32	486,UNDOC,ND	CMPXCHG486 r32, r32	TODO: 486,UNDOC,ND,LOCK	
CMPXCHG8B	mem	PENT,LOCK	CMPXCHG8B mem	Compare EDX:EAX with m64. If equal, set ZF and load ECX:EBX into m64. Else, clear ZF and load m64 into EDX:EAX	CMPXCHG8B:CMPXCHG16B.html
CMPXCHG16B	mem	X64,LOCK	CMPXCHG16B mem	Compare RDX:RAX with m128. If equal, set ZF and load RCX:RBX into m128. Else, clear ZF and load m128 into RDX:RAX	CMPXCHG8B:CMPXCHG16B.html
CPUID	none	PENT	CPUID 	CPU Identification	CPUID.html
CPU_READ	none	PENT,CYRIX	CPU_READ 	TODO: PENT,CYRIX	
CPU_WRITE	none	PENT,CYRIX	CPU_WRITE 	TODO: PENT,CYRIX	
CQO	none	X64	CQO 	Convert Word to Doubleword/Convert Doubleword to Quadword	CWD:CDQ:CQO.html
CWD	none	8086	CWD 	Convert Word to Doubleword/Convert Doubleword to Quadword	CWD:CDQ:CQO.html
CWDE	none	386	CWDE 	Convert Word to Doubleword	CBW:CWDE:CDQE.html
DAA	none	8086,NOLONG	DAA 	Decimal Adjust AL after Addition	DAA.html
DAS	none	8086,NOLONG	DAS 	Decimal Adjust AL after Subtraction	DAS.html
DEC	reg16	8086,NOLONG	DEC r16	Decrement by 1	DEC.html
DEC	reg32	386,NOLONG	DEC r32	Decrement by 1	DEC.html
DEC	rm8	8086,LOCK	DEC r/m8	Decrement by 1	DEC.html
DEC	rm16	8086,LOCK	DEC r/m16	Decrement by 1	DEC.html
DEC	rm32	386,LOCK	DEC r/m32	Decrement by 1	DEC.html
DEC	rm64	X64,LOCK	DEC r/m64	Decrement by 1	DEC.html
DIV	rm8	8086	DIV r/m8	Unsigned Divide	DIV.html
DIV	rm16	8086	DIV r/m16	Unsigned Divide	DIV.html
DIV	rm32	386	DIV r/m32	Unsigned Divide	DIV.html
DIV	rm64	X64	DIV r/m64	Unsigned Divide	DIV.html
DMINT	none	P6,CYRIX	DMINT 	TODO: P6,CYRIX	
EMMS	none	PENT,MMX	EMMS 	Empty MMX Technology State	EMMS.html
ENTER	imm,imm	186	ENTER imm, imm	Make Stack Frame for Procedure Parameters	ENTER.html
EQU	imm	8086	EQU imm	MASM: The first directive assigns numeric value of expression to name.	
EQU	imm:imm	8086	EQU imm:imm	MASM: The first directive assigns numeric value of expression to name.	
F2XM1	none	8086,FPU	F2XM1 	Compute 2x–1	F2XM1.html
FABS	none	8086,FPU	FABS 	Absolute Value	FABS.html
FADD	mem32	8086,FPU	FADD mem32	Add	FADD:FADDP:FIADD.html
FADD	mem64	8086,FPU	FADD mem64	Add	FADD:FADDP:FIADD.html
FADD	fpureg|to	8086,FPU	FADD fpureg|to	Add	FADD:FADDP:FIADD.html
FADD	fpureg	8086,FPU	FADD fpureg	Add	FADD:FADDP:FIADD.html
FADD	fpureg,fpu0	8086,FPU	FADD fpureg, FPU0	Add	FADD:FADDP:FIADD.html
FADD	fpu0,fpureg	8086,FPU	FADD FPU0, fpureg	Add	FADD:FADDP:FIADD.html
FADD	none	8086,FPU,ND	FADD 	Add	FADD:FADDP:FIADD.html
FADDP	fpureg	8086,FPU	FADDP fpureg	Add	FADD:FADDP:FIADD.html
FADDP	fpureg,fpu0	8086,FPU	FADDP fpureg, FPU0	Add	FADD:FADDP:FIADD.html
FADDP	none	8086,FPU,ND	FADDP 	Add	FADD:FADDP:FIADD.html
FBLD	mem80	8086,FPU	FBLD mem80	Load Binary Coded Decimal	FBLD.html
FBLD	mem	8086,FPU	FBLD mem	Load Binary Coded Decimal	FBLD.html
FBSTP	mem80	8086,FPU	FBSTP mem80	Store BCD Integer and Pop	FBSTP.html
FBSTP	mem	8086,FPU	FBSTP mem	Store BCD Integer and Pop	FBSTP.html
FCHS	none	8086,FPU	FCHS 	Change Sign	FCHS.html
FCLEX	none	8086,FPU	FCLEX 	Clear Exceptions	FCLEX:FNCLEX.html
FCMOVB	fpureg	P6,FPU	FCMOVB fpureg	Move Floating-Point if below (CF=1)	FCMOVcc.html
FCMOVB	fpu0,fpureg	P6,FPU	FCMOVB FPU0, fpureg	Move Floating-Point if below (CF=1)	FCMOVcc.html
FCMOVB	none	P6,FPU,ND	FCMOVB 	Move Floating-Point if below (CF=1)	FCMOVcc.html
FCMOVBE	fpureg	P6,FPU	FCMOVBE fpureg	Move Floating-Point if below or equal (CF=1 OR ZF=1)	FCMOVcc.html
FCMOVBE	fpu0,fpureg	P6,FPU	FCMOVBE FPU0, fpureg	Move Floating-Point if below or equal (CF=1 OR ZF=1)	FCMOVcc.html
FCMOVBE	none	P6,FPU,ND	FCMOVBE 	Move Floating-Point if below or equal (CF=1 OR ZF=1)	FCMOVcc.html
FCMOVE	fpureg	P6,FPU	FCMOVE fpureg	Move Floating-Point if equal (ZF=1)	FCMOVcc.html
FCMOVE	fpu0,fpureg	P6,FPU	FCMOVE FPU0, fpureg	Move Floating-Point if equal (ZF=1)	FCMOVcc.html
FCMOVE	none	P6,FPU,ND	FCMOVE 	Move Floating-Point if equal (ZF=1)	FCMOVcc.html
FCMOVNB	fpureg	P6,FPU	FCMOVNB fpureg	Move Floating-Point if not below (CF=0)	FCMOVcc.html
FCMOVNB	fpu0,fpureg	P6,FPU	FCMOVNB FPU0, fpureg	Move Floating-Point if not below (CF=0)	FCMOVcc.html
FCMOVNB	none	P6,FPU,ND	FCMOVNB 	Move Floating-Point if not below (CF=0)	FCMOVcc.html
FCMOVNBE	fpureg	P6,FPU	FCMOVNBE fpureg	Move Floating-Point if not below or equal (CF=0 AND ZF=0)	FCMOVcc.html
FCMOVNBE	fpu0,fpureg	P6,FPU	FCMOVNBE FPU0, fpureg	Move Floating-Point if not below or equal (CF=0 AND ZF=0)	FCMOVcc.html
FCMOVNBE	none	P6,FPU,ND	FCMOVNBE 	Move Floating-Point if not below or equal (CF=0 AND ZF=0)	FCMOVcc.html
FCMOVNE	fpureg	P6,FPU	FCMOVNE fpureg	Move Floating-Point if not equal (ZF=0)	FCMOVcc.html
FCMOVNE	fpu0,fpureg	P6,FPU	FCMOVNE FPU0, fpureg	Move Floating-Point if not equal (ZF=0)	FCMOVcc.html
FCMOVNE	none	P6,FPU,ND	FCMOVNE 	Move Floating-Point if not equal (ZF=0)	FCMOVcc.html
FCMOVNU	fpureg	P6,FPU	FCMOVNU fpureg	Move Floating-Point if not unordered (PF=0)	FCMOVcc.html
FCMOVNU	fpu0,fpureg	P6,FPU	FCMOVNU FPU0, fpureg	Move Floating-Point if not unordered (PF=0)	FCMOVcc.html
FCMOVNU	none	P6,FPU,ND	FCMOVNU 	Move Floating-Point if not unordered (PF=0)	FCMOVcc.html
FCMOVU	fpureg	P6,FPU	FCMOVU fpureg	Move Floating-Point if unordered (PF=1)	FCMOVcc.html
FCMOVU	fpu0,fpureg	P6,FPU	FCMOVU FPU0, fpureg	Move Floating-Point if unordered (PF=1)	FCMOVcc.html
FCMOVU	none	P6,FPU,ND	FCMOVU 	Move Floating-Point if unordered (PF=1)	FCMOVcc.html
FCOM	mem32	8086,FPU	FCOM mem32	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOM	mem64	8086,FPU	FCOM mem64	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOM	fpureg	8086,FPU	FCOM fpureg	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOM	fpu0,fpureg	8086,FPU	FCOM FPU0, fpureg	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOM	none	8086,FPU,ND	FCOM 	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMI	fpureg	P6,FPU	FCOMI fpureg	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMI	fpu0,fpureg	P6,FPU	FCOMI FPU0, fpureg	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMI	none	P6,FPU,ND	FCOMI 	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMIP	fpureg	P6,FPU	FCOMIP fpureg	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMIP	fpu0,fpureg	P6,FPU	FCOMIP FPU0, fpureg	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMIP	none	P6,FPU,ND	FCOMIP 	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FCOMP	mem32	8086,FPU	FCOMP mem32	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMP	mem64	8086,FPU	FCOMP mem64	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMP	fpureg	8086,FPU	FCOMP fpureg	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMP	fpu0,fpureg	8086,FPU	FCOMP FPU0, fpureg	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMP	none	8086,FPU,ND	FCOMP 	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOMPP	none	8086,FPU	FCOMPP 	Compare Floating Point Values	FCOM:FCOMP:FCOMPP.html
FCOS	none	386,FPU	FCOS 	Cosine	FCOS.html
FDECSTP	none	8086,FPU	FDECSTP 	Decrement Stack-Top Pointer	FDECSTP.html
FDISI	none	8086,FPU	FDISI 	TODO: 8086,FPU	
FDIV	mem32	8086,FPU	FDIV mem32	Divide	FDIV:FDIVP:FIDIV.html
FDIV	mem64	8086,FPU	FDIV mem64	Divide	FDIV:FDIVP:FIDIV.html
FDIV	fpureg|to	8086,FPU	FDIV fpureg|to	Divide	FDIV:FDIVP:FIDIV.html
FDIV	fpureg	8086,FPU	FDIV fpureg	Divide	FDIV:FDIVP:FIDIV.html
FDIV	fpureg,fpu0	8086,FPU	FDIV fpureg, FPU0	Divide	FDIV:FDIVP:FIDIV.html
FDIV	fpu0,fpureg	8086,FPU	FDIV FPU0, fpureg	Divide	FDIV:FDIVP:FIDIV.html
FDIV	none	8086,FPU,ND	FDIV 	Divide	FDIV:FDIVP:FIDIV.html
FDIVP	fpureg	8086,FPU	FDIVP fpureg	Divide	FDIV:FDIVP:FIDIV.html
FDIVP	fpureg,fpu0	8086,FPU	FDIVP fpureg, FPU0	Divide	FDIV:FDIVP:FIDIV.html
FDIVP	none	8086,FPU,ND	FDIVP 	Divide	FDIV:FDIVP:FIDIV.html
FDIVR	mem32	8086,FPU	FDIVR mem32	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	mem64	8086,FPU	FDIVR mem64	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	fpureg|to	8086,FPU	FDIVR fpureg|to	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	fpureg,fpu0	8086,FPU	FDIVR fpureg, FPU0	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	fpureg	8086,FPU	FDIVR fpureg	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	fpu0,fpureg	8086,FPU	FDIVR FPU0, fpureg	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVR	none	8086,FPU,ND	FDIVR 	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVRP	fpureg	8086,FPU	FDIVRP fpureg	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVRP	fpureg,fpu0	8086,FPU	FDIVRP fpureg, FPU0	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FDIVRP	none	8086,FPU,ND	FDIVRP 	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FEMMS	none	PENT,3DNOW	FEMMS 	TODO: PENT,3DNOW	
FENI	none	8086,FPU	FENI 	TODO: 8086,FPU	
FFREE	fpureg	8086,FPU	FFREE fpureg	Free Floating-Point Register	FFREE.html
FFREE	none	8086,FPU	FFREE 	Free Floating-Point Register	FFREE.html
FFREEP	fpureg	286,FPU,UNDOC	FFREEP fpureg	TODO: 286,FPU,UNDOC	
FFREEP	none	286,FPU,UNDOC	FFREEP 	TODO: 286,FPU,UNDOC	
FIADD	mem32	8086,FPU	FIADD mem32	Add	FADD:FADDP:FIADD.html
FIADD	mem16	8086,FPU	FIADD mem16	Add	FADD:FADDP:FIADD.html
FICOM	mem32	8086,FPU	FICOM mem32	Compare Integer	FICOM:FICOMP.html
FICOM	mem16	8086,FPU	FICOM mem16	Compare Integer	FICOM:FICOMP.html
FICOMP	mem32	8086,FPU	FICOMP mem32	Compare Integer	FICOM:FICOMP.html
FICOMP	mem16	8086,FPU	FICOMP mem16	Compare Integer	FICOM:FICOMP.html
FIDIV	mem32	8086,FPU	FIDIV mem32	Divide	FDIV:FDIVP:FIDIV.html
FIDIV	mem16	8086,FPU	FIDIV mem16	Divide	FDIV:FDIVP:FIDIV.html
FIDIVR	mem32	8086,FPU	FIDIVR mem32	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FIDIVR	mem16	8086,FPU	FIDIVR mem16	Reverse Divide	FDIVR:FDIVRP:FIDIVR.html
FILD	mem32	8086,FPU	FILD mem32	Load Integer	FILD.html
FILD	mem16	8086,FPU	FILD mem16	Load Integer	FILD.html
FILD	mem64	8086,FPU	FILD mem64	Load Integer	FILD.html
FIMUL	mem32	8086,FPU	FIMUL mem32	Multiply	FMUL:FMULP:FIMUL.html
FIMUL	mem16	8086,FPU	FIMUL mem16	Multiply	FMUL:FMULP:FIMUL.html
FINCSTP	none	8086,FPU	FINCSTP 	Increment Stack-Top Pointer	FINCSTP.html
FINIT	none	8086,FPU	FINIT 	Initialize Floating-Point Unit	FINIT:FNINIT.html
FIST	mem32	8086,FPU	FIST mem32	Store Integer	FIST:FISTP.html
FIST	mem16	8086,FPU	FIST mem16	Store Integer	FIST:FISTP.html
FISTP	mem32	8086,FPU	FISTP mem32	Store Integer	FIST:FISTP.html
FISTP	mem16	8086,FPU	FISTP mem16	Store Integer	FIST:FISTP.html
FISTP	mem64	8086,FPU	FISTP mem64	Store Integer	FIST:FISTP.html
FISTTP	mem16	PRESCOTT,FPU	FISTTP mem16	Store Integer with Truncation	FISTTP.html
FISTTP	mem32	PRESCOTT,FPU	FISTTP mem32	Store Integer with Truncation	FISTTP.html
FISTTP	mem64	PRESCOTT,FPU	FISTTP mem64	Store Integer with Truncation	FISTTP.html
FISUB	mem32	8086,FPU	FISUB mem32	Subtract	FSUB:FSUBP:FISUB.html
FISUB	mem16	8086,FPU	FISUB mem16	Subtract	FSUB:FSUBP:FISUB.html
FISUBR	mem32	8086,FPU	FISUBR mem32	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FISUBR	mem16	8086,FPU	FISUBR mem16	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FLD	mem32	8086,FPU	FLD mem32	Load Floating Point Value	FLD.html
FLD	mem64	8086,FPU	FLD mem64	Load Floating Point Value	FLD.html
FLD	mem80	8086,FPU	FLD mem80	Load Floating Point Value	FLD.html
FLD	fpureg	8086,FPU	FLD fpureg	Load Floating Point Value	FLD.html
FLD	none	8086,FPU,ND	FLD 	Load Floating Point Value	FLD.html
FLD1	none	8086,FPU	FLD1 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDCW	mem	8086,FPU,SW	FLDCW mem	Load x87 FPU Control Word	FLDCW.html
FLDENV	mem	8086,FPU	FLDENV mem	Load x87 FPU Environment	FLDENV.html
FLDL2E	none	8086,FPU	FLDL2E 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDL2T	none	8086,FPU	FLDL2T 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDLG2	none	8086,FPU	FLDLG2 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDLN2	none	8086,FPU	FLDLN2 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDPI	none	8086,FPU	FLDPI 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FLDZ	none	8086,FPU	FLDZ 	Load Constant	FLD1:FLDL2T:FLDL2E:FLDPI:FLDLG2:FLDLN2:FLDZ.html
FMUL	mem32	8086,FPU	FMUL mem32	Multiply	FMUL:FMULP:FIMUL.html
FMUL	mem64	8086,FPU	FMUL mem64	Multiply	FMUL:FMULP:FIMUL.html
FMUL	fpureg|to	8086,FPU	FMUL fpureg|to	Multiply	FMUL:FMULP:FIMUL.html
FMUL	fpureg,fpu0	8086,FPU	FMUL fpureg, FPU0	Multiply	FMUL:FMULP:FIMUL.html
FMUL	fpureg	8086,FPU	FMUL fpureg	Multiply	FMUL:FMULP:FIMUL.html
FMUL	fpu0,fpureg	8086,FPU	FMUL FPU0, fpureg	Multiply	FMUL:FMULP:FIMUL.html
FMUL	none	8086,FPU,ND	FMUL 	Multiply	FMUL:FMULP:FIMUL.html
FMULP	fpureg	8086,FPU	FMULP fpureg	Multiply	FMUL:FMULP:FIMUL.html
FMULP	fpureg,fpu0	8086,FPU	FMULP fpureg, FPU0	Multiply	FMUL:FMULP:FIMUL.html
FMULP	none	8086,FPU,ND	FMULP 	Multiply	FMUL:FMULP:FIMUL.html
FNCLEX	none	8086,FPU	FNCLEX 	Clear Exceptions	FCLEX:FNCLEX.html
FNDISI	none	8086,FPU	FNDISI 	TODO: 8086,FPU	
FNENI	none	8086,FPU	FNENI 	TODO: 8086,FPU	
FNINIT	none	8086,FPU	FNINIT 	Initialize Floating-Point Unit	FINIT:FNINIT.html
FNOP	none	8086,FPU	FNOP 	No Operation	FNOP.html
FNSAVE	mem	8086,FPU	FNSAVE mem	Store x87 FPU State	FSAVE:FNSAVE.html
FNSTCW	mem	8086,FPU,SW	FNSTCW mem	Store x87 FPU Control Word	FSTCW:FNSTCW.html
FNSTENV	mem	8086,FPU	FNSTENV mem	Store x87 FPU Environment	FSTENV:FNSTENV.html
FNSTSW	mem	8086,FPU,SW	FNSTSW mem	Store x87 FPU Status Word	FSTSW:FNSTSW.html
FNSTSW	reg_ax	286,FPU	FNSTSW AX	Store x87 FPU Status Word	FSTSW:FNSTSW.html
FPATAN	none	8086,FPU	FPATAN 	Partial Arctangent	FPATAN.html
FPREM	none	8086,FPU	FPREM 	Partial Remainder	FPREM.html
FPREM1	none	386,FPU	FPREM1 	Partial Remainder	FPREM1.html
FPTAN	none	8086,FPU	FPTAN 	Partial Tangent	FPTAN.html
FRNDINT	none	8086,FPU	FRNDINT 	Round to Integer	FRNDINT.html
FRSTOR	mem	8086,FPU	FRSTOR mem	Restore x87 FPU State	FRSTOR.html
FSAVE	mem	8086,FPU	FSAVE mem	Store x87 FPU State	FSAVE:FNSAVE.html
FSCALE	none	8086,FPU	FSCALE 	Scale	FSCALE.html
FSETPM	none	286,FPU	FSETPM 	TODO: 286,FPU	
FSIN	none	386,FPU	FSIN 	Sine	FSIN.html
FSINCOS	none	386,FPU	FSINCOS 	Sine and Cosine	FSINCOS.html
FSQRT	none	8086,FPU	FSQRT 	Square Root	FSQRT.html
FST	mem32	8086,FPU	FST mem32	Store Floating Point Value	FST:FSTP.html
FST	mem64	8086,FPU	FST mem64	Store Floating Point Value	FST:FSTP.html
FST	fpureg	8086,FPU	FST fpureg	Store Floating Point Value	FST:FSTP.html
FST	none	8086,FPU,ND	FST 	Store Floating Point Value	FST:FSTP.html
FSTCW	mem	8086,FPU,SW	FSTCW mem	Store x87 FPU Control Word	FSTCW:FNSTCW.html
FSTENV	mem	8086,FPU	FSTENV mem	Store x87 FPU Environment	FSTENV:FNSTENV.html
FSTP	mem32	8086,FPU	FSTP mem32	Store Floating Point Value	FST:FSTP.html
FSTP	mem64	8086,FPU	FSTP mem64	Store Floating Point Value	FST:FSTP.html
FSTP	mem80	8086,FPU	FSTP mem80	Store Floating Point Value	FST:FSTP.html
FSTP	fpureg	8086,FPU	FSTP fpureg	Store Floating Point Value	FST:FSTP.html
FSTP	none	8086,FPU,ND	FSTP 	Store Floating Point Value	FST:FSTP.html
FSTSW	mem	8086,FPU,SW	FSTSW mem	Store x87 FPU Status Word	FSTSW:FNSTSW.html
FSTSW	reg_ax	286,FPU	FSTSW AX	Store x87 FPU Status Word	FSTSW:FNSTSW.html
FSUB	mem32	8086,FPU	FSUB mem32	Subtract	FSUB:FSUBP:FISUB.html
FSUB	mem64	8086,FPU	FSUB mem64	Subtract	FSUB:FSUBP:FISUB.html
FSUB	fpureg|to	8086,FPU	FSUB fpureg|to	Subtract	FSUB:FSUBP:FISUB.html
FSUB	fpureg,fpu0	8086,FPU	FSUB fpureg, FPU0	Subtract	FSUB:FSUBP:FISUB.html
FSUB	fpureg	8086,FPU	FSUB fpureg	Subtract	FSUB:FSUBP:FISUB.html
FSUB	fpu0,fpureg	8086,FPU	FSUB FPU0, fpureg	Subtract	FSUB:FSUBP:FISUB.html
FSUB	none	8086,FPU,ND	FSUB 	Subtract	FSUB:FSUBP:FISUB.html
FSUBP	fpureg	8086,FPU	FSUBP fpureg	Subtract	FSUB:FSUBP:FISUB.html
FSUBP	fpureg,fpu0	8086,FPU	FSUBP fpureg, FPU0	Subtract	FSUB:FSUBP:FISUB.html
FSUBP	none	8086,FPU,ND	FSUBP 	Subtract	FSUB:FSUBP:FISUB.html
FSUBR	mem32	8086,FPU	FSUBR mem32	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	mem64	8086,FPU	FSUBR mem64	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	fpureg|to	8086,FPU	FSUBR fpureg|to	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	fpureg,fpu0	8086,FPU	FSUBR fpureg, FPU0	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	fpureg	8086,FPU	FSUBR fpureg	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	fpu0,fpureg	8086,FPU	FSUBR FPU0, fpureg	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBR	none	8086,FPU,ND	FSUBR 	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBRP	fpureg	8086,FPU	FSUBRP fpureg	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBRP	fpureg,fpu0	8086,FPU	FSUBRP fpureg, FPU0	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FSUBRP	none	8086,FPU,ND	FSUBRP 	Reverse Subtract	FSUBR:FSUBRP:FISUBR.html
FTST	none	8086,FPU	FTST 	TEST	FTST.html
FUCOM	fpureg	386,FPU	FUCOM fpureg	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOM	fpu0,fpureg	386,FPU	FUCOM FPU0, fpureg	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOM	none	386,FPU,ND	FUCOM 	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOMI	fpureg	P6,FPU	FUCOMI fpureg	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMI	fpu0,fpureg	P6,FPU	FUCOMI FPU0, fpureg	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMI	none	P6,FPU,ND	FUCOMI 	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMIP	fpureg	P6,FPU	FUCOMIP fpureg	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMIP	fpu0,fpureg	P6,FPU	FUCOMIP FPU0, fpureg	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMIP	none	P6,FPU,ND	FUCOMIP 	Compare Floating Point Values and Set EFLAGS	FCOMI:FCOMIP: FUCOMI:FUCOMIP.html
FUCOMP	fpureg	386,FPU	FUCOMP fpureg	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOMP	fpu0,fpureg	386,FPU	FUCOMP FPU0, fpureg	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOMP	none	386,FPU,ND	FUCOMP 	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FUCOMPP	none	386,FPU	FUCOMPP 	Unordered Compare Floating Point Values	FUCOM:FUCOMP:FUCOMPP.html
FXAM	none	8086,FPU	FXAM 	Examine ModR/M	FXAM.html
FXCH	fpureg	8086,FPU	FXCH fpureg	Exchange Register Contents	FXCH.html
FXCH	fpureg,fpu0	8086,FPU	FXCH fpureg, FPU0	Exchange Register Contents	FXCH.html
FXCH	fpu0,fpureg	8086,FPU	FXCH FPU0, fpureg	Exchange Register Contents	FXCH.html
FXCH	none	8086,FPU,ND	FXCH 	Exchange Register Contents	FXCH.html
FXTRACT	none	8086,FPU	FXTRACT 	Extract Exponent and Significand	FXTRACT.html
FYL2X	none	8086,FPU	FYL2X 	Compute y * log2x	FYL2X.html
FYL2XP1	none	8086,FPU	FYL2XP1 	Compute y * log2(x +1)	FYL2XP1.html
HLT	none	8086,PRIV	HLT 	Halt	HLT.html
IBTS	mem,reg16	386,SW,UNDOC,ND	IBTS mem, r16	TODO: 386,SW,UNDOC,ND,SD	
IBTS	reg16,reg16	386,UNDOC,ND	IBTS r16, r16	TODO: 386,SW,UNDOC,ND,SD	
IBTS	mem,reg32	386,SD,UNDOC,ND	IBTS mem, r32	TODO: 386,SW,UNDOC,ND,SD	
IBTS	reg32,reg32	386,UNDOC,ND	IBTS r32, r32	TODO: 386,SW,UNDOC,ND,SD	
ICEBP	none	386,ND	ICEBP 	TODO: 386,ND	
IDIV	rm8	8086	IDIV r/m8	Signed Divide	IDIV.html
IDIV	rm16	8086	IDIV r/m16	Signed Divide	IDIV.html
IDIV	rm32	386	IDIV r/m32	Signed Divide	IDIV.html
IDIV	rm64	X64	IDIV r/m64	Signed Divide	IDIV.html
IMUL	rm8	8086	IMUL r/m8	Signed Multiply	IMUL.html
IMUL	rm16	8086	IMUL r/m16	Signed Multiply	IMUL.html
IMUL	rm32	386	IMUL r/m32	Signed Multiply	IMUL.html
IMUL	rm64	X64	IMUL r/m64	Signed Multiply	IMUL.html
IMUL	reg16,mem	386	IMUL r16, mem	Signed Multiply	IMUL.html
IMUL	reg16,reg16	386	IMUL r16, r16	Signed Multiply	IMUL.html
IMUL	reg32,mem	386	IMUL r32, mem	Signed Multiply	IMUL.html
IMUL	reg32,reg32	386	IMUL r32, r32	Signed Multiply	IMUL.html
IMUL	reg64,mem	X64	IMUL r64, mem	Signed Multiply	IMUL.html
IMUL	reg64,reg64	X64	IMUL r64, r64	Signed Multiply	IMUL.html
IMUL	reg16,mem,imm8	186	IMUL r16, mem, imm8	Signed Multiply	IMUL.html
IMUL	reg16,mem,imm16	186	IMUL r16, mem, imm16	Signed Multiply	IMUL.html
IMUL	reg16,mem,imm	186,ND	IMUL r16, mem, imm	Signed Multiply	IMUL.html
IMUL	reg16,reg16,imm8	186	IMUL r16, r16, imm8	Signed Multiply	IMUL.html
IMUL	reg16,reg16,imm16	186	IMUL r16, r16, imm16	Signed Multiply	IMUL.html
IMUL	reg16,reg16,imm	186,ND	IMUL r16, r16, imm	Signed Multiply	IMUL.html
IMUL	reg32,mem,imm8	386	IMUL r32, mem, imm8	Signed Multiply	IMUL.html
IMUL	reg32,mem,imm32	386	IMUL r32, mem, imm32	Signed Multiply	IMUL.html
IMUL	reg32,mem,imm	386,ND	IMUL r32, mem, imm	Signed Multiply	IMUL.html
IMUL	reg32,reg32,imm8	386	IMUL r32, r32, imm8	Signed Multiply	IMUL.html
IMUL	reg32,reg32,imm32	386	IMUL r32, r32, imm32	Signed Multiply	IMUL.html
IMUL	reg32,reg32,imm	386,ND	IMUL r32, r32, imm	Signed Multiply	IMUL.html
IMUL	reg64,mem,imm8	X64	IMUL r64, mem, imm8	Signed Multiply	IMUL.html
IMUL	reg64,mem,imm32	X64	IMUL r64, mem, imm32	Signed Multiply	IMUL.html
IMUL	reg64,mem,imm	X64,ND	IMUL r64, mem, imm	Signed Multiply	IMUL.html
IMUL	reg64,reg64,imm8	X64	IMUL r64, r64, imm8	Signed Multiply	IMUL.html
IMUL	reg64,reg64,imm32	X64	IMUL r64, r64, imm32	Signed Multiply	IMUL.html
IMUL	reg64,reg64,imm	X64,ND	IMUL r64, r64, imm	Signed Multiply	IMUL.html
IMUL	reg16,imm8	186	IMUL r16, imm8	Signed Multiply	IMUL.html
IMUL	reg16,imm16	186	IMUL r16, imm16	Signed Multiply	IMUL.html
IMUL	reg16,imm	186,ND	IMUL r16, imm	Signed Multiply	IMUL.html
IMUL	reg32,imm8	386	IMUL r32, imm8	Signed Multiply	IMUL.html
IMUL	reg32,imm32	386	IMUL r32, imm32	Signed Multiply	IMUL.html
IMUL	reg32,imm	386,ND	IMUL r32, imm	Signed Multiply	IMUL.html
IMUL	reg64,imm8	X64	IMUL r64, imm8	Signed Multiply	IMUL.html
IMUL	reg64,imm32	X64	IMUL r64, imm32	Signed Multiply	IMUL.html
IMUL	reg64,imm	X64,ND	IMUL r64, imm	Signed Multiply	IMUL.html
IN	reg_al,imm	8086	IN AL, imm	Input from Port	IN.html
IN	reg_ax,imm	8086	IN AX, imm	Input from Port	IN.html
IN	reg_eax,imm	386	IN EAX, imm	Input from Port	IN.html
IN	reg_al,reg_dx	8086	IN AL, DX	Input from Port	IN.html
IN	reg_ax,reg_dx	8086	IN AX, DX	Input from Port	IN.html
IN	reg_eax,reg_dx	386	IN EAX, DX	Input from Port	IN.html
INC	reg16	8086,NOLONG	INC r16	Increment by 1	INC.html
INC	reg32	386,NOLONG	INC r32	Increment by 1	INC.html
INC	rm8	8086,LOCK	INC r/m8	Increment by 1	INC.html
INC	rm16	8086,LOCK	INC r/m16	Increment by 1	INC.html
INC	rm32	386,LOCK	INC r/m32	Increment by 1	INC.html
INC	rm64	X64,LOCK	INC r/m64	Increment by 1	INC.html
INSB	none	186	INSB 	Input from Port to String	INS:INSB:INSW:INSD.html
INSD	none	386	INSD 	Input from Port to String	INS:INSB:INSW:INSD.html
INSW	none	186	INSW 	Input from Port to String	INS:INSB:INSW:INSD.html
INT	imm	8086	INT imm	Call to Interrupt Procedure	INT n:INTO:INT 3.html
INTO	none	8086,NOLONG	INTO 	Call to Interrupt Procedure	INT n:INTO:INT 3.html
INVD	none	486,PRIV	INVD 	Invalidate Internal Caches	INVD.html
INVPCID	reg32,mem128	FUTURE,INVPCID,PRIV,NOLONG	INVPCID r32, mem128	Invalidate Process-Context Identifier	INVPCID.html
INVPCID	reg64,mem128	FUTURE,INVPCID,PRIV,LONG	INVPCID r64, mem128	Invalidate Process-Context Identifier	INVPCID.html
INVLPG	mem	486,PRIV	INVLPG mem	Invalidate TLB Entries	INVLPG.html
INVLPGA	reg_ax,reg_ecx	X86_64,AMD,NOLONG	INVLPGA AX, ECX	TODO: X86_64,AMD,NOLONG,X64	
INVLPGA	reg_eax,reg_ecx	X86_64,AMD	INVLPGA EAX, ECX	TODO: X86_64,AMD,NOLONG,X64	
INVLPGA	reg_rax,reg_ecx	X64,AMD	INVLPGA RAX, ECX	TODO: X86_64,AMD,NOLONG,X64	
INVLPGA	none	X86_64,AMD	INVLPGA 	TODO: X86_64,AMD,NOLONG,X64	
IRET	none	8086	IRET 	Interrupt Return	IRET:IRETD.html
IRETD	none	386	IRETD 	Interrupt Return	IRET:IRETD.html
IRETQ	none	X64	IRETQ 	TODO: X64	
IRETW	none	8086	IRETW 	TODO: 8086	
JCXZ	imm	8086,NOLONG	JCXZ imm	Jump if CX register is 0	Jcc.html
JECXZ	imm	386	JECXZ imm	Jump if ECX register is 0	Jcc.html
JRCXZ	imm	X64	JRCXZ imm	Jump if RCX register is 0	Jcc.html
JMP	imm|short	8086	JMP imm|short	Unconditional Jump	Jcc.html
JMP	imm	8086,ND	JMP imm	Unconditional Jump	Jcc.html
JMP	imm	8086,BND	JMP imm	Unconditional Jump	Jcc.html
JMP	imm|near	8086,ND,BND	JMP imm|near	Unconditional Jump	Jcc.html
JMP	imm|far	8086,ND,NOLONG	JMP imm|far	Unconditional Jump	Jcc.html
JMP	imm16	8086,NOLONG,BND	JMP imm16	Unconditional Jump	Jcc.html
JMP	imm16|near	8086,ND,NOLONG,BND	JMP imm16|near	Unconditional Jump	Jcc.html
JMP	imm16|far	8086,ND,NOLONG	JMP imm16|far	Unconditional Jump	Jcc.html
JMP	imm32	386,NOLONG,BND	JMP imm32	Unconditional Jump	Jcc.html
JMP	imm32|near	386,ND,NOLONG,BND	JMP imm32|near	Unconditional Jump	Jcc.html
JMP	imm32|far	386,ND,NOLONG	JMP imm32|far	Unconditional Jump	Jcc.html
JMP	imm64	X64,BND	JMP imm64	Unconditional Jump	Jcc.html
JMP	imm64|near	X64,ND,BND	JMP imm64|near	Unconditional Jump	Jcc.html
JMP	imm:imm	8086,NOLONG	JMP imm:imm	Unconditional Jump	Jcc.html
JMP	imm16:imm	8086,NOLONG	JMP imm16:imm	Unconditional Jump	Jcc.html
JMP	imm:imm16	8086,NOLONG	JMP imm:imm16	Unconditional Jump	Jcc.html
JMP	imm32:imm	386,NOLONG	JMP imm32:imm	Unconditional Jump	Jcc.html
JMP	imm:imm32	386,NOLONG	JMP imm:imm32	Unconditional Jump	Jcc.html
JMP	mem|far	8086,NOLONG	JMP mem|far	Unconditional Jump	Jcc.html
JMP	mem|far	X64	JMP mem|far	Unconditional Jump	Jcc.html
JMP	mem16|far	8086	JMP mem16|far	Unconditional Jump	Jcc.html
JMP	mem32|far	386	JMP mem32|far	Unconditional Jump	Jcc.html
JMP	mem64|far	X64	JMP mem64|far	Unconditional Jump	Jcc.html
JMP	mem|near	8086,ND,BND	JMP mem|near	Unconditional Jump	Jcc.html
JMP	rm16|near	8086,NOLONG,ND,BND	JMP r/m16|near	Unconditional Jump	Jcc.html
JMP	rm32|near	386,NOLONG,ND,BND	JMP r/m32|near	Unconditional Jump	Jcc.html
JMP	rm64|near	X64,ND,BND	JMP r/m64|near	Unconditional Jump	Jcc.html
JMP	mem	8086,BND	JMP mem	Unconditional Jump	Jcc.html
JMP	rm16	8086,NOLONG,BND	JMP r/m16	Unconditional Jump	Jcc.html
JMP	rm32	386,NOLONG,BND	JMP r/m32	Unconditional Jump	Jcc.html
JMP	rm64	X64,BND	JMP r/m64	Unconditional Jump	Jcc.html
JMPE	imm	IA64	JMPE imm	TODO: IA64	
JMPE	imm16	IA64	JMPE imm16	TODO: IA64	
JMPE	imm32	IA64	JMPE imm32	TODO: IA64	
JMPE	rm16	IA64	JMPE r/m16	TODO: IA64	
JMPE	rm32	IA64	JMPE r/m32	TODO: IA64	
LAHF	none	8086	LAHF 	Load Status Flags into AH Register	LAHF.html
LAR	reg16,mem	286,PROT,SW	LAR r16, mem	Load Access Rights Byte	LAR.html
LAR	reg16,reg16	286,PROT	LAR r16, r16	Load Access Rights Byte	LAR.html
LAR	reg16,reg32	386,PROT	LAR r16, r32	Load Access Rights Byte	LAR.html
LAR	reg16,reg64	X64,PROT,ND	LAR r16, r64	Load Access Rights Byte	LAR.html
LAR	reg32,mem	386,PROT,SW	LAR r32, mem	Load Access Rights Byte	LAR.html
LAR	reg32,reg16	386,PROT	LAR r32, r16	Load Access Rights Byte	LAR.html
LAR	reg32,reg32	386,PROT	LAR r32, r32	Load Access Rights Byte	LAR.html
LAR	reg32,reg64	X64,PROT,ND	LAR r32, r64	Load Access Rights Byte	LAR.html
LAR	reg64,mem	X64,PROT,SW	LAR r64, mem	Load Access Rights Byte	LAR.html
LAR	reg64,reg16	X64,PROT	LAR r64, r16	Load Access Rights Byte	LAR.html
LAR	reg64,reg32	X64,PROT	LAR r64, r32	Load Access Rights Byte	LAR.html
LAR	reg64,reg64	X64,PROT	LAR r64, r64	Load Access Rights Byte	LAR.html
LDS	reg16,mem	8086,NOLONG	LDS r16, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LDS	reg32,mem	386,NOLONG	LDS r32, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LEA	reg16,mem	8086	LEA r16, mem	Load Effective Address	LEA.html
LEA	reg32,mem	386	LEA r32, mem	Load Effective Address	LEA.html
LEA	reg64,mem	X64	LEA r64, mem	Load Effective Address	LEA.html
LEAVE	none	186	LEAVE 	High Level Procedure Exit	LEAVE.html
LES	reg16,mem	8086,NOLONG	LES r16, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LES	reg32,mem	386,NOLONG	LES r32, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LFENCE	none	X64,AMD	LFENCE 	Load Fence	LFENCE.html
LFENCE	none	WILLAMETTE,SSE2	LFENCE 	Load Fence	LFENCE.html
LFS	reg16,mem	386	LFS r16, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LFS	reg32,mem	386	LFS r32, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LFS	reg64,mem	X64	LFS r64, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LGDT	mem	286,PRIV	LGDT mem	Load Global/Interrupt Descriptor Table Register	LGDT:LIDT.html
LGS	reg16,mem	386	LGS r16, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LGS	reg32,mem	386	LGS r32, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LGS	reg64,mem	X64	LGS r64, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LIDT	mem	286,PRIV	LIDT mem	Load Global/Interrupt Descriptor Table Register	LGDT:LIDT.html
LLDT	mem	286,PROT,PRIV	LLDT mem	Load Local Descriptor Table Register	LLDT.html
LLDT	mem16	286,PROT,PRIV	LLDT mem16	Load Local Descriptor Table Register	LLDT.html
LLDT	reg16	286,PROT,PRIV	LLDT r16	Load Local Descriptor Table Register	LLDT.html
LMSW	mem	286,PRIV	LMSW mem	Load Machine Status Word	LMSW.html
LMSW	mem16	286,PRIV	LMSW mem16	Load Machine Status Word	LMSW.html
LMSW	reg16	286,PRIV	LMSW r16	Load Machine Status Word	LMSW.html
LOADALL	none	386,UNDOC,ND	LOADALL 	TODO: 386,UNDOC,ND	
LOADALL286	none	286,UNDOC,ND	LOADALL286 	TODO: 286,UNDOC,ND	
LODSB	none	8086	LODSB 	Load String	LODS:LODSB:LODSW:LODSD:LODSQ.html
LODSD	none	386	LODSD 	Load String	LODS:LODSB:LODSW:LODSD:LODSQ.html
LODSQ	none	X64	LODSQ 	Load String	LODS:LODSB:LODSW:LODSD:LODSQ.html
LODSW	none	8086	LODSW 	Load String	LODS:LODSB:LODSW:LODSD:LODSQ.html
LOOP	imm	8086	LOOP imm	Loop According to ECX Counter. Jump short if RCX!=0	LOOP:LOOPcc.html
LOOP	imm,reg_cx	8086,NOLONG	LOOP imm, CX	Loop According to ECX Counter. Jump short if RCX!=0	LOOP:LOOPcc.html
LOOP	imm,reg_ecx	386	LOOP imm, ECX	Loop According to ECX Counter. Jump short if RCX!=0	LOOP:LOOPcc.html
LOOP	imm,reg_rcx	X64	LOOP imm, RCX	Loop According to ECX Counter. Jump short if RCX!=0	LOOP:LOOPcc.html
LOOPE	imm	8086	LOOPE imm	Loop According to ECX Counter. Jump short if RCX!=0 and ZF=1	LOOP:LOOPcc.html
LOOPE	imm,reg_cx	8086,NOLONG	LOOPE imm, CX	Loop According to ECX Counter. Jump short if RCX!=0 and ZF=1	LOOP:LOOPcc.html
LOOPE	imm,reg_ecx	386	LOOPE imm, ECX	Loop According to ECX Counter. Jump short if RCX!=0 and ZF=1	LOOP:LOOPcc.html
LOOPE	imm,reg_rcx	X64	LOOPE imm, RCX	Loop According to ECX Counter. Jump short if RCX!=0 and ZF=1	LOOP:LOOPcc.html
LOOPNE	imm	8086	LOOPNE imm	Loop According to ECX Counter. Jump short if RCX!=0 and ZF=0	LOOP:LOOPcc.html
LOOPNE	imm,reg_cx	8086,NOLONG	LOOPNE imm, CX	Loop According to ECX Counter. Jump short if RCX!=0 and ZF=0	LOOP:LOOPcc.html
LOOPNE	imm,reg_ecx	386	LOOPNE imm, ECX	Loop According to ECX Counter. Jump short if RCX!=0 and ZF=0	LOOP:LOOPcc.html
LOOPNE	imm,reg_rcx	X64	LOOPNE imm, RCX	Loop According to ECX Counter. Jump short if RCX!=0 and ZF=0	LOOP:LOOPcc.html
LOOPNZ	imm	8086	LOOPNZ imm	TODO: 8086,NOLONG,386,X64	
LOOPNZ	imm,reg_cx	8086,NOLONG	LOOPNZ imm, CX	TODO: 8086,NOLONG,386,X64	
LOOPNZ	imm,reg_ecx	386	LOOPNZ imm, ECX	TODO: 8086,NOLONG,386,X64	
LOOPNZ	imm,reg_rcx	X64	LOOPNZ imm, RCX	TODO: 8086,NOLONG,386,X64	
LOOPZ	imm	8086	LOOPZ imm	TODO: 8086,NOLONG,386,X64	
LOOPZ	imm,reg_cx	8086,NOLONG	LOOPZ imm, CX	TODO: 8086,NOLONG,386,X64	
LOOPZ	imm,reg_ecx	386	LOOPZ imm, ECX	TODO: 8086,NOLONG,386,X64	
LOOPZ	imm,reg_rcx	X64	LOOPZ imm, RCX	TODO: 8086,NOLONG,386,X64	
LSL	reg16,mem	286,PROT,SW	LSL r16, mem	Load Segment Limit	LSL.html
LSL	reg16,reg16	286,PROT	LSL r16, r16	Load Segment Limit	LSL.html
LSL	reg16,reg32	386,PROT	LSL r16, r32	Load Segment Limit	LSL.html
LSL	reg16,reg64	X64,PROT,ND	LSL r16, r64	Load Segment Limit	LSL.html
LSL	reg32,mem	386,PROT,SW	LSL r32, mem	Load Segment Limit	LSL.html
LSL	reg32,reg16	386,PROT	LSL r32, r16	Load Segment Limit	LSL.html
LSL	reg32,reg32	386,PROT	LSL r32, r32	Load Segment Limit	LSL.html
LSL	reg32,reg64	X64,PROT,ND	LSL r32, r64	Load Segment Limit	LSL.html
LSL	reg64,mem	X64,PROT,SW	LSL r64, mem	Load Segment Limit	LSL.html
LSL	reg64,reg16	X64,PROT	LSL r64, r16	Load Segment Limit	LSL.html
LSL	reg64,reg32	X64,PROT	LSL r64, r32	Load Segment Limit	LSL.html
LSL	reg64,reg64	X64,PROT	LSL r64, r64	Load Segment Limit	LSL.html
LSS	reg16,mem	386	LSS r16, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LSS	reg32,mem	386	LSS r32, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LSS	reg64,mem	X64	LSS r64, mem	Load Far Pointer	LDS:LES:LFS:LGS:LSS.html
LTR	mem	286,PROT,PRIV	LTR mem	Load Task Register	LTR.html
LTR	mem16	286,PROT,PRIV	LTR mem16	Load Task Register	LTR.html
LTR	reg16	286,PROT,PRIV	LTR r16	Load Task Register	LTR.html
MFENCE	none	X64,AMD	MFENCE 	Memory Fence	MFENCE.html
MFENCE	none	WILLAMETTE,SSE2	MFENCE 	Memory Fence	MFENCE.html
MONITOR	none	PRESCOTT	MONITOR 	Set Up Monitor Address	MONITOR.html
MONITOR	reg_eax,reg_ecx,reg_edx	PRESCOTT,NOLONG,ND	MONITOR EAX, ECX, EDX	Set Up Monitor Address	MONITOR.html
MONITOR	reg_rax,reg_ecx,reg_edx	X64,ND	MONITOR RAX, ECX, EDX	Set Up Monitor Address	MONITOR.html
MONITORX	none	X64,AMD	MONITORX 	TODO: X64,AMD,ND	
MONITORX	reg_rax,reg_ecx,reg_edx	X64,AMD,ND	MONITORX RAX, ECX, EDX	TODO: X64,AMD,ND	

MOV	mem,reg_sreg	8086,SW	MOV mem, reg_sreg	Move 	MOV.html
MOV	reg16,reg_sreg	8086	MOV r16, reg_sreg	Move	MOV.html
MOV	reg32,reg_sreg	386	MOV r32, reg_sreg	Move	MOV.html
MOV	reg64,reg_sreg	X64,OPT,ND	MOV r64, reg_sreg	Move	MOV.html
MOV	rm64,reg_sreg	X64	MOV r/m64, reg_sreg	Move	MOV.html
MOV	reg_sreg,mem	8086,SW	MOV reg_sreg, mem	Move	MOV.html
MOV	reg_sreg,reg16	8086,OPT,ND	MOV reg_sreg, r16	Move	MOV.html
MOV	reg_sreg,reg32	386,OPT,ND	MOV reg_sreg, r32	Move	MOV.html
MOV	reg_sreg,reg64	X64,OPT,ND	MOV reg_sreg, r64	Move	MOV.html
MOV	reg_sreg,reg16	8086	MOV reg_sreg, r16	Move	MOV.html
MOV	reg_sreg,reg32	386	MOV reg_sreg, r32	Move	MOV.html
MOV	reg_sreg,rm64	X64	MOV reg_sreg, r/m64	Move	MOV.html

MOV	reg_al,mem_offs	8086	MOV AL, mem_offs	Move	MOV.html
MOV	reg_ax,mem_offs	8086	MOV AX, mem_offs	Move	MOV.html
MOV	reg_eax,mem_offs	386	MOV EAX, mem_offs	Move	MOV.html
MOV	reg_rax,mem_offs	X64	MOV RAX, mem_offs	Move	MOV.html
MOV	mem_offs,reg_al	8086,NOHLE	MOV mem_offs, AL	Move	MOV.html
MOV	mem_offs,reg_ax	8086,NOHLE	MOV mem_offs, AX	Move	MOV.html
MOV	mem_offs,reg_eax	386,NOHLE	MOV mem_offs, EAX	Move	MOV.html
MOV	mem_offs,reg_rax	X64,NOHLE	MOV mem_offs, RAX	Move	MOV.html
MOV	reg32,reg_creg	386,PRIV,NOLONG	MOV r32, reg_creg	Move	MOV.html
MOV	reg64,reg_creg	X64,PRIV	MOV r64, reg_creg	Move	MOV.html
MOV	reg_creg,reg32	386,PRIV,NOLONG	MOV reg_creg, r32	Move	MOV.html
MOV	reg_creg,reg64	X64,PRIV	MOV reg_creg, r64	Move	MOV.html
MOV	reg32,reg_dreg	386,PRIV,NOLONG	MOV r32, reg_dreg	Move	MOV.html
MOV	reg64,reg_dreg	X64,PRIV	MOV r64, reg_dreg	Move	MOV.html
MOV	reg_dreg,reg32	386,PRIV,NOLONG	MOV reg_dreg, r32	Move	MOV.html
MOV	reg_dreg,reg64	X64,PRIV	MOV reg_dreg, r64	Move	MOV.html
MOV	mem,reg8	8086	MOV mem, r8	Move	MOV.html
MOV	reg8,reg8	8086	MOV r8, r8	Move	MOV.html
MOV	mem,reg16	8086	MOV mem, r16	Move	MOV.html
MOV	reg16,reg16	8086	MOV r16, r16	Move	MOV.html
MOV	mem,reg32	386	MOV mem, r32	Move	MOV.html
MOV	reg32,reg32	386	MOV r32, r32	Move	MOV.html
MOV	mem,reg64	X64	MOV mem, r64	Move	MOV.html
MOV	reg64,reg64	X64	MOV r64, r64	Move	MOV.html
MOV	reg8,mem	8086	MOV r8, mem	Move	MOV.html
MOV	reg8,reg8	8086	MOV r8, r8	Move	MOV.html
MOV	reg16,mem	8086	MOV r16, mem	Move	MOV.html
MOV	reg16,reg16	8086	MOV r16, r16	Move	MOV.html
MOV	reg32,mem	386	MOV r32, mem	Move	MOV.html
MOV	reg32,reg32	386	MOV r32, r32	Move	MOV.html
MOV	reg64,mem	X64	MOV r64, mem	Move	MOV.html
MOV	reg64,reg64	X64	MOV r64, r64	Move	MOV.html
MOV	reg8,imm	8086	MOV r8, imm	Move	MOV.html
MOV	reg16,imm	8086	MOV r16, imm	Move	MOV.html
MOV	reg32,imm	386	MOV r32, imm	Move	MOV.html
MOV	reg64,imm	X64	MOV r64, imm	Move	MOV.html
MOV	rm8,imm	8086	MOV r/m8, imm	Move	MOV.html
MOV	rm16,imm	8086	MOV r/m16, imm	Move	MOV.html
MOV	rm32,imm	386	MOV r/m32, imm	Move	MOV.html
MOV	rm64,imm	X64	MOV r/m64, imm	Move	MOV.html
MOV	rm64,imm32	X64	MOV r/m64, imm32	Move	MOV.html
MOV	mem,imm8	8086	MOV mem, imm8	Move	MOV.html
MOV	mem,imm16	8086	MOV mem, imm16	Move	MOV.html
MOV	mem,imm32	386	MOV mem, imm32	Move	MOV.html
MOVD	mmxreg,rm32	PENT,MMX,SD	MOVD mmxreg, r/m32	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	rm32,mmxreg	PENT,MMX,SD	MOVD r/m32, mmxreg	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	mmxreg,rm64	X64,MMX,SX,ND	MOVD mmxreg, r/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	rm64,mmxreg	X64,MMX,SX,ND	MOVD r/m64, mmxreg	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	mem,xmmreg	WILLAMETTE,SSE2,SD	MOVD mem, xmm	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	xmmreg,mem	WILLAMETTE,SSE2,SD	MOVD xmm, mem	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	xmmreg,rm32	WILLAMETTE,SSE2	MOVD xmm, r/m32	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVD	rm32,xmmreg	WILLAMETTE,SSE2	MOVD r/m32, xmm	Move Doubleword/Move Quadword	MOVD:MOVQ.html
MOVQ	mmxreg,mmxrm	PENT,MMX	MOVQ mmxreg, mmx/mem	Move Quadword	MOVD:MOVQ.html
MOVQ	mmxrm,mmxreg	PENT,MMX	MOVQ mmx/mem, mmxreg	Move Quadword	MOVD:MOVQ.html
MOVQ	mmxreg,rm64	X64,MMX	MOVQ mmxreg, r/m64	Move Quadword	MOVD:MOVQ.html
MOVQ	rm64,mmxreg	X64,MMX	MOVQ r/m64, mmxreg	Move Quadword	MOVD:MOVQ.html
MOVQ	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVQ xmm, xmm	Move Quadword	MOVD:MOVQ.html
MOVQ	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVQ xmm, xmm	Move Quadword	MOVD:MOVQ.html
MOVQ	mem,xmmreg	WILLAMETTE,SSE2	MOVQ mem, xmm	Move Quadword	MOVD:MOVQ.html
MOVQ	xmmreg,mem	WILLAMETTE,SSE2	MOVQ xmm, mem	Move Quadword	MOVD:MOVQ.html
MOVQ	xmmreg,rm64	X64,SSE2	MOVQ xmm, r/m64	Move Quadword	MOVD:MOVQ.html
MOVQ	rm64,xmmreg	X64,SSE2	MOVQ r/m64, xmm	Move Quadword	MOVD:MOVQ.html
MOVSB	none	8086	MOVSB 	Move Data from String to String	MOVS:MOVSB:MOVSW:MOVSD:MOVSQ.html
MOVSD	none	386	MOVSD 	Move Data from String to String	MOVSD.html
MOVSD	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVSD xmm, xmm	Move Data from String to String	MOVSD.html
MOVSD	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVSD xmm, xmm	Move Data from String to String	MOVSD.html
MOVSD	mem64,xmmreg	WILLAMETTE,SSE2	MOVSD mem64, xmm	Move Data from String to String	MOVSD.html
MOVSD	xmmreg,mem64	WILLAMETTE,SSE2	MOVSD xmm, mem64	Move Data from String to String	MOVSD.html
MOVSQ	none	X64	MOVSQ 	Move Data from String to String	MOVS:MOVSB:MOVSW:MOVSD:MOVSQ.html
MOVSW	none	8086	MOVSW 	Move Data from String to String	MOVS:MOVSB:MOVSW:MOVSD:MOVSQ.html
MOVSX	reg16,mem	386	MOVSX r16, mem	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	reg16,reg8	386	MOVSX r16, r8	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	reg32,rm8	386	MOVSX r32, r/m8	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	reg32,rm16	386	MOVSX r32, r/m16	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	reg64,rm8	X64	MOVSX r64, r/m8	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	reg64,rm16	X64	MOVSX r64, r/m16	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSX	reg64,rm32	X64,ND	MOVSX r64, r/m32	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVSXD	reg64,rm32	X64	MOVSXD r64, r/m32	Move with Sign-Extension	MOVSX:MOVSXD.html
MOVZX	reg16,mem	386	MOVZX r16, mem	Move with Zero-Extend	MOVZX.html
MOVZX	reg16,reg8	386	MOVZX r16, r8	Move with Zero-Extend	MOVZX.html
MOVZX	reg32,rm8	386	MOVZX r32, r/m8	Move with Zero-Extend	MOVZX.html
MOVZX	reg32,rm16	386	MOVZX r32, r/m16	Move with Zero-Extend	MOVZX.html
MOVZX	reg64,rm8	X64	MOVZX r64, r/m8	Move with Zero-Extend	MOVZX.html
MOVZX	reg64,rm16	X64	MOVZX r64, r/m16	Move with Zero-Extend	MOVZX.html
MUL	rm8	8086	MUL r/m8	Unsigned Multiply	MUL.html
MUL	rm16	8086	MUL r/m16	Unsigned Multiply	MUL.html
MUL	rm32	386	MUL r/m32	Unsigned Multiply	MUL.html
MUL	rm64	X64	MUL r/m64	Unsigned Multiply	MUL.html
MWAIT	none	PRESCOTT	MWAIT 	Monitor Wait	MWAIT.html
MWAIT	reg_eax,reg_ecx	PRESCOTT,ND	MWAIT EAX, ECX	Monitor Wait	MWAIT.html
MWAITX	none	X64,AMD	MWAITX 	TODO: X64,AMD,ND	
MWAITX	reg_eax,reg_ecx	X64,AMD,ND	MWAITX EAX, ECX	TODO: X64,AMD,ND	
NEG	rm8	8086,LOCK	NEG r/m8	Two's Complement Negation	NEG.html
NEG	rm16	8086,LOCK	NEG r/m16	Two's Complement Negation	NEG.html
NEG	rm32	386,LOCK	NEG r/m32	Two's Complement Negation	NEG.html
NEG	rm64	X64,LOCK	NEG r/m64	Two's Complement Negation	NEG.html
NOP	none	8086	NOP 	No Operation	NOP.html
NOP	rm16	P6	NOP r/m16	No Operation	NOP.html
NOP	rm32	P6	NOP r/m32	No Operation	NOP.html
NOP	rm64	X64	NOP r/m64	No Operation	NOP.html
NOT	rm8	8086,LOCK	NOT r/m8	One's Complement Negation	NOT.html
NOT	rm16	8086,LOCK	NOT r/m16	One's Complement Negation	NOT.html
NOT	rm32	386,LOCK	NOT r/m32	One's Complement Negation	NOT.html
NOT	rm64	X64,LOCK	NOT r/m64	One's Complement Negation	NOT.html
OR	mem,reg8	8086,LOCK	OR mem, r8	Logical Inclusive OR	OR.html
OR	reg8,reg8	8086	OR r8, r8	Logical Inclusive OR	OR.html
OR	mem,reg16	8086,LOCK	OR mem, r16	Logical Inclusive OR	OR.html
OR	reg16,reg16	8086	OR r16, r16	Logical Inclusive OR	OR.html
OR	mem,reg32	386,LOCK	OR mem, r32	Logical Inclusive OR	OR.html
OR	reg32,reg32	386	OR r32, r32	Logical Inclusive OR	OR.html
OR	mem,reg64	X64,LOCK	OR mem, r64	Logical Inclusive OR	OR.html
OR	reg64,reg64	X64	OR r64, r64	Logical Inclusive OR	OR.html
OR	reg8,mem	8086	OR r8, mem	Logical Inclusive OR	OR.html
OR	reg8,reg8	8086	OR r8, r8	Logical Inclusive OR	OR.html
OR	reg16,mem	8086	OR r16, mem	Logical Inclusive OR	OR.html
OR	reg16,reg16	8086	OR r16, r16	Logical Inclusive OR	OR.html
OR	reg32,mem	386	OR r32, mem	Logical Inclusive OR	OR.html
OR	reg32,reg32	386	OR r32, r32	Logical Inclusive OR	OR.html
OR	reg64,mem	X64	OR r64, mem	Logical Inclusive OR	OR.html
OR	reg64,reg64	X64	OR r64, r64	Logical Inclusive OR	OR.html
OR	rm16,imm8	8086,LOCK	OR r/m16, imm8	Logical Inclusive OR	OR.html
OR	rm32,imm8	386,LOCK	OR r/m32, imm8	Logical Inclusive OR	OR.html
OR	rm64,imm8	X64,LOCK	OR r/m64, imm8	Logical Inclusive OR	OR.html
OR	reg_al,imm	8086	OR AL, imm	Logical Inclusive OR	OR.html
OR	reg_ax,imm	8086	OR AX, imm	Logical Inclusive OR	OR.html
OR	reg_eax,imm	386	OR EAX, imm	Logical Inclusive OR	OR.html
OR	reg_rax,imm	X64	OR RAX, imm	Logical Inclusive OR	OR.html
OR	rm8,imm	8086,LOCK	OR r/m8, imm	Logical Inclusive OR	OR.html
OR	rm16,imm	8086,LOCK	OR r/m16, imm	Logical Inclusive OR	OR.html
OR	rm32,imm	386,LOCK	OR r/m32, imm	Logical Inclusive OR	OR.html
OR	rm64,imm	X64,LOCK	OR r/m64, imm	Logical Inclusive OR	OR.html
OR	mem,imm8	8086,LOCK	OR mem, imm8	Logical Inclusive OR	OR.html
OR	mem,imm16	8086,LOCK	OR mem, imm16	Logical Inclusive OR	OR.html
OR	mem,imm32	386,LOCK	OR mem, imm32	Logical Inclusive OR	OR.html
OR	rm8,imm	8086,LOCK,ND,NOLONG	OR r/m8, imm	Logical Inclusive OR	OR.html
OUT	imm,reg_al	8086	OUT imm, AL	Output to Port	OUT.html
OUT	imm,reg_ax	8086	OUT imm, AX	Output to Port	OUT.html
OUT	imm,reg_eax	386	OUT imm, EAX	Output to Port	OUT.html
OUT	reg_dx,reg_al	8086	OUT DX, AL	Output to Port	OUT.html
OUT	reg_dx,reg_ax	8086	OUT DX, AX	Output to Port	OUT.html
OUT	reg_dx,reg_eax	386	OUT DX, EAX	Output to Port	OUT.html
OUTSB	none	186	OUTSB 	Output String to Port	OUTS:OUTSB:OUTSW:OUTSD.html
OUTSD	none	386	OUTSD 	Output String to Port	OUTS:OUTSB:OUTSW:OUTSD.html
OUTSW	none	186	OUTSW 	Output String to Port	OUTS:OUTSB:OUTSW:OUTSD.html
PACKSSDW	mmxreg,mmxrm	PENT,MMX	PACKSSDW mmxreg, mmx/mem	Pack Doubleword to word (signed with saturation)	PACKSSWB:PACKSSDW.html
PACKSSDW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PACKSSDW xmm, xmm/m128	Pack Doubleword to word (signed with saturation)	PACKSSWB:PACKSSDW.html
PACKSSWB	mmxreg,mmxrm	PENT,MMX	PACKSSWB mmxreg, mmx/mem	Pack word to byte (signed with saturation)	PACKSSWB:PACKSSDW.html
PACKSSWB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PACKSSWB xmm, xmm/m128	Pack word to byte (signed with saturation)	PACKSSWB:PACKSSDW.html
PACKUSWB	mmxreg,mmxrm	PENT,MMX	PACKUSWB mmxreg, mmx/mem	Pack with Unsigned Saturation	PACKUSWB.html
PACKUSWB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PACKUSWB xmm, xmm/m128	Pack with Unsigned Saturation	PACKUSWB.html
PADDB	mmxreg,mmxrm	PENT,MMX	PADDB mmxreg, mmx/mem	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PADDB xmm, xmm/m128	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDD	mmxreg,mmxrm	PENT,MMX	PADDD mmxreg, mmx/mem	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PADDD xmm, xmm/m128	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDSB	mmxreg,mmxrm	PENT,MMX	PADDSB mmxreg, mmx/mem	Add Packed Signed Integers with Signed Saturation	PADDSB:PADDSW.html
PADDSB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PADDSB xmm, xmm/m128	Add Packed Signed Integers with Signed Saturation	PADDSB:PADDSW.html
PADDSIW	mmxreg,mmxrm	PENT,MMX,CYRIX	PADDSIW mmxreg, mmx/mem	TODO: PENT,MMX,CYRIX	
PADDSW	mmxreg,mmxrm	PENT,MMX	PADDSW mmxreg, mmx/mem	Add Packed Signed Integers with Signed Saturation	PADDSB:PADDSW.html
PADDSW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PADDSW xmm, xmm/m128	Add Packed Signed Integers with Signed Saturation	PADDSB:PADDSW.html
PADDUSB	mmxreg,mmxrm	PENT,MMX	PADDUSB mmxreg, mmx/mem	Add Packed Unsigned Integers with Unsigned Saturation	PADDUSB:PADDUSW.html
PADDUSB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PADDUSB xmm, xmm/m128	Add Packed Unsigned Integers with Unsigned Saturation	PADDUSB:PADDUSW.html
PADDUSW	mmxreg,mmxrm	PENT,MMX	PADDUSW mmxreg, mmx/mem	Add Packed Unsigned Integers with Unsigned Saturation	PADDUSB:PADDUSW.html
PADDUSW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PADDUSW xmm, xmm/m128	Add Packed Unsigned Integers with Unsigned Saturation	PADDUSB:PADDUSW.html
PADDW	mmxreg,mmxrm	PENT,MMX	PADDW mmxreg, mmx/mem	Add Packed Integers	PADDB:PADDW:PADDD.html
PADDW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PADDW xmm, xmm/m128	Add Packed Integers	PADDB:PADDW:PADDD.html
PAND	mmxreg,mmxrm	PENT,MMX	PAND mmxreg, mmx/mem	Logical AND	PAND.html
PAND	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PAND xmm, xmm/m128	Logical AND	PAND.html
PANDN	mmxreg,mmxrm	PENT,MMX	PANDN mmxreg, mmx/mem	Logical AND NOT	PANDN.html
PANDN	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PANDN xmm, xmm/m128	Logical AND NOT	PANDN.html
PAUSE	none	8086	PAUSE 	Spin Loop Hint	PAUSE.html
PAVEB	mmxreg,mmxrm	PENT,MMX,CYRIX	PAVEB mmxreg, mmx/mem	TODO: PENT,MMX,CYRIX	
PAVGUSB	mmxreg,mmxrm	PENT,3DNOW	PAVGUSB mmxreg, mmx/mem	TODO: PENT,3DNOW	
PCMPEQB	mmxreg,mmxrm	PENT,MMX	PCMPEQB mmxreg, mmx/mem	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PCMPEQB xmm, xmm/m128	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQD	mmxreg,mmxrm	PENT,MMX	PCMPEQD mmxreg, mmx/mem	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PCMPEQD xmm, xmm/m128	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQW	mmxreg,mmxrm	PENT,MMX	PCMPEQW mmxreg, mmx/mem	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPEQW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PCMPEQW xmm, xmm/m128	Compare Packed Data for Equal	PCMPEQB:PCMPEQW:PCMPEQD.html
PCMPGTB	mmxreg,mmxrm	PENT,MMX	PCMPGTB mmxreg, mmx/mem	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PCMPGTB xmm, xmm/m128	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTD	mmxreg,mmxrm	PENT,MMX	PCMPGTD mmxreg, mmx/mem	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PCMPGTD xmm, xmm/m128	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTW	mmxreg,mmxrm	PENT,MMX	PCMPGTW mmxreg, mmx/mem	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PCMPGTW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PCMPGTW xmm, xmm/m128	Compare Packed Signed Integers for Greater Than	PCMPGTB:PCMPGTW:PCMPGTD.html
PDISTIB	mmxreg,mem	PENT,MMX,CYRIX	PDISTIB mmxreg, mem	TODO: PENT,MMX,CYRIX	
PF2ID	mmxreg,mmxrm	PENT,3DNOW	PF2ID mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFACC	mmxreg,mmxrm	PENT,3DNOW	PFACC mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFADD	mmxreg,mmxrm	PENT,3DNOW	PFADD mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFCMPEQ	mmxreg,mmxrm	PENT,3DNOW	PFCMPEQ mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFCMPGE	mmxreg,mmxrm	PENT,3DNOW	PFCMPGE mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFCMPGT	mmxreg,mmxrm	PENT,3DNOW	PFCMPGT mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFMAX	mmxreg,mmxrm	PENT,3DNOW	PFMAX mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFMIN	mmxreg,mmxrm	PENT,3DNOW	PFMIN mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFMUL	mmxreg,mmxrm	PENT,3DNOW	PFMUL mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFRCP	mmxreg,mmxrm	PENT,3DNOW	PFRCP mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFRCPIT1	mmxreg,mmxrm	PENT,3DNOW	PFRCPIT1 mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFRCPIT2	mmxreg,mmxrm	PENT,3DNOW	PFRCPIT2 mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFRSQIT1	mmxreg,mmxrm	PENT,3DNOW	PFRSQIT1 mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFRSQRT	mmxreg,mmxrm	PENT,3DNOW	PFRSQRT mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFSUB	mmxreg,mmxrm	PENT,3DNOW	PFSUB mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFSUBR	mmxreg,mmxrm	PENT,3DNOW	PFSUBR mmxreg, mmx/mem	TODO: PENT,3DNOW	
PI2FD	mmxreg,mmxrm	PENT,3DNOW	PI2FD mmxreg, mmx/mem	TODO: PENT,3DNOW	
PMACHRIW	mmxreg,mem	PENT,MMX,CYRIX	PMACHRIW mmxreg, mem	TODO: PENT,MMX,CYRIX	
PMADDWD	mmxreg,mmxrm	PENT,MMX	PMADDWD mmxreg, mmx/mem	Multiply and Add Packed Integers	PMADDWD.html
PMADDWD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PMADDWD xmm, xmm/m128	Multiply and Add Packed Integers	PMADDWD.html
PMAGW	mmxreg,mmxrm	PENT,MMX,CYRIX	PMAGW mmxreg, mmx/mem	TODO: PENT,MMX,CYRIX	
PMULHRIW	mmxreg,mmxrm	PENT,MMX,CYRIX	PMULHRIW mmxreg, mmx/mem	TODO: PENT,MMX,CYRIX	
PMULHRWA	mmxreg,mmxrm	PENT,3DNOW	PMULHRWA mmxreg, mmx/mem	TODO: PENT,3DNOW	
PMULHRWC	mmxreg,mmxrm	PENT,MMX,CYRIX	PMULHRWC mmxreg, mmx/mem	TODO: PENT,MMX,CYRIX	
PMULHW	mmxreg,mmxrm	PENT,MMX	PMULHW mmxreg, mmx/mem	Multiply Packed Signed Integers and Store High Result	PMULHW.html
PMULHW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PMULHW xmm, xmm/m128	Multiply Packed Signed Integers and Store High Result	PMULHW.html
PMULLW	mmxreg,mmxrm	PENT,MMX	PMULLW mmxreg, mmx/mem	Multiply Packed Signed Integers and Store Low Result	PMULLW.html
PMULLW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PMULLW xmm, xmm/m128	Multiply Packed Signed Integers and Store Low Result	PMULLW.html
PMVGEZB	mmxreg,mem	PENT,MMX,CYRIX	PMVGEZB mmxreg, mem	TODO: PENT,MMX,CYRIX	
PMVLZB	mmxreg,mem	PENT,MMX,CYRIX	PMVLZB mmxreg, mem	TODO: PENT,MMX,CYRIX	
PMVNZB	mmxreg,mem	PENT,MMX,CYRIX	PMVNZB mmxreg, mem	TODO: PENT,MMX,CYRIX	
PMVZB	mmxreg,mem	PENT,MMX,CYRIX	PMVZB mmxreg, mem	TODO: PENT,MMX,CYRIX	
POP	reg16	8086	POP r16	Pop a Value from the Stack	POP.html
POP	reg32	386,NOLONG	POP r32	Pop a Value from the Stack	POP.html
POP	reg64	X64	POP r64	Pop a Value from the Stack	POP.html
POP	rm16	8086	POP r/m16	Pop a Value from the Stack	POP.html
POP	rm32	386,NOLONG	POP r/m32	Pop a Value from the Stack	POP.html
POP	rm64	X64	POP r/m64	Pop a Value from the Stack	POP.html
POP	reg_es	8086,NOLONG	POP ES	Pop a Value from the Stack	POP.html
POP	reg_cs	8086,UNDOC,ND	POP CS	Pop a Value from the Stack	POP.html
POP	reg_ss	8086,NOLONG	POP SS	Pop a Value from the Stack	POP.html
POP	reg_ds	8086,NOLONG	POP DS	Pop a Value from the Stack	POP.html
POP	reg_fs	386	POP FS	Pop a Value from the Stack	POP.html
POP	reg_gs	386	POP GS	Pop a Value from the Stack	POP.html
POPA	none	186,NOLONG	POPA 	Pop All General-Purpose Registers	POPA:POPAD.html
POPAD	none	386,NOLONG	POPAD 	Pop All General-Purpose Registers	POPA:POPAD.html
POPAW	none	186,NOLONG	POPAW 	TODO: 186,NOLONG	
POPF	none	8086	POPF 	Pop Stack into EFLAGS Register	POPF:POPFD:POPFQ.html
POPFD	none	386,NOLONG	POPFD 	Pop Stack into EFLAGS Register	POPF:POPFD:POPFQ.html
POPFQ	none	X64	POPFQ 	Pop Stack into EFLAGS Register	POPF:POPFD:POPFQ.html
POPFW	none	8086	POPFW 	TODO: 8086	
POR	mmxreg,mmxrm	PENT,MMX	POR mmxreg, mmx/mem	Bitwise Logical OR	POR.html
POR	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	POR xmm, xmm/m128	Bitwise Logical OR	POR.html
PREFETCH	mem	PENT,3DNOW	PREFETCH mem	TODO: PENT,3DNOW	
PREFETCHW	mem	PENT,3DNOW	PREFETCHW mem	Prefetch Data into Caches in Anticipation of a Write	PREFETCHW.html
PSLLD	mmxreg,mmxrm	PENT,MMX	PSLLD mmxreg, mmx/mem	Shift Packed Word Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLD	mmxreg,imm	PENT,MMX	PSLLD mmxreg, imm	Shift Packed Word Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSLLD xmm, xmm/m128	Shift Packed Word Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLD	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSLLD xmm, imm	Shift Packed Word Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLQ	mmxreg,mmxrm	PENT,MMX	PSLLQ mmxreg, mmx/mem	Shift Packed Doubleword Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLQ	mmxreg,imm	PENT,MMX	PSLLQ mmxreg, imm	Shift Packed Doubleword Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSLLQ xmm, xmm/m128	Shift Packed Doubleword Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLQ	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSLLQ xmm, imm	Shift Packed Doubleword Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLW	mmxreg,mmxrm	PENT,MMX	PSLLW mmxreg, mmx/mem	Shift Packed Data Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLW	mmxreg,imm	PENT,MMX	PSLLW mmxreg, imm	Shift Packed Data Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSLLW xmm, xmm/m128	Shift Packed Data Left Logical	PSLLW:PSLLD:PSLLQ.html
PSLLW	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSLLW xmm, imm	Shift Packed Data Left Logical	PSLLW:PSLLD:PSLLQ.html
PSRAD	mmxreg,mmxrm	PENT,MMX	PSRAD mmxreg, mmx/mem	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAD	mmxreg,imm	PENT,MMX	PSRAD mmxreg, imm	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSRAD xmm, xmm/m128	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAD	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSRAD xmm, imm	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAW	mmxreg,mmxrm	PENT,MMX	PSRAW mmxreg, mmx/mem	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAW	mmxreg,imm	PENT,MMX	PSRAW mmxreg, imm	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSRAW xmm, xmm/m128	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRAW	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSRAW xmm, imm	Shift Packed Data Right Arithmetic	PSRAW:PSRAD.html
PSRLD	mmxreg,mmxrm	PENT,MMX	PSRLD mmxreg, mmx/mem	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLD	mmxreg,imm	PENT,MMX	PSRLD mmxreg, imm	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSRLD xmm, xmm/m128	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLD	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSRLD xmm, imm	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLQ	mmxreg,mmxrm	PENT,MMX	PSRLQ mmxreg, mmx/mem	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLQ	mmxreg,imm	PENT,MMX	PSRLQ mmxreg, imm	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSRLQ xmm, xmm/m128	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLQ	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSRLQ xmm, imm	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLW	mmxreg,mmxrm	PENT,MMX	PSRLW mmxreg, mmx/mem	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLW	mmxreg,imm	PENT,MMX	PSRLW mmxreg, imm	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSRLW xmm, xmm/m128	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSRLW	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSRLW xmm, imm	Shift Packed Data Right Logical	PSRLW:PSRLD:PSRLQ.html
PSUBB	mmxreg,mmxrm	PENT,MMX	PSUBB mmxreg, mmx/mem	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSUBB xmm, xmm/m128	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBD	mmxreg,mmxrm	PENT,MMX	PSUBD mmxreg, mmx/mem	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSUBD xmm, xmm/m128	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBSB	mmxreg,mmxrm	PENT,MMX	PSUBSB mmxreg, mmx/mem	Subtract Packed Signed Integers with Signed Saturation	PSUBSB:PSUBSW.html
PSUBSB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSUBSB xmm, xmm/m128	Subtract Packed Signed Integers with Signed Saturation	PSUBSB:PSUBSW.html
PSUBSIW	mmxreg,mmxrm	PENT,MMX,CYRIX	PSUBSIW mmxreg, mmx/mem	TODO: PENT,MMX,CYRIX	
PSUBSW	mmxreg,mmxrm	PENT,MMX	PSUBSW mmxreg, mmx/mem	Subtract Packed Signed Integers with Signed Saturation	PSUBSB:PSUBSW.html
PSUBSW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSUBSW xmm, xmm/m128	Subtract Packed Signed Integers with Signed Saturation	PSUBSB:PSUBSW.html
PSUBUSB	mmxreg,mmxrm	PENT,MMX	PSUBUSB mmxreg, mmx/mem	Subtract Packed Unsigned Integers with Unsigned Saturation	PSUBUSB:PSUBUSW.html
PSUBUSB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSUBUSB xmm, xmm/m128	Subtract Packed Unsigned Integers with Unsigned Saturation	PSUBUSB:PSUBUSW.html
PSUBUSW	mmxreg,mmxrm	PENT,MMX	PSUBUSW mmxreg, mmx/mem	Subtract Packed Unsigned Integers with Unsigned Saturation	PSUBUSB:PSUBUSW.html
PSUBUSW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSUBUSW xmm, xmm/m128	Subtract Packed Unsigned Integers with Unsigned Saturation	PSUBUSB:PSUBUSW.html
PSUBW	mmxreg,mmxrm	PENT,MMX	PSUBW mmxreg, mmx/mem	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PSUBW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSUBW xmm, xmm/m128	Subtract Packed Integers	PSUBB:PSUBW:PSUBD.html
PUNPCKHBW	mmxreg,mmxrm	PENT,MMX	PUNPCKHBW mmxreg, mmx/mem	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHBW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PUNPCKHBW xmm, xmm/m128	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHDQ	mmxreg,mmxrm	PENT,MMX	PUNPCKHDQ mmxreg, mmx/mem	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHDQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PUNPCKHDQ xmm, xmm/m128	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHWD	mmxreg,mmxrm	PENT,MMX	PUNPCKHWD mmxreg, mmx/mem	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKHWD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PUNPCKHWD xmm, xmm/m128	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKLBW	mmxreg,mmxrm	PENT,MMX	PUNPCKLBW mmxreg, mmx/mem	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLBW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PUNPCKLBW xmm, xmm/m128	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLDQ	mmxreg,mmxrm	PENT,MMX	PUNPCKLDQ mmxreg, mmx/mem	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLDQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PUNPCKLDQ xmm, xmm/m128	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLWD	mmxreg,mmxrm	PENT,MMX	PUNPCKLWD mmxreg, mmx/mem	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUNPCKLWD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PUNPCKLWD xmm, xmm/m128	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
PUSH	reg16	8086	PUSH r16	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	reg32	386,NOLONG	PUSH r32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	reg64	X64	PUSH r64	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	rm16	8086	PUSH r/m16	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	rm32	386,NOLONG	PUSH r/m32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	rm64	X64	PUSH r/m64	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	reg_es	8086,NOLONG	PUSH ES	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	reg_cs	8086,NOLONG	PUSH CS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	reg_ss	8086,NOLONG	PUSH SS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	reg_ds	8086,NOLONG	PUSH DS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	reg_fs	386	PUSH FS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	reg_gs	386	PUSH GS	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	imm8	186	PUSH imm8	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	imm16	186,AR0,SIZE	PUSH imm16	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	imm32	386,NOLONG,AR0,SIZE	PUSH imm32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	imm32	386,NOLONG,SD	PUSH imm32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	imm64	X64,AR0,SIZE	PUSH imm64	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSH	imm32	X64,AR0,SIZE	PUSH imm32	Push Word, Doubleword or Quadword Onto the Stack	PUSH.html
PUSHA	none	186,NOLONG	PUSHA 	Push All General-Purpose Registers	PUSHA:PUSHAD.html
PUSHAD	none	386,NOLONG	PUSHAD 	Push All General-Purpose Registers	PUSHA:PUSHAD.html
PUSHAW	none	186,NOLONG	PUSHAW 	TODO: 186,NOLONG	
PUSHF	none	8086	PUSHF 	Push EFLAGS Register onto the Stack	PUSHF:PUSHFD.html
PUSHFD	none	386,NOLONG	PUSHFD 	Push EFLAGS Register onto the Stack	PUSHF:PUSHFD.html
PUSHFQ	none	X64	PUSHFQ 	Push RFLAGS Register onto the Stack	PUSHF:PUSHFD.html
PUSHFW	none	8086	PUSHFW 	TODO: 8086	
PXOR	mmxreg,mmxrm	PENT,MMX	PXOR mmxreg, mmx/mem	Logical Exclusive OR	PXOR.html
PXOR	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PXOR xmm, xmm/m128	Logical Exclusive OR	PXOR.html
RCL	rm8,unity	8086	RCL r/m8, unity	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm8,reg_cl	8086	RCL r/m8, CL	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm8,imm8	186	RCL r/m8, imm8	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm16,unity	8086	RCL r/m16, unity	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm16,reg_cl	8086	RCL r/m16, CL	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm16,imm8	186	RCL r/m16, imm8	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm32,unity	386	RCL r/m32, unity	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm32,reg_cl	386	RCL r/m32, CL	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm32,imm8	386	RCL r/m32, imm8	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm64,unity	X64	RCL r/m64, unity	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm64,reg_cl	X64	RCL r/m64, CL	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCL	rm64,imm8	X64	RCL r/m64, imm8	Rotate Carry Left	RCL:RCR:ROL:ROR.html
RCR	rm8,unity	8086	RCR r/m8, unity	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm8,reg_cl	8086	RCR r/m8, CL	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm8,imm8	186	RCR r/m8, imm8	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm16,unity	8086	RCR r/m16, unity	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm16,reg_cl	8086	RCR r/m16, CL	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm16,imm8	186	RCR r/m16, imm8	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm32,unity	386	RCR r/m32, unity	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm32,reg_cl	386	RCR r/m32, CL	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm32,imm8	386	RCR r/m32, imm8	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm64,unity	X64	RCR r/m64, unity	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm64,reg_cl	X64	RCR r/m64, CL	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RCR	rm64,imm8	X64	RCR r/m64, imm8	Rotate Carry Right	RCL:RCR:ROL:ROR.html
RDSHR	rm32	P6,CYRIXM	RDSHR r/m32	TODO: P6,CYRIXM	
RDMSR	none	PENT,PRIV	RDMSR 	Read from Model Specific Register	RDMSR.html
RDPMC	none	P6	RDPMC 	Read Performance-Monitoring Counters	RDPMC.html
RDTSC	none	PENT	RDTSC 	Read Time-Stamp Counter	RDTSC.html
RDTSCP	none	X86_64	RDTSCP 	Read Time-Stamp Counter and Processor ID	RDTSCP.html
RET	none	8086,BND	RET 	Return from Procedure	RET.html
RET	imm	8086,SW,BND	RET imm	Return from Procedure	RET.html
RETF	none	8086	RETF 	TODO: 8086,SW	
RETF	imm	8086,SW	RETF imm	TODO: 8086,SW	
RETN	none	8086,BND	RETN 	TODO: 8086,BND,SW	
RETN	imm	8086,SW,BND	RETN imm	TODO: 8086,BND,SW	
ROL	rm8,unity	8086	ROL r/m8, unity	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm8,reg_cl	8086	ROL r/m8, CL	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm8,imm8	186	ROL r/m8, imm8	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm16,unity	8086	ROL r/m16, unity	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm16,reg_cl	8086	ROL r/m16, CL	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm16,imm8	186	ROL r/m16, imm8	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm32,unity	386	ROL r/m32, unity	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm32,reg_cl	386	ROL r/m32, CL	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm32,imm8	386	ROL r/m32, imm8	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm64,unity	X64	ROL r/m64, unity	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm64,reg_cl	X64	ROL r/m64, CL	Rotate Left	RCL:RCR:ROL:ROR.html
ROL	rm64,imm8	X64	ROL r/m64, imm8	Rotate Left	RCL:RCR:ROL:ROR.html
ROR	rm8,unity	8086	ROR r/m8, unity	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm8,reg_cl	8086	ROR r/m8, CL	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm8,imm8	186	ROR r/m8, imm8	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm16,unity	8086	ROR r/m16, unity	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm16,reg_cl	8086	ROR r/m16, CL	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm16,imm8	186	ROR r/m16, imm8	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm32,unity	386	ROR r/m32, unity	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm32,reg_cl	386	ROR r/m32, CL	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm32,imm8	386	ROR r/m32, imm8	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm64,unity	X64	ROR r/m64, unity	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm64,reg_cl	X64	ROR r/m64, CL	Rotate Right	RCL:RCR:ROL:ROR.html
ROR	rm64,imm8	X64	ROR r/m64, imm8	Rotate Right	RCL:RCR:ROL:ROR.html
RDM	none	P6,CYRIX,ND	RDM 	TODO: P6,CYRIX,ND	
RSDC	reg_sreg,mem80	486,CYRIXM	RSDC reg_sreg, mem80	TODO: 486,CYRIXM	
RSLDT	mem80	486,CYRIXM	RSLDT mem80	TODO: 486,CYRIXM	
RSM	none	PENT	RSM 	Resume from System Management Mode	RSM.html
RSTS	mem80	486,CYRIXM	RSTS mem80	TODO: 486,CYRIXM	
SAHF	none	8086	SAHF 	Store AH into Flags	SAHF.html
SAL	rm8,unity	8086,ND	SAL r/m8, unity	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm8,reg_cl	8086,ND	SAL r/m8, CL	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm8,imm8	186,ND	SAL r/m8, imm8	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm16,unity	8086,ND	SAL r/m16, unity	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm16,reg_cl	8086,ND	SAL r/m16, CL	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm16,imm8	186,ND	SAL r/m16, imm8	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm32,unity	386,ND	SAL r/m32, unity	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm32,reg_cl	386,ND	SAL r/m32, CL	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm32,imm8	386,ND	SAL r/m32, imm8	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm64,unity	X64,ND	SAL r/m64, unity	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm64,reg_cl	X64,ND	SAL r/m64, CL	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SAL	rm64,imm8	X64,ND	SAL r/m64, imm8	Shift Arithmetic Left	SAL:SAR:SHL:SHR.html
SALC	none	8086,UNDOC	SALC 	TODO: 8086,UNDOC	
SAR	rm8,unity	8086	SAR r/m8, unity	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm8,reg_cl	8086	SAR r/m8, CL	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm8,imm8	186	SAR r/m8, imm8	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm16,unity	8086	SAR r/m16, unity	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm16,reg_cl	8086	SAR r/m16, CL	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm16,imm8	186	SAR r/m16, imm8	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm32,unity	386	SAR r/m32, unity	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm32,reg_cl	386	SAR r/m32, CL	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm32,imm8	386	SAR r/m32, imm8	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm64,unity	X64	SAR r/m64, unity	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm64,reg_cl	X64	SAR r/m64, CL	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SAR	rm64,imm8	X64	SAR r/m64, imm8	Shift Arithmetic Right	SAL:SAR:SHL:SHR.html
SBB	mem,reg8	8086,LOCK	SBB mem, r8	Integer Subtraction with Borrow	SBB.html
SBB	reg8,reg8	8086	SBB r8, r8	Integer Subtraction with Borrow	SBB.html
SBB	mem,reg16	8086,LOCK	SBB mem, r16	Integer Subtraction with Borrow	SBB.html
SBB	reg16,reg16	8086	SBB r16, r16	Integer Subtraction with Borrow	SBB.html
SBB	mem,reg32	386,LOCK	SBB mem, r32	Integer Subtraction with Borrow	SBB.html
SBB	reg32,reg32	386	SBB r32, r32	Integer Subtraction with Borrow	SBB.html
SBB	mem,reg64	X64,LOCK	SBB mem, r64	Integer Subtraction with Borrow	SBB.html
SBB	reg64,reg64	X64	SBB r64, r64	Integer Subtraction with Borrow	SBB.html
SBB	reg8,mem	8086	SBB r8, mem	Integer Subtraction with Borrow	SBB.html
SBB	reg8,reg8	8086	SBB r8, r8	Integer Subtraction with Borrow	SBB.html
SBB	reg16,mem	8086	SBB r16, mem	Integer Subtraction with Borrow	SBB.html
SBB	reg16,reg16	8086	SBB r16, r16	Integer Subtraction with Borrow	SBB.html
SBB	reg32,mem	386	SBB r32, mem	Integer Subtraction with Borrow	SBB.html
SBB	reg32,reg32	386	SBB r32, r32	Integer Subtraction with Borrow	SBB.html
SBB	reg64,mem	X64	SBB r64, mem	Integer Subtraction with Borrow	SBB.html
SBB	reg64,reg64	X64	SBB r64, r64	Integer Subtraction with Borrow	SBB.html
SBB	rm16,imm8	8086,LOCK	SBB r/m16, imm8	Integer Subtraction with Borrow	SBB.html
SBB	rm32,imm8	386,LOCK	SBB r/m32, imm8	Integer Subtraction with Borrow	SBB.html
SBB	rm64,imm8	X64,LOCK	SBB r/m64, imm8	Integer Subtraction with Borrow	SBB.html
SBB	reg_al,imm	8086	SBB AL, imm	Integer Subtraction with Borrow	SBB.html
SBB	reg_ax,imm	8086	SBB AX, imm	Integer Subtraction with Borrow	SBB.html
SBB	reg_eax,imm	386	SBB EAX, imm	Integer Subtraction with Borrow	SBB.html
SBB	reg_rax,imm	X64	SBB RAX, imm	Integer Subtraction with Borrow	SBB.html
SBB	rm8,imm	8086,LOCK	SBB r/m8, imm	Integer Subtraction with Borrow	SBB.html
SBB	rm16,imm	8086,LOCK	SBB r/m16, imm	Integer Subtraction with Borrow	SBB.html
SBB	rm32,imm	386,LOCK	SBB r/m32, imm	Integer Subtraction with Borrow	SBB.html
SBB	rm64,imm	X64,LOCK	SBB r/m64, imm	Integer Subtraction with Borrow	SBB.html
SBB	mem,imm8	8086,LOCK	SBB mem, imm8	Integer Subtraction with Borrow	SBB.html
SBB	mem,imm16	8086,LOCK	SBB mem, imm16	Integer Subtraction with Borrow	SBB.html
SBB	mem,imm32	386,LOCK	SBB mem, imm32	Integer Subtraction with Borrow	SBB.html
SBB	rm8,imm	8086,LOCK,ND,NOLONG	SBB r/m8, imm	Integer Subtraction with Borrow	SBB.html
SCASB	none	8086	SCASB 	Scan String	SCAS:SCASB:SCASW:SCASD.html
SCASD	none	386	SCASD 	Scan String	SCAS:SCASB:SCASW:SCASD.html
SCASQ	none	X64	SCASQ 	TODO: X64	
SCASW	none	8086	SCASW 	Scan String	SCAS:SCASB:SCASW:SCASD.html
SFENCE	none	X64,AMD	SFENCE 	Store Fence	SFENCE.html
SFENCE	none	KATMAI	SFENCE 	Store Fence	SFENCE.html
SGDT	mem	286	SGDT mem	Store Global Descriptor Table Register	SGDT.html
SHL	rm8,unity	8086	SHL r/m8, unity	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm8,reg_cl	8086	SHL r/m8, CL	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm8,imm8	186	SHL r/m8, imm8	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm16,unity	8086	SHL r/m16, unity	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm16,reg_cl	8086	SHL r/m16, CL	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm16,imm8	186	SHL r/m16, imm8	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm32,unity	386	SHL r/m32, unity	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm32,reg_cl	386	SHL r/m32, CL	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm32,imm8	386	SHL r/m32, imm8	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm64,unity	X64	SHL r/m64, unity	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm64,reg_cl	X64	SHL r/m64, CL	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHL	rm64,imm8	X64	SHL r/m64, imm8	Shift Logical Left	SAL:SAR:SHL:SHR.html
SHLD	mem,reg16,imm	386	SHLD mem, r16, imm	Double Precision Shift Left	SHLD.html
SHLD	reg16,reg16,imm	386	SHLD r16, r16, imm	Double Precision Shift Left	SHLD.html
SHLD	mem,reg32,imm	386	SHLD mem, r32, imm	Double Precision Shift Left	SHLD.html
SHLD	reg32,reg32,imm	386	SHLD r32, r32, imm	Double Precision Shift Left	SHLD.html
SHLD	mem,reg64,imm	X64	SHLD mem, r64, imm	Double Precision Shift Left	SHLD.html
SHLD	reg64,reg64,imm	X64	SHLD r64, r64, imm	Double Precision Shift Left	SHLD.html
SHLD	mem,reg16,reg_cl	386	SHLD mem, r16, CL	Double Precision Shift Left	SHLD.html
SHLD	reg16,reg16,reg_cl	386	SHLD r16, r16, CL	Double Precision Shift Left	SHLD.html
SHLD	mem,reg32,reg_cl	386	SHLD mem, r32, CL	Double Precision Shift Left	SHLD.html
SHLD	reg32,reg32,reg_cl	386	SHLD r32, r32, CL	Double Precision Shift Left	SHLD.html
SHLD	mem,reg64,reg_cl	X64	SHLD mem, r64, CL	Double Precision Shift Left	SHLD.html
SHLD	reg64,reg64,reg_cl	X64	SHLD r64, r64, CL	Double Precision Shift Left	SHLD.html
SHR	rm8,unity	8086	SHR r/m8, unity	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm8,reg_cl	8086	SHR r/m8, CL	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm8,imm8	186	SHR r/m8, imm8	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm16,unity	8086	SHR r/m16, unity	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm16,reg_cl	8086	SHR r/m16, CL	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm16,imm8	186	SHR r/m16, imm8	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm32,unity	386	SHR r/m32, unity	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm32,reg_cl	386	SHR r/m32, CL	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm32,imm8	386	SHR r/m32, imm8	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm64,unity	X64	SHR r/m64, unity	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm64,reg_cl	X64	SHR r/m64, CL	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHR	rm64,imm8	X64	SHR r/m64, imm8	Shift Logical Right	SAL:SAR:SHL:SHR.html
SHRD	mem,reg16,imm	386	SHRD mem, r16, imm	Double Precision Shift Right	SHRD.html
SHRD	reg16,reg16,imm	386	SHRD r16, r16, imm	Double Precision Shift Right	SHRD.html
SHRD	mem,reg32,imm	386	SHRD mem, r32, imm	Double Precision Shift Right	SHRD.html
SHRD	reg32,reg32,imm	386	SHRD r32, r32, imm	Double Precision Shift Right	SHRD.html
SHRD	mem,reg64,imm	X64	SHRD mem, r64, imm	Double Precision Shift Right	SHRD.html
SHRD	reg64,reg64,imm	X64	SHRD r64, r64, imm	Double Precision Shift Right	SHRD.html
SHRD	mem,reg16,reg_cl	386	SHRD mem, r16, CL	Double Precision Shift Right	SHRD.html
SHRD	reg16,reg16,reg_cl	386	SHRD r16, r16, CL	Double Precision Shift Right	SHRD.html
SHRD	mem,reg32,reg_cl	386	SHRD mem, r32, CL	Double Precision Shift Right	SHRD.html
SHRD	reg32,reg32,reg_cl	386	SHRD r32, r32, CL	Double Precision Shift Right	SHRD.html
SHRD	mem,reg64,reg_cl	X64	SHRD mem, r64, CL	Double Precision Shift Right	SHRD.html
SHRD	reg64,reg64,reg_cl	X64	SHRD r64, r64, CL	Double Precision Shift Right	SHRD.html
SIDT	mem	286	SIDT mem	Store Interrupt Descriptor Table Register	SIDT.html
SLDT	mem	286	SLDT mem	Store Local Descriptor Table Register	SLDT.html
SLDT	mem16	286	SLDT mem16	Store Local Descriptor Table Register	SLDT.html
SLDT	reg16	286	SLDT r16	Store Local Descriptor Table Register	SLDT.html
SLDT	reg32	386	SLDT r32	Store Local Descriptor Table Register	SLDT.html
SLDT	reg64	X64,ND	SLDT r64	Store Local Descriptor Table Register	SLDT.html
SLDT	reg64	X64	SLDT r64	Store Local Descriptor Table Register	SLDT.html
SKINIT	none	X64	SKINIT 	TODO: X64	
SMI	none	386,UNDOC	SMI 	TODO: 386,UNDOC	
SMINT	none	P6,CYRIX,ND	SMINT 	TODO: P6,CYRIX,ND	
SMINTOLD	none	486,CYRIX,ND	SMINTOLD 	TODO: 486,CYRIX,ND	
SMSW	mem	286	SMSW mem	Store Machine Status Word	SMSW.html
SMSW	mem16	286	SMSW mem16	Store Machine Status Word	SMSW.html
SMSW	reg16	286	SMSW r16	Store Machine Status Word	SMSW.html
SMSW	reg32	386	SMSW r32	Store Machine Status Word	SMSW.html
SMSW	reg64	X64	SMSW r64	Store Machine Status Word	SMSW.html
STC	none	8086	STC 	Set Carry Flag	STC.html
STD	none	8086	STD 	Set Direction Flag	STD.html
STI	none	8086	STI 	Set Interrupt Flag	STI.html
STOSB	none	8086	STOSB 	Store String	STOS:STOSB:STOSW:STOSD:STOSQ.html
STOSD	none	386	STOSD 	Store String	STOS:STOSB:STOSW:STOSD:STOSQ.html
STOSQ	none	X64	STOSQ 	Store String	STOS:STOSB:STOSW:STOSD:STOSQ.html
STOSW	none	8086	STOSW 	Store String	STOS:STOSB:STOSW:STOSD:STOSQ.html
STR	mem	286,PROT	STR mem	Store Task Register	STR.html
STR	mem16	286,PROT	STR mem16	Store Task Register	STR.html
STR	reg16	286,PROT	STR r16	Store Task Register	STR.html
STR	reg32	386,PROT	STR r32	Store Task Register	STR.html
STR	reg64	X64	STR r64	Store Task Register	STR.html
SUB	mem,reg8	8086,LOCK	SUB mem, r8	Subtract	SUB.html
SUB	reg8,reg8	8086	SUB r8, r8	Subtract	SUB.html
SUB	mem,reg16	8086,LOCK	SUB mem, r16	Subtract	SUB.html
SUB	reg16,reg16	8086	SUB r16, r16	Subtract	SUB.html
SUB	mem,reg32	386,LOCK	SUB mem, r32	Subtract	SUB.html
SUB	reg32,reg32	386	SUB r32, r32	Subtract	SUB.html
SUB	mem,reg64	X64,LOCK	SUB mem, r64	Subtract	SUB.html
SUB	reg64,reg64	X64	SUB r64, r64	Subtract	SUB.html
SUB	reg8,mem	8086	SUB r8, mem	Subtract	SUB.html
SUB	reg8,reg8	8086	SUB r8, r8	Subtract	SUB.html
SUB	reg16,mem	8086	SUB r16, mem	Subtract	SUB.html
SUB	reg16,reg16	8086	SUB r16, r16	Subtract	SUB.html
SUB	reg32,mem	386	SUB r32, mem	Subtract	SUB.html
SUB	reg32,reg32	386	SUB r32, r32	Subtract	SUB.html
SUB	reg64,mem	X64	SUB r64, mem	Subtract	SUB.html
SUB	reg64,reg64	X64	SUB r64, r64	Subtract	SUB.html
SUB	rm16,imm8	8086,LOCK	SUB r/m16, imm8	Subtract	SUB.html
SUB	rm32,imm8	386,LOCK	SUB r/m32, imm8	Subtract	SUB.html
SUB	rm64,imm8	X64,LOCK	SUB r/m64, imm8	Subtract	SUB.html
SUB	reg_al,imm	8086	SUB AL, imm	Subtract	SUB.html
SUB	reg_ax,imm	8086	SUB AX, imm	Subtract	SUB.html
SUB	reg_eax,imm	386	SUB EAX, imm	Subtract	SUB.html
SUB	reg_rax,imm	X64	SUB RAX, imm	Subtract	SUB.html
SUB	rm8,imm	8086,LOCK	SUB r/m8, imm	Subtract	SUB.html
SUB	rm16,imm	8086,LOCK	SUB r/m16, imm	Subtract	SUB.html
SUB	rm32,imm	386,LOCK	SUB r/m32, imm	Subtract	SUB.html
SUB	rm64,imm	X64,LOCK	SUB r/m64, imm	Subtract	SUB.html
SUB	mem,imm8	8086,LOCK	SUB mem, imm8	Subtract	SUB.html
SUB	mem,imm16	8086,LOCK	SUB mem, imm16	Subtract	SUB.html
SUB	mem,imm32	386,LOCK	SUB mem, imm32	Subtract	SUB.html
SUB	rm8,imm	8086,LOCK,ND,NOLONG	SUB r/m8, imm	Subtract	SUB.html
SVDC	mem80,reg_sreg	486,CYRIXM	SVDC mem80, reg_sreg	TODO: 486,CYRIXM	
SVLDT	mem80	486,CYRIXM,ND	SVLDT mem80	TODO: 486,CYRIXM,ND	
SVTS	mem80	486,CYRIXM	SVTS mem80	TODO: 486,CYRIXM	
SWAPGS	none	X64	SWAPGS 	Swap GS Base Register	SWAPGS.html
SYSCALL	none	P6,AMD	SYSCALL 	Fast System Call	SYSCALL.html
SYSENTER	none	P6	SYSENTER 	Fast System Call	SYSENTER.html
SYSEXIT	none	P6,PRIV	SYSEXIT 	Fast Return from Fast System Call	SYSEXIT.html
SYSRET	none	P6,PRIV,AMD	SYSRET 	Return From Fast System Call	SYSRET.html
TEST	mem,reg8	8086	TEST mem, r8	Logical Compare	TEST.html
TEST	reg8,reg8	8086	TEST r8, r8	Logical Compare	TEST.html
TEST	mem,reg16	8086	TEST mem, r16	Logical Compare	TEST.html
TEST	reg16,reg16	8086	TEST r16, r16	Logical Compare	TEST.html
TEST	mem,reg32	386	TEST mem, r32	Logical Compare	TEST.html
TEST	reg32,reg32	386	TEST r32, r32	Logical Compare	TEST.html
TEST	mem,reg64	X64	TEST mem, r64	Logical Compare	TEST.html
TEST	reg64,reg64	X64	TEST r64, r64	Logical Compare	TEST.html
TEST	reg8,mem	8086	TEST r8, mem	Logical Compare	TEST.html
TEST	reg16,mem	8086	TEST r16, mem	Logical Compare	TEST.html
TEST	reg32,mem	386	TEST r32, mem	Logical Compare	TEST.html
TEST	reg64,mem	X64	TEST r64, mem	Logical Compare	TEST.html
TEST	reg_al,imm	8086	TEST AL, imm	Logical Compare	TEST.html
TEST	reg_ax,imm	8086	TEST AX, imm	Logical Compare	TEST.html
TEST	reg_eax,imm	386	TEST EAX, imm	Logical Compare	TEST.html
TEST	reg_rax,imm	X64	TEST RAX, imm	Logical Compare	TEST.html
TEST	rm8,imm	8086	TEST r/m8, imm	Logical Compare	TEST.html
TEST	rm16,imm	8086	TEST r/m16, imm	Logical Compare	TEST.html
TEST	rm32,imm	386	TEST r/m32, imm	Logical Compare	TEST.html
TEST	rm64,imm	X64	TEST r/m64, imm	Logical Compare	TEST.html
TEST	mem,imm8	8086	TEST mem, imm8	Logical Compare	TEST.html
TEST	mem,imm16	8086	TEST mem, imm16	Logical Compare	TEST.html
TEST	mem,imm32	386	TEST mem, imm32	Logical Compare	TEST.html
UMOV	mem,reg8	386,UNDOC,ND	UMOV mem, r8	TODO: 386,UNDOC,ND	
UMOV	reg8,reg8	386,UNDOC,ND	UMOV r8, r8	TODO: 386,UNDOC,ND	
UMOV	mem,reg16	386,UNDOC,ND	UMOV mem, r16	TODO: 386,UNDOC,ND	
UMOV	reg16,reg16	386,UNDOC,ND	UMOV r16, r16	TODO: 386,UNDOC,ND	
UMOV	mem,reg32	386,UNDOC,ND	UMOV mem, r32	TODO: 386,UNDOC,ND	
UMOV	reg32,reg32	386,UNDOC,ND	UMOV r32, r32	TODO: 386,UNDOC,ND	
UMOV	reg8,mem	386,UNDOC,ND	UMOV r8, mem	TODO: 386,UNDOC,ND	
UMOV	reg8,reg8	386,UNDOC,ND	UMOV r8, r8	TODO: 386,UNDOC,ND	
UMOV	reg16,mem	386,UNDOC,ND	UMOV r16, mem	TODO: 386,UNDOC,ND	
UMOV	reg16,reg16	386,UNDOC,ND	UMOV r16, r16	TODO: 386,UNDOC,ND	
UMOV	reg32,mem	386,UNDOC,ND	UMOV r32, mem	TODO: 386,UNDOC,ND	
UMOV	reg32,reg32	386,UNDOC,ND	UMOV r32, r32	TODO: 386,UNDOC,ND	
VERR	mem	286,PROT	VERR mem	Verify a Segment for Reading or Writing	VERR:VERW.html
VERR	mem16	286,PROT	VERR mem16	Verify a Segment for Reading or Writing	VERR:VERW.html
VERR	reg16	286,PROT	VERR r16	Verify a Segment for Reading or Writing	VERR:VERW.html
VERW	mem	286,PROT	VERW mem	Verify a Segment for Reading or Writing	VERR:VERW.html
VERW	mem16	286,PROT	VERW mem16	Verify a Segment for Reading or Writing	VERR:VERW.html
VERW	reg16	286,PROT	VERW r16	Verify a Segment for Reading or Writing	VERR:VERW.html
FWAIT	none	8086	FWAIT 	Wait	WAIT:FWAIT.html
WBINVD	none	486,PRIV	WBINVD 	Write Back and Invalidate Cache	WBINVD.html
WRSHR	rm32	P6,CYRIXM	WRSHR r/m32	TODO: P6,CYRIXM	
WRMSR	none	PENT,PRIV	WRMSR 	Write to Model Specific Register	WRMSR.html
XADD	mem,reg8	486,LOCK	XADD mem, r8	Exchange and Add	XADD.html
XADD	reg8,reg8	486	XADD r8, r8	Exchange and Add	XADD.html
XADD	mem,reg16	486,LOCK	XADD mem, r16	Exchange and Add	XADD.html
XADD	reg16,reg16	486	XADD r16, r16	Exchange and Add	XADD.html
XADD	mem,reg32	486,LOCK	XADD mem, r32	Exchange and Add	XADD.html
XADD	reg32,reg32	486	XADD r32, r32	Exchange and Add	XADD.html
XADD	mem,reg64	X64,LOCK	XADD mem, r64	Exchange and Add	XADD.html
XADD	reg64,reg64	X64	XADD r64, r64	Exchange and Add	XADD.html
XBTS	reg16,mem	386,SW,UNDOC,ND	XBTS r16, mem	TODO: 386,SW,UNDOC,ND,SD	
XBTS	reg16,reg16	386,UNDOC,ND	XBTS r16, r16	TODO: 386,SW,UNDOC,ND,SD	
XBTS	reg32,mem	386,SD,UNDOC,ND	XBTS r32, mem	TODO: 386,SW,UNDOC,ND,SD	
XBTS	reg32,reg32	386,UNDOC,ND	XBTS r32, r32	TODO: 386,SW,UNDOC,ND,SD	
XCHG	reg_ax,reg16	8086	XCHG AX, r16	Exchange Register/Memory with Register	XCHG.html
XCHG	reg_eax,reg32	386	XCHG EAX, reg32	Exchange Register/Memory with Register	XCHG.html
XCHG	reg_rax,reg64	X64	XCHG RAX, r64	Exchange Register/Memory with Register	XCHG.html
XCHG	reg16,reg_ax	8086	XCHG r16, AX	Exchange Register/Memory with Register	XCHG.html
XCHG	reg32,reg_eax	386	XCHG reg32, EAX	Exchange Register/Memory with Register	XCHG.html
XCHG	reg64,reg_rax	X64	XCHG r64, RAX	Exchange Register/Memory with Register	XCHG.html
XCHG	reg_eax,reg_eax	386,NOLONG	XCHG EAX, EAX	Exchange Register/Memory with Register	XCHG.html
XCHG	reg8,mem	8086,LOCK	XCHG r8, mem	Exchange Register/Memory with Register	XCHG.html
XCHG	reg8,reg8	8086	XCHG r8, r8	Exchange Register/Memory with Register	XCHG.html
XCHG	reg16,mem	8086,LOCK	XCHG r16, mem	Exchange Register/Memory with Register	XCHG.html
XCHG	reg16,reg16	8086	XCHG r16, r16	Exchange Register/Memory with Register	XCHG.html
XCHG	reg32,mem	386,LOCK	XCHG r32, mem	Exchange Register/Memory with Register	XCHG.html
XCHG	reg32,reg32	386	XCHG r32, r32	Exchange Register/Memory with Register	XCHG.html
XCHG	reg64,mem	X64,LOCK	XCHG r64, mem	Exchange Register/Memory with Register	XCHG.html
XCHG	reg64,reg64	X64	XCHG r64, r64	Exchange Register/Memory with Register	XCHG.html
XCHG	mem,reg8	8086,LOCK	XCHG mem, r8	Exchange Register/Memory with Register	XCHG.html
XCHG	reg8,reg8	8086	XCHG r8, r8	Exchange Register/Memory with Register	XCHG.html
XCHG	mem,reg16	8086,LOCK	XCHG mem, r16	Exchange Register/Memory with Register	XCHG.html
XCHG	reg16,reg16	8086	XCHG r16, r16	Exchange Register/Memory with Register	XCHG.html
XCHG	mem,reg32	386,LOCK	XCHG mem, r32	Exchange Register/Memory with Register	XCHG.html
XCHG	reg32,reg32	386	XCHG r32, r32	Exchange Register/Memory with Register	XCHG.html
XCHG	mem,reg64	X64,LOCK	XCHG mem, r64	Exchange Register/Memory with Register	XCHG.html
XCHG	reg64,reg64	X64	XCHG r64, r64	Exchange Register/Memory with Register	XCHG.html
XLATB	none	8086	XLATB 	Table Look-up Translation	XLAT:XLATB.html
XLAT	none	8086	XLAT 	Table Look-up Translation	XLAT:XLATB.html
XOR	mem,reg8	8086,LOCK	XOR mem, r8	Logical Exclusive OR	XOR.html
XOR	reg8,reg8	8086	XOR r8, r8	Logical Exclusive OR	XOR.html
XOR	mem,reg16	8086,LOCK	XOR mem, r16	Logical Exclusive OR	XOR.html
XOR	reg16,reg16	8086	XOR r16, r16	Logical Exclusive OR	XOR.html
XOR	mem,reg32	386,LOCK	XOR mem, r32	Logical Exclusive OR	XOR.html
XOR	reg32,reg32	386	XOR r32, r32	Logical Exclusive OR	XOR.html
XOR	mem,reg64	X64,LOCK	XOR mem, r64	Logical Exclusive OR	XOR.html
XOR	reg64,reg64	X64	XOR r64, r64	Logical Exclusive OR	XOR.html
XOR	reg8,mem	8086	XOR r8, mem	Logical Exclusive OR	XOR.html
XOR	reg8,reg8	8086	XOR r8, r8	Logical Exclusive OR	XOR.html
XOR	reg16,mem	8086	XOR r16, mem	Logical Exclusive OR	XOR.html
XOR	reg16,reg16	8086	XOR r16, r16	Logical Exclusive OR	XOR.html
XOR	reg32,mem	386	XOR r32, mem	Logical Exclusive OR	XOR.html
XOR	reg32,reg32	386	XOR r32, r32	Logical Exclusive OR	XOR.html
XOR	reg64,mem	X64	XOR r64, mem	Logical Exclusive OR	XOR.html
XOR	reg64,reg64	X64	XOR r64, r64	Logical Exclusive OR	XOR.html
XOR	rm16,imm8	8086,LOCK	XOR r/m16, imm8	Logical Exclusive OR	XOR.html
XOR	rm32,imm8	386,LOCK	XOR r/m32, imm8	Logical Exclusive OR	XOR.html
XOR	rm64,imm8	X64,LOCK	XOR r/m64, imm8	Logical Exclusive OR	XOR.html
XOR	reg_al,imm	8086	XOR AL, imm	Logical Exclusive OR	XOR.html
XOR	reg_ax,imm	8086	XOR AX, imm	Logical Exclusive OR	XOR.html
XOR	reg_eax,imm	386	XOR EAX, imm	Logical Exclusive OR	XOR.html
XOR	reg_rax,imm	X64	XOR RAX, imm	Logical Exclusive OR	XOR.html
XOR	rm8,imm	8086,LOCK	XOR r/m8, imm	Logical Exclusive OR	XOR.html
XOR	rm16,imm	8086,LOCK	XOR r/m16, imm	Logical Exclusive OR	XOR.html
XOR	rm32,imm	386,LOCK	XOR r/m32, imm	Logical Exclusive OR	XOR.html
XOR	rm64,imm	X64,LOCK	XOR r/m64, imm	Logical Exclusive OR	XOR.html
XOR	mem,imm8	8086,LOCK	XOR mem, imm8	Logical Exclusive OR	XOR.html
XOR	mem,imm16	8086,LOCK	XOR mem, imm16	Logical Exclusive OR	XOR.html
XOR	mem,imm32	386,LOCK	XOR mem, imm32	Logical Exclusive OR	XOR.html
XOR	rm8,imm	8086,LOCK,ND,NOLONG	XOR r/m8, imm	Logical Exclusive OR	XOR.html
;
CMOVA	reg16,rm16	P6	CMOVA r16, r/m16	Move if above (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVAE	reg16,rm16	P6	CMOVAE r16, r/m16	Move if above or equal (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVB	reg16,rm16	P6	CMOVB r16, r/m16	Move if below (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVBE	reg16,rm16	P6	CMOVBE r16, r/m16	Move if below or equal (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVE	reg16,rm16	P6	CMOVE r16, r/m16	Move if equal (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
CMOVG	reg16,rm16	P6	CMOVG r16, r/m16	Move if greater (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVGE	reg16,rm16	P6	CMOVGE r16, r/m16	Move if greater or equal (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVL	reg16,rm16	P6	CMOVL r16, r/m16	Move if less (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVLE	reg16,rm16	P6	CMOVLE r16, r/m16	Move if less or equal (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNA	reg16,rm16	P6	CMOVNA r16, r/m16	Move if not above (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVNAE	reg16,rm16	P6	CMOVNAE r16, r/m16	Move if not above or equal (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVNB	reg16,rm16	P6	CMOVNB r16, r/m16	Move if not below (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNBE	reg16,rm16	P6	CMOVNBE r16, r/m16	Move if not below or equal (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVNC	reg16,rm16	P6	CMOVNC r16, r/m16	Move if not carry (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNE	reg16,rm16	P6	CMOVNE r16, r/m16	Move if not equal (ZF=0) (CMOVNE=CMOVNZ)	CMOVcc.html
CMOVNG	reg16,rm16	P6	CMOVNG r16, r/m16	Move if not greater (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNGE	reg16,rm16	P6	CMOVNGE r16, r/m16	Move if not greater or equal (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVNL	reg16,rm16	P6	CMOVNL r16, r/m16	Move if not less (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVNLE	reg16,rm16	P6	CMOVNLE r16, r/m16	Move if not less or equal (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVNO	reg16,rm16	P6	CMOVNO r16, r/m16	Move if not overflow (OF=0)	CMOVcc.html
CMOVNP	reg16,rm16	P6	CMOVNP r16, r/m16	Move if not parity (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVNS	reg16,rm16	P6	CMOVNS r16, r/m16	Move if not sign (SF=0)	CMOVcc.html
CMOVNZ	reg16,rm16	P6	CMOVNZ r16, r/m16	Move if not zero (ZF=0 CMOVNE=CMOVNZ)	CMOVcc.html
CMOVO	reg16,rm16	P6	CMOVO r16, r/m16	Move if overflow (OF=1)	CMOVcc.html
CMOVP	reg16,rm16	P6	CMOVP r16, r/m16	Move if parity (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPE	reg16,rm16	P6	CMOVPE r16, r/m16	Move if parity even (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPO	reg16,rm16	P6	CMOVPO r16, r/m16	Move if parity odd (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVS	reg16,rm16	P6	CMOVS r16, r/m16	Move if sign (SF=1)	CMOVcc.html
CMOVZ	reg16,rm16	P6	CMOVZ r16, r/m16	Move if zero (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
;
CMOVA	reg32,rm32	P6	CMOVA r32, r/m32	Move if above (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVAE	reg32,rm32	P6	CMOVAE r32, r/m32	Move if above or equal (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVB	reg32,rm32	P6	CMOVB r32, r/m32	Move if below (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVBE	reg32,rm32	P6	CMOVBE r32, r/m32	Move if below or equal (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVE	reg32,rm32	P6	CMOVE r32, r/m32	Move if equal (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
CMOVG	reg32,rm32	P6	CMOVG r32, r/m32	Move if greater (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVGE	reg32,rm32	P6	CMOVGE r32, r/m32	Move if greater or equal (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVL	reg32,rm32	P6	CMOVL r32, r/m32	Move if less (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVLE	reg32,rm32	P6	CMOVLE r32, r/m32	Move if less or equal (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNA	reg32,rm32	P6	CMOVNA r32, r/m32	Move if not above (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVNAE	reg32,rm32	P6	CMOVNAE r32, r/m32	Move if not above or equal (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVNB	reg32,rm32	P6	CMOVNB r32, r/m32	Move if not below (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNBE	reg32,rm32	P6	CMOVNBE r32, r/m32	Move if not below or equal (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVNC	reg32,rm32	P6	CMOVNC r32, r/m32	Move if not carry (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNE	reg32,rm32	P6	CMOVNE r32, r/m32	Move if not equal (ZF=0) (CMOVNE=CMOVNZ)	CMOVcc.html
CMOVNG	reg32,rm32	P6	CMOVNG r32, r/m32	Move if not greater (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNGE	reg32,rm32	P6	CMOVNGE r32, r/m32	Move if not greater or equal (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVNL	reg32,rm32	P6	CMOVNL r32, r/m32	Move if not less (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVNLE	reg32,rm32	P6	CMOVNLE r32, r/m32	Move if not less or equal (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVNO	reg32,rm32	P6	CMOVNO r32, r/m32	Move if not overflow (OF=0)	CMOVcc.html
CMOVNP	reg32,rm32	P6	CMOVNP r32, r/m32	Move if not parity (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVNS	reg32,rm32	P6	CMOVNS r32, r/m32	Move if not sign (SF=0)	CMOVcc.html
CMOVNZ	reg32,rm32	P6	CMOVNZ r32, r/m32	Move if not zero (ZF=0 CMOVNE=CMOVNZ)	CMOVcc.html
CMOVO	reg32,rm32	P6	CMOVO r32, r/m32	Move if overflow (OF=1)	CMOVcc.html
CMOVP	reg32,rm32	P6	CMOVP r32, r/m32	Move if parity (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPE	reg32,rm32	P6	CMOVPE r32, r/m32	Move if parity even (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPO	reg32,rm32	P6	CMOVPO r32, r/m32	Move if parity odd (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVS	reg32,rm32	P6	CMOVS r32, r/m32	Move if sign (SF=1)	CMOVcc.html
CMOVZ	reg32,rm32	P6	CMOVZ r32, r/m32	Move if zero (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
;
CMOVA	reg64,rm64	X64	CMOVA r64, r/m64	Move if above (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVAE	reg64,rm64	X64	CMOVAE r64, r/m64	Move if above or equal (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVB	reg64,rm64	X64	CMOVB r64, r/m64	Move if below (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVBE	reg64,rm64	X64	CMOVBE r64, r/m64	Move if below or equal (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVE	reg64,rm64	X64	CMOVE r64, r/m64	Move if equal (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
CMOVG	reg64,rm64	X64	CMOVG r64, r/m64	Move if greater (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVGE	reg64,rm64	X64	CMOVGE r64, r/m64	Move if greater or equal (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVL	reg64,rm64	X64	CMOVL r64, r/m64	Move if less (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVLE	reg64,rm64	X64	CMOVLE r64, r/m64	Move if less or equal (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNA	reg64,rm64	X64	CMOVNA r64, r/m64	Move if not above (CF=1 or ZF=1) (CMOVBE=CMOVNA)	CMOVcc.html
CMOVNAE	reg64,rm64	X64	CMOVNAE r64, r/m64	Move if not above or equal (CF=1) (CMOVB=CMOVC=CMOVNAE)	CMOVcc.html
CMOVNB	reg64,rm64	X64	CMOVNB r64, r/m64	Move if not below (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNBE	reg64,rm64	X64	CMOVNBE r64, r/m64	Move if not below or equal (CF=0 and ZF=0) (CMOVA=CMOVNBE)	CMOVcc.html
CMOVNC	reg64,rm64	X64	CMOVNC r64, r/m64	Move if not carry (CF=0) (CMOVAE=CMOVNB=CMOVNC)	CMOVcc.html
CMOVNE	reg64,rm64	X64	CMOVNE r64, r/m64	Move if not equal (ZF=0) (CMOVNE=CMOVNZ)	CMOVcc.html
CMOVNG	reg64,rm64	X64	CMOVNG r64, r/m64	Move if not greater (ZF=1 or SF!=OF) (CMOVLE=CMOVNG)	CMOVcc.html
CMOVNGE	reg64,rm64	X64	CMOVNGE r64, r/m64	Move if not greater or equal (SF!=OF) (CMOVL=CMOVNGE)	CMOVcc.html
CMOVNL	reg64,rm64	X64	CMOVNL r64, r/m64	Move if not less (SF=OF) (CMOVGE=CMOVNL)	CMOVcc.html
CMOVNLE	reg64,rm64	X64	CMOVNLE r64, r/m64	Move if not less or equal (ZF=0 and SF=OF) (CMOVG=CMOVNLE)	CMOVcc.html
CMOVNO	reg64,rm64	X64	CMOVNO r64, r/m64	Move if not overflow (OF=0)	CMOVcc.html
CMOVNP	reg64,rm64	X64	CMOVNP r64, r/m64	Move if not parity (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVNS	reg64,rm64	X64	CMOVNS r64, r/m64	Move if not sign (SF=0)	CMOVcc.html
CMOVNZ	reg64,rm64	X64	CMOVNZ r64, r/m64	Move if not zero (ZF=0 CMOVNE=CMOVNZ)	CMOVcc.html
CMOVO	reg64,rm64	X64	CMOVO r64, r/m64	Move if overflow (OF=1)	CMOVcc.html
CMOVP	reg64,rm64	X64	CMOVP r64, r/m64	Move if parity (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPE	reg64,rm64	X64	CMOVPE r64, r/m64	Move if parity even (PF=1) (CMOVP=CMOVPE)	CMOVcc.html
CMOVPO	reg64,rm64	X64	CMOVPO r64, r/m64	Move if parity odd (PF=0) (CMOVNP=CMOVPO)	CMOVcc.html
CMOVS	reg64,rm64	X64	CMOVS r64, r/m64	Move if sign (SF=1)	CMOVcc.html
CMOVZ	reg64,rm64	X64	CMOVZ r64, r/m64	Move if zero (ZF=1) (CMOVE=CMOVZ)	CMOVcc.html
;
JA	imm|near	386	JA imm|near	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	imm|near	386	JAE imm|near	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	imm|near	386	JB imm|near	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	imm|near	386	JBE imm|near	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	imm|near	386	JC imm|near	Jump if carry (CF=1)	Jcc.html
JE	imm|near	386	JE imm|near	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	imm|near	386	JG imm|near	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	imm|near	386	JGE imm|near	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	imm|near	386	JL imm|near	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	imm|near	386	JLE imm|near	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	imm|near	386	JNA imm|near	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	imm|near	386	JNAE imm|near	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	imm|near	386	JNB imm|near	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	imm|near	386	JNBE imm|near	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	imm|near	386	JNC imm|near	Jump if not carry (CF=0)	Jcc.html
JNE	imm|near	386	JNE imm|near	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	imm|near	386	JNG imm|near	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	imm|near	386	JNGE imm|near	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	imm|near	386	JNL imm|near	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	imm|near	386	JNLE imm|near	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	imm|near	386	JNO imm|near	Jump if not overflow (OF=0)	Jcc.html
JNP	imm|near	386	JNP imm|near	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	imm|near	386	JNS imm|near	Jump if not sign (SF=0)	Jcc.html
JNZ	imm|near	386	JNZ imm|near	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	imm|near	386	JO imm|near	Jump if overflow (OF=1)	Jcc.html
JP	imm|near	386	JP imm|near	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	imm|near	386	JPE imm|near	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	imm|near	386	JPO imm|near	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	imm|near	386	JS imm|near	Jump if sign (SF=1)	Jcc.html
JZ	imm|near	386	JZ imm|near	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
JA	imm16|near	386	JA imm16|near	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	imm16|near	386	JAE imm16|near	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	imm16|near	386	JB imm16|near	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	imm16|near	386	JBE imm16|near	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	imm16|near	386	JC imm16|near	Jump if carry (CF=1)	Jcc.html
JE	imm16|near	386	JE imm16|near	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	imm16|near	386	JG imm16|near	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	imm16|near	386	JGE imm16|near	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	imm16|near	386	JL imm16|near	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	imm16|near	386	JLE imm16|near	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	imm16|near	386	JNA imm16|near	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	imm16|near	386	JNAE imm16|near	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	imm16|near	386	JNB imm16|near	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	imm16|near	386	JNBE imm16|near	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	imm16|near	386	JNC imm16|near	Jump if not carry (CF=0)	Jcc.html
JNE	imm16|near	386	JNE imm16|near	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	imm16|near	386	JNG imm16|near	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	imm16|near	386	JNGE imm16|near	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	imm16|near	386	JNL imm16|near	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	imm16|near	386	JNLE imm16|near	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	imm16|near	386	JNO imm16|near	Jump if not overflow (OF=0)	Jcc.html
JNP	imm16|near	386	JNP imm16|near	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	imm16|near	386	JNS imm16|near	Jump if not sign (SF=0)	Jcc.html
JNZ	imm16|near	386	JNZ imm16|near	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	imm16|near	386	JO imm16|near	Jump if overflow (OF=1)	Jcc.html
JP	imm16|near	386	JP imm16|near	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	imm16|near	386	JPE imm16|near	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	imm16|near	386	JPO imm16|near	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	imm16|near	386	JS imm16|near	Jump if sign (SF=1)	Jcc.html
JZ	imm16|near	386	JZ imm16|near	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
JA	imm32|near	386	JA imm32|near	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	imm32|near	386	JAE imm32|near	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	imm32|near	386	JB imm32|near	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	imm32|near	386	JBE imm32|near	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	imm32|near	386	JC imm32|near	Jump if carry (CF=1)	Jcc.html
JE	imm32|near	386	JE imm32|near	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	imm32|near	386	JG imm32|near	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	imm32|near	386	JGE imm32|near	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	imm32|near	386	JL imm32|near	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	imm32|near	386	JLE imm32|near	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	imm32|near	386	JNA imm32|near	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	imm32|near	386	JNAE imm32|near	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	imm32|near	386	JNB imm32|near	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	imm32|near	386	JNBE imm32|near	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	imm32|near	386	JNC imm32|near	Jump if not carry (CF=0)	Jcc.html
JNE	imm32|near	386	JNE imm32|near	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	imm32|near	386	JNG imm32|near	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	imm32|near	386	JNGE imm32|near	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	imm32|near	386	JNL imm32|near	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	imm32|near	386	JNLE imm32|near	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	imm32|near	386	JNO imm32|near	Jump if not overflow (OF=0)	Jcc.html
JNP	imm32|near	386	JNP imm32|near	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	imm32|near	386	JNS imm32|near	Jump if not sign (SF=0)	Jcc.html
JNZ	imm32|near	386	JNZ imm32|near	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	imm32|near	386	JO imm32|near	Jump if overflow (OF=1)	Jcc.html
JP	imm32|near	386	JP imm32|near	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	imm32|near	386	JPE imm32|near	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	imm32|near	386	JPO imm32|near	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	imm32|near	386	JS imm32|near	Jump if sign (SF=1)	Jcc.html
JZ	imm32|near	386	JZ imm32|near	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
JA	imm64|near	X64	JA imm64|near	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	imm64|near	X64	JAE imm64|near	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	imm64|near	X64	JB imm64|near	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	imm64|near	X64	JBE imm64|near	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	imm64|near	X64	JC imm64|near	Jump if carry (CF=1)	Jcc.html
JE	imm64|near	X64	JE imm64|near	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	imm64|near	X64	JG imm64|near	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	imm64|near	X64	JGE imm64|near	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	imm64|near	X64	JL imm64|near	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	imm64|near	X64	JLE imm64|near	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	imm64|near	X64	JNA imm64|near	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	imm64|near	X64	JNAE imm64|near	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	imm64|near	X64	JNB imm64|near	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	imm64|near	X64	JNBE imm64|near	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	imm64|near	X64	JNC imm64|near	Jump if not carry (CF=0)	Jcc.html
JNE	imm64|near	X64	JNE imm64|near	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	imm64|near	X64	JNG imm64|near	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	imm64|near	X64	JNGE imm64|near	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	imm64|near	X64	JNL imm64|near	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	imm64|near	X64	JNLE imm64|near	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	imm64|near	X64	JNO imm64|near	Jump if not overflow (OF=0)	Jcc.html
JNP	imm64|near	X64	JNP imm64|near	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	imm64|near	X64	JNS imm64|near	Jump if not sign (SF=0)	Jcc.html
JNZ	imm64|near	X64	JNZ imm64|near	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	imm64|near	X64	JO imm64|near	Jump if overflow (OF=1)	Jcc.html
JP	imm64|near	X64	JP imm64|near	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	imm64|near	X64	JPE imm64|near	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	imm64|near	X64	JPO imm64|near	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	imm64|near	X64	JS imm64|near	Jump if sign (SF=1)	Jcc.html
JZ	imm64|near	X64	JZ imm64|near	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
JA	imm|short	8086	JA imm|short	Jump if above (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JAE	imm|short	8086	JAE imm|short	Jump if above or equal (CF=0) (JAE=JNB)	Jcc.html
JB	imm|short	8086	JB imm|short	Jump if below (CF=1) (JB=JNAE)	Jcc.html
JBE	imm|short	8086	JBE imm|short	Jump if below or equal (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JC	imm|short	8086	JC imm|short	Jump if carry (CF=1)	Jcc.html
JE	imm|short	8086	JE imm|short	Jump if equal (ZF=1) (JE=JZ)	Jcc.html
JG	imm|short	8086	JG imm|short	Jump if greater (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JGE	imm|short	8086	JGE imm|short	Jump if greater or equal (SF=OF) (JGE=JNL)	Jcc.html
JL	imm|short	8086	JL imm|short	Jump if less (SF!=OF) (JL=JNGE)	Jcc.html
JLE	imm|short	8086	JLE imm|short	Jump if less or equal (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNA	imm|short	8086	JNA imm|short	Jump if not above (CF=1 or ZF=1) (JBE=JNA)	Jcc.html
JNAE	imm|short	8086	JNAE imm|short	Jump if not above or equal (CF=1) (JB=JNAE)	Jcc.html
JNB	imm|short	8086	JNB imm|short	Jump if not below (CF=0) (JAE=JNB)	Jcc.html
JNBE	imm|short	8086	JNBE imm|short	Jump if not below or equal (CF=0 and ZF=0) (JA=JNBE)	Jcc.html
JNC	imm|short	8086	JNC imm|short	Jump if not carry (CF=0)	Jcc.html
JNE	imm|short	8086	JNE imm|short	Jump if not equal (ZF=0) (JNE=JNZ)	Jcc.html
JNG	imm|short	8086	JNG imm|short	Jump if not greater (ZF=1 or SF!=OF) (JLE=JNG)	Jcc.html
JNGE	imm|short	8086	JNGE imm|short	Jump if not greater or equal (SF!=OF) (JL=JNGE)	Jcc.html
JNL	imm|short	8086	JNL imm|short	Jump if not less (SF=OF) (JGE=JNL)	Jcc.html
JNLE	imm|short	8086	JNLE imm|short	Jump if not less or equal (ZF=0 and SF=OF) (JG=JNLE)	Jcc.html
JNO	imm|short	8086	JNO imm|short	Jump if not overflow (OF=0)	Jcc.html
JNP	imm|short	8086	JNP imm|short	Jump if not parity (PF=0) (JNP=JPO)	Jcc.html
JNS	imm|short	8086	JNS imm|short	Jump if not sign (SF=0)	Jcc.html
JNZ	imm|short	8086	JNZ imm|short	Jump if not zero (ZF=0) (JNE=JNZ)	Jcc.html
JO	imm|short	8086	JO imm|short	Jump if overflow (OF=1)	Jcc.html
JP	imm|short	8086	JP imm|short	Jump if parity (PF=1) (JP=JPE)	Jcc.html
JPE	imm|short	8086	JPE imm|short	Jump if parity even (PF=1) (JP=JPE)	Jcc.html
JPO	imm|short	8086	JPO imm|short	Jump if parity odd (PF=0) (JNP=JPO)	Jcc.html
JS	imm|short	8086	JS imm|short	Jump if sign (SF=1)	Jcc.html
JZ	imm|short	8086	JZ imm|short	Jump if zero (ZF=1) (JE=JZ)	Jcc.html
;
SETA	rm8	386	SETA r/m8	Set byte if above (CF=0 and ZF=0) (SETA=SETNBE)	SETcc.html
SETAE	rm8	386	SETAE r/m8	Set byte if above or equal (CF=0) (SETAE=SETNC=SETNB)	SETcc.html
SETB	rm8	386	SETB r/m8	Set byte if below (CF=1) (SETB=SETC=SETNAE)	SETcc.html
SETBE	rm8	386	SETBE r/m8	Set byte if below or equal (CF=1 or ZF=1) (SETBE=SETNA)	SETcc.html
SETC	rm8	386	SETC r/m8	Set byte if carry (CF=1 SETB=SETC=SETNAE)	SETcc.html
SETE	rm8	386	SETE r/m8	Set byte if equal (ZF=1) (SETE=SETZ)	SETcc.html
SETG	rm8	386	SETG r/m8	Set byte if greater (ZF=0 and SF=OF) (SETG=SETNLE)	SETcc.html
SETGE	rm8	386	SETGE r/m8	Set byte if greater or equal (SF=OF) (SETGE=SETNL)	SETcc.html
SETL	rm8	386	SETL r/m8	Set byte if less (SF!=OF) (SETL=SETNGE)	SETcc.html
SETLE	rm8	386	SETLE r/m8	Set byte if less or equal (ZF=1 or SF!=OF) (SETLE=SETNG)	SETcc.html
SETNA	rm8	386	SETNA r/m8	Set byte if not above (CF=1 or ZF=1) (SETBE=SETNA)	SETcc.html
SETNAE	rm8	386	SETNAE r/m8	Set byte if not above or equal (CF=1) (SETB=SETC=SETNAE)	SETcc.html
SETNB	rm8	386	SETNB r/m8	Set byte if not below (CF=0) (SETAE=SETNC=SETNB)	SETcc.html
SETNBE	rm8	386	SETNBE r/m8	Set byte if not below or equal (CF=0 and ZF=0) (SETA=SETNBE)	SETcc.html
SETNC	rm8	386	SETNC r/m8	Set byte if not carry (CF=0) (SETAE=SETNC=SETNB)	SETcc.html
SETNE	rm8	386	SETNE r/m8	Set byte if not equal (ZF=0) (SETNE=SETNZ)	SETcc.html
SETNG	rm8	386	SETNG r/m8	Set byte if not greater (ZF=1 or SF!=OF) (SETLE=SETNG)	SETcc.html
SETNGE	rm8	386	SETNGE r/m8	Set byte if not greater or equal (SF!=OF) (SETL=SETNGE)	SETcc.html
SETNL	rm8	386	SETNL r/m8	Set byte if not less (SF=OF) (SETGE=SETNL)	SETcc.html
SETNLE	rm8	386	SETNLE r/m8	Set byte if not less or equal (ZF=0 and SF=OF) (SETG=SETNLE)	SETcc.html
SETNO	rm8	386	SETNO r/m8	Set byte if not overflow (OF=0)	SETcc.html
SETNP	rm8	386	SETNP r/m8	Set byte if not parity (PF=0) (SETNP=SETPO)	SETcc.html
SETNS	rm8	386	SETNS r/m8	Set byte if not sign (SF=0)	SETcc.html
SETNZ	rm8	386	SETNZ r/m8	Set byte if not zero (ZF=0) (SETNE=SETNZ)	SETcc.html
SETO	rm8	386	SETO r/m8	Set byte if overflow (OF=1)	SETcc.html
SETP	rm8	386	SETP r/m8	Set byte if parity (PF=1) (SETP=SETPE)	SETcc.html
SETPE	rm8	386	SETPE r/m8	Set byte if parity even (PF=1) (SETP=SETPE)	SETcc.html
SETPO	rm8	386	SETPO r/m8	Set byte if parity odd (PF=0 SETNP=SETPO)	SETcc.html
SETS	rm8	386	SETS r/m8	Set byte if sign (SF=1)	SETcc.html
SETZ	rm8	386	SETZ r/m8	Set byte if zero (ZF=1) (SETE=SETZ)	SETcc.html
;
ADDPS	xmmreg,xmmrm128	KATMAI,SSE	ADDPS xmm, xmm/m128	Add Packed Single-Precision Floating-Point Values	ADDPS.html
ADDSS	xmmreg,xmmrm32	KATMAI,SSE	ADDSS xmm, xmm/m32	Add Scalar Single-Precision Floating-Point Values	ADDSS.html
ANDNPS	xmmreg,xmmrm128	KATMAI,SSE	ANDNPS xmm, xmm/m128	Bitwise Logical AND NOT of Packed Single-Precision Floating-Point Values	ANDNPS.html
ANDPS	xmmreg,xmmrm128	KATMAI,SSE	ANDPS xmm, xmm/m128	Bitwise Logical AND of Packed Single-Precision Floating-Point Values	ANDPS.html
CMPEQPS	xmmreg,xmmrm128	KATMAI,SSE	CMPEQPS xmm, xmm/m128	TODO: KATMAI,SSE	
CMPEQSS	xmmreg,xmmrm32	KATMAI,SSE	CMPEQSS xmm, xmm/m32	TODO: KATMAI,SSE	
CMPLEPS	xmmreg,xmmrm128	KATMAI,SSE	CMPLEPS xmm, xmm/m128	TODO: KATMAI,SSE	
CMPLESS	xmmreg,xmmrm32	KATMAI,SSE	CMPLESS xmm, xmm/m32	TODO: KATMAI,SSE	
CMPLTPS	xmmreg,xmmrm128	KATMAI,SSE	CMPLTPS xmm, xmm/m128	TODO: KATMAI,SSE	
CMPLTSS	xmmreg,xmmrm32	KATMAI,SSE	CMPLTSS xmm, xmm/m32	TODO: KATMAI,SSE	
CMPNEQPS	xmmreg,xmmrm128	KATMAI,SSE	CMPNEQPS xmm, xmm/m128	TODO: KATMAI,SSE	
CMPNEQSS	xmmreg,xmmrm32	KATMAI,SSE	CMPNEQSS xmm, xmm/m32	TODO: KATMAI,SSE	
CMPNLEPS	xmmreg,xmmrm128	KATMAI,SSE	CMPNLEPS xmm, xmm/m128	TODO: KATMAI,SSE	
CMPNLESS	xmmreg,xmmrm32	KATMAI,SSE	CMPNLESS xmm, xmm/m32	TODO: KATMAI,SSE	
CMPNLTPS	xmmreg,xmmrm128	KATMAI,SSE	CMPNLTPS xmm, xmm/m128	TODO: KATMAI,SSE	
CMPNLTSS	xmmreg,xmmrm32	KATMAI,SSE	CMPNLTSS xmm, xmm/m32	TODO: KATMAI,SSE	
CMPORDPS	xmmreg,xmmrm128	KATMAI,SSE	CMPORDPS xmm, xmm/m128	TODO: KATMAI,SSE	
CMPORDSS	xmmreg,xmmrm32	KATMAI,SSE	CMPORDSS xmm, xmm/m32	TODO: KATMAI,SSE	
CMPUNORDPS	xmmreg,xmmrm128	KATMAI,SSE	CMPUNORDPS xmm, xmm/m128	TODO: KATMAI,SSE	
CMPUNORDSS	xmmreg,xmmrm32	KATMAI,SSE	CMPUNORDSS xmm, xmm/m32	TODO: KATMAI,SSE	
CMPPS	xmmreg,mem,imm	KATMAI,SSE	CMPPS xmm, mem, imm	Compare Packed Single-Precision Floating-Point Values	CMPPS.html
CMPPS	xmmreg,xmmreg,imm	KATMAI,SSE	CMPPS xmm, xmm, imm	Compare Packed Single-Precision Floating-Point Values	CMPPS.html
CMPSS	xmmreg,mem,imm	KATMAI,SSE	CMPSS xmm, mem, imm	Compare Scalar Single-Precision Floating-Point Values	CMPSS.html
CMPSS	xmmreg,xmmreg,imm	KATMAI,SSE	CMPSS xmm, xmm, imm	Compare Scalar Single-Precision Floating-Point Values	CMPSS.html
COMISS	xmmreg,xmmrm32	KATMAI,SSE	COMISS xmm, xmm/m32	Compare Scalar Ordered Single-Precision Floating-Point Values and Set EFLAGS	COMISS.html
CVTPI2PS	xmmreg,mmxrm64	KATMAI,SSE,MMX	CVTPI2PS xmm, MMXRM64	Convert Packed Dword Integers to Packed Single-Precision FP Values	CVTPI2PS.html
CVTPS2PI	mmxreg,xmmrm64	KATMAI,SSE,MMX	CVTPS2PI mmxreg, xmm/m64	Convert Packed Single-Precision FP Values to Packed Dword Integers	CVTPS2PI.html
CVTSI2SS	xmmreg,mem	KATMAI,SSE,SD,AR1,ND	CVTSI2SS xmm, mem	Convert Dword Integer to Scalar Single-Precision FP Value	CVTSI2SS.html
CVTSI2SS	xmmreg,rm32	KATMAI,SSE,SD,AR1	CVTSI2SS xmm, r/m32	Convert Dword Integer to Scalar Single-Precision FP Value	CVTSI2SS.html
CVTSI2SS	xmmreg,rm64	X64,SSE,AR1	CVTSI2SS xmm, r/m64	Convert Dword Integer to Scalar Single-Precision FP Value	CVTSI2SS.html
CVTSS2SI	reg32,xmmreg	KATMAI,SSE,SD,AR1	CVTSS2SI r32, xmm	Convert Scalar Single-Precision FP Value to Dword Integer	CVTSS2SI.html
CVTSS2SI	reg32,mem	KATMAI,SSE,SD,AR1	CVTSS2SI r32, mem	Convert Scalar Single-Precision FP Value to Dword Integer	CVTSS2SI.html
CVTSS2SI	reg64,xmmreg	X64,SSE,SD,AR1	CVTSS2SI r64, xmm	Convert Scalar Single-Precision FP Value to Dword Integer	CVTSS2SI.html
CVTSS2SI	reg64,mem	X64,SSE,SD,AR1	CVTSS2SI r64, mem	Convert Scalar Single-Precision FP Value to Dword Integer	CVTSS2SI.html
CVTTPS2PI	mmxreg,xmmrm	KATMAI,SSE,MMX	CVTTPS2PI mmxreg, xmm/m128	Convert with Truncation Packed Single-Precision FP Values to Packed Dword Integers	CVTTPS2PI.html
CVTTSS2SI	reg32,xmmrm	KATMAI,SSE,SD,AR1	CVTTSS2SI r32, xmm/m128	Convert with Truncation Scalar Single-Precision FP Value to Dword Integer	CVTTSS2SI.html
CVTTSS2SI	reg64,xmmrm	X64,SSE,SD,AR1	CVTTSS2SI r64, xmm/m128	Convert with Truncation Scalar Single-Precision FP Value to Dword Integer	CVTTSS2SI.html
DIVPS	xmmreg,xmmrm128	KATMAI,SSE	DIVPS xmm, xmm/m128	Divide Packed Single-Precision Floating-Point Values	DIVPS.html
DIVSS	xmmreg,xmmrm32	KATMAI,SSE	DIVSS xmm, xmm/m32	Divide Scalar Single-Precision Floating-Point Values	DIVSS.html
LDMXCSR	mem32	KATMAI,SSE	LDMXCSR mem32	Load MXCSR Register	LDMXCSR.html
MAXPS	xmmreg,xmmrm128	KATMAI,SSE	MAXPS xmm, xmm/m128	Return Maximum Packed Single-Precision Floating-Point Values	MAXPS.html
MAXSS	xmmreg,xmmrm32	KATMAI,SSE	MAXSS xmm, xmm/m32	Return Maximum Scalar Single-Precision Floating-Point Value	MAXSS.html
MINPS	xmmreg,xmmrm128	KATMAI,SSE	MINPS xmm, xmm/m128	Return Minimum Packed Single-Precision Floating-Point Values	MINPS.html
MINSS	xmmreg,xmmrm32	KATMAI,SSE	MINSS xmm, xmm/m32	Return Minimum Scalar Single-Precision Floating-Point Value	MINSS.html
MOVAPS	xmmreg,xmmrm128	KATMAI,SSE	MOVAPS xmm, xmm/m128	Move Aligned Packed Single-Precision Floating-Point Values	MOVAPS.html
MOVAPS	xmmrm128,xmmreg	KATMAI,SSE	MOVAPS xmm/m128, xmm	Move Aligned Packed Single-Precision Floating-Point Values	MOVAPS.html
MOVHPS	xmmreg,mem64	KATMAI,SSE	MOVHPS xmm, mem64	Move High Packed Single-Precision Floating-Point Values	MOVHPS.html
MOVHPS	mem64,xmmreg	KATMAI,SSE	MOVHPS mem64, xmm	Move High Packed Single-Precision Floating-Point Values	MOVHPS.html
MOVLHPS	xmmreg,xmmreg	KATMAI,SSE	MOVLHPS xmm, xmm	Move Packed Single-Precision Floating-Point Values Low to High	MOVLHPS.html
MOVLPS	xmmreg,mem64	KATMAI,SSE	MOVLPS xmm, mem64	Move Low Packed Single-Precision Floating-Point Values	MOVLPS.html
MOVLPS	mem64,xmmreg	KATMAI,SSE	MOVLPS mem64, xmm	Move Low Packed Single-Precision Floating-Point Values	MOVLPS.html
MOVHLPS	xmmreg,xmmreg	KATMAI,SSE	MOVHLPS xmm, xmm	Move Packed Single-Precision Floating-Point Values High to Low	MOVHLPS.html
MOVMSKPS	reg32,xmmreg	KATMAI,SSE	MOVMSKPS r32, xmm	Extract Packed Single-Precision Floating-Point Sign Mask	MOVMSKPS.html
MOVMSKPS	reg64,xmmreg	X64,SSE	MOVMSKPS r64, xmm	Extract Packed Single-Precision Floating-Point Sign Mask	MOVMSKPS.html
MOVNTPS	mem128,xmmreg	KATMAI,SSE	MOVNTPS mem128, xmm	Store Packed Single-Precision Floating-Point Values Using Non-Temporal Hint	MOVNTPS.html
MOVSS	xmmreg,xmmrm32	KATMAI,SSE	MOVSS xmm, xmm/m32	Move Scalar Single-Precision Floating-Point Values	MOVSS.html
MOVSS	mem32,xmmreg	KATMAI,SSE	MOVSS mem32, xmm	Move Scalar Single-Precision Floating-Point Values	MOVSS.html
MOVSS	xmmreg,xmmreg	KATMAI,SSE	MOVSS xmm, xmm	Move Scalar Single-Precision Floating-Point Values	MOVSS.html
MOVUPS	xmmreg,xmmrm128	KATMAI,SSE	MOVUPS xmm, xmm/m128	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
MOVUPS	xmmrm128,xmmreg	KATMAI,SSE	MOVUPS xmm/m128, xmm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
MULPS	xmmreg,xmmrm128	KATMAI,SSE	MULPS xmm, xmm/m128	Multiply Packed Single-Precision Floating-Point Values	MULPS.html
MULSS	xmmreg,xmmrm32	KATMAI,SSE	MULSS xmm, xmm/m32	Multiply Scalar Single-Precision Floating-Point Values	MULSS.html
ORPS	xmmreg,xmmrm128	KATMAI,SSE	ORPS xmm, xmm/m128	Bitwise Logical OR of Single-Precision Floating-Point Values	ORPS.html
RCPPS	xmmreg,xmmrm128	KATMAI,SSE	RCPPS xmm, xmm/m128	Compute Reciprocals of Packed Single-Precision Floating-Point Values	RCPPS.html
RCPSS	xmmreg,xmmrm32	KATMAI,SSE	RCPSS xmm, xmm/m32	Compute Reciprocal of Scalar Single-Precision Floating-Point Values	RCPSS.html
RSQRTPS	xmmreg,xmmrm128	KATMAI,SSE	RSQRTPS xmm, xmm/m128	Compute Reciprocals of Square Roots of Packed Single-Precision Floating-Point Values	RSQRTPS.html
RSQRTSS	xmmreg,xmmrm32	KATMAI,SSE	RSQRTSS xmm, xmm/m32	Compute Reciprocal of Square Root of Scalar Single-Precision Floating-Point Value	RSQRTSS.html
SHUFPS	xmmreg,xmmrm128,imm8	KATMAI,SSE	SHUFPS xmm, xmm/m128, imm8	Shuffle Packed Single-Precision Floating-Point Values	SHUFPS.html
SQRTPS	xmmreg,xmmrm128	KATMAI,SSE	SQRTPS xmm, xmm/m128	Compute Square Roots of Packed Single-Precision Floating-Point Values	SQRTPS.html
SQRTSS	xmmreg,xmmrm32	KATMAI,SSE	SQRTSS xmm, xmm/m32	Compute Square Root of Scalar Single-Precision Floating-Point Value	SQRTSS.html
STMXCSR	mem32	KATMAI,SSE	STMXCSR mem32	Store MXCSR Register State	STMXCSR.html
SUBPS	xmmreg,xmmrm128	KATMAI,SSE	SUBPS xmm, xmm/m128	Subtract Packed Single-Precision Floating-Point Values	SUBPS.html
SUBSS	xmmreg,xmmrm32	KATMAI,SSE	SUBSS xmm, xmm/m32	Subtract Scalar Single-Precision Floating-Point Values	SUBSS.html
UCOMISS	xmmreg,xmmrm32	KATMAI,SSE	UCOMISS xmm, xmm/m32	Unordered Compare Scalar Single-Precision Floating-Point Values and Set EFLAGS	UCOMISS.html
UNPCKHPS	xmmreg,xmmrm128	KATMAI,SSE	UNPCKHPS xmm, xmm/m128	Unpack and Interleave High Packed Single-Precision Floating-Point Values	UNPCKHPS.html
UNPCKLPS	xmmreg,xmmrm128	KATMAI,SSE	UNPCKLPS xmm, xmm/m128	Unpack and Interleave Low Packed Single-Precision Floating-Point Values	UNPCKLPS.html
XORPS	xmmreg,xmmrm128	KATMAI,SSE	XORPS xmm, xmm/m128	Bitwise Logical XOR for Single-Precision Floating-Point Values	XORPS.html
FXRSTOR	mem	P6,SSE,FPU	FXRSTOR mem	Restore x87 FPU, MMX, XMM, and MXCSR State	FXRSTOR.html
FXRSTOR64	mem	X64,SSE,FPU	FXRSTOR64 mem	TODO: X64,SSE,FPU	
FXSAVE	mem	P6,SSE,FPU	FXSAVE mem	Save x87 FPU, MMX Technology, and SSE State	FXSAVE.html
FXSAVE64	mem	X64,SSE,FPU	FXSAVE64 mem	TODO: X64,SSE,FPU	
XGETBV	none	NEHALEM	XGETBV 	Get Value of Extended Control Register	XGETBV.html
XSETBV	none	NEHALEM,PRIV	XSETBV 	Set Extended Control Register	XSETBV.html
XSAVE	mem	NEHALEM	XSAVE mem	Save Processor Extended States	XSAVE.html
XSAVE64	mem	LONG,NEHALEM	XSAVE64 mem	TODO: LONG,NEHALEM	
XSAVEC	mem	FUTURE	XSAVEC mem	Save Processor Extended States with Compaction	XSAVEC.html
XSAVEC64	mem	LONG,FUTURE	XSAVEC64 mem	TODO: LONG,FUTURE	
XSAVEOPT	mem	FUTURE	XSAVEOPT mem	Save Processor Extended States Optimized	XSAVEOPT.html
XSAVEOPT64	mem	LONG,FUTURE	XSAVEOPT64 mem	TODO: LONG,FUTURE	
XSAVES	mem	FUTURE	XSAVES mem	Save Processor Extended States Supervisor	XSAVES.html
XSAVES64	mem	LONG,FUTURE	XSAVES64 mem	TODO: LONG,FUTURE	
XRSTOR	mem	NEHALEM	XRSTOR mem	Restore Processor Extended States	XRSTOR.html
XRSTOR64	mem	LONG,NEHALEM	XRSTOR64 mem	TODO: LONG,NEHALEM	
XRSTORS	mem	FUTURE	XRSTORS mem	Restore Processor Extended States Supervisor	XRSTORS.html
XRSTORS64	mem	LONG,FUTURE	XRSTORS64 mem	TODO: LONG,FUTURE	
PREFETCHNTA	mem8	KATMAI	PREFETCHNTA mem8	Move data from m8 closer to the processor using NTA hint	PREFETCHh.html
PREFETCHT0	mem8	KATMAI	PREFETCHT0 mem8	Move data from m8 closer to the processor using T0 hint	PREFETCHh.html
PREFETCHT1	mem8	KATMAI	PREFETCHT1 mem8	Move data from m8 closer to the processor using T1 hint	PREFETCHh.html
PREFETCHT2	mem8	KATMAI	PREFETCHT2 mem8	Move data from m8 closer to the processor using T2 hint	PREFETCHh.html
MASKMOVQ	mmxreg,mmxreg	KATMAI,MMX	MASKMOVQ mmxreg, mmxreg	Store Selected Bytes of Quadword	MASKMOVQ.html
MOVNTQ	mem,mmxreg	KATMAI,MMX	MOVNTQ mem, mmxreg	Store of Quadword Using Non-Temporal Hint	MOVNTQ.html
PAVGB	mmxreg,mmxrm	KATMAI,MMX	PAVGB mmxreg, mmx/mem	Average Packed Integers	PAVGB:PAVGW.html
PAVGB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PAVGB xmm, xmm/m128	Average Packed Integers	PAVGB:PAVGW.html
PAVGW	mmxreg,mmxrm	KATMAI,MMX	PAVGW mmxreg, mmx/mem	Average Packed Integers	PAVGB:PAVGW.html
PAVGW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PAVGW xmm, xmm/m128	Average Packed Integers	PAVGB:PAVGW.html
PEXTRW	reg32,mmxreg,imm	KATMAI,MMX	PEXTRW r32, mmxreg, imm	Extract Word	PEXTRW.html
PEXTRW	reg32,xmmreg,imm	WILLAMETTE,SSE2	PEXTRW r32, xmm, imm	Extract Word	PEXTRW.html
PEXTRW	reg32,xmmreg,imm	SSE41	PEXTRW r32, xmm, imm	Extract Word	PEXTRW.html
PEXTRW	mem16,xmmreg,imm	SSE41	PEXTRW mem16, xmm, imm	Extract Word	PEXTRW.html
PEXTRW	reg64,xmmreg,imm	SSE41,X64	PEXTRW r64, xmm, imm	Extract Word	PEXTRW.html
PINSRW	mmxreg,mem,imm	KATMAI,MMX	PINSRW mmxreg, mem, imm	Insert Word	PINSRW.html
PINSRW	mmxreg,rm16,imm	KATMAI,MMX	PINSRW mmxreg, r/m16, imm	Insert Word	PINSRW.html
PINSRW	mmxreg,reg32,imm	KATMAI,MMX	PINSRW mmxreg, r32, imm	Insert Word	PINSRW.html
PINSRW	xmmreg,reg16,imm	WILLAMETTE,SSE2	PINSRW xmm, r16, imm	Insert Word	PINSRW.html
PINSRW	xmmreg,reg32,imm	WILLAMETTE,SSE2,ND	PINSRW xmm, r32, imm	Insert Word	PINSRW.html
PINSRW	xmmreg,mem,imm	WILLAMETTE,SSE2	PINSRW xmm, mem, imm	Insert Word	PINSRW.html
PINSRW	xmmreg,mem16,imm	WILLAMETTE,SSE2	PINSRW xmm, mem16, imm	Insert Word	PINSRW.html
PMAXSW	mmxreg,mmxrm	KATMAI,MMX	PMAXSW mmxreg, mmx/mem	Maximum of Packed Signed Word Integers	PMAXSW.html
PMAXSW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PMAXSW xmm, xmm/m128	Maximum of Packed Signed Word Integers	PMAXSW.html
PMAXUB	mmxreg,mmxrm	KATMAI,MMX	PMAXUB mmxreg, mmx/mem	Maximum of Packed Unsigned Byte Integers	PMAXUB.html
PMAXUB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PMAXUB xmm, xmm/m128	Maximum of Packed Unsigned Byte Integers	PMAXUB.html
PMINSW	mmxreg,mmxrm	KATMAI,MMX	PMINSW mmxreg, mmx/mem	Minimum of Packed Signed Word Integers	PMINSW.html
PMINSW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PMINSW xmm, xmm/m128	Minimum of Packed Signed Word Integers	PMINSW.html
PMINUB	mmxreg,mmxrm	KATMAI,MMX	PMINUB mmxreg, mmx/mem	Minimum of Packed Unsigned Byte Integers	PMINUB.html
PMINUB	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PMINUB xmm, xmm/m128	Minimum of Packed Unsigned Byte Integers	PMINUB.html
PMOVMSKB	reg32,mmxreg	KATMAI,MMX	PMOVMSKB r32, mmxreg	Move Byte Mask	PMOVMSKB.html
PMOVMSKB	reg32,xmmreg	WILLAMETTE,SSE2	PMOVMSKB r32, xmm	Move Byte Mask	PMOVMSKB.html
PMULHUW	mmxreg,mmxrm	KATMAI,MMX	PMULHUW mmxreg, mmx/mem	Multiply Packed Unsigned Integers and Store High Result	PMULHUW.html
PMULHUW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PMULHUW xmm, xmm/m128	Multiply Packed Unsigned Integers and Store High Result	PMULHUW.html
PSADBW	mmxreg,mmxrm	KATMAI,MMX	PSADBW mmxreg, mmx/mem	Compute Sum of Absolute Differences	PSADBW.html
PSADBW	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSADBW xmm, xmm/m128	Compute Sum of Absolute Differences	PSADBW.html
PSHUFW	mmxreg,mmxrm,imm	KATMAI,MMX	PSHUFW mmxreg, mmx/mem, imm	Shuffle Packed Words	PSHUFW.html
PF2IW	mmxreg,mmxrm	PENT,3DNOW	PF2IW mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFNACC	mmxreg,mmxrm	PENT,3DNOW	PFNACC mmxreg, mmx/mem	TODO: PENT,3DNOW	
PFPNACC	mmxreg,mmxrm	PENT,3DNOW	PFPNACC mmxreg, mmx/mem	TODO: PENT,3DNOW	
PI2FW	mmxreg,mmxrm	PENT,3DNOW	PI2FW mmxreg, mmx/mem	TODO: PENT,3DNOW	
PSWAPD	mmxreg,mmxrm	PENT,3DNOW	PSWAPD mmxreg, mmx/mem	TODO: PENT,3DNOW	
MASKMOVDQU	xmmreg,xmmreg	WILLAMETTE,SSE2	MASKMOVDQU xmm, xmm	Store Selected Bytes of Double Quadword	MASKMOVDQU.html
CLFLUSH	mem	WILLAMETTE,SSE2	CLFLUSH mem	Flush Cache Line	CLFLUSH.html
MOVNTDQ	mem,xmmreg	WILLAMETTE,SSE2,SO	MOVNTDQ mem, xmm	Store Double Quadword Using Non-Temporal Hint	MOVNTDQ.html
MOVNTI	mem,reg32	WILLAMETTE,SD	MOVNTI mem, r32	Store Doubleword Using Non-Temporal Hint	MOVNTI.html
MOVNTI	mem,reg64	X64	MOVNTI mem, r64	Store Doubleword Using Non-Temporal Hint	MOVNTI.html
MOVNTPD	mem,xmmreg	WILLAMETTE,SSE2,SO	MOVNTPD mem, xmm	Store Packed Double-Precision Floating-Point Values Using Non-Temporal Hint	MOVNTPD.html
MOVDQA	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVDQA xmm, xmm	Move Aligned Double Quadword	MOVDQA.html
MOVDQA	mem,xmmreg	WILLAMETTE,SSE2,SO	MOVDQA mem, xmm	Move Aligned Double Quadword	MOVDQA.html
MOVDQA	xmmreg,mem	WILLAMETTE,SSE2,SO	MOVDQA xmm, mem	Move Aligned Double Quadword	MOVDQA.html
MOVDQA	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVDQA xmm, xmm	Move Aligned Double Quadword	MOVDQA.html
MOVDQU	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVDQU xmm, xmm	Move Unaligned Double Quadword	MOVDQU.html
MOVDQU	mem,xmmreg	WILLAMETTE,SSE2,SO	MOVDQU mem, xmm	Move Unaligned Double Quadword	MOVDQU.html
MOVDQU	xmmreg,mem	WILLAMETTE,SSE2,SO	MOVDQU xmm, mem	Move Unaligned Double Quadword	MOVDQU.html
MOVDQU	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVDQU xmm, xmm	Move Unaligned Double Quadword	MOVDQU.html
MOVDQ2Q	mmxreg,xmmreg	WILLAMETTE,SSE2	MOVDQ2Q mmxreg, xmm	Move Quadword from XMM to MMX Technology Register	MOVDQ2Q.html
MOVQ2DQ	xmmreg,mmxreg	WILLAMETTE,SSE2	MOVQ2DQ xmm, mmxreg	Move Quadword from MMX Technology to XMM Register	MOVQ2DQ.html
PADDQ	mmxreg,mmxrm	WILLAMETTE,MMX	PADDQ mmxreg, mmx/mem	Add Packed Quadword Integers	PADDQ.html
PADDQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PADDQ xmm, xmm/m128	Add Packed Quadword Integers	PADDQ.html
PMULUDQ	mmxreg,mmxrm	WILLAMETTE,SSE2,SO	PMULUDQ mmxreg, mmx/mem	Multiply Packed Unsigned Doubleword Integers	PMULUDQ.html
PMULUDQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PMULUDQ xmm, xmm/m128	Multiply Packed Unsigned Doubleword Integers	PMULUDQ.html
PSHUFD	xmmreg,xmmreg,imm	WILLAMETTE,SSE2	PSHUFD xmm, xmm, imm	Shuffle Packed Doublewords	PSHUFD.html
PSHUFD	xmmreg,mem,imm	WILLAMETTE,SSE2	PSHUFD xmm, mem, imm	Shuffle Packed Doublewords	PSHUFD.html
PSHUFHW	xmmreg,xmmreg,imm	WILLAMETTE,SSE2	PSHUFHW xmm, xmm, imm	Shuffle Packed High Words	PSHUFHW.html
PSHUFHW	xmmreg,mem,imm	WILLAMETTE,SSE2	PSHUFHW xmm, mem, imm	Shuffle Packed High Words	PSHUFHW.html
PSHUFLW	xmmreg,xmmreg,imm	WILLAMETTE,SSE2	PSHUFLW xmm, xmm, imm	Shuffle Packed Low Words	PSHUFLW.html
PSHUFLW	xmmreg,mem,imm	WILLAMETTE,SSE2	PSHUFLW xmm, mem, imm	Shuffle Packed Low Words	PSHUFLW.html
PSLLDQ	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSLLDQ xmm, imm	Shift Double Quadword Left Logical	PSLLDQ.html
PSRLDQ	xmmreg,imm	WILLAMETTE,SSE2,AR1	PSRLDQ xmm, imm	Shift Double Quadword Right Logical	PSRLDQ.html
PSUBQ	mmxreg,mmxrm	WILLAMETTE,SSE2,SO	PSUBQ mmxreg, mmx/mem	Subtract Packed Quadword Integers	PSUBQ.html
PSUBQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PSUBQ xmm, xmm/m128	Subtract Packed Quadword Integers	PSUBQ.html
PUNPCKHQDQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PUNPCKHQDQ xmm, xmm/m128	Unpack High Data	PUNPCKHBW:PUNPCKHWD:PUNPCKHDQ:PUNPCKHQDQ.html
PUNPCKLQDQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	PUNPCKLQDQ xmm, xmm/m128	Unpack Low Data	PUNPCKLBW:PUNPCKLWD:PUNPCKLDQ:PUNPCKLQDQ.html
ADDPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	ADDPD xmm, xmm/m128	Add Packed Double-Precision Floating-Point Values	ADDPD.html
ADDSD	xmmreg,xmmrm	WILLAMETTE,SSE2	ADDSD xmm, xmm/m128	Add Scalar Double-Precision Floating-Point Values	ADDSD.html
ANDNPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	ANDNPD xmm, xmm/m128	Bitwise Logical AND NOT of Packed Double-Precision Floating-Point Values	ANDNPD.html
ANDPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	ANDPD xmm, xmm/m128	Bitwise Logical AND of Packed Double-Precision Floating-Point Values	ANDPD.html
CMPEQPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CMPEQPD xmm, xmm/m128	TODO: WILLAMETTE,SSE2,SO	
CMPEQSD	xmmreg,xmmrm	WILLAMETTE,SSE2	CMPEQSD xmm, xmm/m128	TODO: WILLAMETTE,SSE2	
CMPLEPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CMPLEPD xmm, xmm/m128	TODO: WILLAMETTE,SSE2,SO	
CMPLESD	xmmreg,xmmrm	WILLAMETTE,SSE2	CMPLESD xmm, xmm/m128	TODO: WILLAMETTE,SSE2	
CMPLTPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CMPLTPD xmm, xmm/m128	TODO: WILLAMETTE,SSE2,SO	
CMPLTSD	xmmreg,xmmrm	WILLAMETTE,SSE2	CMPLTSD xmm, xmm/m128	TODO: WILLAMETTE,SSE2	
CMPNEQPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CMPNEQPD xmm, xmm/m128	TODO: WILLAMETTE,SSE2,SO	
CMPNEQSD	xmmreg,xmmrm	WILLAMETTE,SSE2	CMPNEQSD xmm, xmm/m128	TODO: WILLAMETTE,SSE2	
CMPNLEPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CMPNLEPD xmm, xmm/m128	TODO: WILLAMETTE,SSE2,SO	
CMPNLESD	xmmreg,xmmrm	WILLAMETTE,SSE2	CMPNLESD xmm, xmm/m128	TODO: WILLAMETTE,SSE2	
CMPNLTPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CMPNLTPD xmm, xmm/m128	TODO: WILLAMETTE,SSE2,SO	
CMPNLTSD	xmmreg,xmmrm	WILLAMETTE,SSE2	CMPNLTSD xmm, xmm/m128	TODO: WILLAMETTE,SSE2	
CMPORDPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CMPORDPD xmm, xmm/m128	TODO: WILLAMETTE,SSE2,SO	
CMPORDSD	xmmreg,xmmrm	WILLAMETTE,SSE2	CMPORDSD xmm, xmm/m128	TODO: WILLAMETTE,SSE2	
CMPUNORDPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CMPUNORDPD xmm, xmm/m128	TODO: WILLAMETTE,SSE2,SO	
CMPUNORDSD	xmmreg,xmmrm	WILLAMETTE,SSE2	CMPUNORDSD xmm, xmm/m128	TODO: WILLAMETTE,SSE2	
CMPPD	xmmreg,xmmrm128,imm8	WILLAMETTE,SSE2	CMPPD xmm, xmm/m128, imm8	Compare Packed Double-Precision Floating-Point Values	CMPPD.html
COMISD	xmmreg,xmmrm	WILLAMETTE,SSE2	COMISD xmm, xmm/m128	Compare Scalar Ordered Double-Precision Floating-Point Values and Set EFLAGS	COMISD.html
CVTDQ2PD	xmmreg,xmmrm	WILLAMETTE,SSE2	CVTDQ2PD xmm, xmm/m128	Convert Packed Dword Integers to Packed Double-Precision FP Values	CVTDQ2PD.html
CVTDQ2PS	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CVTDQ2PS xmm, xmm/m128	Convert Packed Dword Integers to Packed Single-Precision FP Values	CVTDQ2PS.html
CVTPD2DQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CVTPD2DQ xmm, xmm/m128	Convert Packed Double-Precision FP Values to Packed Dword Integers	CVTPD2DQ.html
CVTPD2PI	mmxreg,xmmrm	WILLAMETTE,SSE2,SO	CVTPD2PI mmxreg, xmm/m128	Convert Packed Double-Precision FP Values to Packed Dword Integers	CVTPD2PI.html
CVTPD2PS	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CVTPD2PS xmm, xmm/m128	Convert Packed Double-Precision FP Values to Packed Single-Precision FP Values	CVTPD2PS.html
CVTPI2PD	xmmreg,mmxrm	WILLAMETTE,SSE2	CVTPI2PD xmm, mmx/mem	Convert Packed Dword Integers to Packed Double-Precision FP Values	CVTPI2PD.html
CVTPS2DQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CVTPS2DQ xmm, xmm/m128	Convert Packed Single-Precision FP Values to Packed Dword Integers	CVTPS2DQ.html
CVTPS2PD	xmmreg,xmmrm	WILLAMETTE,SSE2	CVTPS2PD xmm, xmm/m128	Convert Packed Single-Precision FP Values to Packed Double-Precision FP Values	CVTPS2PD.html
CVTSD2SI	reg32,xmmreg	WILLAMETTE,SSE2,AR1	CVTSD2SI r32, xmm	Convert Scalar Double-Precision FP Value to Integer	CVTSD2SI.html
CVTSD2SI	reg32,mem	WILLAMETTE,SSE2,AR1	CVTSD2SI r32, mem	Convert Scalar Double-Precision FP Value to Integer	CVTSD2SI.html
CVTSD2SI	reg64,xmmreg	X64,SSE2,AR1	CVTSD2SI r64, xmm	Convert Scalar Double-Precision FP Value to Integer	CVTSD2SI.html
CVTSD2SI	reg64,mem	X64,SSE2,AR1	CVTSD2SI r64, mem	Convert Scalar Double-Precision FP Value to Integer	CVTSD2SI.html
CVTSD2SS	xmmreg,xmmrm	WILLAMETTE,SSE2	CVTSD2SS xmm, xmm/m128	Convert Scalar Double-Precision FP Value to Scalar Single-Precision FP Value	CVTSD2SS.html
CVTSI2SD	xmmreg,mem	WILLAMETTE,SSE2,SD,AR1,ND	CVTSI2SD xmm, mem	Convert Dword Integer to Scalar Double-Precision FP Value	CVTSI2SD.html
CVTSI2SD	xmmreg,rm32	WILLAMETTE,SSE2,SD,AR1	CVTSI2SD xmm, r/m32	Convert Dword Integer to Scalar Double-Precision FP Value	CVTSI2SD.html
CVTSI2SD	xmmreg,rm64	X64,SSE2,AR1	CVTSI2SD xmm, r/m64	Convert Dword Integer to Scalar Double-Precision FP Value	CVTSI2SD.html
CVTSS2SD	xmmreg,xmmrm	WILLAMETTE,SSE2,SD	CVTSS2SD xmm, xmm/m128	Convert Scalar Single-Precision FP Value to Scalar Double-Precision FP Value	CVTSS2SD.html
CVTTPD2PI	mmxreg,xmmrm	WILLAMETTE,SSE2,SO	CVTTPD2PI mmxreg, xmm/m128	Convert with Truncation Packed Double-Precision FP Values to Packed Dword Integers	CVTTPD2PI.html
CVTTPD2DQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CVTTPD2DQ xmm, xmm/m128	Convert with Truncation Packed Double-Precision FP Values to Packed Dword Integers	CVTTPD2DQ.html
CVTTPS2DQ	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	CVTTPS2DQ xmm, xmm/m128	Convert with Truncation Packed Single-Precision FP Values to Packed Dword Integers	CVTTPS2DQ.html
CVTTSD2SI	reg32,xmmreg	WILLAMETTE,SSE2,AR1	CVTTSD2SI r32, xmm	Convert with Truncation Scalar Double-Precision FP Value to Signed Integer	CVTTSD2SI.html
CVTTSD2SI	reg32,mem	WILLAMETTE,SSE2,AR1	CVTTSD2SI r32, mem	Convert with Truncation Scalar Double-Precision FP Value to Signed Integer	CVTTSD2SI.html
CVTTSD2SI	reg64,xmmreg	X64,SSE2,AR1	CVTTSD2SI r64, xmm	Convert with Truncation Scalar Double-Precision FP Value to Signed Integer	CVTTSD2SI.html
CVTTSD2SI	reg64,mem	X64,SSE2,AR1	CVTTSD2SI r64, mem	Convert with Truncation Scalar Double-Precision FP Value to Signed Integer	CVTTSD2SI.html
DIVPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	DIVPD xmm, xmm/m128	Divide Packed Double-Precision Floating-Point Values	DIVPD.html
DIVSD	xmmreg,xmmrm	WILLAMETTE,SSE2	DIVSD xmm, xmm/m128	Divide Scalar Double-Precision Floating-Point Values	DIVSD.html
MAXPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	MAXPD xmm, xmm/m128	Return Maximum Packed Double-Precision Floating-Point Values	MAXPD.html
MAXSD	xmmreg,xmmrm	WILLAMETTE,SSE2	MAXSD xmm, xmm/m128	Return Maximum Scalar Double-Precision Floating-Point Value	MAXSD.html
MINPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	MINPD xmm, xmm/m128	Return Minimum Packed Double-Precision Floating-Point Values	MINPD.html
MINSD	xmmreg,xmmrm	WILLAMETTE,SSE2	MINSD xmm, xmm/m128	Return Minimum Scalar Double-Precision Floating-Point Value	MINSD.html
MOVAPD	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVAPD xmm, xmm	Move Aligned Packed Double-Precision Floating-Point Values	MOVAPD.html
MOVAPD	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVAPD xmm, xmm	Move Aligned Packed Double-Precision Floating-Point Values	MOVAPD.html
MOVAPD	mem,xmmreg	WILLAMETTE,SSE2,SO	MOVAPD mem, xmm	Move Aligned Packed Double-Precision Floating-Point Values	MOVAPD.html
MOVAPD	xmmreg,mem	WILLAMETTE,SSE2,SO	MOVAPD xmm, mem	Move Aligned Packed Double-Precision Floating-Point Values	MOVAPD.html
MOVHPD	mem,xmmreg	WILLAMETTE,SSE2	MOVHPD mem, xmm	Move High Packed Double-Precision Floating-Point Value	MOVHPD.html
MOVHPD	xmmreg,mem	WILLAMETTE,SSE2	MOVHPD xmm, mem	Move High Packed Double-Precision Floating-Point Value	MOVHPD.html
MOVLPD	mem64,xmmreg	WILLAMETTE,SSE2	MOVLPD mem64, xmm	Move Low Packed Double-Precision Floating-Point Value	MOVLPD.html
MOVLPD	xmmreg,mem64	WILLAMETTE,SSE2	MOVLPD xmm, mem64	Move Low Packed Double-Precision Floating-Point Value	MOVLPD.html
MOVMSKPD	reg32,xmmreg	WILLAMETTE,SSE2	MOVMSKPD r32, xmm	Extract Packed Double-Precision Floating-Point Sign Mask	MOVMSKPD.html
MOVMSKPD	reg64,xmmreg	X64,SSE2	MOVMSKPD r64, xmm	Extract Packed Double-Precision Floating-Point Sign Mask	MOVMSKPD.html
MOVUPD	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVUPD xmm, xmm	Move Unaligned Packed Double-Precision Floating-Point Values	MOVUPD.html
MOVUPD	xmmreg,xmmreg	WILLAMETTE,SSE2	MOVUPD xmm, xmm	Move Unaligned Packed Double-Precision Floating-Point Values	MOVUPD.html
MOVUPD	mem,xmmreg	WILLAMETTE,SSE2,SO	MOVUPD mem, xmm	Move Unaligned Packed Double-Precision Floating-Point Values	MOVUPD.html
MOVUPD	xmmreg,mem	WILLAMETTE,SSE2,SO	MOVUPD xmm, mem	Move Unaligned Packed Double-Precision Floating-Point Values	MOVUPD.html
MULPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	MULPD xmm, xmm/m128	Multiply Packed Double-Precision Floating-Point Values	MULPD.html
MULSD	xmmreg,xmmrm	WILLAMETTE,SSE2	MULSD xmm, xmm/m128	Multiply Scalar Double-Precision Floating-Point Values	MULSD.html
ORPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	ORPD xmm, xmm/m128	Bitwise Logical OR of Double-Precision Floating-Point Values	ORPD.html
SHUFPD	xmmreg,xmmreg,imm	WILLAMETTE,SSE2	SHUFPD xmm, xmm, imm	Shuffle Packed Double-Precision Floating-Point Values	SHUFPD.html
SHUFPD	xmmreg,mem,imm	WILLAMETTE,SSE2	SHUFPD xmm, mem, imm	Shuffle Packed Double-Precision Floating-Point Values	SHUFPD.html
SQRTPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	SQRTPD xmm, xmm/m128	Compute Square Roots of Packed Double-Precision Floating-Point Values	SQRTPD.html
SQRTSD	xmmreg,xmmrm	WILLAMETTE,SSE2	SQRTSD xmm, xmm/m128	Compute Square Root of Scalar Double-Precision Floating-Point Value	SQRTSD.html
SUBPD	xmmreg,xmmrm	WILLAMETTE,SSE2,SO	SUBPD xmm, xmm/m128	Subtract Packed Double-Precision Floating-Point Values	SUBPD.html
SUBSD	xmmreg,xmmrm	WILLAMETTE,SSE2	SUBSD xmm, xmm/m128	Subtract Scalar Double-Precision Floating-Point Values	SUBSD.html
UCOMISD	xmmreg,xmmrm	WILLAMETTE,SSE2	UCOMISD xmm, xmm/m128	Unordered Compare Scalar Double-Precision Floating-Point Values and Set EFLAGS	UCOMISD.html
UNPCKHPD	xmmreg,xmmrm128	WILLAMETTE,SSE2	UNPCKHPD xmm, xmm/m128	Unpack and Interleave High Packed Double-Precision Floating-Point Values	UNPCKHPD.html
UNPCKLPD	xmmreg,xmmrm128	WILLAMETTE,SSE2	UNPCKLPD xmm, xmm/m128	Unpack and Interleave Low Packed Double-Precision Floating-Point Values	UNPCKLPD.html
XORPD	xmmreg,xmmrm128	WILLAMETTE,SSE2	XORPD xmm, xmm/m128	Bitwise Logical XOR for Double-Precision Floating-Point Values	XORPD.html
ADDSUBPD	xmmreg,xmmrm	PRESCOTT,SSE3,SO	ADDSUBPD xmm, xmm/m128	Packed Double-FP Add/Subtract. Input: {A0,A1},{B0,B1}; Output: {A0-B0},{A1+B1}	ADDSUBPD.html
ADDSUBPS	xmmreg,xmmrm	PRESCOTT,SSE3,SO	ADDSUBPS xmm, xmm/m128	Packed Single-FP Add/Subtract. Input: {A0,A1,A2,A3},{B0,B1,B2,B3}; Output: {A0-B0,A1+B1,A2-B2,A3+B3}	ADDSUBPS.html
HADDPD	xmmreg,xmmrm	PRESCOTT,SSE3,SO	HADDPD xmm, xmm/m128	Packed Double-FP Horizontal Add. Input: {A0,A1},{B0,B1}; Output: {A0+A1,B0+B1}	HADDPD.html
HADDPS	xmmreg,xmmrm	PRESCOTT,SSE3,SO	HADDPS xmm, xmm/m128	Packed Single-FP Horizontal Add. Input: {A0,A1,A2,A3},{B0,B1,B2,B3}; Output: {A0+A1,A2+A3,B0+B1,B2+B3}	HADDPS.html
HSUBPD	xmmreg,xmmrm	PRESCOTT,SSE3,SO	HSUBPD xmm, xmm/m128	Packed Double-FP Horizontal Subtract. Input: {A0,A1},{B0,B1}; Output: {A0-A1,B0-B1}	HSUBPD.html
HSUBPS	xmmreg,xmmrm	PRESCOTT,SSE3,SO	HSUBPS xmm, xmm/m128	Packed Single-FP Horizontal Subtract. Input: {A0,A1,A2,A3},{B0,B1,B2,B3}; Output: {A0-A1,A2-A3,B0-B1,B2-B3}	HSUBPS.html
LDDQU	xmmreg,mem	PRESCOTT,SSE3,SO	LDDQU xmm, mem	Load Unaligned Integer 128 Bits	LDDQU.html
MOVDDUP	xmmreg,xmmrm	PRESCOTT,SSE3	MOVDDUP xmm, xmm/m128	Move One Double-FP and Duplicate	MOVDDUP.html
MOVSHDUP	xmmreg,xmmrm	PRESCOTT,SSE3	MOVSHDUP xmm, xmm/m128	Move Packed Single-FP High and Duplicate	MOVSHDUP.html
MOVSLDUP	xmmreg,xmmrm	PRESCOTT,SSE3	MOVSLDUP xmm, xmm/m128	Move Packed Single-FP Low and Duplicate	MOVSLDUP.html
CLGI	none	VMX,AMD	CLGI 	TODO: VMX,AMD	
STGI	none	VMX,AMD	STGI 	TODO: VMX,AMD	
VMCALL	none	VMX	VMCALL 	TODO: VMX	
VMCLEAR	mem	VMX	VMCLEAR mem	TODO: VMX	
VMFUNC	none	VMX	VMFUNC 	TODO: VMX	
VMLAUNCH	none	VMX	VMLAUNCH 	TODO: VMX	
VMLOAD	none	VMX,AMD	VMLOAD 	TODO: VMX,AMD	
VMMCALL	none	VMX,AMD	VMMCALL 	TODO: VMX,AMD	
VMPTRLD	mem	VMX	VMPTRLD mem	TODO: VMX	
VMPTRST	mem	VMX	VMPTRST mem	TODO: VMX	
VMREAD	rm32,reg32	VMX,NOLONG,SD	VMREAD r/m32, r32	TODO: VMX,NOLONG,SD,X64	
VMREAD	rm64,reg64	X64,VMX	VMREAD r/m64, r64	TODO: VMX,NOLONG,SD,X64	
VMRESUME	none	VMX	VMRESUME 	TODO: VMX	
VMRUN	none	VMX,AMD	VMRUN 	TODO: VMX,AMD	
VMSAVE	none	VMX,AMD	VMSAVE 	TODO: VMX,AMD	
VMWRITE	reg32,rm32	VMX,NOLONG,SD	VMWRITE r32, r/m32	TODO: VMX,NOLONG,SD,X64	
VMWRITE	reg64,rm64	X64,VMX	VMWRITE r64, r/m64	TODO: VMX,NOLONG,SD,X64	
VMXOFF	none	VMX	VMXOFF 	TODO: VMX	
VMXON	mem	VMX	VMXON mem	TODO: VMX	
INVEPT	reg32,mem	VMX,SO,NOLONG	INVEPT r32, mem	TODO: VMX,SO,NOLONG,LONG	
INVEPT	reg64,mem	VMX,SO,LONG	INVEPT r64, mem	TODO: VMX,SO,NOLONG,LONG	
INVVPID	reg32,mem	VMX,SO,NOLONG	INVVPID r32, mem	TODO: VMX,SO,NOLONG,LONG	
INVVPID	reg64,mem	VMX,SO,LONG	INVVPID r64, mem	TODO: VMX,SO,NOLONG,LONG	
PABSB	mmxreg,mmxrm	SSSE3,MMX	PABSB mmxreg, mmx/mem	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSB	xmmreg,xmmrm	SSSE3	PABSB xmm, xmm/m128	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSW	mmxreg,mmxrm	SSSE3,MMX	PABSW mmxreg, mmx/mem	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSW	xmmreg,xmmrm	SSSE3	PABSW xmm, xmm/m128	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSD	mmxreg,mmxrm	SSSE3,MMX	PABSD mmxreg, mmx/mem	Packed Absolute Value	PABSB:PABSW:PABSD.html
PABSD	xmmreg,xmmrm	SSSE3	PABSD xmm, xmm/m128	Packed Absolute Value	PABSB:PABSW:PABSD.html
PALIGNR	mmxreg,mmxrm,imm	SSSE3,MMX	PALIGNR mmxreg, mmx/mem, imm	Packed Align Right	PALIGNR.html
PALIGNR	xmmreg,xmmrm,imm	SSSE3	PALIGNR xmm, xmm/m128, imm	Packed Align Right	PALIGNR.html
PHADDW	mmxreg,mmxrm	SSSE3,MMX	PHADDW mmxreg, mmx/mem	Packed Horizontal Add	PHADDW:PHADDD.html
PHADDW	xmmreg,xmmrm	SSSE3	PHADDW xmm, xmm/m128	Packed Horizontal Add	PHADDW:PHADDD.html
PHADDD	mmxreg,mmxrm	SSSE3,MMX	PHADDD mmxreg, mmx/mem	Packed Horizontal Add	PHADDW:PHADDD.html
PHADDD	xmmreg,xmmrm	SSSE3	PHADDD xmm, xmm/m128	Packed Horizontal Add	PHADDW:PHADDD.html
PHADDSW	mmxreg,mmxrm	SSSE3,MMX	PHADDSW mmxreg, mmx/mem	Packed Horizontal Add and Saturate	PHADDSW.html
PHADDSW	xmmreg,xmmrm	SSSE3	PHADDSW xmm, xmm/m128	Packed Horizontal Add and Saturate	PHADDSW.html
PHSUBW	mmxreg,mmxrm	SSSE3,MMX	PHSUBW mmxreg, mmx/mem	Packed Horizontal Subtract	PHSUBW:PHSUBD.html
PHSUBW	xmmreg,xmmrm	SSSE3	PHSUBW xmm, xmm/m128	Packed Horizontal Subtract	PHSUBW:PHSUBD.html
PHSUBD	mmxreg,mmxrm	SSSE3,MMX	PHSUBD mmxreg, mmx/mem	Packed Horizontal Subtract	PHSUBW:PHSUBD.html
PHSUBD	xmmreg,xmmrm	SSSE3	PHSUBD xmm, xmm/m128	Packed Horizontal Subtract	PHSUBW:PHSUBD.html
PHSUBSW	mmxreg,mmxrm	SSSE3,MMX	PHSUBSW mmxreg, mmx/mem	Packed Horizontal Subtract and Saturate	PHSUBSW.html
PHSUBSW	xmmreg,xmmrm	SSSE3	PHSUBSW xmm, xmm/m128	Packed Horizontal Subtract and Saturate	PHSUBSW.html
PMADDUBSW	mmxreg,mmxrm	SSSE3,MMX	PMADDUBSW mmxreg, mmx/mem	Multiply and Add Packed Signed and Unsigned Bytes	PMADDUBSW.html
PMADDUBSW	xmmreg,xmmrm	SSSE3	PMADDUBSW xmm, xmm/m128	Multiply and Add Packed Signed and Unsigned Bytes	PMADDUBSW.html
PMULHRSW	mmxreg,mmxrm	SSSE3,MMX	PMULHRSW mmxreg, mmx/mem	Packed Multiply High with Round and Scale	PMULHRSW.html
PMULHRSW	xmmreg,xmmrm	SSSE3	PMULHRSW xmm, xmm/m128	Packed Multiply High with Round and Scale	PMULHRSW.html
PSHUFB	mmxreg,mmxrm	SSSE3,MMX	PSHUFB mmxreg, mmx/mem	Packed Shuffle Bytes	PSHUFB.html
PSHUFB	xmmreg,xmmrm	SSSE3	PSHUFB xmm, xmm/m128	Packed Shuffle Bytes	PSHUFB.html
PSIGNB	mmxreg,mmxrm	SSSE3,MMX	PSIGNB mmxreg, mmx/mem	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGNB	xmmreg,xmmrm	SSSE3	PSIGNB xmm, xmm/m128	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGNW	mmxreg,mmxrm	SSSE3,MMX	PSIGNW mmxreg, mmx/mem	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGNW	xmmreg,xmmrm	SSSE3	PSIGNW xmm, xmm/m128	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGND	mmxreg,mmxrm	SSSE3,MMX	PSIGND mmxreg, mmx/mem	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
PSIGND	xmmreg,xmmrm	SSSE3	PSIGND xmm, xmm/m128	Packed SIGN	PSIGNB:PSIGNW:PSIGND.html
EXTRQ	xmmreg,imm,imm	SSE4A,AMD	EXTRQ xmm, imm, imm	TODO: SSE4A,AMD	
EXTRQ	xmmreg,xmmreg	SSE4A,AMD	EXTRQ xmm, xmm	TODO: SSE4A,AMD	
INSERTQ	xmmreg,xmmreg,imm,imm	SSE4A,AMD	INSERTQ xmm, xmm, imm, imm	TODO: SSE4A,AMD	
INSERTQ	xmmreg,xmmreg	SSE4A,AMD	INSERTQ xmm, xmm	TODO: SSE4A,AMD	
MOVNTSD	mem,xmmreg	SSE4A,AMD	MOVNTSD mem, xmm	TODO: SSE4A,AMD	
MOVNTSS	mem,xmmreg	SSE4A,AMD,SD	MOVNTSS mem, xmm	TODO: SSE4A,AMD,SD	
LZCNT	reg16,rm16	P6,AMD	LZCNT r16, r/m16	Leading Zero Count	LZCNT.html
LZCNT	reg32,rm32	P6,AMD	LZCNT r32, r/m32	Leading Zero Count	LZCNT.html
LZCNT	reg64,rm64	X64,AMD	LZCNT r64, r/m64	Leading Zero Count	LZCNT.html
BLENDPD	xmmreg,xmmrm,imm	SSE41	BLENDPD xmm, xmm/m128, imm	Blend Packed Double Precision Floating-Point Values	BLENDPD.html
BLENDPS	xmmreg,xmmrm,imm	SSE41	BLENDPS xmm, xmm/m128, imm	Blend Packed Single Precision Floating-Point Values	BLENDPS.html
BLENDVPD	xmmreg,xmmrm,xmm0	SSE41	BLENDVPD xmm, xmm/m128, XMM0	Variable Blend Packed Double Precision Floating-Point Values	BLENDVPD.html
BLENDVPD	xmmreg,xmmrm	SSE41	BLENDVPD xmm, xmm/m128	Variable Blend Packed Double Precision Floating-Point Values	BLENDVPD.html
BLENDVPS	xmmreg,xmmrm,xmm0	SSE41	BLENDVPS xmm, xmm/m128, XMM0	Variable Blend Packed Single Precision Floating-Point Values	BLENDVPS.html
BLENDVPS	xmmreg,xmmrm	SSE41	BLENDVPS xmm, xmm/m128	Variable Blend Packed Single Precision Floating-Point Values	BLENDVPS.html
DPPD	xmmreg,xmmrm,imm	SSE41	DPPD xmm, xmm/m128, imm	Dot Product of Packed Double Precision Floating-Point Values	DPPD.html
DPPS	xmmreg,xmmrm,imm	SSE41	DPPS xmm, xmm/m128, imm	Dot Product of Packed Single Precision Floating-Point Values	DPPS.html
EXTRACTPS	rm32,xmmreg,imm	SSE41	EXTRACTPS r/m32, xmm, imm	Extract Packed Single Precision Floating-Point Value	EXTRACTPS.html
EXTRACTPS	reg64,xmmreg,imm	SSE41,X64	EXTRACTPS r64, xmm, imm	Extract Packed Single Precision Floating-Point Value	EXTRACTPS.html
INSERTPS	xmmreg,xmmrm,imm	SSE41,SD	INSERTPS xmm, xmm/m128, imm	Insert Packed Single Precision Floating-Point Value	INSERTPS.html
MOVNTDQA	xmmreg,mem128	SSE41	MOVNTDQA xmm, mem128	Load Double Quadword Non-Temporal Aligned Hint	MOVNTDQA.html
MPSADBW	xmmreg,xmmrm,imm	SSE41	MPSADBW xmm, xmm/m128, imm	Compute Multiple Packed Sums of Absolute Difference	MPSADBW.html
PACKUSDW	xmmreg,xmmrm	SSE41	PACKUSDW xmm, xmm/m128	Pack with Unsigned Saturation	PACKUSDW.html
PBLENDVB	xmmreg,xmmrm,xmm0	SSE41	PBLENDVB xmm, xmm/m128, XMM0	Variable Blend Packed Bytes	PBLENDVB.html
PBLENDVB	xmmreg,xmmrm	SSE41	PBLENDVB xmm, xmm/m128	Variable Blend Packed Bytes	PBLENDVB.html
PBLENDW	xmmreg,xmmrm,imm	SSE41	PBLENDW xmm, xmm/m128, imm	Blend Packed Words	PBLENDW.html
PCMPEQQ	xmmreg,xmmrm	SSE41	PCMPEQQ xmm, xmm/m128	Compare Packed Qword Data for Equal	PCMPEQQ.html
PEXTRB	reg32,xmmreg,imm	SSE41	PEXTRB r32, xmm, imm	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PEXTRB	mem8,xmmreg,imm	SSE41	PEXTRB mem8, xmm, imm	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PEXTRB	reg64,xmmreg,imm	SSE41,X64	PEXTRB r64, xmm, imm	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PEXTRD	rm32,xmmreg,imm	SSE41	PEXTRD r/m32, xmm, imm	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PEXTRQ	rm64,xmmreg,imm	SSE41,X64	PEXTRQ r/m64, xmm, imm	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
PHMINPOSUW	xmmreg,xmmrm	SSE41	PHMINPOSUW xmm, xmm/m128	Packed Horizontal Word Minimum	PHMINPOSUW.html
PINSRB	xmmreg,mem,imm	SSE41	PINSRB xmm, mem, imm	Insert Byte	PINSRB:PINSRD:PINSRQ.html
PINSRB	xmmreg,rm8,imm	SSE41	PINSRB xmm, r/m8, imm	Insert Byte	PINSRB:PINSRD:PINSRQ.html
PINSRB	xmmreg,reg32,imm	SSE41	PINSRB xmm, r32, imm	Insert Byte	PINSRB:PINSRD:PINSRQ.html
PINSRD	xmmreg,mem,imm	SSE41	PINSRD xmm, mem, imm	Insert Dword	PINSRB:PINSRD:PINSRQ.html
PINSRD	xmmreg,rm32,imm	SSE41	PINSRD xmm, r/m32, imm	Insert Dword	PINSRB:PINSRD:PINSRQ.html
PINSRQ	xmmreg,mem,imm	SSE41,X64	PINSRQ xmm, mem, imm	Insert Qword	PINSRB:PINSRD:PINSRQ.html
PINSRQ	xmmreg,rm64,imm	SSE41,X64	PINSRQ xmm, r/m64, imm	Insert Qword	PINSRB:PINSRD:PINSRQ.html
PMAXSB	xmmreg,xmmrm	SSE41	PMAXSB xmm, xmm/m128	Maximum of Packed Signed Byte Integers	PMAXSB.html
PMAXSD	xmmreg,xmmrm	SSE41	PMAXSD xmm, xmm/m128	Maximum of Packed Signed Dword Integers	PMAXSD.html
PMAXUD	xmmreg,xmmrm	SSE41	PMAXUD xmm, xmm/m128	Maximum of Packed Unsigned Dword Integers	PMAXUD.html
PMAXUW	xmmreg,xmmrm	SSE41	PMAXUW xmm, xmm/m128	Maximum of Packed Word Integers	PMAXUW.html
PMINSB	xmmreg,xmmrm	SSE41	PMINSB xmm, xmm/m128	Minimum of Packed Signed Byte Integers	PMINSB.html
PMINSD	xmmreg,xmmrm	SSE41	PMINSD xmm, xmm/m128	Minimum of Packed Dword Integers	PMINSD.html
PMINUD	xmmreg,xmmrm	SSE41	PMINUD xmm, xmm/m128	Minimum of Packed Dword Integers	PMINUD.html
PMINUW	xmmreg,xmmrm	SSE41	PMINUW xmm, xmm/m128	Minimum of Packed Word Integers	PMINUW.html
PMOVSXBW	xmmreg,xmmrm	SSE41	PMOVSXBW xmm, xmm/m128	PMOVSXBW xmm1, xmm2/m64: Sign extend 8 packed signed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed signed 16-bit integers in xmm1	PMOVSX.html
PMOVSXBD	xmmreg,xmmrm	SSE41,SD	PMOVSXBD xmm, xmm/m128	PMOVSXBD xmm1, xmm2/m32: Sign extend 4 packed signed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed signed 32-bit integers in xmm1	PMOVSX.html
PMOVSXBQ	xmmreg,xmmrm	SSE41,SW	PMOVSXBQ xmm, xmm/m128	PMOVSXWD xmm1, xmm2/m64: Sign extend 4 packed signed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed signed 32-bit integers in xmm1	PMOVSX.html
PMOVSXWD	xmmreg,xmmrm	SSE41	PMOVSXWD xmm, xmm/m128	PMOVSXWD xmm1, xmm2/m64: Sign extend 4 packed signed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed signed 32-bit integers in xmm1	PMOVSX.html
PMOVSXWQ	xmmreg,xmmrm	SSE41,SD	PMOVSXWQ xmm, xmm/m128	PMOVSXWQ xmm1, xmm2/m32: Sign extend 2 packed signed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed signed 64-bit integers in xmm1	PMOVSX.html
PMOVSXDQ	xmmreg,xmmrm	SSE41	PMOVSXDQ xmm, xmm/m128	PMOVSXDQ xmm1, xmm2/m64: Sign extend 2 packed signed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed signed 64-bit integers in xmm1	PMOVSX.html
PMOVZXBW	xmmreg,xmmrm	SSE41	PMOVZXBW xmm, xmm/m128	PMOVZXBW xmm1, xmm2/m64: Zero extend 8 packed 8-bit integers in the low 8 bytes of xmm2/m64 to 8 packed 16-bit integers in xmm1	PMOVZX.html
PMOVZXBD	xmmreg,xmmrm	SSE41,SD	PMOVZXBD xmm, xmm/m128	PMOVZXBD xmm1, xmm2/m32: Zero extend 4 packed 8-bit integers in the low 4 bytes of xmm2/m32 to 4 packed 32-bit integers in xmm1	PMOVZX.html
PMOVZXBQ	xmmreg,xmmrm	SSE41,SW	PMOVZXBQ xmm, xmm/m128	PMOVZXBQ xmm1, xmm2/m16: Zero extend 2 packed 8-bit integers in the low 2 bytes of xmm2/m16 to 2 packed 64-bit integers in xmm1	PMOVZX.html
PMOVZXWD	xmmreg,xmmrm	SSE41	PMOVZXWD xmm, xmm/m128	PMOVZXWD xmm1, xmm2/m64: Zero extend 4 packed 16-bit integers in the low 8 bytes of xmm2/m64 to 4 packed 32-bit integers in xmm1	PMOVZX.html
PMOVZXWQ	xmmreg,xmmrm	SSE41,SD	PMOVZXWQ xmm, xmm/m128	PMOVZXWQ xmm1, xmm2/m32: Zero extend 2 packed 16-bit integers in the low 4 bytes of xmm2/m32 to 2 packed 64-bit integers in xmm1	PMOVZX.html
PMOVZXDQ	xmmreg,xmmrm	SSE41	PMOVZXDQ xmm, xmm/m128	PMOVZXDQ xmm1, xmm2/m64: Zero extend 2 packed 32-bit integers in the low 8 bytes of xmm2/m64 to 2 packed 64-bit integers in xmm1	PMOVZX.html
PMULDQ	xmmreg,xmmrm	SSE41	PMULDQ xmm, xmm/m128	Multiply Packed Signed Dword Integers	PMULDQ.html
PMULLD	xmmreg,xmmrm	SSE41	PMULLD xmm, xmm/m128	Multiply Packed Signed Dword Integers and Store Low Result	PMULLD.html
PTEST	xmmreg,xmmrm	SSE41	PTEST xmm, xmm/m128	Logical Compare	PTEST.html
ROUNDPD	xmmreg,xmmrm,imm	SSE41	ROUNDPD xmm, xmm/m128, imm	Round Packed Double Precision Floating-Point Values	ROUNDPD.html
ROUNDPS	xmmreg,xmmrm,imm	SSE41	ROUNDPS xmm, xmm/m128, imm	Round Packed Single Precision Floating-Point Values	ROUNDPS.html
ROUNDSD	xmmreg,xmmrm,imm	SSE41	ROUNDSD xmm, xmm/m128, imm	Round Scalar Double Precision Floating-Point Values	ROUNDSD.html
ROUNDSS	xmmreg,xmmrm,imm	SSE41	ROUNDSS xmm, xmm/m128, imm	Round Scalar Single Precision Floating-Point Values	ROUNDSS.html
CRC32	reg32,rm8	SSE42	CRC32 r32, r/m8	Accumulate CRC32 Value	CRC32.html
CRC32	reg32,rm16	SSE42	CRC32 r32, r/m16	Accumulate CRC32 Value	CRC32.html
CRC32	reg32,rm32	SSE42	CRC32 r32, r/m32	Accumulate CRC32 Value	CRC32.html
CRC32	reg64,rm8	SSE42,X64	CRC32 r64, r/m8	Accumulate CRC32 Value	CRC32.html
CRC32	reg64,rm64	SSE42,X64	CRC32 r64, r/m64	Accumulate CRC32 Value	CRC32.html
PCMPESTRI	xmmreg,xmmrm,imm	SSE42	PCMPESTRI xmm, xmm/m128, imm	Packed Compare Explicit Length Strings, Return Index	PCMPESTRI.html
PCMPESTRM	xmmreg,xmmrm,imm	SSE42	PCMPESTRM xmm, xmm/m128, imm	Packed Compare Explicit Length Strings, Return Mask	PCMPESTRM.html
PCMPISTRI	xmmreg,xmmrm,imm	SSE42	PCMPISTRI xmm, xmm/m128, imm	Packed Compare Implicit Length Strings, Return Index	PCMPISTRI.html
PCMPISTRM	xmmreg,xmmrm,imm	SSE42	PCMPISTRM xmm, xmm/m128, imm	Packed Compare Implicit Length Strings, Return Mask	PCMPISTRM.html
PCMPGTQ	xmmreg,xmmrm	SSE42	PCMPGTQ xmm, xmm/m128	Compare Packed Data for Greater Than	PCMPGTQ.html
POPCNT	reg16,rm16	NEHALEM,SW	POPCNT r16, r/m16	Return the Count of Number of Bits Set to 1	POPCNT.html
POPCNT	reg32,rm32	NEHALEM,SD	POPCNT r32, r/m32	Return the Count of Number of Bits Set to 1	POPCNT.html
POPCNT	reg64,rm64	NEHALEM,X64	POPCNT r64, r/m64	Return the Count of Number of Bits Set to 1	POPCNT.html
GETSEC	none	KATMAI	GETSEC 	TODO: KATMAI	
PFRCPV	mmxreg,mmxrm	PENT,3DNOW,CYRIX	PFRCPV mmxreg, mmx/mem	TODO: PENT,3DNOW,CYRIX	
PFRSQRTV	mmxreg,mmxrm	PENT,3DNOW,CYRIX	PFRSQRTV mmxreg, mmx/mem	TODO: PENT,3DNOW,CYRIX	
MOVBE	reg16,mem16	NEHALEM	MOVBE r16, mem16	Move Data After Swapping Bytes	MOVBE.html
MOVBE	reg32,mem32	NEHALEM	MOVBE r32, mem32	Move Data After Swapping Bytes	MOVBE.html
MOVBE	reg64,mem64	NEHALEM	MOVBE r64, mem64	Move Data After Swapping Bytes	MOVBE.html
MOVBE	mem16,reg16	NEHALEM	MOVBE mem16, r16	Move Data After Swapping Bytes	MOVBE.html
MOVBE	mem32,reg32	NEHALEM	MOVBE mem32, r32	Move Data After Swapping Bytes	MOVBE.html
MOVBE	mem64,reg64	NEHALEM	MOVBE mem64, r64	Move Data After Swapping Bytes	MOVBE.html
AESENC	xmmreg,xmmrm128	SSE,WESTMERE	AESENC xmm, xmm/m128	Perform One Round of an AES Encryption Flow	AESENC.html
AESENCLAST	xmmreg,xmmrm128	SSE,WESTMERE	AESENCLAST xmm, xmm/m128	Perform Last Round of an AES Encryption Flow	AESENCLAST.html
AESDEC	xmmreg,xmmrm128	SSE,WESTMERE	AESDEC xmm, xmm/m128	Perform One Round of an AES Decryption Flow	AESDEC.html
AESDECLAST	xmmreg,xmmrm128	SSE,WESTMERE	AESDECLAST xmm, xmm/m128	Perform Last Round of an AES Decryption Flow	AESDECLAST.html
AESIMC	xmmreg,xmmrm128	SSE,WESTMERE	AESIMC xmm, xmm/m128	Perform the AES InvMixColumn Transformation	AESIMC.html
AESKEYGENASSIST	xmmreg,xmmrm128,imm8	SSE,WESTMERE	AESKEYGENASSIST xmm, xmm/m128, imm8	AES Round Key Generation Assist	AESKEYGENASSIST.html
VAESENC	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VAESENC xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VAESENCLAST	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VAESENCLAST xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VAESDEC	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VAESDEC xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VAESDECLAST	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VAESDECLAST xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VAESIMC	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VAESIMC xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VAESKEYGENASSIST	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VAESKEYGENASSIST xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VADDPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VADDPD xmm, xmm, xmm/m128	Add Float64 Vectors	
VADDPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VADDPD ymm, ymm, ymm/m256	Add Float64 Vectors	
VADDPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VADDPD xmm|mask|z, xmm, xmm/m128|b32	Add Float64 Vectors	
VADDPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VADDPD ymm|mask|z, ymm, ymm/m256|b32	Add Float64 Vectors	
VADDPD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VADDPD zmm|mask|z, zmm, zmm/m512|b32|er	Add Float64 Vectors	
VADDPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VADDPS xmm, xmm, xmm/m128	Add Float32 Vectors	
VADDPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VADDPS ymm, ymm, ymm/m256	Add Float32 Vectors	
VADDPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VADDPS xmm|mask|z, xmm, xmm/m128|b32	Add Float32 Vectors	
VADDPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VADDPS ymm|mask|z, ymm, ymm/m256|b32	Add Float32 Vectors	
VADDPS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VADDPS zmm|mask|z, zmm, zmm/m512|b32|er	Add Float32 Vectors	
VADDSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VADDSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VADDSD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VADDSD xmm|mask|z, xmm, xmm/m64|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VADDSS	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VADDSS xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VADDSS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VADDSS xmm|mask|z, xmm, xmm/m32|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VADDSUBPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VADDSUBPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VADDSUBPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VADDSUBPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VADDSUBPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VADDSUBPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VADDSUBPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VADDSUBPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VANDPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VANDPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VANDPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VANDPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VANDPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512DQ,FUTURE	VANDPD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VANDPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VANDPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512DQ,FUTURE	VANDPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512DQ,FUTURE	VANDPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDPS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512DQ,FUTURE	VANDPS zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VANDNPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VANDNPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VANDNPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VANDNPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512DQ,FUTURE	VANDNPD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VANDNPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VANDNPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512DQ,FUTURE	VANDNPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512DQ,FUTURE	VANDNPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VANDNPS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512DQ,FUTURE	VANDNPS zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VBLENDPD	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VBLENDPD xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VBLENDPD	ymmreg,ymmreg*,ymmrm256,imm8	AVX,SANDYBRIDGE	VBLENDPD ymm, ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE	
VBLENDPS	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VBLENDPS xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VBLENDPS	ymmreg,ymmreg*,ymmrm256,imm8	AVX,SANDYBRIDGE	VBLENDPS ymm, ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE	
VBLENDVPD	xmmreg,xmmreg*,xmmrm128,xmmreg	AVX,SANDYBRIDGE	VBLENDVPD xmm, xmm, xmm/m128, xmm	TODO: AVX,SANDYBRIDGE	
VBLENDVPD	ymmreg,ymmreg*,ymmrm256,ymmreg	AVX,SANDYBRIDGE	VBLENDVPD ymm, ymm, ymm/m256, ymm	TODO: AVX,SANDYBRIDGE	
VBLENDVPS	xmmreg,xmmreg*,xmmrm128,xmmreg	AVX,SANDYBRIDGE	VBLENDVPS xmm, xmm, xmm/m128, xmm	TODO: AVX,SANDYBRIDGE	
VBLENDVPS	ymmreg,ymmreg*,ymmrm256,ymmreg	AVX,SANDYBRIDGE	VBLENDVPS ymm, ymm, ymm/m256, ymm	TODO: AVX,SANDYBRIDGE	
VBROADCASTSS	xmmreg,mem32	AVX,SANDYBRIDGE	VBROADCASTSS xmm, mem32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	ymmreg,mem32	AVX,SANDYBRIDGE	VBROADCASTSS ymm, mem32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	xmmreg,xmmreg	FUTURE,AVX2	VBROADCASTSS xmm, xmm	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	ymmreg,xmmreg	FUTURE,AVX2	VBROADCASTSS ymm, xmm	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	xmmreg|mask|z,mem32	AVX512VL,AVX512,FUTURE	VBROADCASTSS xmm|mask|z, mem32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	ymmreg|mask|z,mem32	AVX512VL,AVX512,FUTURE	VBROADCASTSS ymm|mask|z, mem32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	zmmreg|mask|z,mem32	AVX512,FUTURE	VBROADCASTSS zmm|mask|z, mem32	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VBROADCASTSS xmm|mask|z, xmm	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	ymmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VBROADCASTSS ymm|mask|z, xmm	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSS	zmmreg|mask|z,xmmreg	AVX512,FUTURE	VBROADCASTSS zmm|mask|z, xmm	Broadcast Float32 Vector	VBROADCAST.html
VBROADCASTSD	ymmreg,mem64	AVX,SANDYBRIDGE	VBROADCASTSD ymm, mem64	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	ymmreg,xmmreg	FUTURE,AVX2	VBROADCASTSD ymm, xmm	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	ymmreg|mask|z,mem64	AVX512VL,AVX512,FUTURE	VBROADCASTSD ymm|mask|z, mem64	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	zmmreg|mask|z,mem64	AVX512,FUTURE	VBROADCASTSD zmm|mask|z, mem64	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	ymmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VBROADCASTSD ymm|mask|z, xmm	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTSD	zmmreg|mask|z,xmmreg	AVX512,FUTURE	VBROADCASTSD zmm|mask|z, xmm	Broadcast Float64 Vector	VBROADCAST.html
VBROADCASTF128	ymmreg,mem128	AVX,SANDYBRIDGE	VBROADCASTF128 ymm, mem128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQ_OSPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQ_OSPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQ_OSPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQ_OSPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLT_OSPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLT_OSPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLTPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLTPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLTPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLTPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLE_OSPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLE_OSPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLEPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLEPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLEPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLEPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPUNORD_QPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPUNORD_QPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORDPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPUNORDPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPUNORDPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPUNORDPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQ_UQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQ_UQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLT_USPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLT_USPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLTPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLTPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLTPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLTPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLE_USPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLE_USPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLEPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLEPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLEPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLEPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPORD_QPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPORD_QPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPORD_QPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPORD_QPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPORDPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPORDPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPORDPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPORDPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQ_UQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQ_UQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGE_USPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGE_USPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGEPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGEPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGEPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGEPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGT_USPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGT_USPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGTPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGTPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGTPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGTPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPFALSE_OQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPFALSE_OQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSEPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPFALSEPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPFALSEPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPFALSEPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQ_OQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQ_OQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGE_OSPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGE_OSPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGEPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGEPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGEPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGEPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGT_OSPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGT_OSPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGTPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGTPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGTPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGTPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPTRUE_UQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPTRUE_UQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUEPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPTRUEPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPTRUEPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPTRUEPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLT_OQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLT_OQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLE_OQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLE_OQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPUNORD_SPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPUNORD_SPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQ_USPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQ_USPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLT_UQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLT_UQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLE_UQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLE_UQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPORD_SPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPORD_SPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPORD_SPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPORD_SPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQ_USPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQ_USPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGE_UQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGE_UQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGT_UQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGT_UQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPFALSE_OSPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPFALSE_OSPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQ_OSPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQ_OSPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGE_OQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGE_OQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGT_OQPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGT_OQPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPTRUE_USPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPTRUE_USPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPPD	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VCMPPD xmm, xmm, xmm/m128, imm8	Compare Float64 Vectors and Set Vector Mask	
VCMPPD	ymmreg,ymmreg*,ymmrm256,imm8	AVX,SANDYBRIDGE	VCMPPD ymm, ymm, ymm/m256, imm8	Compare Float64 Vectors and Set Vector Mask	
VCMPPD	kreg|mask,xmmreg,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VCMPPD kreg|mask, xmm, xmm/m128|b32, imm8	Compare Float64 Vectors and Set Vector Mask	
VCMPPD	kreg|mask,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VCMPPD kreg|mask, ymm, ymm/m256|b32, imm8	Compare Float64 Vectors and Set Vector Mask	
VCMPPD	kreg|mask,zmmreg,zmmrm512|b64|sae,imm8	AVX512,FUTURE	VCMPPD kreg|mask, zmm, zmm/m512|b32|sae, imm8	Compare Float64 Vectors and Set Vector Mask	
VCMPEQ_OSPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQ_OSPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQ_OSPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQ_OSPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQ_OSPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLT_OSPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLT_OSPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLTPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLTPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLTPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLTPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLE_OSPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLE_OSPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLEPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLEPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLEPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLEPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPUNORD_QPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPUNORD_QPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORDPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPUNORDPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPUNORDPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPUNORDPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQ_UQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQ_UQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLT_USPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLT_USPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLTPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLTPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLTPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLTPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLE_USPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLE_USPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLEPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLEPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLEPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLEPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPORD_QPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPORD_QPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPORD_QPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPORD_QPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPORDPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPORDPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPORDPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPORDPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQ_UQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQ_UQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGE_USPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGE_USPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGEPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGEPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGEPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGEPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGT_USPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGT_USPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGTPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGTPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGTPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGTPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPFALSE_OQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPFALSE_OQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSEPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPFALSEPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPFALSEPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPFALSEPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQ_OQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQ_OQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGE_OSPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGE_OSPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGEPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGEPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGEPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGEPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGT_OSPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGT_OSPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGTPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGTPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGTPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGTPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPTRUE_UQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPTRUE_UQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUEPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPTRUEPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPTRUEPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPTRUEPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLT_OQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLT_OQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPLE_OQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPLE_OQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPUNORD_SPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPUNORD_SPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQ_USPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQ_USPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLT_UQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLT_UQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNLE_UQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNLE_UQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPORD_SPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPORD_SPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPORD_SPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPORD_SPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPEQ_USPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPEQ_USPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGE_UQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGE_UQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNGT_UQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNGT_UQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPFALSE_OSPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPFALSE_OSPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPNEQ_OSPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPNEQ_OSPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGE_OQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGE_OQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPGT_OQPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPGT_OQPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VCMPTRUE_USPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VCMPTRUE_USPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VCMPPS	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VCMPPS xmm, xmm, xmm/m128, imm8	Compare Float32 Vectors and Set Vector Mask	
VCMPPS	ymmreg,ymmreg*,ymmrm256,imm8	AVX,SANDYBRIDGE	VCMPPS ymm, ymm, ymm/m256, imm8	Compare Float32 Vectors and Set Vector Mask	
VCMPPS	kreg|mask,xmmreg,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VCMPPS kreg|mask, xmm, xmm/m128|b32, imm8	Compare Float32 Vectors and Set Vector Mask	
VCMPPS	kreg|mask,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VCMPPS kreg|mask, ymm, ymm/m256|b32, imm8	Compare Float32 Vectors and Set Vector Mask	
VCMPPS	kreg|mask,zmmreg,zmmrm512|b32|sae,imm8	AVX512,FUTURE	VCMPPS kreg|mask, zmm, zmm/m512|b32|sae, imm8	Compare Float32 Vectors and Set Vector Mask	
VCMPEQ_OSSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQ_OSSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQ_OSSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLT_OSSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLTSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLTSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLE_OSSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLESD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLESD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPUNORD_QSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORDSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPUNORDSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQ_UQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLT_USSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLTSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLTSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLE_USSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLESD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLESD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPORD_QSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPORD_QSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPORDSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPORDSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQ_UQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGE_USSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGESD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGESD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGT_USSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGTSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGTSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPFALSE_OQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSESD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPFALSESD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQ_OQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGE_OSSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGESD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGESD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGT_OSSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGTSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGTSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPTRUE_UQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUESD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPTRUESD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLT_OQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLE_OQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPUNORD_SSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQ_USSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLT_UQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLE_UQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPORD_SSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPORD_SSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQ_USSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGE_UQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGT_UQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPFALSE_OSSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQ_OSSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGE_OQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGT_OQSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPTRUE_USSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPSD	xmmreg,xmmreg*,xmmrm64,imm8	AVX,SANDYBRIDGE	VCMPSD xmm, xmm, xmm/m64, imm8	Compare Scalar Double-Precision Floating-Point Values	CMPSD.html
VCMPSD	kreg|mask,xmmreg,xmmrm64|sae,imm8	AVX512,FUTURE	VCMPSD kreg|mask, xmm, xmm/m64|sae, imm8	Compare Scalar Double-Precision Floating-Point Values	CMPSD.html
VCMPEQ_OSSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQ_OSSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_OSSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQ_OSSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLT_OSSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLT_OSSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLTSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLTSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLE_OSSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLE_OSSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLESS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLESS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_QSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPUNORD_QSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORDSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPUNORDSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_UQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQ_UQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLT_USSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLT_USSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLTSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLTSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLE_USSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLE_USSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLESS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLESS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPORD_QSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPORD_QSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPORDSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPORDSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_UQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQ_UQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGE_USSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGE_USSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGESS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGESS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGT_USSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGT_USSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGTSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGTSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPFALSE_OQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSESS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPFALSESS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQ_OQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGE_OSSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGE_OSSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGESS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGESS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGT_OSSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGT_OSSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGTSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGTSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_UQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPTRUE_UQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUESS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPTRUESS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLT_OQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLT_OQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPLE_OQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPLE_OQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPUNORD_SSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPUNORD_SSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_USSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQ_USSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLT_UQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLT_UQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNLE_UQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNLE_UQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPORD_SSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPORD_SSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPEQ_USSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPEQ_USSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGE_UQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGE_UQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNGT_UQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNGT_UQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPFALSE_OSSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPFALSE_OSSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPNEQ_OSSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPNEQ_OSSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGE_OQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGE_OQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPGT_OQSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPGT_OQSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPTRUE_USSS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCMPTRUE_USSS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE	
VCMPSS	xmmreg,xmmreg*,xmmrm64,imm8	AVX,SANDYBRIDGE	VCMPSS xmm, xmm, xmm/m64, imm8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCMPSS	kreg|mask,xmmreg,xmmrm32|sae,imm8	AVX512,FUTURE	VCMPSS kreg|mask, xmm, xmm/m32|sae, imm8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCOMISD	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VCOMISD xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCOMISD	xmmreg,xmmrm64|sae	AVX512,FUTURE	VCOMISD xmm, xmm/m64|sae	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCOMISS	xmmreg,xmmrm32	AVX,SANDYBRIDGE	VCOMISS xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCOMISS	xmmreg,xmmrm32|sae	AVX512,FUTURE	VCOMISS xmm, xmm/m32|sae	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTDQ2PD	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VCVTDQ2PD xmm, xmm/m64	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PD	ymmreg,xmmrm128	AVX,SANDYBRIDGE	VCVTDQ2PD ymm, xmm/m128	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PD	xmmreg|mask|z,xmmrm64|b32	AVX512VL,AVX512,FUTURE	VCVTDQ2PD xmm|mask|z, xmm/m64|b32	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PD	ymmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VCVTDQ2PD ymm|mask|z, xmm/m128|b32	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PD	zmmreg|mask|z,ymmrm256|b32|er	AVX512,FUTURE	VCVTDQ2PD zmm|mask|z, ymm/m256|b32|er	Convert Int32 Vector to Float64 Vector	
VCVTDQ2PS	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VCVTDQ2PS xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTDQ2PS	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VCVTDQ2PS ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTDQ2PS	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VCVTDQ2PS xmm|mask|z, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTDQ2PS	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VCVTDQ2PS ymm|mask|z, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTDQ2PS	zmmreg|mask|z,zmmrm512|b32|er	AVX512,FUTURE	VCVTDQ2PS zmm|mask|z, zmm/m512|b32|er	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	xmmreg,xmmreg	AVX,SANDYBRIDGE	VCVTPD2DQ xmm, xmm	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	xmmreg,mem128	AVX,SANDYBRIDGE,SO	VCVTPD2DQ xmm, mem128	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	xmmreg,ymmreg	AVX,SANDYBRIDGE	VCVTPD2DQ xmm, ymm	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	xmmreg,mem256	AVX,SANDYBRIDGE,SY	VCVTPD2DQ xmm, mem256	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VCVTPD2DQ xmm|mask|z, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	xmmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VCVTPD2DQ xmm|mask|z, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2DQ	ymmreg|mask|z,zmmrm512|b64|er	AVX512,FUTURE	VCVTPD2DQ ymm|mask|z, zmm/m512|b32|er	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTPD2PS	xmmreg,xmmreg	AVX,SANDYBRIDGE	VCVTPD2PS xmm, xmm	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	xmmreg,mem128	AVX,SANDYBRIDGE,SO	VCVTPD2PS xmm, mem128	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	xmmreg,ymmreg	AVX,SANDYBRIDGE	VCVTPD2PS xmm, ymm	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	xmmreg,mem256	AVX,SANDYBRIDGE,SY	VCVTPD2PS xmm, mem256	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VCVTPD2PS xmm|mask|z, xmm/m128|b32	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	xmmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VCVTPD2PS xmm|mask|z, ymm/m256|b32	Convert Float64 Vector to Float32 Vector	
VCVTPD2PS	ymmreg|mask|z,zmmrm512|b64|er	AVX512,FUTURE	VCVTPD2PS ymm|mask|z, zmm/m512|b32|er	Convert Float64 Vector to Float32 Vector	
VCVTPS2DQ	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VCVTPS2DQ xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2DQ	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VCVTPS2DQ ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2DQ	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VCVTPS2DQ xmm|mask|z, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2DQ	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VCVTPS2DQ ymm|mask|z, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2DQ	zmmreg|mask|z,zmmrm512|b32|er	AVX512,FUTURE	VCVTPS2DQ zmm|mask|z, zmm/m512|b32|er	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTPS2PD	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VCVTPS2PD xmm, xmm/m64	Convert Float32 Vector to Float64 Vector	
VCVTPS2PD	ymmreg,xmmrm128	AVX,SANDYBRIDGE	VCVTPS2PD ymm, xmm/m128	Convert Float32 Vector to Float64 Vector	
VCVTPS2PD	xmmreg|mask|z,xmmrm64|b32	AVX512VL,AVX512,FUTURE	VCVTPS2PD xmm|mask|z, xmm/m64|b32	Convert Float32 Vector to Float64 Vector	
VCVTPS2PD	ymmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VCVTPS2PD ymm|mask|z, xmm/m128|b32	Convert Float32 Vector to Float64 Vector	
VCVTPS2PD	zmmreg|mask|z,ymmrm256|b32|sae	AVX512,FUTURE	VCVTPS2PD zmm|mask|z, ymm/m256|b32|sae	Convert Float32 Vector to Float64 Vector	
VCVTSD2SI	reg32,xmmrm64	AVX,SANDYBRIDGE	VCVTSD2SI r32, xmm/m64	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSD2SI	reg64,xmmrm64	AVX,SANDYBRIDGE,LONG	VCVTSD2SI r64, xmm/m64	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSD2SI	reg32,xmmrm64|er	AVX512,FUTURE	VCVTSD2SI r32, xmm/m64|er	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSD2SI	reg64,xmmrm64|er	AVX512,FUTURE	VCVTSD2SI r64, xmm/m64|er	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSD2SS	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VCVTSD2SS xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTSD2SS	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VCVTSD2SS xmm|mask|z, xmm, xmm/m64|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTSI2SD	xmmreg,xmmreg*,rm32	AVX,SANDYBRIDGE,SD	VCVTSI2SD xmm, xmm, r/m32	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSI2SD	xmmreg,xmmreg*,mem32	AVX,SANDYBRIDGE,ND,SD	VCVTSI2SD xmm, xmm, mem32	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSI2SD	xmmreg,xmmreg*,rm64	AVX,SANDYBRIDGE,LONG	VCVTSI2SD xmm, xmm, r/m64	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSI2SD	xmmreg,xmmreg|er,rm32	AVX512,FUTURE	VCVTSI2SD xmm, xmm|er, r/m32	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSI2SD	xmmreg,xmmreg|er,rm64	AVX512,FUTURE	VCVTSI2SD xmm, xmm|er, r/m64	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSI2SS	xmmreg,xmmreg*,rm32	AVX,SANDYBRIDGE,SD	VCVTSI2SS xmm, xmm, r/m32	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSI2SS	xmmreg,xmmreg*,mem32	AVX,SANDYBRIDGE,ND,SD	VCVTSI2SS xmm, xmm, mem32	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSI2SS	xmmreg,xmmreg*,rm64	AVX,SANDYBRIDGE,LONG	VCVTSI2SS xmm, xmm, r/m64	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSI2SS	xmmreg,xmmreg|er,rm32	AVX512,FUTURE	VCVTSI2SS xmm, xmm|er, r/m32	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSI2SS	xmmreg,xmmreg|er,rm64	AVX512,FUTURE	VCVTSI2SS xmm, xmm|er, r/m64	TODO: AVX,SANDYBRIDGE,SD,ND,LONG,AVX512,FUTURE	
VCVTSS2SD	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VCVTSS2SD xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTSS2SD	xmmreg|mask|z,xmmreg,xmmrm32|sae	AVX512,FUTURE	VCVTSS2SD xmm|mask|z, xmm, xmm/m32|sae	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VCVTSS2SI	reg32,xmmrm32	AVX,SANDYBRIDGE	VCVTSS2SI r32, xmm/m32	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSS2SI	reg64,xmmrm32	AVX,SANDYBRIDGE,LONG	VCVTSS2SI r64, xmm/m32	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSS2SI	reg32,xmmrm32|er	AVX512,FUTURE	VCVTSS2SI r32, xmm/m32|er	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTSS2SI	reg64,xmmrm32|er	AVX512,FUTURE	VCVTSS2SI r64, xmm/m32|er	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTPD2DQ	xmmreg,xmmreg	AVX,SANDYBRIDGE	VCVTTPD2DQ xmm, xmm	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	xmmreg,mem128	AVX,SANDYBRIDGE,SO	VCVTTPD2DQ xmm, mem128	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	xmmreg,ymmreg	AVX,SANDYBRIDGE	VCVTTPD2DQ xmm, ymm	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	xmmreg,mem256	AVX,SANDYBRIDGE,SY	VCVTTPD2DQ xmm, mem256	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VCVTTPD2DQ xmm|mask|z, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	xmmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VCVTTPD2DQ xmm|mask|z, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTTPD2DQ	ymmreg|mask|z,zmmrm512|b64|sae	AVX512,FUTURE	VCVTTPD2DQ ymm|mask|z, zmm/m512|b32|sae	TODO: AVX,SANDYBRIDGE,SO,SY,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VCVTTPS2DQ xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VCVTTPS2DQ ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VCVTTPS2DQ xmm|mask|z, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VCVTTPS2DQ ymm|mask|z, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTPS2DQ	zmmreg|mask|z,zmmrm512|b32|sae	AVX512,FUTURE	VCVTTPS2DQ zmm|mask|z, zmm/m512|b32|sae	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VCVTTSD2SI	reg32,xmmrm64	AVX,SANDYBRIDGE	VCVTTSD2SI r32, xmm/m64	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSD2SI	reg64,xmmrm64	AVX,SANDYBRIDGE,LONG	VCVTTSD2SI r64, xmm/m64	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSD2SI	reg32,xmmrm64|sae	AVX512,FUTURE	VCVTTSD2SI r32, xmm/m64|sae	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSD2SI	reg64,xmmrm64|sae	AVX512,FUTURE	VCVTTSD2SI r64, xmm/m64|sae	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSS2SI	reg32,xmmrm32	AVX,SANDYBRIDGE	VCVTTSS2SI r32, xmm/m32	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSS2SI	reg64,xmmrm32	AVX,SANDYBRIDGE,LONG	VCVTTSS2SI r64, xmm/m32	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSS2SI	reg32,xmmrm32|sae	AVX512,FUTURE	VCVTTSS2SI r32, xmm/m32|sae	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VCVTTSS2SI	reg64,xmmrm32|sae	AVX512,FUTURE	VCVTTSS2SI r64, xmm/m32|sae	TODO: AVX,SANDYBRIDGE,LONG,AVX512,FUTURE	
VDIVPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VDIVPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VDIVPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VDIVPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VDIVPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VDIVPD zmm|mask|z, zmm, zmm/m512|b32|er	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VDIVPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VDIVPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VDIVPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VDIVPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVPS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VDIVPS zmm|mask|z, zmm, zmm/m512|b32|er	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VDIVSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VDIVSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VDIVSD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VDIVSD xmm|mask|z, xmm, xmm/m64|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VDIVSS	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VDIVSS xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VDIVSS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VDIVSS xmm|mask|z, xmm, xmm/m32|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VDPPD	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VDPPD xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VDPPS	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VDPPS xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VDPPS	ymmreg,ymmreg*,ymmrm256,imm8	AVX,SANDYBRIDGE	VDPPS ymm, ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE	
VEXTRACTF128	xmmrm128,ymmreg,imm8	AVX,SANDYBRIDGE	VEXTRACTF128 xmm/m128, ymm, imm8	Extract Packed Floating-Point Values	VEXTRACTF128.html
VEXTRACTPS	rm32,xmmreg,imm8	AVX,SANDYBRIDGE	VEXTRACTPS r/m32, xmm, imm8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VEXTRACTPS	reg32,xmmreg,imm8	AVX512,FUTURE	VEXTRACTPS r32, xmm, imm8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VEXTRACTPS	reg64,xmmreg,imm8	AVX512,FUTURE	VEXTRACTPS r64, xmm, imm8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VEXTRACTPS	mem32,xmmreg,imm8	AVX512,FUTURE	VEXTRACTPS mem32, xmm, imm8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VHADDPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VHADDPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VHADDPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VHADDPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VHADDPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VHADDPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VHADDPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VHADDPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VHSUBPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VHSUBPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VHSUBPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VHSUBPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VHSUBPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VHSUBPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VHSUBPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VHSUBPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VINSERTF128	ymmreg,ymmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VINSERTF128 ymm, ymm, xmm/m128, imm8	Insert Packed Floating-Point Values	VINSERTF128.html
VINSERTPS	xmmreg,xmmreg*,xmmrm32,imm8	AVX,SANDYBRIDGE	VINSERTPS xmm, xmm, xmm/m32, imm8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VINSERTPS	xmmreg,xmmreg,xmmrm32,imm8	AVX512,FUTURE	VINSERTPS xmm, xmm, xmm/m32, imm8	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VLDDQU	xmmreg,mem128	AVX,SANDYBRIDGE	VLDDQU xmm, mem128	TODO: AVX,SANDYBRIDGE	
VLDDQU	ymmreg,mem256	AVX,SANDYBRIDGE	VLDDQU ymm, mem256	TODO: AVX,SANDYBRIDGE	
VLDQQU	ymmreg,mem256	AVX,SANDYBRIDGE	VLDQQU ymm, mem256	TODO: AVX,SANDYBRIDGE	
VLDMXCSR	mem32	AVX,SANDYBRIDGE	VLDMXCSR mem32	TODO: AVX,SANDYBRIDGE	
VMASKMOVDQU	xmmreg,xmmreg	AVX,SANDYBRIDGE	VMASKMOVDQU xmm, xmm	TODO: AVX,SANDYBRIDGE	
VMASKMOVPS	xmmreg,xmmreg,mem128	AVX,SANDYBRIDGE	VMASKMOVPS xmm, xmm, mem128	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPS	ymmreg,ymmreg,mem256	AVX,SANDYBRIDGE	VMASKMOVPS ymm, ymm, mem256	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPS	mem128,xmmreg,xmmreg	AVX,SANDYBRIDGE,SO	VMASKMOVPS mem128, xmm, xmm	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPS	mem256,ymmreg,ymmreg	AVX,SANDYBRIDGE,SY	VMASKMOVPS mem256, ymm, ymm	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPD	xmmreg,xmmreg,mem128	AVX,SANDYBRIDGE	VMASKMOVPD xmm, xmm, mem128	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPD	ymmreg,ymmreg,mem256	AVX,SANDYBRIDGE	VMASKMOVPD ymm, ymm, mem256	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPD	mem128,xmmreg,xmmreg	AVX,SANDYBRIDGE	VMASKMOVPD mem128, xmm, xmm	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMASKMOVPD	mem256,ymmreg,ymmreg	AVX,SANDYBRIDGE	VMASKMOVPD mem256, ymm, ymm	Conditional SIMD Packed Loads and Stores	VMASKMOV.html
VMAXPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VMAXPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VMAXPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VMAXPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VMAXPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPD	zmmreg|mask|z,zmmreg,zmmrm512|b64|sae	AVX512,FUTURE	VMAXPD zmm|mask|z, zmm, zmm/m512|b32|sae	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VMAXPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VMAXPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VMAXPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VMAXPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXPS	zmmreg|mask|z,zmmreg,zmmrm512|b32|sae	AVX512,FUTURE	VMAXPS zmm|mask|z, zmm, zmm/m512|b32|sae	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMAXSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VMAXSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMAXSD	xmmreg|mask|z,xmmreg,xmmrm64|sae	AVX512,FUTURE	VMAXSD xmm|mask|z, xmm, xmm/m64|sae	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMAXSS	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VMAXSS xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMAXSS	xmmreg|mask|z,xmmreg,xmmrm32|sae	AVX512,FUTURE	VMAXSS xmm|mask|z, xmm, xmm/m32|sae	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMINPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VMINPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VMINPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VMINPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VMINPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPD	zmmreg|mask|z,zmmreg,zmmrm512|b64|sae	AVX512,FUTURE	VMINPD zmm|mask|z, zmm, zmm/m512|b32|sae	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VMINPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VMINPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VMINPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VMINPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINPS	zmmreg|mask|z,zmmreg,zmmrm512|b32|sae	AVX512,FUTURE	VMINPS zmm|mask|z, zmm, zmm/m512|b32|sae	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMINSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VMINSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMINSD	xmmreg|mask|z,xmmreg,xmmrm64|sae	AVX512,FUTURE	VMINSD xmm|mask|z, xmm, xmm/m64|sae	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMINSS	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VMINSS xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMINSS	xmmreg|mask|z,xmmreg,xmmrm32|sae	AVX512,FUTURE	VMINSS xmm|mask|z, xmm, xmm/m32|sae	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVAPD	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VMOVAPD xmm, xmm/m128	Move Aligned Float64 Vector	
VMOVAPD	xmmrm128,xmmreg	AVX,SANDYBRIDGE	VMOVAPD xmm/m128, xmm	Move Aligned Float64 Vector	
VMOVAPD	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVAPD ymm, ymm/m256	Move Aligned Float64 Vector	
VMOVAPD	ymmrm256,ymmreg	AVX,SANDYBRIDGE	VMOVAPD ymm/m256, ymm	Move Aligned Float64 Vector	
VMOVAPD	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVAPD xmm|mask|z, xmm/m128	Move Aligned Float64 Vector	
VMOVAPD	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVAPD ymm|mask|z, ymm/m256	Move Aligned Float64 Vector	
VMOVAPD	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVAPD zmm|mask|z, zmm/m512	Move Aligned Float64 Vector	
VMOVAPD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VMOVAPD xmm|mask|z, xmm	Move Aligned Float64 Vector	
VMOVAPD	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VMOVAPD ymm|mask|z, ymm	Move Aligned Float64 Vector	
VMOVAPD	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VMOVAPD zmm|mask|z, zmm	Move Aligned Float64 Vector	
VMOVAPD	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VMOVAPD mem128|mask, xmm	Move Aligned Float64 Vector	
VMOVAPD	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VMOVAPD mem256|mask, ymm	Move Aligned Float64 Vector	
VMOVAPD	mem512|mask,zmmreg	AVX512,FUTURE	VMOVAPD mem512|mask, zmm	Move Aligned Float64 Vector	
VMOVAPS	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VMOVAPS xmm, xmm/m128	Move Aligned Float32 Vector	
VMOVAPS	xmmrm128,xmmreg	AVX,SANDYBRIDGE	VMOVAPS xmm/m128, xmm	Move Aligned Float32 Vector	
VMOVAPS	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVAPS ymm, ymm/m256	Move Aligned Float32 Vector	
VMOVAPS	ymmrm256,ymmreg	AVX,SANDYBRIDGE	VMOVAPS ymm/m256, ymm	Move Aligned Float32 Vector	
VMOVAPS	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVAPS xmm|mask|z, xmm/m128	Move Aligned Float32 Vector	
VMOVAPS	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVAPS ymm|mask|z, ymm/m256	Move Aligned Float32 Vector	
VMOVAPS	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVAPS zmm|mask|z, zmm/m512	Move Aligned Float32 Vector	
VMOVAPS	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VMOVAPS xmm|mask|z, xmm	Move Aligned Float32 Vector	
VMOVAPS	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VMOVAPS ymm|mask|z, ymm	Move Aligned Float32 Vector	
VMOVAPS	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VMOVAPS zmm|mask|z, zmm	Move Aligned Float32 Vector	
VMOVAPS	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VMOVAPS mem128|mask, xmm	Move Aligned Float32 Vector	
VMOVAPS	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VMOVAPS mem256|mask, ymm	Move Aligned Float32 Vector	
VMOVAPS	mem512|mask,zmmreg	AVX512,FUTURE	VMOVAPS mem512|mask, zmm	Move Aligned Float32 Vector	
VMOVD	xmmreg,rm32	AVX,SANDYBRIDGE	VMOVD xmm, r/m32	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVD	rm32,xmmreg	AVX,SANDYBRIDGE	VMOVD r/m32, xmm	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVD	xmmreg,rm32	AVX512,FUTURE	VMOVD xmm, r/m32	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVD	rm32,xmmreg	AVX512,FUTURE	VMOVD r/m32, xmm	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VMOVQ xmm, xmm/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	xmmrm64,xmmreg	AVX,SANDYBRIDGE	VMOVQ xmm/m64, xmm	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	xmmreg,rm64	AVX,SANDYBRIDGE,LONG	VMOVQ xmm, r/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	rm64,xmmreg	AVX,SANDYBRIDGE,LONG	VMOVQ r/m64, xmm	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	xmmreg,rm64	AVX512,FUTURE	VMOVQ xmm, r/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	rm64,xmmreg	AVX512,FUTURE	VMOVQ r/m64, xmm	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	xmmreg,xmmrm64	AVX512,FUTURE	VMOVQ xmm, xmm/m64	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVQ	xmmrm64,xmmreg	AVX512,FUTURE	VMOVQ xmm/m64, xmm	Move Doubleword/Move Quadword	MOVD:MOVQ.html
VMOVDDUP	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VMOVDDUP xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDDUP	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVDDUP ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDDUP	xmmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VMOVDDUP xmm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDDUP	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVDDUP ymm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDDUP	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVDDUP zmm|mask|z, zmm/m512	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVDQA	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VMOVDQA xmm, xmm/m128	Move Aligned Double Quadword	MOVDQA.html
VMOVDQA	xmmrm128,xmmreg	AVX,SANDYBRIDGE	VMOVDQA xmm/m128, xmm	Move Aligned Double Quadword	MOVDQA.html
VMOVDQA	ymmreg,ymmrm	AVX,SANDYBRIDGE	VMOVDQA ymm, ymm/m256	Move Aligned Double Quadword	MOVDQA.html
VMOVDQA	ymmrm256,ymmreg	AVX,SANDYBRIDGE	VMOVDQA ymm/m256, ymm	Move Aligned Double Quadword	MOVDQA.html
VMOVQQA	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVQQA ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VMOVQQA	ymmrm256,ymmreg	AVX,SANDYBRIDGE	VMOVQQA ymm/m256, ymm	TODO: AVX,SANDYBRIDGE	
VMOVDQU	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VMOVDQU xmm, xmm/m128	Move Unaligned Double Quadword	MOVDQU.html
VMOVDQU	xmmrm128,xmmreg	AVX,SANDYBRIDGE	VMOVDQU xmm/m128, xmm	Move Unaligned Double Quadword	MOVDQU.html
VMOVDQU	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVDQU ymm, ymm/m256	Move Unaligned Double Quadword	MOVDQU.html
VMOVDQU	ymmrm256,ymmreg	AVX,SANDYBRIDGE	VMOVDQU ymm/m256, ymm	Move Unaligned Double Quadword	MOVDQU.html
VMOVQQU	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVQQU ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VMOVQQU	ymmrm256,ymmreg	AVX,SANDYBRIDGE	VMOVQQU ymm/m256, ymm	TODO: AVX,SANDYBRIDGE	
VMOVHLPS	xmmreg,xmmreg*,xmmreg	AVX,SANDYBRIDGE	VMOVHLPS xmm, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHLPS	xmmreg,xmmreg,xmmreg	AVX512,FUTURE	VMOVHLPS xmm, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPD	xmmreg,xmmreg*,mem64	AVX,SANDYBRIDGE	VMOVHPD xmm, xmm, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPD	mem64,xmmreg	AVX,SANDYBRIDGE	VMOVHPD mem64, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPD	xmmreg,xmmreg,mem64	AVX512,FUTURE	VMOVHPD xmm, xmm, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPD	mem64,xmmreg	AVX512,FUTURE	VMOVHPD mem64, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPS	xmmreg,xmmreg*,mem64	AVX,SANDYBRIDGE	VMOVHPS xmm, xmm, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPS	mem64,xmmreg	AVX,SANDYBRIDGE	VMOVHPS mem64, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPS	xmmreg,xmmreg,mem64	AVX512,FUTURE	VMOVHPS xmm, xmm, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVHPS	mem64,xmmreg	AVX512,FUTURE	VMOVHPS mem64, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLHPS	xmmreg,xmmreg*,xmmreg	AVX,SANDYBRIDGE	VMOVLHPS xmm, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLHPS	xmmreg,xmmreg,xmmreg	AVX512,FUTURE	VMOVLHPS xmm, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPD	xmmreg,xmmreg*,mem64	AVX,SANDYBRIDGE	VMOVLPD xmm, xmm, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPD	mem64,xmmreg	AVX,SANDYBRIDGE	VMOVLPD mem64, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPD	xmmreg,xmmreg,mem64	AVX512,FUTURE	VMOVLPD xmm, xmm, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPD	mem64,xmmreg	AVX512,FUTURE	VMOVLPD mem64, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPS	xmmreg,xmmreg*,mem64	AVX,SANDYBRIDGE	VMOVLPS xmm, xmm, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPS	mem64,xmmreg	AVX,SANDYBRIDGE	VMOVLPS mem64, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPS	xmmreg,xmmreg,mem64	AVX512,FUTURE	VMOVLPS xmm, xmm, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVLPS	mem64,xmmreg	AVX512,FUTURE	VMOVLPS mem64, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVMSKPD	reg64,xmmreg	AVX,SANDYBRIDGE,LONG	VMOVMSKPD r64, xmm	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPD	reg32,xmmreg	AVX,SANDYBRIDGE	VMOVMSKPD r32, xmm	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPD	reg64,ymmreg	AVX,SANDYBRIDGE,LONG	VMOVMSKPD r64, ymm	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPD	reg32,ymmreg	AVX,SANDYBRIDGE	VMOVMSKPD r32, ymm	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPS	reg64,xmmreg	AVX,SANDYBRIDGE,LONG	VMOVMSKPS r64, xmm	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPS	reg32,xmmreg	AVX,SANDYBRIDGE	VMOVMSKPS r32, xmm	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPS	reg64,ymmreg	AVX,SANDYBRIDGE,LONG	VMOVMSKPS r64, ymm	TODO: AVX,SANDYBRIDGE,LONG	
VMOVMSKPS	reg32,ymmreg	AVX,SANDYBRIDGE	VMOVMSKPS r32, ymm	TODO: AVX,SANDYBRIDGE,LONG	
VMOVNTDQ	mem128,xmmreg	AVX,SANDYBRIDGE	VMOVNTDQ mem128, xmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTDQ	mem256,ymmreg	AVX,SANDYBRIDGE	VMOVNTDQ mem256, ymm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTDQ	mem128,xmmreg	AVX512VL,AVX512,FUTURE	VMOVNTDQ mem128, xmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTDQ	mem256,ymmreg	AVX512VL,AVX512,FUTURE	VMOVNTDQ mem256, ymm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTDQ	mem512,zmmreg	AVX512,FUTURE	VMOVNTDQ mem512, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTQQ	mem256,ymmreg	AVX,SANDYBRIDGE	VMOVNTQQ mem256, ymm	TODO: AVX,SANDYBRIDGE	
VMOVNTDQA	xmmreg,mem128	AVX,SANDYBRIDGE	VMOVNTDQA xmm, mem128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTDQA	ymmreg,mem256	FUTURE,AVX2	VMOVNTDQA ymm, mem256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTDQA	xmmreg,mem128	AVX512VL,AVX512,FUTURE	VMOVNTDQA xmm, mem128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTDQA	ymmreg,mem256	AVX512VL,AVX512,FUTURE	VMOVNTDQA ymm, mem256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTDQA	zmmreg,mem512	AVX512,FUTURE	VMOVNTDQA zmm, mem512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VMOVNTPD	mem128,xmmreg	AVX,SANDYBRIDGE	VMOVNTPD mem128, xmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPD	mem256,ymmreg	AVX,SANDYBRIDGE	VMOVNTPD mem256, ymm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPD	mem128,xmmreg	AVX512VL,AVX512,FUTURE	VMOVNTPD mem128, xmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPD	mem256,ymmreg	AVX512VL,AVX512,FUTURE	VMOVNTPD mem256, ymm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPD	mem512,zmmreg	AVX512,FUTURE	VMOVNTPD mem512, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	mem128,xmmreg	AVX,SANDYBRIDGE	VMOVNTPS mem128, xmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	mem256,ymmreg	AVX,SANDYBRIDGE	VMOVNTPS mem256, ymm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	mem128,xmmreg	AVX512VL,AVX512,FUTURE	VMOVNTPS mem128, xmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	mem256,ymmreg	AVX512VL,AVX512,FUTURE	VMOVNTPS mem256, ymm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVNTPS	mem512,zmmreg	AVX512,FUTURE	VMOVNTPS mem512, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSD	xmmreg,xmmreg*,xmmreg	AVX,SANDYBRIDGE	VMOVSD xmm, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	xmmreg,mem64	AVX,SANDYBRIDGE	VMOVSD xmm, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	xmmreg,xmmreg*,xmmreg	AVX,SANDYBRIDGE	VMOVSD xmm, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	mem64,xmmreg	AVX,SANDYBRIDGE	VMOVSD mem64, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	xmmreg|mask|z,mem64	AVX512,FUTURE	VMOVSD xmm|mask|z, mem64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	mem64|mask,xmmreg	AVX512,FUTURE	VMOVSD mem64|mask, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	xmmreg|mask|z,xmmreg,xmmreg	AVX512,FUTURE	VMOVSD xmm|mask|z, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSD	xmmreg|mask|z,xmmreg,xmmreg	AVX512,FUTURE	VMOVSD xmm|mask|z, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSHDUP	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VMOVSHDUP xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSHDUP	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVSHDUP ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSHDUP	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVSHDUP xmm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSHDUP	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVSHDUP ymm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSHDUP	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVSHDUP zmm|mask|z, zmm/m512	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VMOVSLDUP xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVSLDUP ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVSLDUP xmm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVSLDUP ymm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSLDUP	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVSLDUP zmm|mask|z, zmm/m512	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVSS	xmmreg,xmmreg*,xmmreg	AVX,SANDYBRIDGE	VMOVSS xmm, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	xmmreg,mem32	AVX,SANDYBRIDGE	VMOVSS xmm, mem32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	xmmreg,xmmreg*,xmmreg	AVX,SANDYBRIDGE	VMOVSS xmm, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	mem32,xmmreg	AVX,SANDYBRIDGE	VMOVSS mem32, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	xmmreg|mask|z,mem32	AVX512,FUTURE	VMOVSS xmm|mask|z, mem32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	mem32|mask,xmmreg	AVX512,FUTURE	VMOVSS mem32|mask, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	xmmreg|mask|z,xmmreg,xmmreg	AVX512,FUTURE	VMOVSS xmm|mask|z, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVSS	xmmreg|mask|z,xmmreg,xmmreg	AVX512,FUTURE	VMOVSS xmm|mask|z, xmm, xmm	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMOVUPD	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VMOVUPD xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	xmmrm128,xmmreg	AVX,SANDYBRIDGE	VMOVUPD xmm/m128, xmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVUPD ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	ymmrm256,ymmreg	AVX,SANDYBRIDGE	VMOVUPD ymm/m256, ymm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVUPD xmm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVUPD ymm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVUPD zmm|mask|z, zmm/m512	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VMOVUPD xmm|mask|z, xmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VMOVUPD ymm|mask|z, ymm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VMOVUPD zmm|mask|z, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VMOVUPD mem128|mask, xmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VMOVUPD mem256|mask, ymm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPD	mem512|mask,zmmreg	AVX512,FUTURE	VMOVUPD mem512|mask, zmm	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VMOVUPS	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VMOVUPS xmm, xmm/m128	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	xmmrm128,xmmreg	AVX,SANDYBRIDGE	VMOVUPS xmm/m128, xmm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VMOVUPS ymm, ymm/m256	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	ymmrm256,ymmreg	AVX,SANDYBRIDGE	VMOVUPS ymm/m256, ymm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVUPS xmm|mask|z, xmm/m128	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVUPS ymm|mask|z, ymm/m256	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVUPS zmm|mask|z, zmm/m512	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VMOVUPS xmm|mask|z, xmm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VMOVUPS ymm|mask|z, ymm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VMOVUPS zmm|mask|z, zmm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VMOVUPS mem128|mask, xmm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VMOVUPS mem256|mask, ymm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMOVUPS	mem512|mask,zmmreg	AVX512,FUTURE	VMOVUPS mem512|mask, zmm	Move Unaligned Packed Single-Precision Floating-Point Values	MOVUPS.html
VMPSADBW	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VMPSADBW xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VMPSADBW	ymmreg,ymmreg*,ymmrm256,imm8	FUTURE,AVX2	VMPSADBW ymm, ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VMULPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VMULPD xmm, xmm, xmm/m128	Multiply Float64 Vectors	
VMULPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VMULPD ymm, ymm, ymm/m256	Multiply Float64 Vectors	
VMULPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VMULPD xmm|mask|z, xmm, xmm/m128|b32	Multiply Float64 Vectors	
VMULPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VMULPD ymm|mask|z, ymm, ymm/m256|b32	Multiply Float64 Vectors	
VMULPD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VMULPD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Float64 Vectors	
VMULPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VMULPS xmm, xmm, xmm/m128	Multiply Float32 Vectors	
VMULPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VMULPS ymm, ymm, ymm/m256	Multiply Float32 Vectors	
VMULPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VMULPS xmm|mask|z, xmm, xmm/m128|b32	Multiply Float32 Vectors	
VMULPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VMULPS ymm|mask|z, ymm, ymm/m256|b32	Multiply Float32 Vectors	
VMULPS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VMULPS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Float32 Vectors	
VMULSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VMULSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMULSD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VMULSD xmm|mask|z, xmm, xmm/m64|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMULSS	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VMULSS xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VMULSS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VMULSS xmm|mask|z, xmm, xmm/m32|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VORPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VORPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VORPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VORPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VORPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512DQ,FUTURE	VORPD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VORPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VORPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512DQ,FUTURE	VORPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512DQ,FUTURE	VORPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VORPS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512DQ,FUTURE	VORPS zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VPABSB	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VPABSB xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSB	ymmreg,ymmrm256	FUTURE,AVX2	VPABSB ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSB	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPABSB xmm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSB	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPABSB ymm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSB	zmmreg|mask|z,zmmrm512	AVX512BW,FUTURE	VPABSB zmm|mask|z, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VPABSW xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	ymmreg,ymmrm256	FUTURE,AVX2	VPABSW ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPABSW xmm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPABSW ymm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSW	zmmreg|mask|z,zmmrm512	AVX512BW,FUTURE	VPABSW zmm|mask|z, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPABSD	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VPABSD xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPABSD	ymmreg,ymmrm256	FUTURE,AVX2	VPABSD ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPABSD	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPABSD xmm|mask|z, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPABSD	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPABSD ymm|mask|z, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPABSD	zmmreg|mask|z,zmmrm512|b32	AVX512,FUTURE	VPABSD zmm|mask|z, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPACKSSWB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPACKSSWB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSWB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPACKSSWB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSWB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPACKSSWB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSWB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPACKSSWB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSWB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPACKSSWB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPACKSSDW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPACKSSDW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512BW,FUTURE	VPACKSSDW xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512BW,FUTURE	VPACKSSDW ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKSSDW	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512BW,FUTURE	VPACKSSDW zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPACKUSWB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPACKUSWB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPACKUSWB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPACKUSWB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSWB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPACKUSWB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPACKUSDW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPACKUSDW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512BW,FUTURE	VPACKUSDW xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512BW,FUTURE	VPACKUSDW ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPACKUSDW	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512BW,FUTURE	VPACKUSDW zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPADDB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPADDB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPADDB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPADDB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPADDB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPADDW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPADDW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPADDW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPADDW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPADDW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPADDD xmm, xmm, xmm/m128	Add Int32 Vectors	
VPADDD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPADDD ymm, ymm, ymm/m256	Add Int32 Vectors	
VPADDD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPADDD xmm|mask|z, xmm, xmm/m128|b32	Add Int32 Vectors	
VPADDD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPADDD ymm|mask|z, ymm, ymm/m256|b32	Add Int32 Vectors	
VPADDD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPADDD zmm|mask|z, zmm, zmm/m512|b32	Add Int32 Vectors	
VPADDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPADDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPADDQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPADDQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPADDQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPADDQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPADDSB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPADDSB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPADDSB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPADDSB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPADDSB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPADDSB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPADDSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPADDSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPADDSW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPADDSW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDSW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPADDSW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPADDUSB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPADDUSB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPADDUSB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPADDUSB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPADDUSB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPADDUSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPADDUSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPADDUSW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPADDUSW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPADDUSW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPADDUSW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VPALIGNR xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	ymmreg,ymmreg*,ymmrm256,imm8	FUTURE,AVX2	VPALIGNR ymm, ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	xmmreg|mask|z,xmmreg,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPALIGNR xmm|mask|z, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	ymmreg|mask|z,ymmreg,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPALIGNR ymm|mask|z, ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPALIGNR	zmmreg|mask|z,zmmreg,zmmrm512,imm8	AVX512BW,FUTURE	VPALIGNR zmm|mask|z, zmm, zmm/m512, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAND	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPAND xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPAND	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPAND ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPANDN	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPANDN xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPANDN	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPANDN ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPAVGB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPAVGB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPAVGB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPAVGB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPAVGB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPAVGB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPAVGW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPAVGW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPAVGW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPAVGW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPAVGW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPAVGW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPBLENDVB	xmmreg,xmmreg*,xmmrm128,xmmreg	AVX,SANDYBRIDGE	VPBLENDVB xmm, xmm, xmm/m128, xmm	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPBLENDVB	ymmreg,ymmreg*,ymmrm256,ymmreg	FUTURE,AVX2	VPBLENDVB ymm, ymm, ymm/m256, ymm	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPBLENDW	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VPBLENDW xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPBLENDW	ymmreg,ymmreg*,ymmrm256,imm8	FUTURE,AVX2	VPBLENDW ymm, ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPCMPESTRI	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VPCMPESTRI xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VPCMPESTRM	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VPCMPESTRM xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VPCMPISTRI	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VPCMPISTRI xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VPCMPISTRM	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VPCMPISTRM xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VPCMPEQB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCMPEQB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPCMPEQB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQB	kreg|mask,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPCMPEQB kreg|mask, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQB	kreg|mask,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPCMPEQB kreg|mask, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQB	kreg|mask,zmmreg,zmmrm512	AVX512BW,FUTURE	VPCMPEQB kreg|mask, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCMPEQW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPCMPEQW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	kreg|mask,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPCMPEQW kreg|mask, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	kreg|mask,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPCMPEQW kreg|mask, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQW	kreg|mask,zmmreg,zmmrm512	AVX512BW,FUTURE	VPCMPEQW kreg|mask, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPEQD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCMPEQD xmm, xmm, xmm/m128	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPCMPEQD ymm, ymm, ymm/m256	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQD	kreg|mask,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPCMPEQD kreg|mask, xmm, xmm/m128|b32	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQD	kreg|mask,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPCMPEQD kreg|mask, ymm, ymm/m256|b32	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQD	kreg|mask,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPCMPEQD kreg|mask, zmm, zmm/m512|b32	Compare Equal Int32 Vectors and Set Vector Mask	
VPCMPEQQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCMPEQQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPEQQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPCMPEQQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPEQQ	kreg|mask,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPCMPEQQ kreg|mask, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPEQQ	kreg|mask,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPCMPEQQ kreg|mask, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPEQQ	kreg|mask,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPCMPEQQ kreg|mask, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCMPGTB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPCMPGTB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTB	kreg|mask,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPCMPGTB kreg|mask, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTB	kreg|mask,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPCMPGTB kreg|mask, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTB	kreg|mask,zmmreg,zmmrm512	AVX512BW,FUTURE	VPCMPGTB kreg|mask, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCMPGTW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPCMPGTW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	kreg|mask,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPCMPGTW kreg|mask, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	kreg|mask,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPCMPGTW kreg|mask, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTW	kreg|mask,zmmreg,zmmrm512	AVX512BW,FUTURE	VPCMPGTW kreg|mask, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPCMPGTD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCMPGTD xmm, xmm, xmm/m128	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPCMPGTD ymm, ymm, ymm/m256	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTD	kreg|mask,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPCMPGTD kreg|mask, xmm, xmm/m128|b32	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTD	kreg|mask,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPCMPGTD kreg|mask, ymm, ymm/m256|b32	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTD	kreg|mask,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPCMPGTD kreg|mask, zmm, zmm/m512|b32	Compare Greater Than Int32 Vectors and Set Vector Mask	
VPCMPGTQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCMPGTQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPCMPGTQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTQ	kreg|mask,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPCMPGTQ kreg|mask, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTQ	kreg|mask,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPCMPGTQ kreg|mask, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPCMPGTQ	kreg|mask,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPCMPGTQ kreg|mask, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPERMILPD	xmmreg,xmmreg,xmmrm128	AVX,SANDYBRIDGE	VPERMILPD xmm, xmm, xmm/m128	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	ymmreg,ymmreg,ymmrm256	AVX,SANDYBRIDGE	VPERMILPD ymm, ymm, ymm/m256	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VPERMILPD xmm, xmm/m128, imm8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	ymmreg,ymmrm256,imm8	AVX,SANDYBRIDGE	VPERMILPD ymm, ymm/m256, imm8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	xmmreg|mask|z,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VPERMILPD xmm|mask|z, xmm/m128|b32, imm8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPERMILPD ymm|mask|z, ymm/m256|b32, imm8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	zmmreg|mask|z,zmmrm512|b64,imm8	AVX512,FUTURE	VPERMILPD zmm|mask|z, zmm/m512|b32, imm8	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPERMILPD xmm|mask|z, xmm, xmm/m128|b32	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPERMILPD ymm|mask|z, ymm, ymm/m256|b32	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPERMILPD zmm|mask|z, zmm, zmm/m512|b32	Permute Double-Precision Floating-Point Values	VPERMILPD.html
VPERMILPS	xmmreg,xmmreg,xmmrm128	AVX,SANDYBRIDGE	VPERMILPS xmm, xmm, xmm/m128	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	ymmreg,ymmreg,ymmrm256	AVX,SANDYBRIDGE	VPERMILPS ymm, ymm, ymm/m256	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VPERMILPS xmm, xmm/m128, imm8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	ymmreg,ymmrm256,imm8	AVX,SANDYBRIDGE	VPERMILPS ymm, ymm/m256, imm8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPERMILPS xmm|mask|z, xmm/m128|b32, imm8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPERMILPS ymm|mask|z, ymm/m256|b32, imm8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	zmmreg|mask|z,zmmrm512|b32,imm8	AVX512,FUTURE	VPERMILPS zmm|mask|z, zmm/m512|b32, imm8	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPERMILPS xmm|mask|z, xmm, xmm/m128|b32	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPERMILPS ymm|mask|z, ymm, ymm/m256|b32	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERMILPS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPERMILPS zmm|mask|z, zmm, zmm/m512|b32	Permute Single-Precision Floating-Point Values	VPERMILPS.html
VPERM2F128	ymmreg,ymmreg,ymmrm256,imm8	AVX,SANDYBRIDGE	VPERM2F128 ymm, ymm, ymm/m256, imm8	Permute Floating-Point Values	VPERM2F128.html
VPEXTRB	reg64,xmmreg,imm8	AVX,SANDYBRIDGE,LONG	VPEXTRB r64, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	reg32,xmmreg,imm8	AVX,SANDYBRIDGE	VPEXTRB r32, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	mem8,xmmreg,imm8	AVX,SANDYBRIDGE	VPEXTRB mem8, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	reg8,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRB r8, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	reg16,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRB r16, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	reg32,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRB r32, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	reg64,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRB r64, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRB	mem8,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRB mem8, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRW	reg64,xmmreg,imm8	AVX,SANDYBRIDGE,LONG	VPEXTRW r64, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	reg32,xmmreg,imm8	AVX,SANDYBRIDGE	VPEXTRW r32, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	reg64,xmmreg,imm8	AVX,SANDYBRIDGE,LONG	VPEXTRW r64, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	reg32,xmmreg,imm8	AVX,SANDYBRIDGE	VPEXTRW r32, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	mem16,xmmreg,imm8	AVX,SANDYBRIDGE	VPEXTRW mem16, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	reg16,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRW r16, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	reg32,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRW r32, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	reg64,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRW r64, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	mem16,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRW mem16, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	reg16,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRW r16, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	reg32,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRW r32, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRW	reg64,xmmreg,imm8	AVX512BW,FUTURE	VPEXTRW r64, xmm, imm8	Extract Word	PEXTRW.html
VPEXTRD	reg64,xmmreg,imm8	AVX,SANDYBRIDGE,LONG	VPEXTRD r64, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRD	rm32,xmmreg,imm8	AVX,SANDYBRIDGE	VPEXTRD r/m32, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRD	rm32,xmmreg,imm8	AVX512DQ,FUTURE	VPEXTRD r/m32, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRQ	rm64,xmmreg,imm8	AVX,SANDYBRIDGE,LONG	VPEXTRQ r/m64, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPEXTRQ	rm64,xmmreg,imm8	AVX512DQ,FUTURE	VPEXTRQ r/m64, xmm, imm8	Extract Byte/Dword/Qword	PEXTRB:PEXTRD:PEXTRQ.html
VPHADDW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPHADDW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPHADDW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPHADDD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPHADDD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPHADDSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHADDSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPHADDSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHMINPOSUW	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VPHMINPOSUW xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VPHSUBW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPHSUBW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPHSUBW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPHSUBD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPHSUBD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPHSUBSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPHSUBSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPHSUBSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPINSRB	xmmreg,xmmreg*,mem8,imm8	AVX,SANDYBRIDGE	VPINSRB xmm, xmm, mem8, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRB	xmmreg,xmmreg*,rm8,imm8	AVX,SANDYBRIDGE	VPINSRB xmm, xmm, r/m8, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRB	xmmreg,xmmreg*,reg32,imm8	AVX,SANDYBRIDGE	VPINSRB xmm, xmm, r32, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRB	xmmreg,xmmreg,reg32,imm8	AVX512BW,FUTURE	VPINSRB xmm, xmm, r32, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRB	xmmreg,xmmreg,mem8,imm8	AVX512BW,FUTURE	VPINSRB xmm, xmm, mem8, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	xmmreg,xmmreg*,mem16,imm8	AVX,SANDYBRIDGE	VPINSRW xmm, xmm, mem16, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	xmmreg,xmmreg*,rm16,imm8	AVX,SANDYBRIDGE	VPINSRW xmm, xmm, r/m16, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	xmmreg,xmmreg*,reg32,imm8	AVX,SANDYBRIDGE	VPINSRW xmm, xmm, r32, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	xmmreg,xmmreg,reg32,imm8	AVX512BW,FUTURE	VPINSRW xmm, xmm, r32, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRW	xmmreg,xmmreg,mem16,imm8	AVX512BW,FUTURE	VPINSRW xmm, xmm, mem16, imm8	TODO: AVX,SANDYBRIDGE,AVX512BW,FUTURE	
VPINSRD	xmmreg,xmmreg*,mem32,imm8	AVX,SANDYBRIDGE	VPINSRD xmm, xmm, mem32, imm8	TODO: AVX,SANDYBRIDGE,AVX512DQ,FUTURE	
VPINSRD	xmmreg,xmmreg*,rm32,imm8	AVX,SANDYBRIDGE	VPINSRD xmm, xmm, r/m32, imm8	TODO: AVX,SANDYBRIDGE,AVX512DQ,FUTURE	
VPINSRD	xmmreg,xmmreg,rm32,imm8	AVX512DQ,FUTURE	VPINSRD xmm, xmm, r/m32, imm8	TODO: AVX,SANDYBRIDGE,AVX512DQ,FUTURE	
VPINSRQ	xmmreg,xmmreg*,mem64,imm8	AVX,SANDYBRIDGE,LONG	VPINSRQ xmm, xmm, mem64, imm8	TODO: AVX,SANDYBRIDGE,LONG,AVX512DQ,FUTURE	
VPINSRQ	xmmreg,xmmreg*,rm64,imm8	AVX,SANDYBRIDGE,LONG	VPINSRQ xmm, xmm, r/m64, imm8	TODO: AVX,SANDYBRIDGE,LONG,AVX512DQ,FUTURE	
VPINSRQ	xmmreg,xmmreg,rm64,imm8	AVX512DQ,FUTURE	VPINSRQ xmm, xmm, r/m64, imm8	TODO: AVX,SANDYBRIDGE,LONG,AVX512DQ,FUTURE	
VPMADDWD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMADDWD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDWD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMADDWD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDWD	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMADDWD xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDWD	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMADDWD ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDWD	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMADDWD zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMADDUBSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMADDUBSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMADDUBSW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMADDUBSW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMADDUBSW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMADDUBSW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMAXSB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMAXSB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMAXSB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMAXSB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMAXSB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMAXSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMAXSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMAXSW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMAXSW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMAXSW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXSD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMAXSD xmm, xmm, xmm/m128	Maximum of Int32 Vectors	
VPMAXSD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMAXSD ymm, ymm, ymm/m256	Maximum of Int32 Vectors	
VPMAXSD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPMAXSD xmm|mask|z, xmm, xmm/m128|b32	Maximum of Int32 Vectors	
VPMAXSD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPMAXSD ymm|mask|z, ymm, ymm/m256|b32	Maximum of Int32 Vectors	
VPMAXSD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPMAXSD zmm|mask|z, zmm, zmm/m512|b32	Maximum of Int32 Vectors	
VPMAXUB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMAXUB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMAXUB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMAXUB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMAXUB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMAXUB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMAXUW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMAXUW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMAXUW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMAXUW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMAXUW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMAXUD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMAXUD xmm, xmm, xmm/m128	Maximum of Uint32 Vectors	
VPMAXUD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMAXUD ymm, ymm, ymm/m256	Maximum of Uint32 Vectors	
VPMAXUD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPMAXUD xmm|mask|z, xmm, xmm/m128|b32	Maximum of Uint32 Vectors	
VPMAXUD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPMAXUD ymm|mask|z, ymm, ymm/m256|b32	Maximum of Uint32 Vectors	
VPMAXUD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPMAXUD zmm|mask|z, zmm, zmm/m512|b32	Maximum of Uint32 Vectors	
VPMINSB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMINSB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMINSB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMINSB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMINSB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMINSB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMINSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMINSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMINSW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMINSW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMINSW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINSD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMINSD xmm, xmm, xmm/m128	Minimum of Int32 Vectors	
VPMINSD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMINSD ymm, ymm, ymm/m256	Minimum of Int32 Vectors	
VPMINSD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPMINSD xmm|mask|z, xmm, xmm/m128|b32	Minimum of Int32 Vectors	
VPMINSD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPMINSD ymm|mask|z, ymm, ymm/m256|b32	Minimum of Int32 Vectors	
VPMINSD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPMINSD zmm|mask|z, zmm, zmm/m512|b32	Minimum of Int32 Vectors	
VPMINUB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMINUB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMINUB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMINUB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMINUB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMINUB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMINUW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMINUW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMINUW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMINUW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMINUW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMINUD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMINUD xmm, xmm, xmm/m128	Minimum of Uint32 Vectors	
VPMINUD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMINUD ymm, ymm, ymm/m256	Minimum of Uint32 Vectors	
VPMINUD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPMINUD xmm|mask|z, xmm, xmm/m128|b32	Minimum of Uint32 Vectors	
VPMINUD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPMINUD ymm|mask|z, ymm, ymm/m256|b32	Minimum of Uint32 Vectors	
VPMINUD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPMINUD zmm|mask|z, zmm, zmm/m512|b32	Minimum of Uint32 Vectors	
VPMOVMSKB	reg64,xmmreg	AVX,SANDYBRIDGE,LONG	VPMOVMSKB r64, xmm	TODO: AVX,SANDYBRIDGE,LONG,FUTURE,AVX2	
VPMOVMSKB	reg32,xmmreg	AVX,SANDYBRIDGE	VPMOVMSKB r32, xmm	TODO: AVX,SANDYBRIDGE,LONG,FUTURE,AVX2	
VPMOVMSKB	reg32,ymmreg	FUTURE,AVX2	VPMOVMSKB r32, ymm	TODO: AVX,SANDYBRIDGE,LONG,FUTURE,AVX2	
VPMOVMSKB	reg64,ymmreg	FUTURE,AVX2	VPMOVMSKB r64, ymm	TODO: AVX,SANDYBRIDGE,LONG,FUTURE,AVX2	
VPMOVSXBW	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VPMOVSXBW xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBW	ymmreg,xmmrm128	FUTURE,AVX2	VPMOVSXBW ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBW	xmmreg|mask|z,xmmrm64	AVX512VL,AVX512BW,FUTURE	VPMOVSXBW xmm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBW	ymmreg|mask|z,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMOVSXBW ymm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBW	zmmreg|mask|z,ymmrm256	AVX512BW,FUTURE	VPMOVSXBW zmm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVSXBD	xmmreg,xmmrm32	AVX,SANDYBRIDGE	VPMOVSXBD xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	ymmreg,mem64	FUTURE,AVX2	VPMOVSXBD ymm, mem64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	ymmreg,xmmreg	FUTURE,AVX2	VPMOVSXBD ymm, xmm	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	xmmreg|mask|z,xmmrm32	AVX512VL,AVX512,FUTURE	VPMOVSXBD xmm|mask|z, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	ymmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VPMOVSXBD ymm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBD	zmmreg|mask|z,xmmrm128	AVX512,FUTURE	VPMOVSXBD zmm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	xmmreg,xmmrm16	AVX,SANDYBRIDGE	VPMOVSXBQ xmm, xmm/m16	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	ymmreg,mem32	FUTURE,AVX2	VPMOVSXBQ ymm, mem32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	ymmreg,xmmreg	FUTURE,AVX2	VPMOVSXBQ ymm, xmm	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	xmmreg|mask|z,xmmrm16	AVX512VL,AVX512,FUTURE	VPMOVSXBQ xmm|mask|z, xmm/m16	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	ymmreg|mask|z,xmmrm32	AVX512VL,AVX512,FUTURE	VPMOVSXBQ ymm|mask|z, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXBQ	zmmreg|mask|z,xmmrm64	AVX512,FUTURE	VPMOVSXBQ zmm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VPMOVSXWD xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	ymmreg,xmmrm128	FUTURE,AVX2	VPMOVSXWD ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	xmmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VPMOVSXWD xmm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	ymmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VPMOVSXWD ymm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWD	zmmreg|mask|z,ymmrm256	AVX512,FUTURE	VPMOVSXWD zmm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	xmmreg,xmmrm32	AVX,SANDYBRIDGE	VPMOVSXWQ xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	ymmreg,mem64	FUTURE,AVX2	VPMOVSXWQ ymm, mem64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	ymmreg,xmmreg	FUTURE,AVX2	VPMOVSXWQ ymm, xmm	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	xmmreg|mask|z,xmmrm32	AVX512VL,AVX512,FUTURE	VPMOVSXWQ xmm|mask|z, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	ymmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VPMOVSXWQ ymm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXWQ	zmmreg|mask|z,xmmrm128	AVX512,FUTURE	VPMOVSXWQ zmm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VPMOVSXDQ xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	ymmreg,xmmrm128	FUTURE,AVX2	VPMOVSXDQ ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	xmmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VPMOVSXDQ xmm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	ymmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VPMOVSXDQ ymm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVSXDQ	zmmreg|mask|z,ymmrm256	AVX512,FUTURE	VPMOVSXDQ zmm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBW	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VPMOVZXBW xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBW	ymmreg,xmmrm128	FUTURE,AVX2	VPMOVZXBW ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBW	xmmreg|mask|z,xmmrm64	AVX512VL,AVX512BW,FUTURE	VPMOVZXBW xmm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBW	ymmreg|mask|z,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMOVZXBW ymm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBW	zmmreg|mask|z,ymmrm256	AVX512BW,FUTURE	VPMOVZXBW zmm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMOVZXBD	xmmreg,xmmrm32	AVX,SANDYBRIDGE	VPMOVZXBD xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	ymmreg,mem64	FUTURE,AVX2	VPMOVZXBD ymm, mem64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	ymmreg,xmmreg	FUTURE,AVX2	VPMOVZXBD ymm, xmm	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	xmmreg|mask|z,xmmrm32	AVX512VL,AVX512,FUTURE	VPMOVZXBD xmm|mask|z, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	ymmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VPMOVZXBD ymm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBD	zmmreg|mask|z,xmmrm128	AVX512,FUTURE	VPMOVZXBD zmm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	xmmreg,xmmrm16	AVX,SANDYBRIDGE	VPMOVZXBQ xmm, xmm/m16	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	ymmreg,mem32	FUTURE,AVX2	VPMOVZXBQ ymm, mem32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	ymmreg,xmmreg	FUTURE,AVX2	VPMOVZXBQ ymm, xmm	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	xmmreg|mask|z,xmmrm16	AVX512VL,AVX512,FUTURE	VPMOVZXBQ xmm|mask|z, xmm/m16	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	ymmreg|mask|z,xmmrm32	AVX512VL,AVX512,FUTURE	VPMOVZXBQ ymm|mask|z, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXBQ	zmmreg|mask|z,xmmrm64	AVX512,FUTURE	VPMOVZXBQ zmm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VPMOVZXWD xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	ymmreg,xmmrm128	FUTURE,AVX2	VPMOVZXWD ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	xmmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VPMOVZXWD xmm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	ymmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VPMOVZXWD ymm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWD	zmmreg|mask|z,ymmrm256	AVX512,FUTURE	VPMOVZXWD zmm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	xmmreg,xmmrm32	AVX,SANDYBRIDGE	VPMOVZXWQ xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	ymmreg,mem64	FUTURE,AVX2	VPMOVZXWQ ymm, mem64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	ymmreg,xmmreg	FUTURE,AVX2	VPMOVZXWQ ymm, xmm	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	xmmreg|mask|z,xmmrm32	AVX512VL,AVX512,FUTURE	VPMOVZXWQ xmm|mask|z, xmm/m32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	ymmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VPMOVZXWQ ymm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXWQ	zmmreg|mask|z,xmmrm128	AVX512,FUTURE	VPMOVZXWQ zmm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VPMOVZXDQ xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	ymmreg,xmmrm128	FUTURE,AVX2	VPMOVZXDQ ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	xmmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VPMOVZXDQ xmm|mask|z, xmm/m64	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	ymmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VPMOVZXDQ ymm|mask|z, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMOVZXDQ	zmmreg|mask|z,ymmrm256	AVX512,FUTURE	VPMOVZXDQ zmm|mask|z, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULHUW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMULHUW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHUW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMULHUW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHUW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMULHUW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHUW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMULHUW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHUW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMULHUW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMULHRSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMULHRSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMULHRSW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMULHRSW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHRSW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMULHRSW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMULHW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMULHW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMULHW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMULHW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULHW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMULHW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMULLW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMULLW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPMULLW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPMULLW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPMULLW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPMULLD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMULLD xmm, xmm, xmm/m128	Multiply Int32 Vectors And Store Low Result	
VPMULLD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMULLD ymm, ymm, ymm/m256	Multiply Int32 Vectors And Store Low Result	
VPMULLD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPMULLD xmm|mask|z, xmm, xmm/m128|b32	Multiply Int32 Vectors And Store Low Result	
VPMULLD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPMULLD ymm|mask|z, ymm, ymm/m256|b32	Multiply Int32 Vectors And Store Low Result	
VPMULLD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPMULLD zmm|mask|z, zmm, zmm/m512|b32	Multiply Int32 Vectors And Store Low Result	
VPMULUDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMULUDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULUDQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMULUDQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULUDQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPMULUDQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULUDQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPMULUDQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULUDQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPMULUDQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPMULDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPMULDQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPMULDQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPMULDQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPMULDQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPMULDQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPOR	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPOR xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPOR	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPOR ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSADBW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSADBW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSADBW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSADBW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSADBW	xmmreg,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSADBW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSADBW	ymmreg,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSADBW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSADBW	zmmreg,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSADBW zmm, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSHUFB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSHUFB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSHUFB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSHUFB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSHUFB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFD	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VPSHUFD xmm, xmm/m128, imm8	Shuf?le Vector Doublewords	
VPSHUFD	ymmreg,ymmrm256,imm8	FUTURE,AVX2	VPSHUFD ymm, ymm/m256, imm8	Shuf?le Vector Doublewords	
VPSHUFD	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPSHUFD xmm|mask|z, xmm/m128|b32, imm8	Shuf?le Vector Doublewords	
VPSHUFD	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPSHUFD ymm|mask|z, ymm/m256|b32, imm8	Shuf?le Vector Doublewords	
VPSHUFD	zmmreg|mask|z,zmmrm512|b32,imm8	AVX512,FUTURE	VPSHUFD zmm|mask|z, zmm/m512|b32, imm8	Shuf?le Vector Doublewords	
VPSHUFHW	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VPSHUFHW xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFHW	ymmreg,ymmrm256,imm8	FUTURE,AVX2	VPSHUFHW ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFHW	xmmreg|mask|z,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPSHUFHW xmm|mask|z, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFHW	ymmreg|mask|z,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPSHUFHW ymm|mask|z, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFHW	zmmreg|mask|z,zmmrm512,imm8	AVX512BW,FUTURE	VPSHUFHW zmm|mask|z, zmm/m512, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VPSHUFLW xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	ymmreg,ymmrm256,imm8	FUTURE,AVX2	VPSHUFLW ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	xmmreg|mask|z,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPSHUFLW xmm|mask|z, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	ymmreg|mask|z,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPSHUFLW ymm|mask|z, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSHUFLW	zmmreg|mask|z,zmmrm512,imm8	AVX512BW,FUTURE	VPSHUFLW zmm|mask|z, zmm/m512, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSIGNB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSIGNB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGNB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSIGNB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGNW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSIGNW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGNW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSIGNW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGND	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSIGND xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSIGND	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSIGND ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2	
VPSLLDQ	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSLLDQ xmm, xmm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLDQ	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSLLDQ ymm, ymm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLDQ	xmmreg,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPSLLDQ xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLDQ	ymmreg,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPSLLDQ ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLDQ	zmmreg,zmmrm512,imm8	AVX512BW,FUTURE	VPSLLDQ zmm, zmm/m512, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSRLDQ xmm, xmm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSRLDQ ymm, ymm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	xmmreg,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPSRLDQ xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	ymmreg,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPSRLDQ ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLDQ	zmmreg,zmmrm512,imm8	AVX512BW,FUTURE	VPSRLDQ zmm, zmm/m512, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSLLW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSLLW xmm, xmm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	ymmreg,ymmreg*,xmmrm128	FUTURE,AVX2	VPSLLW ymm, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSLLW ymm, ymm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSLLW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	ymmreg|mask|z,ymmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSLLW ymm|mask|z, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	zmmreg|mask|z,zmmreg,xmmrm128	AVX512BW,FUTURE	VPSLLW zmm|mask|z, zmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	xmmreg|mask|z,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPSLLW xmm|mask|z, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	ymmreg|mask|z,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPSLLW ymm|mask|z, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLW	zmmreg|mask|z,zmmrm512,imm8	AVX512BW,FUTURE	VPSLLW zmm|mask|z, zmm/m512, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSLLD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSLLD xmm, xmm, xmm/m128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSLLD xmm, xmm, imm8	Shift Int32 Vector Immediate Left Logical	
VPSLLD	ymmreg,ymmreg*,xmmrm128	FUTURE,AVX2	VPSLLD ymm, ymm, xmm/m128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSLLD ymm, ymm, imm8	Shift Int32 Vector Immediate Left Logical	
VPSLLD	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSLLD xmm|mask|z, xmm, xmm/m128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	ymmreg|mask|z,ymmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSLLD ymm|mask|z, ymm, xmm/m128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	zmmreg|mask|z,zmmreg,xmmrm128	AVX512,FUTURE	VPSLLD zmm|mask|z, zmm, xmm/m128	Shift Int32 Vector Immediate Left Logical	
VPSLLD	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPSLLD xmm|mask|z, xmm/m128|b32, imm8	Shift Int32 Vector Immediate Left Logical	
VPSLLD	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPSLLD ymm|mask|z, ymm/m256|b32, imm8	Shift Int32 Vector Immediate Left Logical	
VPSLLD	zmmreg|mask|z,zmmrm512|b32,imm8	AVX512,FUTURE	VPSLLD zmm|mask|z, zmm/m512|b32, imm8	Shift Int32 Vector Immediate Left Logical	
VPSLLQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSLLQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSLLQ xmm, xmm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	ymmreg,ymmreg*,xmmrm128	FUTURE,AVX2	VPSLLQ ymm, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSLLQ ymm, ymm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSLLQ xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	ymmreg|mask|z,ymmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSLLQ ymm|mask|z, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	zmmreg|mask|z,zmmreg,xmmrm128	AVX512,FUTURE	VPSLLQ zmm|mask|z, zmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	xmmreg|mask|z,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VPSLLQ xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPSLLQ ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSLLQ	zmmreg|mask|z,zmmrm512|b64,imm8	AVX512,FUTURE	VPSLLQ zmm|mask|z, zmm/m512|b32, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRAW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSRAW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSRAW xmm, xmm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	ymmreg,ymmreg*,xmmrm128	FUTURE,AVX2	VPSRAW ymm, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSRAW ymm, ymm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSRAW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	ymmreg|mask|z,ymmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSRAW ymm|mask|z, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	zmmreg|mask|z,zmmreg,xmmrm128	AVX512BW,FUTURE	VPSRAW zmm|mask|z, zmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	xmmreg|mask|z,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPSRAW xmm|mask|z, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	ymmreg|mask|z,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPSRAW ymm|mask|z, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAW	zmmreg|mask|z,zmmrm512,imm8	AVX512BW,FUTURE	VPSRAW zmm|mask|z, zmm/m512, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRAD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSRAD xmm, xmm, xmm/m128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSRAD xmm, xmm, imm8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	ymmreg,ymmreg*,xmmrm128	FUTURE,AVX2	VPSRAD ymm, ymm, xmm/m128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSRAD ymm, ymm, imm8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSRAD xmm|mask|z, xmm, xmm/m128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	ymmreg|mask|z,ymmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSRAD ymm|mask|z, ymm, xmm/m128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	zmmreg|mask|z,zmmreg,xmmrm128	AVX512,FUTURE	VPSRAD zmm|mask|z, zmm, xmm/m128	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPSRAD xmm|mask|z, xmm/m128|b32, imm8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPSRAD ymm|mask|z, ymm/m256|b32, imm8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRAD	zmmreg|mask|z,zmmrm512|b32,imm8	AVX512,FUTURE	VPSRAD zmm|mask|z, zmm/m512|b32, imm8	Shift Int32 Vector Immediate Right Arithmetic	
VPSRLW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSRLW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSRLW xmm, xmm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	ymmreg,ymmreg*,xmmrm128	FUTURE,AVX2	VPSRLW ymm, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSRLW ymm, ymm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSRLW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	ymmreg|mask|z,ymmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSRLW ymm|mask|z, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	zmmreg|mask|z,zmmreg,xmmrm128	AVX512BW,FUTURE	VPSRLW zmm|mask|z, zmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	xmmreg|mask|z,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPSRLW xmm|mask|z, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	ymmreg|mask|z,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPSRLW ymm|mask|z, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLW	zmmreg|mask|z,zmmrm512,imm8	AVX512BW,FUTURE	VPSRLW zmm|mask|z, zmm/m512, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSRLD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSRLD xmm, xmm, xmm/m128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSRLD xmm, xmm, imm8	Shift Int32 Vector Immediate Right Logical	
VPSRLD	ymmreg,ymmreg*,xmmrm128	FUTURE,AVX2	VPSRLD ymm, ymm, xmm/m128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSRLD ymm, ymm, imm8	Shift Int32 Vector Immediate Right Logical	
VPSRLD	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSRLD xmm|mask|z, xmm, xmm/m128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	ymmreg|mask|z,ymmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSRLD ymm|mask|z, ymm, xmm/m128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	zmmreg|mask|z,zmmreg,xmmrm128	AVX512,FUTURE	VPSRLD zmm|mask|z, zmm, xmm/m128	Shift Int32 Vector Immediate Right Logical	
VPSRLD	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPSRLD xmm|mask|z, xmm/m128|b32, imm8	Shift Int32 Vector Immediate Right Logical	
VPSRLD	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPSRLD ymm|mask|z, ymm/m256|b32, imm8	Shift Int32 Vector Immediate Right Logical	
VPSRLD	zmmreg|mask|z,zmmrm512|b32,imm8	AVX512,FUTURE	VPSRLD zmm|mask|z, zmm/m512|b32, imm8	Shift Int32 Vector Immediate Right Logical	
VPSRLQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSRLQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	xmmreg,xmmreg*,imm8	AVX,SANDYBRIDGE	VPSRLQ xmm, xmm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	ymmreg,ymmreg*,xmmrm128	FUTURE,AVX2	VPSRLQ ymm, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	ymmreg,ymmreg*,imm8	FUTURE,AVX2	VPSRLQ ymm, ymm, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSRLQ xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	ymmreg|mask|z,ymmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSRLQ ymm|mask|z, ymm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	zmmreg|mask|z,zmmreg,xmmrm128	AVX512,FUTURE	VPSRLQ zmm|mask|z, zmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	xmmreg|mask|z,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VPSRLQ xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPSRLQ ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSRLQ	zmmreg|mask|z,zmmrm512|b64,imm8	AVX512,FUTURE	VPSRLQ zmm|mask|z, zmm/m512|b32, imm8	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPTEST	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VPTEST xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VPTEST	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VPTEST ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VPSUBB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSUBB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSUBB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSUBB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSUBB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSUBB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSUBW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSUBW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSUBW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSUBW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSUBW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSUBD xmm, xmm, xmm/m128	Subtract Int32 Vectors	
VPSUBD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSUBD ymm, ymm, ymm/m256	Subtract Int32 Vectors	
VPSUBD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPSUBD xmm|mask|z, xmm, xmm/m128|b32	Subtract Int32 Vectors	
VPSUBD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPSUBD ymm|mask|z, ymm, ymm/m256|b32	Subtract Int32 Vectors	
VPSUBD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPSUBD zmm|mask|z, zmm, zmm/m512|b32	Subtract Int32 Vectors	
VPSUBQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSUBQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSUBQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPSUBQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPSUBQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPSUBQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPSUBSB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSUBSB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSUBSB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSUBSB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSUBSB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSUBSB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSUBSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSUBSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSUBSW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSUBSW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBSW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSUBSW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSUBUSB xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSUBUSB ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSUBUSB xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSUBUSB ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSUBUSB zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPSUBUSW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSUBUSW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSUBUSW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSUBUSW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPSUBUSW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSUBUSW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPUNPCKHBW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPUNPCKHBW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPUNPCKHBW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPUNPCKHBW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHBW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPUNPCKHBW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPUNPCKHWD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPUNPCKHWD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPUNPCKHWD xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPUNPCKHWD ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHWD	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPUNPCKHWD zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKHDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPUNPCKHDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHDQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPUNPCKHDQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHDQ	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPUNPCKHDQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHDQ	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPUNPCKHDQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHDQ	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPUNPCKHDQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPUNPCKHQDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPUNPCKHQDQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPUNPCKHQDQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPUNPCKHQDQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKHQDQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPUNPCKHQDQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLBW	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPUNPCKLBW xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLBW	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPUNPCKLBW ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLBW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPUNPCKLBW xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLBW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPUNPCKLBW ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLBW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPUNPCKLBW zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPUNPCKLWD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPUNPCKLWD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPUNPCKLWD xmm|mask|z, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPUNPCKLWD ymm|mask|z, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLWD	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPUNPCKLWD zmm|mask|z, zmm, zmm/m512	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512BW	
VPUNPCKLDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPUNPCKLDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLDQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPUNPCKLDQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLDQ	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPUNPCKLDQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLDQ	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPUNPCKLDQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLDQ	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPUNPCKLDQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPUNPCKLQDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPUNPCKLQDQ ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPUNPCKLQDQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPUNPCKLQDQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPUNPCKLQDQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPUNPCKLQDQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,FUTURE,AVX2,AVX512VL,AVX512	
VPXOR	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPXOR xmm, xmm, xmm/m128	Logical Exclusive OR	PXOR.html
VPXOR	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPXOR ymm, ymm, ymm/m256	Logical Exclusive OR	PXOR.html
VRCPPS	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VRCPPS xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VRCPPS	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VRCPPS ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VRCPSS	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VRCPSS xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE	
VRSQRTPS	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VRSQRTPS xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VRSQRTPS	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VRSQRTPS ymm, ymm/m256	TODO: AVX,SANDYBRIDGE	
VRSQRTSS	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VRSQRTSS xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE	
VROUNDPD	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VROUNDPD xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VROUNDPD	ymmreg,ymmrm256,imm8	AVX,SANDYBRIDGE	VROUNDPD ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE	
VROUNDPS	xmmreg,xmmrm128,imm8	AVX,SANDYBRIDGE	VROUNDPS xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VROUNDPS	ymmreg,ymmrm256,imm8	AVX,SANDYBRIDGE	VROUNDPS ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE	
VROUNDSD	xmmreg,xmmreg*,xmmrm64,imm8	AVX,SANDYBRIDGE	VROUNDSD xmm, xmm, xmm/m64, imm8	TODO: AVX,SANDYBRIDGE	
VROUNDSS	xmmreg,xmmreg*,xmmrm32,imm8	AVX,SANDYBRIDGE	VROUNDSS xmm, xmm, xmm/m32, imm8	TODO: AVX,SANDYBRIDGE	
VSHUFPD	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VSHUFPD xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPD	ymmreg,ymmreg*,ymmrm256,imm8	AVX,SANDYBRIDGE	VSHUFPD ymm, ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPD	xmmreg|mask|z,xmmreg,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VSHUFPD xmm|mask|z, xmm, xmm/m128|b32, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPD	ymmreg|mask|z,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VSHUFPD ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPD	zmmreg|mask|z,zmmreg,zmmrm512|b64,imm8	AVX512,FUTURE	VSHUFPD zmm|mask|z, zmm, zmm/m512|b32, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VSHUFPS xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	ymmreg,ymmreg*,ymmrm256,imm8	AVX,SANDYBRIDGE	VSHUFPS ymm, ymm, ymm/m256, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	xmmreg|mask|z,xmmreg,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VSHUFPS xmm|mask|z, xmm, xmm/m128|b32, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	ymmreg|mask|z,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VSHUFPS ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSHUFPS	zmmreg|mask|z,zmmreg,zmmrm512|b32,imm8	AVX512,FUTURE	VSHUFPS zmm|mask|z, zmm, zmm/m512|b32, imm8	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VSQRTPD xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VSQRTPD ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VSQRTPD xmm|mask|z, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VSQRTPD ymm|mask|z, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPD	zmmreg|mask|z,zmmrm512|b64|er	AVX512,FUTURE	VSQRTPD zmm|mask|z, zmm/m512|b32|er	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VSQRTPS xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VSQRTPS ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VSQRTPS xmm|mask|z, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VSQRTPS ymm|mask|z, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTPS	zmmreg|mask|z,zmmrm512|b32|er	AVX512,FUTURE	VSQRTPS zmm|mask|z, zmm/m512|b32|er	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VSQRTSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VSQRTSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSQRTSD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VSQRTSD xmm|mask|z, xmm, xmm/m64|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSQRTSS	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VSQRTSS xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSQRTSS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VSQRTSS xmm|mask|z, xmm, xmm/m32|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSTMXCSR	mem32	AVX,SANDYBRIDGE	VSTMXCSR mem32	Store MXCSR Register State	STMXCSR.html
VSUBPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VSUBPD xmm, xmm, xmm/m128	Subtract Float64 Vectors	
VSUBPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VSUBPD ymm, ymm, ymm/m256	Subtract Float64 Vectors	
VSUBPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VSUBPD xmm|mask|z, xmm, xmm/m128|b32	Subtract Float64 Vectors	
VSUBPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VSUBPD ymm|mask|z, ymm, ymm/m256|b32	Subtract Float64 Vectors	
VSUBPD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VSUBPD zmm|mask|z, zmm, zmm/m512|b32|er	Subtract Float64 Vectors	
VSUBPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VSUBPS xmm, xmm, xmm/m128	Subtract Float32 Vectors	
VSUBPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VSUBPS ymm, ymm, ymm/m256	Subtract Float32 Vectors	
VSUBPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VSUBPS xmm|mask|z, xmm, xmm/m128|b32	Subtract Float32 Vectors	
VSUBPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VSUBPS ymm|mask|z, ymm, ymm/m256|b32	Subtract Float32 Vectors	
VSUBPS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VSUBPS zmm|mask|z, zmm, zmm/m512|b32|er	Subtract Float32 Vectors	
VSUBSD	xmmreg,xmmreg*,xmmrm64	AVX,SANDYBRIDGE	VSUBSD xmm, xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSUBSD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VSUBSD xmm|mask|z, xmm, xmm/m64|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSUBSS	xmmreg,xmmreg*,xmmrm32	AVX,SANDYBRIDGE	VSUBSS xmm, xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VSUBSS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VSUBSS xmm|mask|z, xmm, xmm/m32|er	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VTESTPS	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VTESTPS xmm, xmm/m128	Packed Bit Test	VTESTPD:VTESTPS.html
VTESTPS	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VTESTPS ymm, ymm/m256	Packed Bit Test	VTESTPD:VTESTPS.html
VTESTPD	xmmreg,xmmrm128	AVX,SANDYBRIDGE	VTESTPD xmm, xmm/m128	Packed Bit Test	VTESTPD:VTESTPS.html
VTESTPD	ymmreg,ymmrm256	AVX,SANDYBRIDGE	VTESTPD ymm, ymm/m256	Packed Bit Test	VTESTPD:VTESTPS.html
VUCOMISD	xmmreg,xmmrm64	AVX,SANDYBRIDGE	VUCOMISD xmm, xmm/m64	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VUCOMISD	xmmreg,xmmrm64|sae	AVX512,FUTURE	VUCOMISD xmm, xmm/m64|sae	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VUCOMISS	xmmreg,xmmrm32	AVX,SANDYBRIDGE	VUCOMISS xmm, xmm/m32	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VUCOMISS	xmmreg,xmmrm32|sae	AVX512,FUTURE	VUCOMISS xmm, xmm/m32|sae	TODO: AVX,SANDYBRIDGE,AVX512,FUTURE	
VUNPCKHPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VUNPCKHPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VUNPCKHPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VUNPCKHPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VUNPCKHPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VUNPCKHPD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VUNPCKHPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VUNPCKHPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VUNPCKHPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VUNPCKHPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKHPS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VUNPCKHPS zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VUNPCKLPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VUNPCKLPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VUNPCKLPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VUNPCKLPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VUNPCKLPD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VUNPCKLPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VUNPCKLPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VUNPCKLPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VUNPCKLPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VUNPCKLPS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VUNPCKLPS zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512,FUTURE	
VXORPD	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VXORPD xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPD	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VXORPD ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VXORPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VXORPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512DQ,FUTURE	VXORPD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VXORPS xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	ymmreg,ymmreg*,ymmrm256	AVX,SANDYBRIDGE	VXORPS ymm, ymm, ymm/m256	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512DQ,FUTURE	VXORPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512DQ,FUTURE	VXORPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VXORPS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512DQ,FUTURE	VXORPS zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX,SANDYBRIDGE,AVX512VL,AVX512DQ,FUTURE	
VZEROALL	none	AVX,SANDYBRIDGE	VZEROALL 	Zero All YMM Registers	VZEROALL.html
VZEROUPPER	none	AVX,SANDYBRIDGE	VZEROUPPER 	Zero Upper Bits of YMM Registers	VZEROUPPER.html
PCLMULLQLQDQ	xmmreg,xmmrm128	SSE,WESTMERE	PCLMULLQLQDQ xmm, xmm/m128	TODO: SSE,WESTMERE	
PCLMULHQLQDQ	xmmreg,xmmrm128	SSE,WESTMERE	PCLMULHQLQDQ xmm, xmm/m128	TODO: SSE,WESTMERE	
PCLMULLQHQDQ	xmmreg,xmmrm128	SSE,WESTMERE	PCLMULLQHQDQ xmm, xmm/m128	TODO: SSE,WESTMERE	
PCLMULHQHQDQ	xmmreg,xmmrm128	SSE,WESTMERE	PCLMULHQHQDQ xmm, xmm/m128	TODO: SSE,WESTMERE	
PCLMULQDQ	xmmreg,xmmrm128,imm8	SSE,WESTMERE	PCLMULQDQ xmm, xmm/m128, imm8	Carry-Less Multiplication Quadword	PCLMULQDQ.html
VPCLMULLQLQDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCLMULLQLQDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VPCLMULHQLQDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCLMULHQLQDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VPCLMULLQHQDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCLMULLQHQDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VPCLMULHQHQDQ	xmmreg,xmmreg*,xmmrm128	AVX,SANDYBRIDGE	VPCLMULHQHQDQ xmm, xmm, xmm/m128	TODO: AVX,SANDYBRIDGE	
VPCLMULQDQ	xmmreg,xmmreg*,xmmrm128,imm8	AVX,SANDYBRIDGE	VPCLMULQDQ xmm, xmm, xmm/m128, imm8	TODO: AVX,SANDYBRIDGE	
VFMADD132PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD132PS xmm, xmm, xmm/m128	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD132PS ymm, ymm, ymm/m256	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMADD132PS xmm|mask|z, xmm, xmm/m128|b32	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMADD132PS ymm|mask|z, ymm, ymm/m256|b32	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMADD132PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Destination By Second Source and Add To First Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD132PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD132PD xmm, xmm, xmm/m128	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD132PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD132PD ymm, ymm, ymm/m256	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD132PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMADD132PD xmm|mask|z, xmm, xmm/m128|b32	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD132PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMADD132PD ymm|mask|z, ymm, ymm/m256|b32	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD132PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMADD132PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Destination By Second Source and Add To First Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD312PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD312PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADD312PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD312PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADD312PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD312PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADD312PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD312PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADD213PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD213PS xmm, xmm, xmm/m128	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD213PS ymm, ymm, ymm/m256	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMADD213PS xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMADD213PS ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMADD213PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Destination and Add Second Source Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD213PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD213PD xmm, xmm, xmm/m128	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD213PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD213PD ymm, ymm, ymm/m256	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD213PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMADD213PD xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD213PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMADD213PD ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD213PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMADD213PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Destination and Add Second Source Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD123PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD123PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADD123PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD123PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADD123PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD123PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADD123PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD123PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADD231PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD231PS xmm, xmm, xmm/m128	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD231PS ymm, ymm, ymm/m256	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMADD231PS xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMADD231PS ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMADD231PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Second Source and Add To Destination Float32 Vectors	VFMADD132PS:VFMADD213PS:VFMADD231PS.html
VFMADD231PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD231PD xmm, xmm, xmm/m128	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD231PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD231PD ymm, ymm, ymm/m256	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD231PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMADD231PD xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD231PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMADD231PD ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD231PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMADD231PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Second Source and Add To Destination Float64 Vectors	VFMADD132PD:VFMADD213PD:VFMADD231PD.html
VFMADD321PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD321PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADD321PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD321PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADD321PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADD321PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADD321PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADD321PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADDSUB132PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB132PS xmm, xmm, xmm/m128	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB132PS ymm, ymm, ymm/m256	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMADDSUB132PS xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMADDSUB132PS ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMADDSUB132PS zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB132PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB132PD xmm, xmm, xmm/m128	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB132PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB132PD ymm, ymm, ymm/m256	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB132PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMADDSUB132PD xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB132PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMADDSUB132PD ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB132PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMADDSUB132PD zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB312PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB312PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADDSUB312PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB312PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADDSUB312PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB312PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADDSUB312PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB312PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADDSUB213PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB213PS xmm, xmm, xmm/m128	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB213PS ymm, ymm, ymm/m256	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMADDSUB213PS xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMADDSUB213PS ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMADDSUB213PS zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB213PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB213PD xmm, xmm, xmm/m128	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB213PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB213PD ymm, ymm, ymm/m256	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB213PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMADDSUB213PD xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB213PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMADDSUB213PD ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB213PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMADDSUB213PD zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB123PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB123PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADDSUB123PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB123PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADDSUB123PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB123PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADDSUB123PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB123PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADDSUB231PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB231PS xmm, xmm, xmm/m128	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB231PS ymm, ymm, ymm/m256	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMADDSUB231PS xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMADDSUB231PS ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMADDSUB231PS zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Add/Subtract of Packed Single-Precision Floating-Point Values	VFMADDSUB132PS:VFMADDSUB213PS:VFMADDSUB231PS.html
VFMADDSUB231PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB231PD xmm, xmm, xmm/m128	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB231PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB231PD ymm, ymm, ymm/m256	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB231PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMADDSUB231PD xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB231PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMADDSUB231PD ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB231PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMADDSUB231PD zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Add/Subtract of Packed Double-Precision Floating-Point Values	VFMADDSUB132PD:VFMADDSUB213PD:VFMADDSUB231PD.html
VFMADDSUB321PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB321PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADDSUB321PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB321PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADDSUB321PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMADDSUB321PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMADDSUB321PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMADDSUB321PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUB132PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB132PS xmm, xmm, xmm/m128	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB132PS ymm, ymm, ymm/m256	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMSUB132PS xmm|mask|z, xmm, xmm/m128|b32	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMSUB132PS ymm|mask|z, ymm, ymm/m256|b32	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMSUB132PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Destination By Second Source and Subtract First Source Float32 Vectors231	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB132PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB132PD xmm, xmm, xmm/m128	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB132PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB132PD ymm, ymm, ymm/m256	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB132PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMSUB132PD xmm|mask|z, xmm, xmm/m128|b32	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB132PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMSUB132PD ymm|mask|z, ymm, ymm/m256|b32	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB132PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMSUB132PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Destination By Second Source and Subtract First Source Float64 Vectors	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB312PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB312PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUB312PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB312PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUB312PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB312PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUB312PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB312PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUB213PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB213PS xmm, xmm, xmm/m128	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB213PS ymm, ymm, ymm/m256	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMSUB213PS xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMSUB213PS ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMSUB213PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Destination and Subtract Second Source Float32 Vectors238	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB213PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB213PD xmm, xmm, xmm/m128	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB213PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB213PD ymm, ymm, ymm/m256	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB213PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMSUB213PD xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB213PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMSUB213PD ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB213PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMSUB213PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Destination and Subtract Second Source Float64 Vectors234	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB123PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB123PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUB123PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB123PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUB123PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB123PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUB123PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB123PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUB231PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB231PS xmm, xmm, xmm/m128	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB231PS ymm, ymm, ymm/m256	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMSUB231PS xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMSUB231PS ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMSUB231PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Second Source and Subtract Destination Float32 Vectors245	VFMSUB132PS:VFMSUB213PS:VFMSUB231PS.html
VFMSUB231PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB231PD xmm, xmm, xmm/m128	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB231PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB231PD ymm, ymm, ymm/m256	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB231PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMSUB231PD xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB231PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMSUB231PD ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB231PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMSUB231PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Second Source and Subtract Destination Float64 Vectors241	VFMSUB132PD:VFMSUB213PD:VFMSUB231PD.html
VFMSUB321PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB321PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUB321PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB321PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUB321PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUB321PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUB321PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUB321PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUBADD132PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD132PS xmm, xmm, xmm/m128	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD132PS ymm, ymm, ymm/m256	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMSUBADD132PS xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMSUBADD132PS ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMSUBADD132PS zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD132PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD132PD xmm, xmm, xmm/m128	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD132PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD132PD ymm, ymm, ymm/m256	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD132PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMSUBADD132PD xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD132PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMSUBADD132PD ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD132PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMSUBADD132PD zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD312PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD312PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUBADD312PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD312PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUBADD312PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD312PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUBADD312PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD312PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUBADD213PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD213PS xmm, xmm, xmm/m128	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD213PS ymm, ymm, ymm/m256	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMSUBADD213PS xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMSUBADD213PS ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMSUBADD213PS zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD213PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD213PD xmm, xmm, xmm/m128	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD213PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD213PD ymm, ymm, ymm/m256	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD213PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMSUBADD213PD xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD213PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMSUBADD213PD ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD213PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMSUBADD213PD zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD123PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD123PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUBADD123PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD123PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUBADD123PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD123PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUBADD123PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD123PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUBADD231PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD231PS xmm, xmm, xmm/m128	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD231PS ymm, ymm, ymm/m256	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFMSUBADD231PS xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFMSUBADD231PS ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFMSUBADD231PS zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Subtract/Add of Packed Single-Precision Floating-Point Values	VFMSUBADD132PS:VFMSUBADD213PS:VFMSUBADD231PS.html
VFMSUBADD231PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD231PD xmm, xmm, xmm/m128	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD231PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD231PD ymm, ymm, ymm/m256	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD231PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFMSUBADD231PD xmm|mask|z, xmm, xmm/m128|b32	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD231PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFMSUBADD231PD ymm|mask|z, ymm, ymm/m256|b32	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD231PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFMSUBADD231PD zmm|mask|z, zmm, zmm/m512|b32|er	Fused Multiply-Alternating Subtract/Add of Packed Double-Precision Floating-Point Values	VFMSUBADD132PD:VFMSUBADD213PD:VFMSUBADD231PD.html
VFMSUBADD321PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD321PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUBADD321PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD321PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMSUBADD321PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFMSUBADD321PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFMSUBADD321PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFMSUBADD321PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMADD132PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD132PS xmm, xmm, xmm/m128	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD132PS ymm, ymm, ymm/m256	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFNMADD132PS xmm|mask|z, xmm, xmm/m128|b32	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFNMADD132PS ymm|mask|z, ymm, ymm/m256|b32	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFNMADD132PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Destination By Second Source and Subtract From First Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD132PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD132PD xmm, xmm, xmm/m128	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD132PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD132PD ymm, ymm, ymm/m256	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD132PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFNMADD132PD xmm|mask|z, xmm, xmm/m128|b32	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD132PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFNMADD132PD ymm|mask|z, ymm, ymm/m256|b32	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD132PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFNMADD132PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Destination By Second Source and Subtract From First Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD312PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD312PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMADD312PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD312PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMADD312PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD312PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMADD312PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD312PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMADD213PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD213PS xmm, xmm, xmm/m128	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD213PS ymm, ymm, ymm/m256	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFNMADD213PS xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFNMADD213PS ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFNMADD213PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Destination and Subtract From Second Source Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD213PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD213PD xmm, xmm, xmm/m128	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD213PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD213PD ymm, ymm, ymm/m256	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD213PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFNMADD213PD xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD213PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFNMADD213PD ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD213PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFNMADD213PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Destination and Subtract From Second Source Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD123PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD123PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMADD123PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD123PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMADD123PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD123PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMADD123PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD123PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMADD231PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD231PS xmm, xmm, xmm/m128	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD231PS ymm, ymm, ymm/m256	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFNMADD231PS xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFNMADD231PS ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFNMADD231PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Second Source and Subtract From Destination Float32 Vectors	VFNMADD132PS:VFNMADD213PS:VFNMADD231PS.html
VFNMADD231PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD231PD xmm, xmm, xmm/m128	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD231PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD231PD ymm, ymm, ymm/m256	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD231PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFNMADD231PD xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD231PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFNMADD231PD ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD231PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFNMADD231PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Second Source and Subtract From Destination Float64 Vectors	VFNMADD132PD:VFNMADD213PD:VFNMADD231PD.html
VFNMADD321PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD321PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMADD321PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD321PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMADD321PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMADD321PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMADD321PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMADD321PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMSUB132PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB132PS xmm, xmm, xmm/m128	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB132PS ymm, ymm, ymm/m256	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFNMSUB132PS xmm|mask|z, xmm, xmm/m128|b32	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFNMSUB132PS ymm|mask|z, ymm, ymm/m256|b32	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFNMSUB132PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Destination By Second Source, Negate, and Subtract First Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB132PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB132PD xmm, xmm, xmm/m128	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB132PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB132PD ymm, ymm, ymm/m256	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB132PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFNMSUB132PD xmm|mask|z, xmm, xmm/m128|b32	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB132PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFNMSUB132PD ymm|mask|z, ymm, ymm/m256|b32	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB132PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFNMSUB132PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply Destination By Second Source, Negate, and Subtract First Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB312PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB312PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMSUB312PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB312PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMSUB312PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB312PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMSUB312PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB312PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMSUB213PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB213PS xmm, xmm, xmm/m128	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB213PS ymm, ymm, ymm/m256	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFNMSUB213PS xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFNMSUB213PS ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFNMSUB213PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Destination, Negate, and Subtract Second Source Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB213PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB213PD xmm, xmm, xmm/m128	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB213PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB213PD ymm, ymm, ymm/m256	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB213PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFNMSUB213PD xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB213PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFNMSUB213PD ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB213PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFNMSUB213PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Destination, Negate, and Subtract Second Source Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB123PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB123PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMSUB123PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB123PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMSUB123PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB123PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMSUB123PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB123PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMSUB231PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB231PS xmm, xmm, xmm/m128	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB231PS ymm, ymm, ymm/m256	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VFNMSUB231PS xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VFNMSUB231PS ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VFNMSUB231PS zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Second Source, Negate, and Subtract Destination Float32 Vectors	VFNMSUB132PS:VFNMSUB213PS:VFNMSUB231PS.html
VFNMSUB231PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB231PD xmm, xmm, xmm/m128	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB231PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB231PD ymm, ymm, ymm/m256	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB231PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VFNMSUB231PD xmm|mask|z, xmm, xmm/m128|b32	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB231PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VFNMSUB231PD ymm|mask|z, ymm, ymm/m256|b32	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB231PD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VFNMSUB231PD zmm|mask|z, zmm, zmm/m512|b32|er	Multiply First Source By Second Source, Negate, and Subtract Destination Float64 Vectors	VFNMSUB132PD:VFNMSUB213PD:VFNMSUB231PD.html
VFNMSUB321PS	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB321PS xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMSUB321PS	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB321PS ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFNMSUB321PD	xmmreg,xmmreg,xmmrm128	FMA,FUTURE	VFNMSUB321PD xmm, xmm, xmm/m128	TODO: FMA,FUTURE	
VFNMSUB321PD	ymmreg,ymmreg,ymmrm256	FMA,FUTURE	VFNMSUB321PD ymm, ymm, ymm/m256	TODO: FMA,FUTURE	
VFMADD132SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMADD132SS xmm, xmm, xmm/m32	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD132SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFMADD132SS xmm|mask|z, xmm, xmm/m32|er	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD132SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMADD132SD xmm, xmm, xmm/m64	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD132SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFMADD132SD xmm|mask|z, xmm, xmm/m64|er	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD312SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMADD312SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFMADD312SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMADD312SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFMADD213SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMADD213SS xmm, xmm, xmm/m32	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD213SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFMADD213SS xmm|mask|z, xmm, xmm/m32|er	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD213SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMADD213SD xmm, xmm, xmm/m64	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD213SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFMADD213SD xmm|mask|z, xmm, xmm/m64|er	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD123SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMADD123SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFMADD123SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMADD123SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFMADD231SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMADD231SS xmm, xmm, xmm/m32	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD231SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFMADD231SS xmm|mask|z, xmm, xmm/m32|er	Fused Multiply-Add of Scalar Single-Precision Floating-Point Values	VFMADD132SS:VFMADD213SS:VFMADD231SS.html
VFMADD231SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMADD231SD xmm, xmm, xmm/m64	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD231SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFMADD231SD xmm|mask|z, xmm, xmm/m64|er	Fused Multiply-Add of Scalar Double-Precision Floating-Point Values	VFMADD132SD:VFMADD213SD:VFMADD231SD.html
VFMADD321SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMADD321SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFMADD321SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMADD321SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFMSUB132SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMSUB132SS xmm, xmm, xmm/m32	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB132SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFMSUB132SS xmm|mask|z, xmm, xmm/m32|er	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB132SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMSUB132SD xmm, xmm, xmm/m64	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB132SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFMSUB132SD xmm|mask|z, xmm, xmm/m64|er	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB312SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMSUB312SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFMSUB312SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMSUB312SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFMSUB213SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMSUB213SS xmm, xmm, xmm/m32	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB213SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFMSUB213SS xmm|mask|z, xmm, xmm/m32|er	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB213SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMSUB213SD xmm, xmm, xmm/m64	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB213SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFMSUB213SD xmm|mask|z, xmm, xmm/m64|er	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB123SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMSUB123SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFMSUB123SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMSUB123SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFMSUB231SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMSUB231SS xmm, xmm, xmm/m32	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB231SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFMSUB231SS xmm|mask|z, xmm, xmm/m32|er	Fused Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFMSUB132SS:VFMSUB213SS:VFMSUB231SS.html
VFMSUB231SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMSUB231SD xmm, xmm, xmm/m64	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB231SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFMSUB231SD xmm|mask|z, xmm, xmm/m64|er	Fused Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFMSUB132SD:VFMSUB213SD:VFMSUB231SD.html
VFMSUB321SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFMSUB321SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFMSUB321SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFMSUB321SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFNMADD132SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMADD132SS xmm, xmm, xmm/m32	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD132SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFNMADD132SS xmm|mask|z, xmm, xmm/m32|er	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD132SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMADD132SD xmm, xmm, xmm/m64	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD132SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFNMADD132SD xmm|mask|z, xmm, xmm/m64|er	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD312SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMADD312SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFNMADD312SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMADD312SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFNMADD213SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMADD213SS xmm, xmm, xmm/m32	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD213SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFNMADD213SS xmm|mask|z, xmm, xmm/m32|er	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD213SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMADD213SD xmm, xmm, xmm/m64	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD213SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFNMADD213SD xmm|mask|z, xmm, xmm/m64|er	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD123SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMADD123SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFNMADD123SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMADD123SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFNMADD231SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMADD231SS xmm, xmm, xmm/m32	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD231SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFNMADD231SS xmm|mask|z, xmm, xmm/m32|er	Fused Negative Multiply-Add of Scalar Single-Precision Floating-Point Values	VFNMADD132SS:VFNMADD213SS:VFNMADD231SS.html
VFNMADD231SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMADD231SD xmm, xmm, xmm/m64	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD231SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFNMADD231SD xmm|mask|z, xmm, xmm/m64|er	Fused Negative Multiply-Add of Scalar Double-Precision Floating-Point Values	VFNMADD132SD:VFNMADD213SD:VFNMADD231SD.html
VFNMADD321SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMADD321SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFNMADD321SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMADD321SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFNMSUB132SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMSUB132SS xmm, xmm, xmm/m32	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB132SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFNMSUB132SS xmm|mask|z, xmm, xmm/m32|er	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB132SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMSUB132SD xmm, xmm, xmm/m64	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB132SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFNMSUB132SD xmm|mask|z, xmm, xmm/m64|er	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB312SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMSUB312SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFNMSUB312SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMSUB312SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFNMSUB213SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMSUB213SS xmm, xmm, xmm/m32	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB213SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFNMSUB213SS xmm|mask|z, xmm, xmm/m32|er	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB213SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMSUB213SD xmm, xmm, xmm/m64	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB213SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFNMSUB213SD xmm|mask|z, xmm, xmm/m64|er	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB123SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMSUB123SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFNMSUB123SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMSUB123SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
VFNMSUB231SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMSUB231SS xmm, xmm, xmm/m32	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB231SS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VFNMSUB231SS xmm|mask|z, xmm, xmm/m32|er	Fused Negative Multiply-Subtract of Scalar Single-Precision Floating-Point Values	VFNMSUB132SS:VFNMSUB213SS:VFNMSUB231SS.html
VFNMSUB231SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMSUB231SD xmm, xmm, xmm/m64	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB231SD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VFNMSUB231SD xmm|mask|z, xmm, xmm/m64|er	Fused Negative Multiply-Subtract of Scalar Double-Precision Floating-Point Values	VFNMSUB132SD:VFNMSUB213SD:VFNMSUB231SD.html
VFNMSUB321SS	xmmreg,xmmreg,xmmrm32	FMA,FUTURE	VFNMSUB321SS xmm, xmm, xmm/m32	TODO: FMA,FUTURE	
VFNMSUB321SD	xmmreg,xmmreg,xmmrm64	FMA,FUTURE	VFNMSUB321SD xmm, xmm, xmm/m64	TODO: FMA,FUTURE	
RDFSBASE	reg32	LONG,FUTURE	RDFSBASE r32	Read FS/GS Segment Base	RDFSBASE:RDGSBASE.html
RDFSBASE	reg64	LONG,FUTURE	RDFSBASE r64	Read FS/GS Segment Base	RDFSBASE:RDGSBASE.html
RDGSBASE	reg32	LONG,FUTURE	RDGSBASE r32	Read FS/GS Segment Base	RDFSBASE:RDGSBASE.html
RDGSBASE	reg64	LONG,FUTURE	RDGSBASE r64	Read FS/GS Segment Base	RDFSBASE:RDGSBASE.html
RDRAND	reg16	FUTURE	RDRAND r16	Read Random Number	RDRAND.html
RDRAND	reg32	FUTURE	RDRAND r32	Read Random Number	RDRAND.html
RDRAND	reg64	LONG,FUTURE	RDRAND r64	Read Random Number	RDRAND.html
WRFSBASE	reg32	LONG,FUTURE	WRFSBASE r32	Write FS/GS Segment Base	WRFSBASE:WRGSBASE.html
WRFSBASE	reg64	LONG,FUTURE	WRFSBASE r64	Write FS/GS Segment Base	WRFSBASE:WRGSBASE.html
WRGSBASE	reg32	LONG,FUTURE	WRGSBASE r32	Write FS/GS Segment Base	WRFSBASE:WRGSBASE.html
WRGSBASE	reg64	LONG,FUTURE	WRGSBASE r64	Write FS/GS Segment Base	WRFSBASE:WRGSBASE.html
VCVTPH2PS	ymmreg,xmmrm128	AVX,FUTURE	VCVTPH2PS ymm, xmm/m128	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPH2PS	xmmreg,xmmrm64	AVX,FUTURE	VCVTPH2PS xmm, xmm/m64	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPH2PS	xmmreg|mask|z,xmmrm64	AVX512VL,AVX512,FUTURE	VCVTPH2PS xmm|mask|z, xmm/m64	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPH2PS	ymmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VCVTPH2PS ymm|mask|z, xmm/m128	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPH2PS	zmmreg|mask|z,ymmrm256|sae	AVX512,FUTURE	VCVTPH2PS zmm|mask|z, ymm/m256|sae	Convert 16-bit FP Values to Single-Precision FP Values	VCVTPH2PS.html
VCVTPS2PH	xmmrm128,ymmreg,imm8	AVX,FUTURE	VCVTPS2PH xmm/m128, ymm, imm8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	xmmrm64,xmmreg,imm8	AVX,FUTURE	VCVTPS2PH xmm/m64, xmm, imm8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	xmmreg|mask|z,xmmreg,imm8	AVX512VL,AVX512,FUTURE	VCVTPS2PH xmm|mask|z, xmm, imm8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	xmmreg|mask|z,ymmreg,imm8	AVX512VL,AVX512,FUTURE	VCVTPS2PH xmm|mask|z, ymm, imm8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	ymmreg|mask|z,zmmreg|sae,imm8	AVX512,FUTURE	VCVTPS2PH ymm|mask|z, zmm|sae, imm8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	mem64|mask,xmmreg,imm8	AVX512VL,AVX512,FUTURE	VCVTPS2PH mem64|mask, xmm, imm8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	mem128|mask,ymmreg,imm8	AVX512VL,AVX512,FUTURE	VCVTPS2PH mem128|mask, ymm, imm8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
VCVTPS2PH	mem256|mask,zmmreg|sae,imm8	AVX512,FUTURE	VCVTPS2PH mem256|mask, zmm|sae, imm8	Convert Single-Precision FP value to 16-bit FP value	VCVTPS2PH.html
ADCX	reg32,rm32	FUTURE	ADCX r32, r/m32	Unsigned Integer Addition of Two Operands with Carry Flag	ADCX.html
ADCX	reg64,rm64	LONG,FUTURE	ADCX r64, r/m64	Unsigned Integer Addition of Two Operands with Carry Flag	ADCX.html
ADOX	reg32,rm32	FUTURE	ADOX r32, r/m32	Unsigned Integer Addition of Two Operands with Overflow Flag	ADOX.html
ADOX	reg64,rm64	LONG,FUTURE	ADOX r64, r/m64	Unsigned Integer Addition of Two Operands with Overflow Flag	ADOX.html
RDSEED	reg16	FUTURE	RDSEED r16	Read Random SEED	RDSEED.html
RDSEED	reg32	FUTURE	RDSEED r32	Read Random SEED	RDSEED.html
RDSEED	reg64	LONG,FUTURE	RDSEED r64	Read Random SEED	RDSEED.html
CLAC	none	PRIV,FUTURE	CLAC 	Clear AC Flag in EFLAGS Register	CLAC.html
STAC	none	PRIV,FUTURE	STAC 	Set AC Flag in EFLAGS Register	STAC.html
XSTORE	none	PENT,CYRIX	XSTORE 	TODO: PENT,CYRIX	
XCRYPTECB	none	PENT,CYRIX	XCRYPTECB 	TODO: PENT,CYRIX	
XCRYPTCBC	none	PENT,CYRIX	XCRYPTCBC 	TODO: PENT,CYRIX	
XCRYPTCTR	none	PENT,CYRIX	XCRYPTCTR 	TODO: PENT,CYRIX	
XCRYPTCFB	none	PENT,CYRIX	XCRYPTCFB 	TODO: PENT,CYRIX	
XCRYPTOFB	none	PENT,CYRIX	XCRYPTOFB 	TODO: PENT,CYRIX	
MONTMUL	none	PENT,CYRIX	MONTMUL 	TODO: PENT,CYRIX	
XSHA1	none	PENT,CYRIX	XSHA1 	TODO: PENT,CYRIX	
XSHA256	none	PENT,CYRIX	XSHA256 	TODO: PENT,CYRIX	
LLWPCB	reg32	AMD,386	LLWPCB r32	TODO: AMD,386,X64	
LLWPCB	reg64	AMD,X64	LLWPCB r64	TODO: AMD,386,X64	
SLWPCB	reg32	AMD,386	SLWPCB r32	TODO: AMD,386,X64	
SLWPCB	reg64	AMD,X64	SLWPCB r64	TODO: AMD,386,X64	
LWPVAL	reg32,rm32,imm32	AMD,386	LWPVAL r32, r/m32, imm32	TODO: AMD,386,X64	
LWPVAL	reg64,rm32,imm32	AMD,X64	LWPVAL r64, r/m32, imm32	TODO: AMD,386,X64	
LWPINS	reg32,rm32,imm32	AMD,386	LWPINS r32, r/m32, imm32	TODO: AMD,386,X64	
LWPINS	reg64,rm32,imm32	AMD,X64	LWPINS r64, r/m32, imm32	TODO: AMD,386,X64	
VFMADDPD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFMADDPD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFMADDPD	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFMADDPD ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFMADDPD	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFMADDPD xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFMADDPD	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFMADDPD ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFMADDPS	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFMADDPS xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFMADDPS	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFMADDPS ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFMADDPS	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFMADDPS xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFMADDPS	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFMADDPS ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFMADDSD	xmmreg,xmmreg*,xmmrm64,xmmreg	AMD,SSE5	VFMADDSD xmm, xmm, xmm/m64, xmm	TODO: AMD,SSE5	
VFMADDSD	xmmreg,xmmreg*,xmmreg,xmmrm64	AMD,SSE5	VFMADDSD xmm, xmm, xmm, xmm/m64	TODO: AMD,SSE5	
VFMADDSS	xmmreg,xmmreg*,xmmrm32,xmmreg	AMD,SSE5	VFMADDSS xmm, xmm, xmm/m32, xmm	TODO: AMD,SSE5	
VFMADDSS	xmmreg,xmmreg*,xmmreg,xmmrm32	AMD,SSE5	VFMADDSS xmm, xmm, xmm, xmm/m32	TODO: AMD,SSE5	
VFMADDSUBPD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFMADDSUBPD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFMADDSUBPD	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFMADDSUBPD ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFMADDSUBPD	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFMADDSUBPD xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFMADDSUBPD	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFMADDSUBPD ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFMADDSUBPS	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFMADDSUBPS xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFMADDSUBPS	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFMADDSUBPS ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFMADDSUBPS	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFMADDSUBPS xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFMADDSUBPS	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFMADDSUBPS ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFMSUBADDPD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFMSUBADDPD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFMSUBADDPD	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFMSUBADDPD ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFMSUBADDPD	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFMSUBADDPD xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFMSUBADDPD	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFMSUBADDPD ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFMSUBADDPS	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFMSUBADDPS xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFMSUBADDPS	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFMSUBADDPS ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFMSUBADDPS	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFMSUBADDPS xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFMSUBADDPS	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFMSUBADDPS ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFMSUBPD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFMSUBPD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFMSUBPD	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFMSUBPD ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFMSUBPD	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFMSUBPD xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFMSUBPD	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFMSUBPD ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFMSUBPS	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFMSUBPS xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFMSUBPS	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFMSUBPS ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFMSUBPS	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFMSUBPS xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFMSUBPS	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFMSUBPS ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFMSUBSD	xmmreg,xmmreg*,xmmrm64,xmmreg	AMD,SSE5	VFMSUBSD xmm, xmm, xmm/m64, xmm	TODO: AMD,SSE5	
VFMSUBSD	xmmreg,xmmreg*,xmmreg,xmmrm64	AMD,SSE5	VFMSUBSD xmm, xmm, xmm, xmm/m64	TODO: AMD,SSE5	
VFMSUBSS	xmmreg,xmmreg*,xmmrm32,xmmreg	AMD,SSE5	VFMSUBSS xmm, xmm, xmm/m32, xmm	TODO: AMD,SSE5	
VFMSUBSS	xmmreg,xmmreg*,xmmreg,xmmrm32	AMD,SSE5	VFMSUBSS xmm, xmm, xmm, xmm/m32	TODO: AMD,SSE5	
VFNMADDPD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFNMADDPD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFNMADDPD	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFNMADDPD ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFNMADDPD	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFNMADDPD xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFNMADDPD	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFNMADDPD ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFNMADDPS	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFNMADDPS xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFNMADDPS	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFNMADDPS ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFNMADDPS	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFNMADDPS xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFNMADDPS	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFNMADDPS ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFNMADDSD	xmmreg,xmmreg*,xmmrm64,xmmreg	AMD,SSE5	VFNMADDSD xmm, xmm, xmm/m64, xmm	TODO: AMD,SSE5	
VFNMADDSD	xmmreg,xmmreg*,xmmreg,xmmrm64	AMD,SSE5	VFNMADDSD xmm, xmm, xmm, xmm/m64	TODO: AMD,SSE5	
VFNMADDSS	xmmreg,xmmreg*,xmmrm32,xmmreg	AMD,SSE5	VFNMADDSS xmm, xmm, xmm/m32, xmm	TODO: AMD,SSE5	
VFNMADDSS	xmmreg,xmmreg*,xmmreg,xmmrm32	AMD,SSE5	VFNMADDSS xmm, xmm, xmm, xmm/m32	TODO: AMD,SSE5	
VFNMSUBPD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFNMSUBPD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFNMSUBPD	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFNMSUBPD ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFNMSUBPD	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFNMSUBPD xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFNMSUBPD	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFNMSUBPD ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFNMSUBPS	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VFNMSUBPS xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VFNMSUBPS	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VFNMSUBPS ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VFNMSUBPS	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VFNMSUBPS xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VFNMSUBPS	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VFNMSUBPS ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VFNMSUBSD	xmmreg,xmmreg*,xmmrm64,xmmreg	AMD,SSE5	VFNMSUBSD xmm, xmm, xmm/m64, xmm	TODO: AMD,SSE5	
VFNMSUBSD	xmmreg,xmmreg*,xmmreg,xmmrm64	AMD,SSE5	VFNMSUBSD xmm, xmm, xmm, xmm/m64	TODO: AMD,SSE5	
VFNMSUBSS	xmmreg,xmmreg*,xmmrm32,xmmreg	AMD,SSE5	VFNMSUBSS xmm, xmm, xmm/m32, xmm	TODO: AMD,SSE5	
VFNMSUBSS	xmmreg,xmmreg*,xmmreg,xmmrm32	AMD,SSE5	VFNMSUBSS xmm, xmm, xmm, xmm/m32	TODO: AMD,SSE5	
VFRCZPD	xmmreg,xmmrm128*	AMD,SSE5	VFRCZPD xmm, xmm/m128	TODO: AMD,SSE5	
VFRCZPD	ymmreg,ymmrm256*	AMD,SSE5	VFRCZPD ymm, ymm/m256	TODO: AMD,SSE5	
VFRCZPS	xmmreg,xmmrm128*	AMD,SSE5	VFRCZPS xmm, xmm/m128	TODO: AMD,SSE5	
VFRCZPS	ymmreg,ymmrm256*	AMD,SSE5	VFRCZPS ymm, ymm/m256	TODO: AMD,SSE5	
VFRCZSD	xmmreg,xmmrm64*	AMD,SSE5	VFRCZSD xmm, xmm/m64	TODO: AMD,SSE5	
VFRCZSS	xmmreg,xmmrm32*	AMD,SSE5	VFRCZSS xmm, xmm/m32	TODO: AMD,SSE5	
VPCMOV	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPCMOV xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPCMOV	ymmreg,ymmreg*,ymmrm256,ymmreg	AMD,SSE5	VPCMOV ymm, ymm, ymm/m256, ymm	TODO: AMD,SSE5	
VPCMOV	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VPCMOV xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPCMOV	ymmreg,ymmreg*,ymmreg,ymmrm256	AMD,SSE5	VPCMOV ymm, ymm, ymm, ymm/m256	TODO: AMD,SSE5	
VPCOMB	xmmreg,xmmreg*,xmmrm128,imm8	AMD,SSE5	VPCOMB xmm, xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPCOMD	xmmreg,xmmreg*,xmmrm128,imm8	AMD,SSE5	VPCOMD xmm, xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPCOMQ	xmmreg,xmmreg*,xmmrm128,imm8	AMD,SSE5	VPCOMQ xmm, xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPCOMUB	xmmreg,xmmreg*,xmmrm128,imm8	AMD,SSE5	VPCOMUB xmm, xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPCOMUD	xmmreg,xmmreg*,xmmrm128,imm8	AMD,SSE5	VPCOMUD xmm, xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPCOMUQ	xmmreg,xmmreg*,xmmrm128,imm8	AMD,SSE5	VPCOMUQ xmm, xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPCOMUW	xmmreg,xmmreg*,xmmrm128,imm8	AMD,SSE5	VPCOMUW xmm, xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPCOMW	xmmreg,xmmreg*,xmmrm128,imm8	AMD,SSE5	VPCOMW xmm, xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPHADDBD	xmmreg,xmmrm128*	AMD,SSE5	VPHADDBD xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDBQ	xmmreg,xmmrm128*	AMD,SSE5	VPHADDBQ xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDBW	xmmreg,xmmrm128*	AMD,SSE5	VPHADDBW xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDDQ	xmmreg,xmmrm128*	AMD,SSE5	VPHADDDQ xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDUBD	xmmreg,xmmrm128*	AMD,SSE5	VPHADDUBD xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDUBQ	xmmreg,xmmrm128*	AMD,SSE5	VPHADDUBQ xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDUBW	xmmreg,xmmrm128*	AMD,SSE5	VPHADDUBW xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDUDQ	xmmreg,xmmrm128*	AMD,SSE5	VPHADDUDQ xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDUWD	xmmreg,xmmrm128*	AMD,SSE5	VPHADDUWD xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDUWQ	xmmreg,xmmrm128*	AMD,SSE5	VPHADDUWQ xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDWD	xmmreg,xmmrm128*	AMD,SSE5	VPHADDWD xmm, xmm/m128	TODO: AMD,SSE5	
VPHADDWQ	xmmreg,xmmrm128*	AMD,SSE5	VPHADDWQ xmm, xmm/m128	TODO: AMD,SSE5	
VPHSUBBW	xmmreg,xmmrm128*	AMD,SSE5	VPHSUBBW xmm, xmm/m128	TODO: AMD,SSE5	
VPHSUBDQ	xmmreg,xmmrm128*	AMD,SSE5	VPHSUBDQ xmm, xmm/m128	TODO: AMD,SSE5	
VPHSUBWD	xmmreg,xmmrm128*	AMD,SSE5	VPHSUBWD xmm, xmm/m128	TODO: AMD,SSE5	
VPMACSDD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSDD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMACSDQH	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSDQH xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMACSDQL	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSDQL xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMACSSDD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSSDD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMACSSDQH	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSSDQH xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMACSSDQL	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSSDQL xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMACSSWD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSSWD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMACSSWW	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSSWW xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMACSWD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSWD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMACSWW	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMACSWW xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMADCSSWD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMADCSSWD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPMADCSWD	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPMADCSWD xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPPERM	xmmreg,xmmreg*,xmmreg,xmmrm128	AMD,SSE5	VPPERM xmm, xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPPERM	xmmreg,xmmreg*,xmmrm128,xmmreg	AMD,SSE5	VPPERM xmm, xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPROTB	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPROTB xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPROTB	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPROTB xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPROTB	xmmreg,xmmrm128*,imm8	AMD,SSE5	VPROTB xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPROTD	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPROTD xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPROTD	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPROTD xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPROTD	xmmreg,xmmrm128*,imm8	AMD,SSE5	VPROTD xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPROTQ	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPROTQ xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPROTQ	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPROTQ xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPROTQ	xmmreg,xmmrm128*,imm8	AMD,SSE5	VPROTQ xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPROTW	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPROTW xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPROTW	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPROTW xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPROTW	xmmreg,xmmrm128*,imm8	AMD,SSE5	VPROTW xmm, xmm/m128, imm8	TODO: AMD,SSE5	
VPSHAB	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPSHAB xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPSHAB	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPSHAB xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPSHAD	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPSHAD xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPSHAD	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPSHAD xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPSHAQ	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPSHAQ xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPSHAQ	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPSHAQ xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPSHAW	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPSHAW xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPSHAW	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPSHAW xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPSHLB	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPSHLB xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPSHLB	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPSHLB xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPSHLD	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPSHLD xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPSHLD	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPSHLD xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPSHLQ	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPSHLQ xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPSHLQ	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPSHLQ xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VPSHLW	xmmreg,xmmrm128*,xmmreg	AMD,SSE5	VPSHLW xmm, xmm/m128, xmm	TODO: AMD,SSE5	
VPSHLW	xmmreg,xmmreg*,xmmrm128	AMD,SSE5	VPSHLW xmm, xmm, xmm/m128	TODO: AMD,SSE5	
VBROADCASTI128	ymmreg,mem128	FUTURE,AVX2	VBROADCASTI128 ymm, mem128	Copy a 128-bit memory operand to all elements of a YMM vector Register	VPBROADCAST.html
VPBLENDD	xmmreg,xmmreg*,xmmrm128,imm8	FUTURE,AVX2	VPBLENDD xmm, xmm, xmm/m128, imm8	Blend Packed Dwords	VPBLENDD.html
VPBLENDD	ymmreg,ymmreg*,ymmrm256,imm8	FUTURE,AVX2	VPBLENDD ymm, ymm, ymm/m256, imm8	Blend Packed Dwords	VPBLENDD.html
VPBROADCASTB	xmmreg,mem8	FUTURE,AVX2	VPBROADCASTB xmm, mem8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	xmmreg,xmmreg	FUTURE,AVX2	VPBROADCASTB xmm, xmm	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ymmreg,mem8	FUTURE,AVX2	VPBROADCASTB ymm, mem8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ymmreg,xmmreg	FUTURE,AVX2	VPBROADCASTB ymm, xmm	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	xmmreg|mask|z,xmmrm8	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB xmm|mask|z, xmm/m8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ymmreg|mask|z,xmmrm8	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB ymm|mask|z, xmm/m8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	zmmreg|mask|z,xmmrm8	AVX512BW,FUTURE	VPBROADCASTB zmm|mask|z, xmm/m8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	xmmreg|mask|z,reg8	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB xmm|mask|z, r8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	xmmreg|mask|z,reg16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB xmm|mask|z, r16	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	xmmreg|mask|z,reg32	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB xmm|mask|z, r32	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	xmmreg|mask|z,reg64	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB xmm|mask|z, r64	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ymmreg|mask|z,reg8	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB ymm|mask|z, r8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ymmreg|mask|z,reg16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB ymm|mask|z, r16	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ymmreg|mask|z,reg32	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB ymm|mask|z, r32	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	ymmreg|mask|z,reg64	AVX512VL,AVX512BW,FUTURE	VPBROADCASTB ymm|mask|z, r64	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	zmmreg|mask|z,reg8	AVX512BW,FUTURE	VPBROADCASTB zmm|mask|z, r8	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	zmmreg|mask|z,reg16	AVX512BW,FUTURE	VPBROADCASTB zmm|mask|z, r16	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	zmmreg|mask|z,reg32	AVX512BW,FUTURE	VPBROADCASTB zmm|mask|z, r32	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTB	zmmreg|mask|z,reg64	AVX512BW,FUTURE	VPBROADCASTB zmm|mask|z, r64	Copy an 8-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	xmmreg,mem16	FUTURE,AVX2	VPBROADCASTW xmm, mem16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	xmmreg,xmmreg	FUTURE,AVX2	VPBROADCASTW xmm, xmm	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ymmreg,mem16	FUTURE,AVX2	VPBROADCASTW ymm, mem16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ymmreg,xmmreg	FUTURE,AVX2	VPBROADCASTW ymm, xmm	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	xmmreg|mask|z,xmmrm16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW xmm|mask|z, xmm/m16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ymmreg|mask|z,xmmrm16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW ymm|mask|z, xmm/m16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	zmmreg|mask|z,xmmrm16	AVX512BW,FUTURE	VPBROADCASTW zmm|mask|z, xmm/m16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	xmmreg|mask|z,reg16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW xmm|mask|z, r16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	xmmreg|mask|z,reg32	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW xmm|mask|z, r32	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	xmmreg|mask|z,reg64	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW xmm|mask|z, r64	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ymmreg|mask|z,reg16	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW ymm|mask|z, r16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ymmreg|mask|z,reg32	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW ymm|mask|z, r32	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	ymmreg|mask|z,reg64	AVX512VL,AVX512BW,FUTURE	VPBROADCASTW ymm|mask|z, r64	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	zmmreg|mask|z,reg16	AVX512BW,FUTURE	VPBROADCASTW zmm|mask|z, r16	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	zmmreg|mask|z,reg32	AVX512BW,FUTURE	VPBROADCASTW zmm|mask|z, r32	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTW	zmmreg|mask|z,reg64	AVX512BW,FUTURE	VPBROADCASTW zmm|mask|z, r64	Copy an 16-bit integer register or memory operand to all elements of a XMM or YMM vector Register	VPBROADCAST.html
VPBROADCASTD	xmmreg,mem32	FUTURE,AVX2	VPBROADCASTD xmm, mem32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	xmmreg,xmmreg	FUTURE,AVX2	VPBROADCASTD xmm, xmm	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	ymmreg,mem32	FUTURE,AVX2	VPBROADCASTD ymm, mem32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	ymmreg,xmmreg	FUTURE,AVX2	VPBROADCASTD ymm, xmm	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	xmmreg|mask|z,mem32	AVX512VL,AVX512,FUTURE	VPBROADCASTD xmm|mask|z, mem32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	ymmreg|mask|z,mem32	AVX512VL,AVX512,FUTURE	VPBROADCASTD ymm|mask|z, mem32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	zmmreg|mask|z,mem32	AVX512,FUTURE	VPBROADCASTD zmm|mask|z, mem32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPBROADCASTD xmm|mask|z, xmm	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	ymmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPBROADCASTD ymm|mask|z, xmm	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	zmmreg|mask|z,xmmreg	AVX512,FUTURE	VPBROADCASTD zmm|mask|z, xmm	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	xmmreg|mask|z,reg32	AVX512VL,AVX512,FUTURE	VPBROADCASTD xmm|mask|z, r32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	ymmreg|mask|z,reg32	AVX512VL,AVX512,FUTURE	VPBROADCASTD ymm|mask|z, r32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTD	zmmreg|mask|z,reg32	AVX512,FUTURE	VPBROADCASTD zmm|mask|z, r32	Broadcast Int32 Vector	VPBROADCAST.html
VPBROADCASTQ	xmmreg,mem64	FUTURE,AVX2	VPBROADCASTQ xmm, mem64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	xmmreg,xmmreg	FUTURE,AVX2	VPBROADCASTQ xmm, xmm	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	ymmreg,mem64	FUTURE,AVX2	VPBROADCASTQ ymm, mem64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	ymmreg,xmmreg	FUTURE,AVX2	VPBROADCASTQ ymm, xmm	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	xmmreg|mask|z,mem64	AVX512VL,AVX512,FUTURE	VPBROADCASTQ xmm|mask|z, mem64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	ymmreg|mask|z,mem64	AVX512VL,AVX512,FUTURE	VPBROADCASTQ ymm|mask|z, mem64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	zmmreg|mask|z,mem64	AVX512,FUTURE	VPBROADCASTQ zmm|mask|z, mem64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPBROADCASTQ xmm|mask|z, xmm	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	ymmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPBROADCASTQ ymm|mask|z, xmm	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	zmmreg|mask|z,xmmreg	AVX512,FUTURE	VPBROADCASTQ zmm|mask|z, xmm	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	xmmreg|mask|z,reg64	AVX512VL,AVX512,FUTURE	VPBROADCASTQ xmm|mask|z, r64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	ymmreg|mask|z,reg64	AVX512VL,AVX512,FUTURE	VPBROADCASTQ ymm|mask|z, r64	Broadcast Int64 Vector	VPBROADCAST.html
VPBROADCASTQ	zmmreg|mask|z,reg64	AVX512,FUTURE	VPBROADCASTQ zmm|mask|z, r64	Broadcast Int64 Vector	VPBROADCAST.html
VPERMD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPERMD ymm, ymm, ymm/m256	Permutes Int32 Vectors	VPERMD.html
VPERMD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPERMD ymm|mask|z, ymm, ymm/m256|b32	Permutes Int32 Vectors	VPERMD.html
VPERMD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPERMD zmm|mask|z, zmm, zmm/m512|b32	Permutes Int32 Vectors	VPERMD.html
VPERMPD	ymmreg,ymmrm256,imm8	FUTURE,AVX2	VPERMPD ymm, ymm/m256, imm8	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPD	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPERMPD ymm|mask|z, ymm/m256|b32, imm8	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPD	zmmreg|mask|z,zmmrm512|b64,imm8	AVX512,FUTURE	VPERMPD zmm|mask|z, zmm/m512|b32, imm8	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPERMPD ymm|mask|z, ymm, ymm/m256|b32	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPERMPD zmm|mask|z, zmm, zmm/m512|b32	Permute Double-Precision Floating-Point Elements	VPERMPD.html
VPERMPS	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPERMPS ymm, ymm, ymm/m256	Permute Single-Precision Floating-Point Elements	VPERMPS.html
VPERMPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPERMPS ymm|mask|z, ymm, ymm/m256|b32	Permute Single-Precision Floating-Point Elements	VPERMPS.html
VPERMPS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPERMPS zmm|mask|z, zmm, zmm/m512|b32	Permute Single-Precision Floating-Point Elements	VPERMPS.html
VPERMQ	ymmreg,ymmrm256,imm8	FUTURE,AVX2	VPERMQ ymm, ymm/m256, imm8	Qwords Element Permutation	VPERMQ.html
VPERMQ	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPERMQ ymm|mask|z, ymm/m256|b32, imm8	Qwords Element Permutation	VPERMQ.html
VPERMQ	zmmreg|mask|z,zmmrm512|b64,imm8	AVX512,FUTURE	VPERMQ zmm|mask|z, zmm/m512|b32, imm8	Qwords Element Permutation	VPERMQ.html
VPERMQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPERMQ ymm|mask|z, ymm, ymm/m256|b32	Qwords Element Permutation	VPERMQ.html
VPERMQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPERMQ zmm|mask|z, zmm, zmm/m512|b32	Qwords Element Permutation	VPERMQ.html
VPERM2I128	ymmreg,ymmreg,ymmrm256,imm8	FUTURE,AVX2	VPERM2I128 ymm, ymm, ymm/m256, imm8	Permute Integer Values	VPERM2I128.html
VEXTRACTI128	xmmrm128,ymmreg,imm8	FUTURE,AVX2	VEXTRACTI128 xmm/m128, ymm, imm8	Extract packed Integer Values	VEXTRACTI128.html
VINSERTI128	ymmreg,ymmreg*,xmmrm128,imm8	FUTURE,AVX2	VINSERTI128 ymm, ymm, xmm/m128, imm8	Insert Packed Integer Values	VINSERTI128.html
VPMASKMOVD	xmmreg,xmmreg*,mem128	FUTURE,AVX2	VPMASKMOVD xmm, xmm, mem128	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVD	ymmreg,ymmreg*,mem256	FUTURE,AVX2	VPMASKMOVD ymm, ymm, mem256	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVD	mem128,xmmreg*,xmmreg	FUTURE,AVX2	VPMASKMOVD mem128, xmm, xmm	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVD	mem256,ymmreg*,ymmreg	FUTURE,AVX2	VPMASKMOVD mem256, ymm, ymm	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVQ	xmmreg,xmmreg*,mem128	FUTURE,AVX2	VPMASKMOVQ xmm, xmm, mem128	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVQ	ymmreg,ymmreg*,mem256	FUTURE,AVX2	VPMASKMOVQ ymm, ymm, mem256	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVQ	mem128,xmmreg*,xmmreg	FUTURE,AVX2	VPMASKMOVQ mem128, xmm, xmm	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPMASKMOVQ	mem256,ymmreg*,ymmreg	FUTURE,AVX2	VPMASKMOVQ mem256, ymm, ymm	Conditional SIMD Integer Packed Loads and Stores	VPMASKMOV.html
VPSLLVD	xmmreg,xmmreg*,xmmrm128	FUTURE,AVX2	VPSLLVD xmm, xmm, xmm/m128	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSLLVD ymm, ymm, ymm/m256	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPSLLVD xmm|mask|z, xmm, xmm/m128|b32	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPSLLVD ymm|mask|z, ymm, ymm/m256|b32	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPSLLVD zmm|mask|z, zmm, zmm/m512|b32	Shift Int32 Vector Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	xmmreg,xmmreg*,xmmrm128	FUTURE,AVX2	VPSLLVQ xmm, xmm, xmm/m128	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSLLVQ ymm, ymm, ymm/m256	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPSLLVQ xmm|mask|z, xmm, xmm/m128|b32	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPSLLVQ ymm|mask|z, ymm, ymm/m256|b32	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSLLVQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPSLLVQ zmm|mask|z, zmm, zmm/m512|b32	Variable Bit Shift Left Logical	VPSLLVD:VPSLLVQ.html
VPSRAVD	xmmreg,xmmreg*,xmmrm128	FUTURE,AVX2	VPSRAVD xmm, xmm, xmm/m128	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRAVD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSRAVD ymm, ymm, ymm/m256	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRAVD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPSRAVD xmm|mask|z, xmm, xmm/m128|b32	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRAVD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPSRAVD ymm|mask|z, ymm, ymm/m256|b32	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRAVD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPSRAVD zmm|mask|z, zmm, zmm/m512|b32	Shift Int32 Vector Right Arithmetic	VPSRAVD.html
VPSRLVD	xmmreg,xmmreg*,xmmrm128	FUTURE,AVX2	VPSRLVD xmm, xmm, xmm/m128	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVD	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSRLVD ymm, ymm, ymm/m256	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPSRLVD xmm|mask|z, xmm, xmm/m128|b32	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPSRLVD ymm|mask|z, ymm, ymm/m256|b32	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPSRLVD zmm|mask|z, zmm, zmm/m512|b32	Shift Int32 Vector Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	xmmreg,xmmreg*,xmmrm128	FUTURE,AVX2	VPSRLVQ xmm, xmm, xmm/m128	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	ymmreg,ymmreg*,ymmrm256	FUTURE,AVX2	VPSRLVQ ymm, ymm, ymm/m256	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPSRLVQ xmm|mask|z, xmm, xmm/m128|b32	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPSRLVQ ymm|mask|z, ymm, ymm/m256|b32	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VPSRLVQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPSRLVQ zmm|mask|z, zmm, zmm/m512|b32	Variable Bit Shift Right Logical	VPSRLVD:VPSRLVQ.html
VGATHERDPD	xmmreg,xmem64,xmmreg	FUTURE,AVX2	VGATHERDPD xmm, xmem64, xmm	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPD	ymmreg,xmem64,ymmreg	FUTURE,AVX2	VGATHERDPD ymm, xmem64, ymm	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPD	xmmreg|mask,xmem64	AVX512VL,AVX512,FUTURE	VGATHERDPD xmm|mask, xmem64	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPD	ymmreg|mask,xmem64	AVX512VL,AVX512,FUTURE	VGATHERDPD ymm|mask, xmem64	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPD	zmmreg|mask,ymem64	AVX512,FUTURE	VGATHERDPD zmm|mask, ymem64	Gather Float64 Vector With Signed Dword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	xmmreg,xmem64,xmmreg	FUTURE,AVX2	VGATHERQPD xmm, xmem64, xmm	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	ymmreg,ymem64,ymmreg	FUTURE,AVX2	VGATHERQPD ymm, ymem64, ymm	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	xmmreg|mask,xmem64	AVX512VL,AVX512,FUTURE	VGATHERQPD xmm|mask, xmem64	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	ymmreg|mask,ymem64	AVX512VL,AVX512,FUTURE	VGATHERQPD ymm|mask, ymem64	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERQPD	zmmreg|mask,zmem64	AVX512,FUTURE	VGATHERQPD zmm|mask, zmem64	Gather Packed DP FP Values Using Signed Dword/Qword Indices	VGATHERDPD:VGATHERQPD.html
VGATHERDPS	xmmreg,xmem32,xmmreg	FUTURE,AVX2	VGATHERDPS xmm, xmem32, xmm	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERDPS	ymmreg,ymem32,ymmreg	FUTURE,AVX2	VGATHERDPS ymm, ymem32, ymm	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERDPS	xmmreg|mask,xmem32	AVX512VL,AVX512,FUTURE	VGATHERDPS xmm|mask, xmem32	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERDPS	ymmreg|mask,ymem32	AVX512VL,AVX512,FUTURE	VGATHERDPS ymm|mask, ymem32	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERDPS	zmmreg|mask,zmem32	AVX512,FUTURE	VGATHERDPS zmm|mask, zmem32	Gather Float32 Vector With Signed Dword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	xmmreg,xmem32,xmmreg	FUTURE,AVX2	VGATHERQPS xmm, xmem32, xmm	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	xmmreg,ymem32,xmmreg	FUTURE,AVX2	VGATHERQPS xmm, ymem32, xmm	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	xmmreg|mask,xmem32	AVX512VL,AVX512,FUTURE	VGATHERQPS xmm|mask, xmem32	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	xmmreg|mask,ymem32	AVX512VL,AVX512,FUTURE	VGATHERQPS xmm|mask, ymem32	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VGATHERQPS	ymmreg|mask,zmem32	AVX512,FUTURE	VGATHERQPS ymm|mask, zmem32	Gather Packed SP FP values Using Signed Dword/Qword Indices	VGATHERDPS:VGATHERQPS.html
VPGATHERDD	xmmreg,xmem32,xmmreg	FUTURE,AVX2	VPGATHERDD xmm, xmem32, xmm	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDD	ymmreg,ymem32,ymmreg	FUTURE,AVX2	VPGATHERDD ymm, ymem32, ymm	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDD	xmmreg|mask,xmem32	AVX512VL,AVX512,FUTURE	VPGATHERDD xmm|mask, xmem32	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDD	ymmreg|mask,ymem32	AVX512VL,AVX512,FUTURE	VPGATHERDD ymm|mask, ymem32	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDD	zmmreg|mask,zmem32	AVX512,FUTURE	VPGATHERDD zmm|mask, zmem32	Gather Int32 Vector With Signed Dword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	xmmreg,xmem32,xmmreg	FUTURE,AVX2	VPGATHERQD xmm, xmem32, xmm	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	xmmreg,ymem32,xmmreg	FUTURE,AVX2	VPGATHERQD xmm, ymem32, xmm	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	xmmreg|mask,xmem32	AVX512VL,AVX512,FUTURE	VPGATHERQD xmm|mask, xmem32	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	xmmreg|mask,ymem32	AVX512VL,AVX512,FUTURE	VPGATHERQD xmm|mask, ymem32	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERQD	ymmreg|mask,zmem32	AVX512,FUTURE	VPGATHERQD ymm|mask, zmem32	Gather Packed Dword Values Using Signed Dword/Qword Indices	VPGATHERDD:VPGATHERQD.html
VPGATHERDQ	xmmreg,xmem64,xmmreg	FUTURE,AVX2	VPGATHERDQ xmm, xmem64, xmm	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERDQ	ymmreg,xmem64,ymmreg	FUTURE,AVX2	VPGATHERDQ ymm, xmem64, ymm	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERDQ	xmmreg|mask,xmem64	AVX512VL,AVX512,FUTURE	VPGATHERDQ xmm|mask, xmem64	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERDQ	ymmreg|mask,xmem64	AVX512VL,AVX512,FUTURE	VPGATHERDQ ymm|mask, xmem64	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERDQ	zmmreg|mask,ymem64	AVX512,FUTURE	VPGATHERDQ zmm|mask, ymem64	Gather Int64 Vector With Signed Dword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	xmmreg,xmem64,xmmreg	FUTURE,AVX2	VPGATHERQQ xmm, xmem64, xmm	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	ymmreg,ymem64,ymmreg	FUTURE,AVX2	VPGATHERQQ ymm, ymem64, ymm	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	xmmreg|mask,xmem64	AVX512VL,AVX512,FUTURE	VPGATHERQQ xmm|mask, xmem64	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	ymmreg|mask,ymem64	AVX512VL,AVX512,FUTURE	VPGATHERQQ ymm|mask, ymem64	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
VPGATHERQQ	zmmreg|mask,zmem64	AVX512,FUTURE	VPGATHERQQ zmm|mask, zmem64	Gather Packed Qword Values Using Signed Dword/Qword Indices	VPGATHERDQ:VPGATHERQQ.html
XABORT	imm	FUTURE,RTM	XABORT imm	Transactional Abort	XABORT.html
XABORT	imm8	FUTURE,RTM	XABORT imm8	Transactional Abort	XABORT.html
XBEGIN	imm	FUTURE,RTM	XBEGIN imm	Transactional Begin	XBEGIN.html
XBEGIN	imm|near	FUTURE,RTM,ND	XBEGIN imm|near	Transactional Begin	XBEGIN.html
XBEGIN	imm16	FUTURE,RTM,NOLONG	XBEGIN imm16	Transactional Begin	XBEGIN.html
XBEGIN	imm16|near	FUTURE,RTM,NOLONG,ND	XBEGIN imm16|near	Transactional Begin	XBEGIN.html
XBEGIN	imm32	FUTURE,RTM,NOLONG	XBEGIN imm32	Transactional Begin	XBEGIN.html
XBEGIN	imm32|near	FUTURE,RTM,NOLONG,ND	XBEGIN imm32|near	Transactional Begin	XBEGIN.html
XBEGIN	imm64	FUTURE,RTM,LONG	XBEGIN imm64	Transactional Begin	XBEGIN.html
XBEGIN	imm64|near	FUTURE,RTM,LONG,ND	XBEGIN imm64|near	Transactional Begin	XBEGIN.html
XEND	none	FUTURE,RTM	XEND 	Transactional End	XEND.html
XTEST	none	FUTURE,HLE,RTM	XTEST 	Test If In Transactional Execution	XTEST.html
ANDN	reg32,reg32,rm32	FUTURE,BMI1	ANDN r32, r32, r/m32	Logical AND NOT	ANDN.html
ANDN	reg64,reg64,rm64	LONG,FUTURE,BMI1	ANDN r64, r64, r/m64	Logical AND NOT	ANDN.html
BEXTR	reg32,rm32,reg32	FUTURE,BMI1	BEXTR r32, r/m32, r32	Bit Field Extract	BEXTR.html
BEXTR	reg64,rm64,reg64	LONG,FUTURE,BMI1	BEXTR r64, r/m64, r64	Bit Field Extract	BEXTR.html
BEXTR	reg32,rm32,imm32	FUTURE,TBM	BEXTR r32, r/m32, imm32	Bit Field Extract	BEXTR.html
BEXTR	reg64,rm64,imm32	LONG,FUTURE,TBM	BEXTR r64, r/m64, imm32	Bit Field Extract	BEXTR.html
BLCI	reg32,rm32	FUTURE,TBM	BLCI r32, r/m32	TODO: FUTURE,TBM,LONG	
BLCI	reg64,rm64	LONG,FUTURE,TBM	BLCI r64, r/m64	TODO: FUTURE,TBM,LONG	
BLCIC	reg32,rm32	FUTURE,TBM	BLCIC r32, r/m32	TODO: FUTURE,TBM,LONG	
BLCIC	reg64,rm64	LONG,FUTURE,TBM	BLCIC r64, r/m64	TODO: FUTURE,TBM,LONG	
BLSI	reg32,rm32	FUTURE,BMI1	BLSI r32, r/m32	Extract Lowest Set Isolated Bit	BLSI.html
BLSI	reg64,rm64	LONG,FUTURE,BMI1	BLSI r64, r/m64	Extract Lowest Set Isolated Bit	BLSI.html
BLSIC	reg32,rm32	FUTURE,TBM	BLSIC r32, r/m32	TODO: FUTURE,TBM,LONG	
BLSIC	reg64,rm64	LONG,FUTURE,TBM	BLSIC r64, r/m64	TODO: FUTURE,TBM,LONG	
BLCFILL	reg32,rm32	FUTURE,TBM	BLCFILL r32, r/m32	TODO: FUTURE,TBM,LONG	
BLCFILL	reg64,rm64	LONG,FUTURE,TBM	BLCFILL r64, r/m64	TODO: FUTURE,TBM,LONG	
BLSFILL	reg32,rm32	FUTURE,TBM	BLSFILL r32, r/m32	TODO: FUTURE,TBM,LONG	
BLSFILL	reg64,rm64	LONG,FUTURE,TBM	BLSFILL r64, r/m64	TODO: FUTURE,TBM,LONG	
BLCMSK	reg32,rm32	FUTURE,TBM	BLCMSK r32, r/m32	TODO: FUTURE,TBM,LONG	
BLCMSK	reg64,rm64	LONG,FUTURE,TBM	BLCMSK r64, r/m64	TODO: FUTURE,TBM,LONG	
BLSMSK	reg32,rm32	FUTURE,BMI1	BLSMSK r32, r/m32	Get Mask Up to Lowest Set Bit	BLSMSK.html
BLSMSK	reg64,rm64	LONG,FUTURE,BMI1	BLSMSK r64, r/m64	Get Mask Up to Lowest Set Bit	BLSMSK.html
BLSR	reg32,rm32	FUTURE,BMI1	BLSR r32, r/m32	Reset Lowest Set Bit	BLSR.html
BLSR	reg64,rm64	LONG,FUTURE,BMI1	BLSR r64, r/m64	Reset Lowest Set Bit	BLSR.html
BLCS	reg32,rm32	FUTURE,TBM	BLCS r32, r/m32	TODO: FUTURE,TBM,LONG	
BLCS	reg64,rm64	LONG,FUTURE,TBM	BLCS r64, r/m64	TODO: FUTURE,TBM,LONG	
BZHI	reg32,rm32,reg32	FUTURE,BMI2	BZHI r32, r/m32, r32	Zero High Bits Starting with Specified Bit Position	BZHI.html
BZHI	reg64,rm64,reg64	LONG,FUTURE,BMI2	BZHI r64, r/m64, r64	Zero High Bits Starting with Specified Bit Position	BZHI.html
MULX	reg32,reg32,rm32	FUTURE,BMI2	MULX r32, r32, r/m32	Unsigned Multiply Without Affecting Flags	MULX.html
MULX	reg64,reg64,rm64	LONG,FUTURE,BMI2	MULX r64, r64, r/m64	Unsigned Multiply Without Affecting Flags	MULX.html
PDEP	reg32,reg32,rm32	FUTURE,BMI2	PDEP r32, r32, r/m32	Parallel Bits Deposit	PDEP.html
PDEP	reg64,reg64,rm64	LONG,FUTURE,BMI2	PDEP r64, r64, r/m64	Parallel Bits Deposit	PDEP.html
PEXT	reg32,reg32,rm32	FUTURE,BMI2	PEXT r32, r32, r/m32	Parallel Bits Extract	PEXT.html
PEXT	reg64,reg64,rm64	LONG,FUTURE,BMI2	PEXT r64, r64, r/m64	Parallel Bits Extract	PEXT.html
RORX	reg32,rm32,imm8	FUTURE,BMI2	RORX r32, r/m32, imm8	Rotate Right Logical Without Affecting Flags	RORX.html
RORX	reg64,rm64,imm8	LONG,FUTURE,BMI2	RORX r64, r/m64, imm8	Rotate Right Logical Without Affecting Flags	RORX.html
SARX	reg32,rm32,reg32	FUTURE,BMI2	SARX r32, r/m32, r32	Shift Arithmetic Right Without Affecting Flags	SARX:SHLX:SHRX.html
SARX	reg64,rm64,reg64	LONG,FUTURE,BMI2	SARX r64, r/m64, r64	Shift Arithmetic Right Without Affecting Flags	SARX:SHLX:SHRX.html
SHLX	reg32,rm32,reg32	FUTURE,BMI2	SHLX r32, r/m32, r32	Shift Logical Left Without Affecting Flags	SARX:SHLX:SHRX.html
SHLX	reg64,rm64,reg64	LONG,FUTURE,BMI2	SHLX r64, r/m64, r64	Shift Logical Left Without Affecting Flags	SARX:SHLX:SHRX.html
SHRX	reg32,rm32,reg32	FUTURE,BMI2	SHRX r32, r/m32, r32	Shift Logical Right Without Affecting Flags	SARX:SHLX:SHRX.html
SHRX	reg64,rm64,reg64	LONG,FUTURE,BMI2	SHRX r64, r/m64, r64	Shift Logical Right Without Affecting Flags	SARX:SHLX:SHRX.html
TZCNT	reg16,rm16	FUTURE,BMI1	TZCNT r16, r/m16	Trailing Zero Count	TZCNT.html
TZCNT	reg32,rm32	FUTURE,BMI1	TZCNT r32, r/m32	Trailing Zero Count	TZCNT.html
TZCNT	reg64,rm64	LONG,FUTURE,BMI1	TZCNT r64, r/m64	Trailing Zero Count	TZCNT.html
TZMSK	reg32,rm32	FUTURE,TBM	TZMSK r32, r/m32	TODO: FUTURE,TBM,LONG	
TZMSK	reg64,rm64	LONG,FUTURE,TBM	TZMSK r64, r/m64	TODO: FUTURE,TBM,LONG	
T1MSKC	reg32,rm32	FUTURE,TBM	T1MSKC r32, r/m32	TODO: FUTURE,TBM,LONG	
T1MSKC	reg64,rm64	LONG,FUTURE,TBM	T1MSKC r64, r/m64	TODO: FUTURE,TBM,LONG	
PREFETCHWT1	mem8	PREFETCHWT1,FUTURE	PREFETCHWT1 mem8	Prefetch Vector Data Into Caches with Intent to Write and T1 Hint	PREFETCHWT1.html

BNDMK	bndreg,mem	MPX,MIB,FUTURE	BNDMK b, m	Create LowerBound (LB) and UpperBound (UB) in the bounds register b	

BNDCL	bndreg,mem	MPX,FUTURE	BNDCL b, mem	 Checks the address of a memory reference or address in r against the lower bound 	
BNDCL	bndreg,reg32	MPX,NOLONG,FUTURE	BNDCL b, r32	 Checks the address of a memory reference or address in r against the lower bound 	
BNDCL	bndreg,reg64	MPX,LONG,FUTURE	BNDCL b, r64	 Checks the address of a memory reference or address in r against the lower bound 	

BNDCU	bndreg,mem	MPX,FUTURE	BNDCU bndreg, mem	Checks the address of a memory reference or address in r against the upper bound in 1's complement form	
BNDCU	bndreg,reg32	MPX,NOLONG,FUTURE	BNDCU bndreg, r32	Checks the address of a memory reference or address in r against the upper bound in 1's complement form	
BNDCU	bndreg,reg64	MPX,LONG,FUTURE	BNDCU bndreg, r64	Checks the address of a memory reference or address in r against the upper bound in 1's complement form	
BNDCN	bndreg,mem	MPX,FUTURE	BNDCN bndreg, mem	Checks the address of a memory reference or address in r against the upper bound in 1's complement formChecks the address of a memory reference or address in r against the upper bound not in 1's complement form	
BNDCN	bndreg,reg32	MPX,NOLONG,FUTURE	BNDCN bndreg, r32	Checks the address of a memory reference or address in r against the upper bound in 1's complement formChecks the address of a memory reference or address in r against the upper bound not in 1's complement form	
BNDCN	bndreg,reg64	MPX,LONG,FUTURE	BNDCN bndreg, r64	Checks the address of a memory reference or address in r against the upper bound in 1's complement formChecks the address of a memory reference or address in r against the upper bound not in 1's complement form	

BNDMOV	bndreg,bndreg	MPX,FUTURE	BNDMOV bndreg, bndreg	Copy/load LB and UB bounds from memory or a bounds register	
BNDMOV	bndreg,mem	MPX,FUTURE	BNDMOV bndreg, mem	Copy/load LB and UB bounds from memory or a bounds register	
BNDMOV	mem,bndreg	MPX,FUTURE	BNDMOV mem, bndreg	Store LB and UB bounds in a bounds register to memory or another register	

BNDLDX	bndreg,mem	MPX,MIB,FUTURE	BNDLDX bndreg, mem	Load bounds using address translation using an sib-addressing expression mib	
BNDLDX	bndreg,mem,reg32	MPX,MIB,NOLONG,FUTURE	BNDLDX bndreg, mem, r32	Load bounds using address translation using an sib-addressing expression mib	
BNDLDX	bndreg,mem,reg64	MPX,MIB,LONG,FUTURE	BNDLDX bndreg, mem, r64	Load bounds using address translation using an sib-addressing expression mib	
BNDSTX	mem,bndreg	MPX,MIB,FUTURE	BNDSTX mem, bndreg	Store bounds using address translation using an sib-addressing expression mib	
BNDSTX	mem,reg32,bndreg	MPX,MIB,NOLONG,FUTURE	BNDSTX mem, r32, bndreg	Store bounds using address translation using an sib-addressing expression mib	
BNDSTX	mem,reg64,bndreg	MPX,MIB,LONG,FUTURE	BNDSTX mem, r64, bndreg	Store bounds using address translation using an sib-addressing expression mib	
BNDSTX	mem,bndreg,reg32	MPX,MIB,NOLONG,FUTURE	BNDSTX mem, bndreg, r32	Store bounds using address translation using an sib-addressing expression mib	
BNDSTX	mem,bndreg,reg64	MPX,MIB,LONG,FUTURE	BNDSTX mem, bndreg, r64	Store bounds using address translation using an sib-addressing expression mib	

KADDB	kreg,kreg,kreg	FUTURE	KADDB kreg, kreg, kreg	TODO: FUTURE	
KADDD	kreg,kreg,kreg	FUTURE	KADDD kreg, kreg, kreg	TODO: FUTURE	
KADDQ	kreg,kreg,kreg	FUTURE	KADDQ kreg, kreg, kreg	TODO: FUTURE	
KADDW	kreg,kreg,kreg	FUTURE	KADDW kreg, kreg, kreg	TODO: FUTURE	
KANDB	kreg,kreg,kreg	FUTURE	KANDB kreg, kreg, kreg	TODO: FUTURE	
KANDD	kreg,kreg,kreg	FUTURE	KANDD kreg, kreg, kreg	TODO: FUTURE	
KANDNB	kreg,kreg,kreg	FUTURE	KANDNB kreg, kreg, kreg	TODO: FUTURE	
KANDND	kreg,kreg,kreg	FUTURE	KANDND kreg, kreg, kreg	TODO: FUTURE	
KANDNQ	kreg,kreg,kreg	FUTURE	KANDNQ kreg, kreg, kreg	TODO: FUTURE	
KANDNW	kreg,kreg,kreg	FUTURE	KANDNW kreg, kreg, kreg	TODO: FUTURE	
KANDQ	kreg,kreg,kreg	FUTURE	KANDQ kreg, kreg, kreg	TODO: FUTURE	
KANDW	kreg,kreg,kreg	FUTURE	KANDW kreg, kreg, kreg	TODO: FUTURE	
KMOVB	kreg,krm8	FUTURE	KMOVB kreg, krm8	TODO: FUTURE	
KMOVB	mem8,kreg	FUTURE	KMOVB mem8, kreg	TODO: FUTURE	
KMOVB	kreg,reg32	FUTURE	KMOVB kreg, r32	TODO: FUTURE	
KMOVB	reg32,kreg	FUTURE	KMOVB r32, kreg	TODO: FUTURE	
KMOVD	kreg,krm32	FUTURE	KMOVD kreg, krm32	TODO: FUTURE	
KMOVD	mem32,kreg	FUTURE	KMOVD mem32, kreg	TODO: FUTURE	
KMOVD	kreg,reg32	FUTURE	KMOVD kreg, r32	TODO: FUTURE	
KMOVD	reg32,kreg	FUTURE	KMOVD r32, kreg	TODO: FUTURE	
KMOVQ	kreg,krm64	FUTURE	KMOVQ kreg, krm64	TODO: FUTURE	
KMOVQ	mem64,kreg	FUTURE	KMOVQ mem64, kreg	TODO: FUTURE	
KMOVQ	kreg,reg64	FUTURE	KMOVQ kreg, r64	TODO: FUTURE	
KMOVQ	reg64,kreg	FUTURE	KMOVQ r64, kreg	TODO: FUTURE	
KMOVW	kreg,krm16	FUTURE	KMOVW kreg, krm16	TODO: FUTURE	
KMOVW	mem16,kreg	FUTURE	KMOVW mem16, kreg	TODO: FUTURE	
KMOVW	kreg,reg32	FUTURE	KMOVW kreg, r32	TODO: FUTURE	
KMOVW	reg32,kreg	FUTURE	KMOVW r32, kreg	TODO: FUTURE	
KNOTB	kreg,kreg	FUTURE	KNOTB kreg, kreg	TODO: FUTURE	
KNOTD	kreg,kreg	FUTURE	KNOTD kreg, kreg	TODO: FUTURE	
KNOTQ	kreg,kreg	FUTURE	KNOTQ kreg, kreg	TODO: FUTURE	
KNOTW	kreg,kreg	FUTURE	KNOTW kreg, kreg	TODO: FUTURE	
KORB	kreg,kreg,kreg	FUTURE	KORB kreg, kreg, kreg	TODO: FUTURE	
KORD	kreg,kreg,kreg	FUTURE	KORD kreg, kreg, kreg	TODO: FUTURE	
KORQ	kreg,kreg,kreg	FUTURE	KORQ kreg, kreg, kreg	TODO: FUTURE	
KORTESTB	kreg,kreg	FUTURE	KORTESTB kreg, kreg	TODO: FUTURE	
KORTESTD	kreg,kreg	FUTURE	KORTESTD kreg, kreg	TODO: FUTURE	
KORTESTQ	kreg,kreg	FUTURE	KORTESTQ kreg, kreg	TODO: FUTURE	
KORTESTW	kreg,kreg	FUTURE	KORTESTW kreg, kreg	TODO: FUTURE	
KORW	kreg,kreg,kreg	FUTURE	KORW kreg, kreg, kreg	TODO: FUTURE	
KSHIFTLB	kreg,kreg,imm8	FUTURE	KSHIFTLB kreg, kreg, imm8	TODO: FUTURE	
KSHIFTLD	kreg,kreg,imm8	FUTURE	KSHIFTLD kreg, kreg, imm8	TODO: FUTURE	
KSHIFTLQ	kreg,kreg,imm8	FUTURE	KSHIFTLQ kreg, kreg, imm8	TODO: FUTURE	
KSHIFTLW	kreg,kreg,imm8	FUTURE	KSHIFTLW kreg, kreg, imm8	TODO: FUTURE	
KSHIFTRB	kreg,kreg,imm8	FUTURE	KSHIFTRB kreg, kreg, imm8	TODO: FUTURE	
KSHIFTRD	kreg,kreg,imm8	FUTURE	KSHIFTRD kreg, kreg, imm8	TODO: FUTURE	
KSHIFTRQ	kreg,kreg,imm8	FUTURE	KSHIFTRQ kreg, kreg, imm8	TODO: FUTURE	
KSHIFTRW	kreg,kreg,imm8	FUTURE	KSHIFTRW kreg, kreg, imm8	TODO: FUTURE	
KTESTB	kreg,kreg	FUTURE	KTESTB kreg, kreg	TODO: FUTURE	
KTESTD	kreg,kreg	FUTURE	KTESTD kreg, kreg	TODO: FUTURE	
KTESTQ	kreg,kreg	FUTURE	KTESTQ kreg, kreg	TODO: FUTURE	
KTESTW	kreg,kreg	FUTURE	KTESTW kreg, kreg	TODO: FUTURE	
KUNPCKBW	kreg,kreg,kreg	FUTURE	KUNPCKBW kreg, kreg, kreg	TODO: FUTURE	
KUNPCKDQ	kreg,kreg,kreg	FUTURE	KUNPCKDQ kreg, kreg, kreg	TODO: FUTURE	
KUNPCKWD	kreg,kreg,kreg	FUTURE	KUNPCKWD kreg, kreg, kreg	TODO: FUTURE	
KXNORB	kreg,kreg,kreg	FUTURE	KXNORB kreg, kreg, kreg	TODO: FUTURE	
KXNORD	kreg,kreg,kreg	FUTURE	KXNORD kreg, kreg, kreg	TODO: FUTURE	
KXNORQ	kreg,kreg,kreg	FUTURE	KXNORQ kreg, kreg, kreg	TODO: FUTURE	
KXNORW	kreg,kreg,kreg	FUTURE	KXNORW kreg, kreg, kreg	TODO: FUTURE	
KXORB	kreg,kreg,kreg	FUTURE	KXORB kreg, kreg, kreg	TODO: FUTURE	
KXORD	kreg,kreg,kreg	FUTURE	KXORD kreg, kreg, kreg	TODO: FUTURE	
KXORQ	kreg,kreg,kreg	FUTURE	KXORQ kreg, kreg, kreg	TODO: FUTURE	
KXORW	kreg,kreg,kreg	FUTURE	KXORW kreg, kreg, kreg	TODO: FUTURE	
SHA1MSG1	xmmreg,xmmrm128	SHA,FUTURE	SHA1MSG1 xmm, xmm/m128	TODO: SHA,FUTURE	
SHA1MSG2	xmmreg,xmmrm128	SHA,FUTURE	SHA1MSG2 xmm, xmm/m128	TODO: SHA,FUTURE	
SHA1NEXTE	xmmreg,xmmrm128	SHA,FUTURE	SHA1NEXTE xmm, xmm/m128	TODO: SHA,FUTURE	
SHA1RNDS4	xmmreg,xmmrm128,imm8	SHA,FUTURE	SHA1RNDS4 xmm, xmm/m128, imm8	TODO: SHA,FUTURE	
SHA256MSG1	xmmreg,xmmrm128	SHA,FUTURE	SHA256MSG1 xmm, xmm/m128	TODO: SHA,FUTURE	
SHA256MSG2	xmmreg,xmmrm128	SHA,FUTURE	SHA256MSG2 xmm, xmm/m128	TODO: SHA,FUTURE	
SHA256RNDS2	xmmreg,xmmrm128,xmm0	SHA,FUTURE	SHA256RNDS2 xmm, xmm/m128, XMM0	TODO: SHA,FUTURE	
VALIGND	xmmreg|mask|z,xmmreg,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VALIGND xmm|mask|z, xmm, xmm/m128|b32, imm8	Align Doubleword Vectors	
VALIGND	ymmreg|mask|z,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VALIGND ymm|mask|z, ymm, ymm/m256|b32, imm8	Align Doubleword Vectors	
VALIGND	zmmreg|mask|z,zmmreg,zmmrm512|b32,imm8	AVX512,FUTURE	VALIGND zmm|mask|z, zmm, zmm/m512|b32, imm8	Align Doubleword Vectors	
VALIGNQ	xmmreg|mask|z,xmmreg,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VALIGNQ xmm|mask|z, xmm, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VALIGNQ	ymmreg|mask|z,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VALIGNQ ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VALIGNQ	zmmreg|mask|z,zmmreg,zmmrm512|b64,imm8	AVX512,FUTURE	VALIGNQ zmm|mask|z, zmm, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VBLENDMPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VBLENDMPD xmm|mask|z, xmm, xmm/m128|b32	Blend Float64 Vectors using the Instruction Mask	
VBLENDMPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VBLENDMPD ymm|mask|z, ymm, ymm/m256|b32	Blend Float64 Vectors using the Instruction Mask	
VBLENDMPD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VBLENDMPD zmm|mask|z, zmm, zmm/m512|b32	Blend Float64 Vectors using the Instruction Mask	
VBLENDMPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VBLENDMPS xmm|mask|z, xmm, xmm/m128|b32	Blend Float32 Vectors using the Instruction Mask	
VBLENDMPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VBLENDMPS ymm|mask|z, ymm, ymm/m256|b32	Blend Float32 Vectors using the Instruction Mask	
VBLENDMPS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VBLENDMPS zmm|mask|z, zmm, zmm/m512|b32	Blend Float32 Vectors using the Instruction Mask	
VBROADCASTF32X2	ymmreg|mask|z,xmmrm64	AVX512VL,AVX512DQ,FUTURE	VBROADCASTF32X2 ymm|mask|z, xmm/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTF32X2	zmmreg|mask|z,xmmrm64	AVX512DQ,FUTURE	VBROADCASTF32X2 zmm|mask|z, xmm/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTF32X4	ymmreg|mask|z,mem128	AVX512VL,AVX512,FUTURE	VBROADCASTF32X4 ymm|mask|z, mem128	Broadcast 4xFloat32 Vector	
VBROADCASTF32X4	zmmreg|mask|z,mem128	AVX512,FUTURE	VBROADCASTF32X4 zmm|mask|z, mem128	Broadcast 4xFloat32 Vector	
VBROADCASTF32X8	zmmreg|mask|z,mem256	AVX512DQ,FUTURE	VBROADCASTF32X8 zmm|mask|z, mem256	TODO: AVX512DQ,FUTURE	
VBROADCASTF64X2	ymmreg|mask|z,mem128	AVX512VL,AVX512DQ,FUTURE	VBROADCASTF64X2 ymm|mask|z, mem128	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTF64X2	zmmreg|mask|z,mem128	AVX512DQ,FUTURE	VBROADCASTF64X2 zmm|mask|z, mem128	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTF64X4	zmmreg|mask|z,mem256	AVX512,FUTURE	VBROADCASTF64X4 zmm|mask|z, mem256	Broadcast 4xFloat64 Vector	
VBROADCASTI32X2	xmmreg|mask|z,xmmrm64	AVX512VL,AVX512DQ,FUTURE	VBROADCASTI32X2 xmm|mask|z, xmm/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI32X2	ymmreg|mask|z,xmmrm64	AVX512VL,AVX512DQ,FUTURE	VBROADCASTI32X2 ymm|mask|z, xmm/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI32X2	zmmreg|mask|z,xmmrm64	AVX512DQ,FUTURE	VBROADCASTI32X2 zmm|mask|z, xmm/m64	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI32X4	ymmreg|mask|z,mem128	AVX512VL,AVX512,FUTURE	VBROADCASTI32X4 ymm|mask|z, mem128	Broadcast 4xInt32 Vector	
VBROADCASTI32X4	zmmreg|mask|z,mem128	AVX512,FUTURE	VBROADCASTI32X4 zmm|mask|z, mem128	Broadcast 4xInt32 Vector	
VBROADCASTI32X8	zmmreg|mask|z,mem256	AVX512DQ,FUTURE	VBROADCASTI32X8 zmm|mask|z, mem256	TODO: AVX512DQ,FUTURE	
VBROADCASTI64X2	ymmreg|mask|z,mem128	AVX512VL,AVX512DQ,FUTURE	VBROADCASTI64X2 ymm|mask|z, mem128	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI64X2	zmmreg|mask|z,mem128	AVX512DQ,FUTURE	VBROADCASTI64X2 zmm|mask|z, mem128	TODO: AVX512VL,AVX512DQ,FUTURE	
VBROADCASTI64X4	zmmreg|mask|z,mem256	AVX512,FUTURE	VBROADCASTI64X4 zmm|mask|z, mem256	Broadcast 4xInt64 Vector	
VCOMPRESSPD	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VCOMPRESSPD mem128|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VCOMPRESSPD mem256|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	mem512|mask,zmmreg	AVX512,FUTURE	VCOMPRESSPD mem512|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VCOMPRESSPD xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VCOMPRESSPD ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPD	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VCOMPRESSPD zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VCOMPRESSPS mem128|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VCOMPRESSPS mem256|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	mem512|mask,zmmreg	AVX512,FUTURE	VCOMPRESSPS mem512|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VCOMPRESSPS xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VCOMPRESSPS ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VCOMPRESSPS	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VCOMPRESSPS zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VCVTPD2QQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VCVTPD2QQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2QQ	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VCVTPD2QQ ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2QQ	zmmreg|mask|z,zmmrm512|b64|er	AVX512DQ,FUTURE	VCVTPD2QQ zmm|mask|z, zmm/m512|b32|er	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2UDQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VCVTPD2UDQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTPD2UDQ	xmmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VCVTPD2UDQ xmm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTPD2UDQ	ymmreg|mask|z,zmmrm512|b64|er	AVX512,FUTURE	VCVTPD2UDQ ymm|mask|z, zmm/m512|b32|er	TODO: AVX512VL,AVX512,FUTURE	
VCVTPD2UQQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VCVTPD2UQQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2UQQ	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VCVTPD2UQQ ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPD2UQQ	zmmreg|mask|z,zmmrm512|b64|er	AVX512DQ,FUTURE	VCVTPD2UQQ zmm|mask|z, zmm/m512|b32|er	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2QQ	xmmreg|mask|z,xmmrm64|b32	AVX512VL,AVX512DQ,FUTURE	VCVTPS2QQ xmm|mask|z, xmm/m64|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2QQ	ymmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512DQ,FUTURE	VCVTPS2QQ ymm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2QQ	zmmreg|mask|z,ymmrm256|b32|er	AVX512DQ,FUTURE	VCVTPS2QQ zmm|mask|z, ymm/m256|b32|er	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2UDQ	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VCVTPS2UDQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTPS2UDQ	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VCVTPS2UDQ ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTPS2UDQ	zmmreg|mask|z,zmmrm512|b32|er	AVX512,FUTURE	VCVTPS2UDQ zmm|mask|z, zmm/m512|b32|er	TODO: AVX512VL,AVX512,FUTURE	
VCVTPS2UQQ	xmmreg|mask|z,xmmrm64|b32	AVX512VL,AVX512DQ,FUTURE	VCVTPS2UQQ xmm|mask|z, xmm/m64|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2UQQ	ymmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512DQ,FUTURE	VCVTPS2UQQ ymm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTPS2UQQ	zmmreg|mask|z,ymmrm256|b32|er	AVX512DQ,FUTURE	VCVTPS2UQQ zmm|mask|z, ymm/m256|b32|er	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PD	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VCVTQQ2PD xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PD	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VCVTQQ2PD ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PD	zmmreg|mask|z,zmmrm512|b64|er	AVX512DQ,FUTURE	VCVTQQ2PD zmm|mask|z, zmm/m512|b32|er	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PS	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VCVTQQ2PS xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PS	xmmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VCVTQQ2PS xmm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTQQ2PS	ymmreg|mask|z,zmmrm512|b64|er	AVX512DQ,FUTURE	VCVTQQ2PS ymm|mask|z, zmm/m512|b32|er	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTSD2USI	reg32,xmmrm64|er	AVX512,FUTURE	VCVTSD2USI r32, xmm/m64|er	TODO: AVX512,FUTURE	
VCVTSD2USI	reg64,xmmrm64|er	AVX512,FUTURE	VCVTSD2USI r64, xmm/m64|er	TODO: AVX512,FUTURE	
VCVTSS2USI	reg32,xmmrm32|er	AVX512,FUTURE	VCVTSS2USI r32, xmm/m32|er	TODO: AVX512,FUTURE	
VCVTSS2USI	reg64,xmmrm32|er	AVX512,FUTURE	VCVTSS2USI r64, xmm/m32|er	TODO: AVX512,FUTURE	
VCVTTPD2QQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VCVTTPD2QQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2QQ	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VCVTTPD2QQ ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2QQ	zmmreg|mask|z,zmmrm512|b64|sae	AVX512DQ,FUTURE	VCVTTPD2QQ zmm|mask|z, zmm/m512|b32|sae	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2UDQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VCVTTPD2UDQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPD2UDQ	xmmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VCVTTPD2UDQ xmm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPD2UDQ	ymmreg|mask|z,zmmrm512|b64|sae	AVX512,FUTURE	VCVTTPD2UDQ ymm|mask|z, zmm/m512|b32|sae	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPD2UQQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VCVTTPD2UQQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2UQQ	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VCVTTPD2UQQ ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPD2UQQ	zmmreg|mask|z,zmmrm512|b64|sae	AVX512DQ,FUTURE	VCVTTPD2UQQ zmm|mask|z, zmm/m512|b32|sae	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2QQ	xmmreg|mask|z,xmmrm64|b32	AVX512VL,AVX512DQ,FUTURE	VCVTTPS2QQ xmm|mask|z, xmm/m64|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2QQ	ymmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512DQ,FUTURE	VCVTTPS2QQ ymm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2QQ	zmmreg|mask|z,ymmrm256|b32|sae	AVX512DQ,FUTURE	VCVTTPS2QQ zmm|mask|z, ymm/m256|b32|sae	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2UDQ	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VCVTTPS2UDQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPS2UDQ	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VCVTTPS2UDQ ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPS2UDQ	zmmreg|mask|z,zmmrm512|b32|sae	AVX512,FUTURE	VCVTTPS2UDQ zmm|mask|z, zmm/m512|b32|sae	TODO: AVX512VL,AVX512,FUTURE	
VCVTTPS2UQQ	xmmreg|mask|z,xmmrm64|b32	AVX512VL,AVX512DQ,FUTURE	VCVTTPS2UQQ xmm|mask|z, xmm/m64|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2UQQ	ymmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512DQ,FUTURE	VCVTTPS2UQQ ymm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTPS2UQQ	zmmreg|mask|z,ymmrm256|b32|sae	AVX512DQ,FUTURE	VCVTTPS2UQQ zmm|mask|z, ymm/m256|b32|sae	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTTSD2USI	reg32,xmmrm64|sae	AVX512,FUTURE	VCVTTSD2USI r32, xmm/m64|sae	TODO: AVX512,FUTURE	
VCVTTSD2USI	reg64,xmmrm64|sae	AVX512,FUTURE	VCVTTSD2USI r64, xmm/m64|sae	TODO: AVX512,FUTURE	
VCVTTSS2USI	reg32,xmmrm32|sae	AVX512,FUTURE	VCVTTSS2USI r32, xmm/m32|sae	TODO: AVX512,FUTURE	
VCVTTSS2USI	reg64,xmmrm32|sae	AVX512,FUTURE	VCVTTSS2USI r64, xmm/m32|sae	TODO: AVX512,FUTURE	
VCVTUDQ2PD	xmmreg|mask|z,xmmrm64|b32	AVX512VL,AVX512,FUTURE	VCVTUDQ2PD xmm|mask|z, xmm/m64|b32	Convert Uint32 Vector to Float64 Vector	
VCVTUDQ2PD	ymmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VCVTUDQ2PD ymm|mask|z, xmm/m128|b32	Convert Uint32 Vector to Float64 Vector	
VCVTUDQ2PD	zmmreg|mask|z,ymmrm256|b32|er	AVX512,FUTURE	VCVTUDQ2PD zmm|mask|z, ymm/m256|b32|er	Convert Uint32 Vector to Float64 Vector	
VCVTUDQ2PS	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VCVTUDQ2PS xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTUDQ2PS	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VCVTUDQ2PS ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VCVTUDQ2PS	zmmreg|mask|z,zmmrm512|b32|er	AVX512,FUTURE	VCVTUDQ2PS zmm|mask|z, zmm/m512|b32|er	TODO: AVX512VL,AVX512,FUTURE	
VCVTUQQ2PD	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VCVTUQQ2PD xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PD	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VCVTUQQ2PD ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PD	zmmreg|mask|z,zmmrm512|b64|er	AVX512DQ,FUTURE	VCVTUQQ2PD zmm|mask|z, zmm/m512|b32|er	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PS	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VCVTUQQ2PS xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PS	xmmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VCVTUQQ2PS xmm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUQQ2PS	ymmreg|mask|z,zmmrm512|b64|er	AVX512DQ,FUTURE	VCVTUQQ2PS ymm|mask|z, zmm/m512|b32|er	TODO: AVX512VL,AVX512DQ,FUTURE	
VCVTUSI2SD	xmmreg,xmmreg|er,rm32	AVX512,FUTURE	VCVTUSI2SD xmm, xmm|er, r/m32	TODO: AVX512,FUTURE	
VCVTUSI2SD	xmmreg,xmmreg|er,rm64	AVX512,FUTURE	VCVTUSI2SD xmm, xmm|er, r/m64	TODO: AVX512,FUTURE	
VCVTUSI2SS	xmmreg,xmmreg|er,rm32	AVX512,FUTURE	VCVTUSI2SS xmm, xmm|er, r/m32	TODO: AVX512,FUTURE	
VCVTUSI2SS	xmmreg,xmmreg|er,rm64	AVX512,FUTURE	VCVTUSI2SS xmm, xmm|er, r/m64	TODO: AVX512,FUTURE	
VDBPSADBW	xmmreg|mask|z,xmmreg,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VDBPSADBW xmm|mask|z, xmm, xmm/m128, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VDBPSADBW	ymmreg|mask|z,ymmreg,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VDBPSADBW ymm|mask|z, ymm, ymm/m256, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VDBPSADBW	zmmreg|mask|z,zmmreg,zmmrm512,imm8	AVX512BW,FUTURE	VDBPSADBW zmm|mask|z, zmm, zmm/m512, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VEXP2PD	zmmreg|mask|z,zmmrm512|b64|sae	AVX512ER,FUTURE	VEXP2PD zmm|mask|z, zmm/m512|b32|sae	TODO: AVX512ER,FUTURE	
VEXP2PS	zmmreg|mask|z,zmmrm512|b32|sae	AVX512ER,FUTURE	VEXP2PS zmm|mask|z, zmm/m512|b32|sae	TODO: AVX512ER,FUTURE	
VEXPANDPD	xmmreg|mask|z,mem128	AVX512VL,AVX512,FUTURE	VEXPANDPD xmm|mask|z, mem128	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	ymmreg|mask|z,mem256	AVX512VL,AVX512,FUTURE	VEXPANDPD ymm|mask|z, mem256	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	zmmreg|mask|z,mem512	AVX512,FUTURE	VEXPANDPD zmm|mask|z, mem512	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VEXPANDPD xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VEXPANDPD ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPD	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VEXPANDPD zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	xmmreg|mask|z,mem128	AVX512VL,AVX512,FUTURE	VEXPANDPS xmm|mask|z, mem128	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	ymmreg|mask|z,mem256	AVX512VL,AVX512,FUTURE	VEXPANDPS ymm|mask|z, mem256	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	zmmreg|mask|z,mem512	AVX512,FUTURE	VEXPANDPS zmm|mask|z, mem512	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VEXPANDPS xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VEXPANDPS ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VEXPANDPS	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VEXPANDPS zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X4	xmmreg|mask|z,ymmreg,imm8	AVX512VL,AVX512,FUTURE	VEXTRACTF32X4 xmm|mask|z, ymm, imm8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X4	xmmreg|mask|z,zmmreg,imm8	AVX512,FUTURE	VEXTRACTF32X4 xmm|mask|z, zmm, imm8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X4	mem128|mask,ymmreg,imm8	AVX512VL,AVX512,FUTURE	VEXTRACTF32X4 mem128|mask, ymm, imm8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X4	mem128|mask,zmmreg,imm8	AVX512,FUTURE	VEXTRACTF32X4 mem128|mask, zmm, imm8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTF32X8	ymmreg|mask|z,zmmreg,imm8	AVX512DQ,FUTURE	VEXTRACTF32X8 ymm|mask|z, zmm, imm8	TODO: AVX512DQ,FUTURE	
VEXTRACTF32X8	mem256|mask,zmmreg,imm8	AVX512DQ,FUTURE	VEXTRACTF32X8 mem256|mask, zmm, imm8	TODO: AVX512DQ,FUTURE	
VEXTRACTF64X2	xmmreg|mask|z,ymmreg,imm8	AVX512VL,AVX512DQ,FUTURE	VEXTRACTF64X2 xmm|mask|z, ymm, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTF64X2	xmmreg|mask|z,zmmreg,imm8	AVX512DQ,FUTURE	VEXTRACTF64X2 xmm|mask|z, zmm, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTF64X2	mem128|mask,ymmreg,imm8	AVX512VL,AVX512DQ,FUTURE	VEXTRACTF64X2 mem128|mask, ymm, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTF64X2	mem128|mask,zmmreg,imm8	AVX512DQ,FUTURE	VEXTRACTF64X2 mem128|mask, zmm, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTF64X4	ymmreg|mask|z,zmmreg,imm8	AVX512,FUTURE	VEXTRACTF64X4 ymm|mask|z, zmm, imm8	TODO: AVX512,FUTURE	
VEXTRACTF64X4	mem256|mask,zmmreg,imm8	AVX512,FUTURE	VEXTRACTF64X4 mem256|mask, zmm, imm8	TODO: AVX512,FUTURE	
VEXTRACTI32X4	xmmreg|mask|z,ymmreg,imm8	AVX512VL,AVX512,FUTURE	VEXTRACTI32X4 xmm|mask|z, ymm, imm8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTI32X4	xmmreg|mask|z,zmmreg,imm8	AVX512,FUTURE	VEXTRACTI32X4 xmm|mask|z, zmm, imm8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTI32X4	mem128|mask,ymmreg,imm8	AVX512VL,AVX512,FUTURE	VEXTRACTI32X4 mem128|mask, ymm, imm8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTI32X4	mem128|mask,zmmreg,imm8	AVX512,FUTURE	VEXTRACTI32X4 mem128|mask, zmm, imm8	TODO: AVX512VL,AVX512,FUTURE	
VEXTRACTI32X8	ymmreg|mask|z,zmmreg,imm8	AVX512DQ,FUTURE	VEXTRACTI32X8 ymm|mask|z, zmm, imm8	TODO: AVX512DQ,FUTURE	
VEXTRACTI32X8	mem256|mask,zmmreg,imm8	AVX512DQ,FUTURE	VEXTRACTI32X8 mem256|mask, zmm, imm8	TODO: AVX512DQ,FUTURE	
VEXTRACTI64X2	xmmreg|mask|z,ymmreg,imm8	AVX512VL,AVX512DQ,FUTURE	VEXTRACTI64X2 xmm|mask|z, ymm, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTI64X2	xmmreg|mask|z,zmmreg,imm8	AVX512DQ,FUTURE	VEXTRACTI64X2 xmm|mask|z, zmm, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTI64X2	mem128|mask,ymmreg,imm8	AVX512VL,AVX512DQ,FUTURE	VEXTRACTI64X2 mem128|mask, ymm, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTI64X2	mem128|mask,zmmreg,imm8	AVX512DQ,FUTURE	VEXTRACTI64X2 mem128|mask, zmm, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VEXTRACTI64X4	ymmreg|mask|z,zmmreg,imm8	AVX512,FUTURE	VEXTRACTI64X4 ymm|mask|z, zmm, imm8	TODO: AVX512,FUTURE	
VEXTRACTI64X4	mem256|mask,zmmreg,imm8	AVX512,FUTURE	VEXTRACTI64X4 mem256|mask, zmm, imm8	TODO: AVX512,FUTURE	
VFIXUPIMMPD	xmmreg|mask|z,xmmreg,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VFIXUPIMMPD xmm|mask|z, xmm, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPD	ymmreg|mask|z,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VFIXUPIMMPD ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPD	zmmreg|mask|z,zmmreg,zmmrm512|b64|sae,imm8	AVX512,FUTURE	VFIXUPIMMPD zmm|mask|z, zmm, zmm/m512|b32|sae, imm8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPS	xmmreg|mask|z,xmmreg,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VFIXUPIMMPS xmm|mask|z, xmm, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPS	ymmreg|mask|z,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VFIXUPIMMPS ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMPS	zmmreg|mask|z,zmmreg,zmmrm512|b32|sae,imm8	AVX512,FUTURE	VFIXUPIMMPS zmm|mask|z, zmm, zmm/m512|b32|sae, imm8	TODO: AVX512VL,AVX512,FUTURE	
VFIXUPIMMSD	xmmreg|mask|z,xmmreg,xmmrm64|sae,imm8	AVX512,FUTURE	VFIXUPIMMSD xmm|mask|z, xmm, xmm/m64|sae, imm8	TODO: AVX512,FUTURE	
VFIXUPIMMSS	xmmreg|mask|z,xmmreg,xmmrm32|sae,imm8	AVX512,FUTURE	VFIXUPIMMSS xmm|mask|z, xmm, xmm/m32|sae, imm8	TODO: AVX512,FUTURE	
VFPCLASSPD	kreg|mask,xmmrm128|b64,imm8	AVX512VL,AVX512DQ,FUTURE	VFPCLASSPD kreg|mask, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPD	kreg|mask,ymmrm256|b64,imm8	AVX512VL,AVX512DQ,FUTURE	VFPCLASSPD kreg|mask, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPD	kreg|mask,zmmrm512|b64,imm8	AVX512DQ,FUTURE	VFPCLASSPD kreg|mask, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPS	kreg|mask,xmmrm128|b32,imm8	AVX512VL,AVX512DQ,FUTURE	VFPCLASSPS kreg|mask, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPS	kreg|mask,ymmrm256|b32,imm8	AVX512VL,AVX512DQ,FUTURE	VFPCLASSPS kreg|mask, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSPS	kreg|mask,zmmrm512|b32,imm8	AVX512DQ,FUTURE	VFPCLASSPS kreg|mask, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VFPCLASSSD	kreg|mask,xmmrm64,imm8	AVX512DQ,FUTURE	VFPCLASSSD kreg|mask, xmm/m64, imm8	TODO: AVX512DQ,FUTURE	
VFPCLASSSS	kreg|mask,xmmrm32,imm8	AVX512DQ,FUTURE	VFPCLASSSS kreg|mask, xmm/m32, imm8	TODO: AVX512DQ,FUTURE	
VGATHERPF0DPD	ymem64|mask	AVX512PF,FUTURE	VGATHERPF0DPD ymem64|mask	TODO: AVX512PF,FUTURE	
VGATHERPF0DPS	zmem32|mask	AVX512PF,FUTURE	VGATHERPF0DPS zmem32|mask	Gather Prefetch Float32 Vector With Signed Dword Indices Into L1	
VGATHERPF0QPD	zmem64|mask	AVX512PF,FUTURE	VGATHERPF0QPD zmem64|mask	TODO: AVX512PF,FUTURE	
VGATHERPF0QPS	zmem32|mask	AVX512PF,FUTURE	VGATHERPF0QPS zmem32|mask	TODO: AVX512PF,FUTURE	
VGATHERPF1DPD	ymem64|mask	AVX512PF,FUTURE	VGATHERPF1DPD ymem64|mask	TODO: AVX512PF,FUTURE	
VGATHERPF1DPS	zmem32|mask	AVX512PF,FUTURE	VGATHERPF1DPS zmem32|mask	Gather Prefetch Float32 Vector With Signed Dword Indices Into L2	
VGATHERPF1QPD	zmem64|mask	AVX512PF,FUTURE	VGATHERPF1QPD zmem64|mask	TODO: AVX512PF,FUTURE	
VGATHERPF1QPS	zmem32|mask	AVX512PF,FUTURE	VGATHERPF1QPS zmem32|mask	TODO: AVX512PF,FUTURE	
VGETEXPPD	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VGETEXPPD xmm|mask|z, xmm/m128|b32	Extract Float64 Vector of Exponents from Float64 Vector	
VGETEXPPD	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VGETEXPPD ymm|mask|z, ymm/m256|b32	Extract Float64 Vector of Exponents from Float64 Vector	
VGETEXPPD	zmmreg|mask|z,zmmrm512|b64|sae	AVX512,FUTURE	VGETEXPPD zmm|mask|z, zmm/m512|b32|sae	Extract Float64 Vector of Exponents from Float64 Vector	
VGETEXPPS	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VGETEXPPS xmm|mask|z, xmm/m128|b32	Extract Float32 Vector of Exponents from Float32 Vector	
VGETEXPPS	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VGETEXPPS ymm|mask|z, ymm/m256|b32	Extract Float32 Vector of Exponents from Float32 Vector	
VGETEXPPS	zmmreg|mask|z,zmmrm512|b32|sae	AVX512,FUTURE	VGETEXPPS zmm|mask|z, zmm/m512|b32|sae	Extract Float32 Vector of Exponents from Float32 Vector	
VGETEXPSD	xmmreg|mask|z,xmmreg,xmmrm64|sae	AVX512,FUTURE	VGETEXPSD xmm|mask|z, xmm, xmm/m64|sae	TODO: AVX512,FUTURE	
VGETEXPSS	xmmreg|mask|z,xmmreg,xmmrm32|sae	AVX512,FUTURE	VGETEXPSS xmm|mask|z, xmm, xmm/m32|sae	TODO: AVX512,FUTURE	
VGETMANTPD	xmmreg|mask|z,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VGETMANTPD xmm|mask|z, xmm/m128|b32, imm8	Extract Float64 Vector of Normalized Mantissas from Float64 Vector	
VGETMANTPD	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VGETMANTPD ymm|mask|z, ymm/m256|b32, imm8	Extract Float64 Vector of Normalized Mantissas from Float64 Vector	
VGETMANTPD	zmmreg|mask|z,zmmrm512|b64|sae,imm8	AVX512,FUTURE	VGETMANTPD zmm|mask|z, zmm/m512|b32|sae, imm8	Extract Float64 Vector of Normalized Mantissas from Float64 Vector	
VGETMANTPS	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VGETMANTPS xmm|mask|z, xmm/m128|b32, imm8	Extract Float32 Vector of Normalized Mantissas from Float32 Vector	
VGETMANTPS	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VGETMANTPS ymm|mask|z, ymm/m256|b32, imm8	Extract Float32 Vector of Normalized Mantissas from Float32 Vector	
VGETMANTPS	zmmreg|mask|z,zmmrm512|b32|sae,imm8	AVX512,FUTURE	VGETMANTPS zmm|mask|z, zmm/m512|b32|sae, imm8	Extract Float32 Vector of Normalized Mantissas from Float32 Vector	
VGETMANTSD	xmmreg|mask|z,xmmreg,xmmrm64|sae,imm8	AVX512,FUTURE	VGETMANTSD xmm|mask|z, xmm, xmm/m64|sae, imm8	TODO: AVX512,FUTURE	
VGETMANTSS	xmmreg|mask|z,xmmreg,xmmrm32|sae,imm8	AVX512,FUTURE	VGETMANTSS xmm|mask|z, xmm, xmm/m32|sae, imm8	TODO: AVX512,FUTURE	
VINSERTF32X4	ymmreg|mask|z,ymmreg,xmmrm128,imm8	AVX512VL,AVX512,FUTURE	VINSERTF32X4 ymm|mask|z, ymm, xmm/m128, imm8	TODO: AVX512VL,AVX512,FUTURE	
VINSERTF32X4	zmmreg|mask|z,zmmreg,xmmrm128,imm8	AVX512,FUTURE	VINSERTF32X4 zmm|mask|z, zmm, xmm/m128, imm8	TODO: AVX512VL,AVX512,FUTURE	
VINSERTF32X8	zmmreg|mask|z,zmmreg,ymmrm256,imm8	AVX512DQ,FUTURE	VINSERTF32X8 zmm|mask|z, zmm, ymm/m256, imm8	TODO: AVX512DQ,FUTURE	
VINSERTF64X2	ymmreg|mask|z,ymmreg,xmmrm128,imm8	AVX512VL,AVX512DQ,FUTURE	VINSERTF64X2 ymm|mask|z, ymm, xmm/m128, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VINSERTF64X2	zmmreg|mask|z,zmmreg,xmmrm128,imm8	AVX512DQ,FUTURE	VINSERTF64X2 zmm|mask|z, zmm, xmm/m128, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VINSERTF64X4	zmmreg|mask|z,zmmreg,ymmrm256,imm8	AVX512,FUTURE	VINSERTF64X4 zmm|mask|z, zmm, ymm/m256, imm8	TODO: AVX512,FUTURE	
VINSERTI32X4	ymmreg|mask|z,ymmreg,xmmrm128,imm8	AVX512VL,AVX512,FUTURE	VINSERTI32X4 ymm|mask|z, ymm, xmm/m128, imm8	TODO: AVX512VL,AVX512,FUTURE	
VINSERTI32X4	zmmreg|mask|z,zmmreg,xmmrm128,imm8	AVX512,FUTURE	VINSERTI32X4 zmm|mask|z, zmm, xmm/m128, imm8	TODO: AVX512VL,AVX512,FUTURE	
VINSERTI32X8	zmmreg|mask|z,zmmreg,ymmrm256,imm8	AVX512DQ,FUTURE	VINSERTI32X8 zmm|mask|z, zmm, ymm/m256, imm8	TODO: AVX512DQ,FUTURE	
VINSERTI64X2	ymmreg|mask|z,ymmreg,xmmrm128,imm8	AVX512VL,AVX512DQ,FUTURE	VINSERTI64X2 ymm|mask|z, ymm, xmm/m128, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VINSERTI64X2	zmmreg|mask|z,zmmreg,xmmrm128,imm8	AVX512DQ,FUTURE	VINSERTI64X2 zmm|mask|z, zmm, xmm/m128, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VINSERTI64X4	zmmreg|mask|z,zmmreg,ymmrm256,imm8	AVX512,FUTURE	VINSERTI64X4 zmm|mask|z, zmm, ymm/m256, imm8	TODO: AVX512,FUTURE	
VMOVDQA32	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVDQA32 xmm|mask|z, xmm/m128	Move Aligned Int32 Vector	
VMOVDQA32	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVDQA32 ymm|mask|z, ymm/m256	Move Aligned Int32 Vector	
VMOVDQA32	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVDQA32 zmm|mask|z, zmm/m512	Move Aligned Int32 Vector	
VMOVDQA32	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VMOVDQA32 xmm|mask|z, xmm	Move Aligned Int32 Vector	
VMOVDQA32	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VMOVDQA32 ymm|mask|z, ymm	Move Aligned Int32 Vector	
VMOVDQA32	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VMOVDQA32 zmm|mask|z, zmm	Move Aligned Int32 Vector	
VMOVDQA32	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VMOVDQA32 mem128|mask, xmm	Move Aligned Int32 Vector	
VMOVDQA32	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VMOVDQA32 mem256|mask, ymm	Move Aligned Int32 Vector	
VMOVDQA32	mem512|mask,zmmreg	AVX512,FUTURE	VMOVDQA32 mem512|mask, zmm	Move Aligned Int32 Vector	
VMOVDQA64	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVDQA64 xmm|mask|z, xmm/m128	Move Aligned Int64 Vector	
VMOVDQA64	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVDQA64 ymm|mask|z, ymm/m256	Move Aligned Int64 Vector	
VMOVDQA64	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVDQA64 zmm|mask|z, zmm/m512	Move Aligned Int64 Vector	
VMOVDQA64	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VMOVDQA64 xmm|mask|z, xmm	Move Aligned Int64 Vector	
VMOVDQA64	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VMOVDQA64 ymm|mask|z, ymm	Move Aligned Int64 Vector	
VMOVDQA64	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VMOVDQA64 zmm|mask|z, zmm	Move Aligned Int64 Vector	
VMOVDQA64	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VMOVDQA64 mem128|mask, xmm	Move Aligned Int64 Vector	
VMOVDQA64	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VMOVDQA64 mem256|mask, ymm	Move Aligned Int64 Vector	
VMOVDQA64	mem512|mask,zmmreg	AVX512,FUTURE	VMOVDQA64 mem512|mask, zmm	Move Aligned Int64 Vector	
VMOVDQU16	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 xmm|mask|z, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 ymm|mask|z, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	zmmreg|mask|z,zmmrm512	AVX512BW,FUTURE	VMOVDQU16 zmm|mask|z, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	xmmreg|mask|z,xmmreg	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 xmm|mask|z, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	ymmreg|mask|z,ymmreg	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 ymm|mask|z, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	zmmreg|mask|z,zmmreg	AVX512BW,FUTURE	VMOVDQU16 zmm|mask|z, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	mem128|mask,xmmreg	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 mem128|mask, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	mem256|mask,ymmreg	AVX512VL,AVX512BW,FUTURE	VMOVDQU16 mem256|mask, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU16	mem512|mask,zmmreg	AVX512BW,FUTURE	VMOVDQU16 mem512|mask, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU32	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVDQU32 xmm|mask|z, xmm/m128	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVDQU32 ymm|mask|z, ymm/m256	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVDQU32 zmm|mask|z, zmm/m512	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VMOVDQU32 xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VMOVDQU32 ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VMOVDQU32 zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VMOVDQU32 mem128|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VMOVDQU32 mem256|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU32	mem512|mask,zmmreg	AVX512,FUTURE	VMOVDQU32 mem512|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512,FUTURE	VMOVDQU64 xmm|mask|z, xmm/m128	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512,FUTURE	VMOVDQU64 ymm|mask|z, ymm/m256	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	zmmreg|mask|z,zmmrm512	AVX512,FUTURE	VMOVDQU64 zmm|mask|z, zmm/m512	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VMOVDQU64 xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VMOVDQU64 ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VMOVDQU64 zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VMOVDQU64 mem128|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VMOVDQU64 mem256|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU64	mem512|mask,zmmreg	AVX512,FUTURE	VMOVDQU64 mem512|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VMOVDQU8	xmmreg|mask|z,xmmrm128	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 xmm|mask|z, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	ymmreg|mask|z,ymmrm256	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 ymm|mask|z, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	zmmreg|mask|z,zmmrm512	AVX512BW,FUTURE	VMOVDQU8 zmm|mask|z, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	xmmreg|mask|z,xmmreg	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 xmm|mask|z, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	ymmreg|mask|z,ymmreg	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 ymm|mask|z, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	zmmreg|mask|z,zmmreg	AVX512BW,FUTURE	VMOVDQU8 zmm|mask|z, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	mem128|mask,xmmreg	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 mem128|mask, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	mem256|mask,ymmreg	AVX512VL,AVX512BW,FUTURE	VMOVDQU8 mem256|mask, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VMOVDQU8	mem512|mask,zmmreg	AVX512BW,FUTURE	VMOVDQU8 mem512|mask, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPABSQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPABSQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPABSQ	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPABSQ ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPABSQ	zmmreg|mask|z,zmmrm512|b64	AVX512,FUTURE	VPABSQ zmm|mask|z, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPANDD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPANDD xmm|mask|z, xmm, xmm/m128|b32	Bitwise AND Int32 Vectors	
VPANDD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPANDD ymm|mask|z, ymm, ymm/m256|b32	Bitwise AND Int32 Vectors	
VPANDD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPANDD zmm|mask|z, zmm, zmm/m512|b32	Bitwise AND Int32 Vectors	
VPANDND	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPANDND xmm|mask|z, xmm, xmm/m128|b32	Bitwise AND NOT Int32 Vectors	
VPANDND	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPANDND ymm|mask|z, ymm, ymm/m256|b32	Bitwise AND NOT Int32 Vectors	
VPANDND	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPANDND zmm|mask|z, zmm, zmm/m512|b32	Bitwise AND NOT Int32 Vectors	
VPANDNQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPANDNQ xmm|mask|z, xmm, xmm/m128|b32	Bitwise AND NOT Int64 Vectors	
VPANDNQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPANDNQ ymm|mask|z, ymm, ymm/m256|b32	Bitwise AND NOT Int64 Vectors	
VPANDNQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPANDNQ zmm|mask|z, zmm, zmm/m512|b32	Bitwise AND NOT Int64 Vectors	
VPANDQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPANDQ xmm|mask|z, xmm, xmm/m128|b32	Bitwise AND Int64 Vectors	
VPANDQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPANDQ ymm|mask|z, ymm, ymm/m256|b32	Bitwise AND Int64 Vectors	
VPANDQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPANDQ zmm|mask|z, zmm, zmm/m512|b32	Bitwise AND Int64 Vectors	
VPBLENDMB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPBLENDMB xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPBLENDMB ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPBLENDMB zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPBLENDMD xmm|mask|z, xmm, xmm/m128|b32	Blend Int32 Vectors using the Instruction Mask	
VPBLENDMD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPBLENDMD ymm|mask|z, ymm, ymm/m256|b32	Blend Int32 Vectors using the Instruction Mask	
VPBLENDMD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPBLENDMD zmm|mask|z, zmm, zmm/m512|b32	Blend Int32 Vectors using the Instruction Mask	
VPBLENDMQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPBLENDMQ xmm|mask|z, xmm, xmm/m128|b32	Blend Int64 Vectors using the Instruction Mask	
VPBLENDMQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPBLENDMQ ymm|mask|z, ymm, ymm/m256|b32	Blend Int64 Vectors using the Instruction Mask	
VPBLENDMQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPBLENDMQ zmm|mask|z, zmm, zmm/m512|b32	Blend Int64 Vectors using the Instruction Mask	
VPBLENDMW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPBLENDMW xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPBLENDMW ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPBLENDMW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPBLENDMW zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPBROADCASTMB2Q	xmmreg,kreg	AVX512VL,AVX512CD,FUTURE	VPBROADCASTMB2Q xmm, kreg	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMB2Q	ymmreg,kreg	AVX512VL,AVX512CD,FUTURE	VPBROADCASTMB2Q ymm, kreg	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMB2Q	zmmreg,kreg	AVX512CD,FUTURE	VPBROADCASTMB2Q zmm, kreg	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMW2D	xmmreg,kreg	AVX512VL,AVX512CD,FUTURE	VPBROADCASTMW2D xmm, kreg	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMW2D	ymmreg,kreg	AVX512VL,AVX512CD,FUTURE	VPBROADCASTMW2D ymm, kreg	TODO: AVX512VL,AVX512CD,FUTURE	
VPBROADCASTMW2D	zmmreg,kreg	AVX512CD,FUTURE	VPBROADCASTMW2D zmm, kreg	TODO: AVX512VL,AVX512CD,FUTURE	
VPCMPB	kreg|mask,xmmreg,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPCMPB kreg|mask, xmm, xmm/m128, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPB	kreg|mask,ymmreg,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPCMPB kreg|mask, ymm, ymm/m256, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPB	kreg|mask,zmmreg,zmmrm512,imm8	AVX512BW,FUTURE	VPCMPB kreg|mask, zmm, zmm/m512, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPD	kreg|mask,xmmreg,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPCMPD kreg|mask, xmm, xmm/m128|b32, imm8	Compare Int32 Vectors and Set Vector Mask	
VPCMPD	kreg|mask,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPCMPD kreg|mask, ymm, ymm/m256|b32, imm8	Compare Int32 Vectors and Set Vector Mask	
VPCMPD	kreg|mask,zmmreg,zmmrm512|b32,imm8	AVX512,FUTURE	VPCMPD kreg|mask, zmm, zmm/m512|b32, imm8	Compare Int32 Vectors and Set Vector Mask	
VPCMPQ	kreg|mask,xmmreg,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VPCMPQ kreg|mask, xmm, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPQ	kreg|mask,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPCMPQ kreg|mask, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPQ	kreg|mask,zmmreg,zmmrm512|b64,imm8	AVX512,FUTURE	VPCMPQ kreg|mask, zmm, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPUB	kreg|mask,xmmreg,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPCMPUB kreg|mask, xmm, xmm/m128, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUB	kreg|mask,ymmreg,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPCMPUB kreg|mask, ymm, ymm/m256, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUB	kreg|mask,zmmreg,zmmrm512,imm8	AVX512BW,FUTURE	VPCMPUB kreg|mask, zmm, zmm/m512, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUD	kreg|mask,xmmreg,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPCMPUD kreg|mask, xmm, xmm/m128|b32, imm8	Compare Uint32 Vectors and Set Vector Mask	
VPCMPUD	kreg|mask,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPCMPUD kreg|mask, ymm, ymm/m256|b32, imm8	Compare Uint32 Vectors and Set Vector Mask	
VPCMPUD	kreg|mask,zmmreg,zmmrm512|b32,imm8	AVX512,FUTURE	VPCMPUD kreg|mask, zmm, zmm/m512|b32, imm8	Compare Uint32 Vectors and Set Vector Mask	
VPCMPUQ	kreg|mask,xmmreg,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VPCMPUQ kreg|mask, xmm, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPUQ	kreg|mask,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPCMPUQ kreg|mask, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPUQ	kreg|mask,zmmreg,zmmrm512|b64,imm8	AVX512,FUTURE	VPCMPUQ kreg|mask, zmm, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPCMPUW	kreg|mask,xmmreg,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPCMPUW kreg|mask, xmm, xmm/m128, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUW	kreg|mask,ymmreg,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPCMPUW kreg|mask, ymm, ymm/m256, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPUW	kreg|mask,zmmreg,zmmrm512,imm8	AVX512BW,FUTURE	VPCMPUW kreg|mask, zmm, zmm/m512, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPW	kreg|mask,xmmreg,xmmrm128,imm8	AVX512VL,AVX512BW,FUTURE	VPCMPW kreg|mask, xmm, xmm/m128, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPW	kreg|mask,ymmreg,ymmrm256,imm8	AVX512VL,AVX512BW,FUTURE	VPCMPW kreg|mask, ymm, ymm/m256, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCMPW	kreg|mask,zmmreg,zmmrm512,imm8	AVX512BW,FUTURE	VPCMPW kreg|mask, zmm, zmm/m512, imm8	TODO: AVX512VL,AVX512BW,FUTURE	
VPCOMPRESSD	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPCOMPRESSD mem128|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPCOMPRESSD mem256|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	mem512|mask,zmmreg	AVX512,FUTURE	VPCOMPRESSD mem512|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPCOMPRESSD xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPCOMPRESSD ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSD	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VPCOMPRESSD zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	mem128|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPCOMPRESSQ mem128|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	mem256|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPCOMPRESSQ mem256|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	mem512|mask,zmmreg	AVX512,FUTURE	VPCOMPRESSQ mem512|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPCOMPRESSQ xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPCOMPRESSQ ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPCOMPRESSQ	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VPCOMPRESSQ zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPCONFLICTD	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512CD,FUTURE	VPCONFLICTD xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTD	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512CD,FUTURE	VPCONFLICTD ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTD	zmmreg|mask|z,zmmrm512|b32	AVX512CD,FUTURE	VPCONFLICTD zmm|mask|z, zmm/m512|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512CD,FUTURE	VPCONFLICTQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTQ	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512CD,FUTURE	VPCONFLICTQ ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPCONFLICTQ	zmmreg|mask|z,zmmrm512|b64	AVX512CD,FUTURE	VPCONFLICTQ zmm|mask|z, zmm/m512|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPERMB	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512VBMI,FUTURE	VPERMB xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMB	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512VBMI,FUTURE	VPERMB ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMB	zmmreg|mask|z,zmmreg,zmmrm512	AVX512VBMI,FUTURE	VPERMB zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMI2B	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512VBMI,FUTURE	VPERMI2B xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMI2B	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512VBMI,FUTURE	VPERMI2B ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMI2B	zmmreg|mask|z,zmmreg,zmmrm512	AVX512VBMI,FUTURE	VPERMI2B zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMI2D	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPERMI2D xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2D	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPERMI2D ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2D	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPERMI2D zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPERMI2PD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPERMI2PD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPERMI2PD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPERMI2PS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPERMI2PS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2PS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPERMI2PS zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2Q	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPERMI2Q xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2Q	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPERMI2Q ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2Q	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPERMI2Q zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMI2W	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPERMI2W xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMI2W	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPERMI2W ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMI2W	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPERMI2W zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMT2B	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512VBMI,FUTURE	VPERMT2B xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMT2B	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512VBMI,FUTURE	VPERMT2B ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMT2B	zmmreg|mask|z,zmmreg,zmmrm512	AVX512VBMI,FUTURE	VPERMT2B zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPERMT2D	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPERMT2D xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2D	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPERMT2D ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2D	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPERMT2D zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPERMT2PD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPERMT2PD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PD	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPERMT2PD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPERMT2PS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPERMT2PS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2PS	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPERMT2PS zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2Q	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPERMT2Q xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2Q	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPERMT2Q ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2Q	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPERMT2Q zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPERMT2W	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPERMT2W xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMT2W	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPERMT2W ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMT2W	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPERMT2W zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPERMW xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPERMW ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPERMW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPERMW zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPEXPANDD	xmmreg|mask|z,mem128	AVX512VL,AVX512,FUTURE	VPEXPANDD xmm|mask|z, mem128	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	ymmreg|mask|z,mem256	AVX512VL,AVX512,FUTURE	VPEXPANDD ymm|mask|z, mem256	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	zmmreg|mask|z,mem512	AVX512,FUTURE	VPEXPANDD zmm|mask|z, mem512	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPEXPANDD xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPEXPANDD ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDD	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VPEXPANDD zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	xmmreg|mask|z,mem128	AVX512VL,AVX512,FUTURE	VPEXPANDQ xmm|mask|z, mem128	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	ymmreg|mask|z,mem256	AVX512VL,AVX512,FUTURE	VPEXPANDQ ymm|mask|z, mem256	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	zmmreg|mask|z,mem512	AVX512,FUTURE	VPEXPANDQ zmm|mask|z, mem512	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPEXPANDQ xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	ymmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPEXPANDQ ymm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPEXPANDQ	zmmreg|mask|z,zmmreg	AVX512,FUTURE	VPEXPANDQ zmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPLZCNTD	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512CD,FUTURE	VPLZCNTD xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTD	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512CD,FUTURE	VPLZCNTD ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTD	zmmreg|mask|z,zmmrm512|b32	AVX512CD,FUTURE	VPLZCNTD zmm|mask|z, zmm/m512|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTQ	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512CD,FUTURE	VPLZCNTQ xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTQ	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512CD,FUTURE	VPLZCNTQ ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPLZCNTQ	zmmreg|mask|z,zmmrm512|b64	AVX512CD,FUTURE	VPLZCNTQ zmm|mask|z, zmm/m512|b32	TODO: AVX512VL,AVX512CD,FUTURE	
VPMADD52HUQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512IFMA,FUTURE	VPMADD52HUQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52HUQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512IFMA,FUTURE	VPMADD52HUQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52HUQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512IFMA,FUTURE	VPMADD52HUQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52LUQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512IFMA,FUTURE	VPMADD52LUQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52LUQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512IFMA,FUTURE	VPMADD52LUQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMADD52LUQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512IFMA,FUTURE	VPMADD52LUQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512IFMA,FUTURE	
VPMAXSQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPMAXSQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMAXSQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPMAXSQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMAXSQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPMAXSQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMAXUQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPMAXUQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMAXUQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPMAXUQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMAXUQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPMAXUQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMINSQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPMINSQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMINSQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPMINSQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMINSQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPMINSQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMINUQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPMINUQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMINUQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPMINUQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMINUQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPMINUQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPMOVB2M	kreg,xmmreg	AVX512VL,AVX512BW,FUTURE	VPMOVB2M kreg, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVB2M	kreg,ymmreg	AVX512VL,AVX512BW,FUTURE	VPMOVB2M kreg, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVB2M	kreg,zmmreg	AVX512BW,FUTURE	VPMOVB2M kreg, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVD2M	kreg,xmmreg	AVX512VL,AVX512DQ,FUTURE	VPMOVD2M kreg, xmm	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVD2M	kreg,ymmreg	AVX512VL,AVX512DQ,FUTURE	VPMOVD2M kreg, ymm	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVD2M	kreg,zmmreg	AVX512DQ,FUTURE	VPMOVD2M kreg, zmm	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVDB	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVDB xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVDB xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	xmmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVDB xmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	mem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVDB mem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	mem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVDB mem64|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDB	mem128|mask,zmmreg	AVX512,FUTURE	VPMOVDB mem128|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVDW xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVDW xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	ymmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVDW ymm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	mem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVDW mem64|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	mem128|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVDW mem128|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVDW	mem256|mask,zmmreg	AVX512,FUTURE	VPMOVDW mem256|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVM2B	xmmreg,kreg	AVX512VL,AVX512BW,FUTURE	VPMOVM2B xmm, kreg	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2B	ymmreg,kreg	AVX512VL,AVX512BW,FUTURE	VPMOVM2B ymm, kreg	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2B	zmmreg,kreg	AVX512BW,FUTURE	VPMOVM2B zmm, kreg	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2D	xmmreg,kreg	AVX512VL,AVX512DQ,FUTURE	VPMOVM2D xmm, kreg	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2D	ymmreg,kreg	AVX512VL,AVX512DQ,FUTURE	VPMOVM2D ymm, kreg	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2D	zmmreg,kreg	AVX512DQ,FUTURE	VPMOVM2D zmm, kreg	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2Q	xmmreg,kreg	AVX512VL,AVX512DQ,FUTURE	VPMOVM2Q xmm, kreg	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2Q	ymmreg,kreg	AVX512VL,AVX512DQ,FUTURE	VPMOVM2Q ymm, kreg	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2Q	zmmreg,kreg	AVX512DQ,FUTURE	VPMOVM2Q zmm, kreg	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVM2W	xmmreg,kreg	AVX512VL,AVX512BW,FUTURE	VPMOVM2W xmm, kreg	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2W	ymmreg,kreg	AVX512VL,AVX512BW,FUTURE	VPMOVM2W ymm, kreg	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVM2W	zmmreg,kreg	AVX512BW,FUTURE	VPMOVM2W zmm, kreg	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVQ2M	kreg,xmmreg	AVX512VL,AVX512DQ,FUTURE	VPMOVQ2M kreg, xmm	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVQ2M	kreg,ymmreg	AVX512VL,AVX512DQ,FUTURE	VPMOVQ2M kreg, ymm	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVQ2M	kreg,zmmreg	AVX512DQ,FUTURE	VPMOVQ2M kreg, zmm	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMOVQB	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVQB xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVQB xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	xmmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVQB xmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	mem16|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVQB mem16|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	mem32|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVQB mem32|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQB	mem64|mask,zmmreg	AVX512,FUTURE	VPMOVQB mem64|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVQD xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVQD xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	ymmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVQD ymm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	mem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVQD mem64|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	mem128|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVQD mem128|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQD	mem256|mask,zmmreg	AVX512,FUTURE	VPMOVQD mem256|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVQW xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVQW xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	xmmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVQW xmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	mem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVQW mem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	mem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVQW mem64|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVQW	mem128|mask,zmmreg	AVX512,FUTURE	VPMOVQW mem128|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSDB xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSDB xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	xmmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVSDB xmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	mem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSDB mem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	mem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSDB mem64|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDB	mem128|mask,zmmreg	AVX512,FUTURE	VPMOVSDB mem128|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSDW xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSDW xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	ymmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVSDW ymm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	mem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSDW mem64|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	mem128|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSDW mem128|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSDW	mem256|mask,zmmreg	AVX512,FUTURE	VPMOVSDW mem256|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSQB xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSQB xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	xmmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVSQB xmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	mem16|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSQB mem16|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	mem32|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSQB mem32|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQB	mem64|mask,zmmreg	AVX512,FUTURE	VPMOVSQB mem64|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSQD xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSQD xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	ymmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVSQD ymm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	mem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSQD mem64|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	mem128|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSQD mem128|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQD	mem256|mask,zmmreg	AVX512,FUTURE	VPMOVSQD mem256|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSQW xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSQW xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	xmmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVSQW xmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	mem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVSQW mem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	mem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVSQW mem64|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSQW	mem128|mask,zmmreg	AVX512,FUTURE	VPMOVSQW mem128|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVSWB	xmmreg|mask|z,xmmreg	AVX512VL,AVX512BW,FUTURE	VPMOVSWB xmm|mask|z, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	xmmreg|mask|z,ymmreg	AVX512VL,AVX512BW,FUTURE	VPMOVSWB xmm|mask|z, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	ymmreg|mask|z,zmmreg	AVX512BW,FUTURE	VPMOVSWB ymm|mask|z, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	mem64|mask,xmmreg	AVX512VL,AVX512BW,FUTURE	VPMOVSWB mem64|mask, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	mem128|mask,ymmreg	AVX512VL,AVX512BW,FUTURE	VPMOVSWB mem128|mask, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVSWB	mem256|mask,zmmreg	AVX512BW,FUTURE	VPMOVSWB mem256|mask, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSDB	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSDB xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSDB xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	xmmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVUSDB xmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	mem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSDB mem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	mem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSDB mem64|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDB	mem128|mask,zmmreg	AVX512,FUTURE	VPMOVUSDB mem128|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSDW xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSDW xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	ymmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVUSDW ymm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	mem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSDW mem64|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	mem128|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSDW mem128|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSDW	mem256|mask,zmmreg	AVX512,FUTURE	VPMOVUSDW mem256|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQB xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQB xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	xmmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVUSQB xmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	mem16|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQB mem16|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	mem32|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQB mem32|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQB	mem64|mask,zmmreg	AVX512,FUTURE	VPMOVUSQB mem64|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQD xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQD xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	ymmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVUSQD ymm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	mem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQD mem64|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	mem128|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQD mem128|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQD	mem256|mask,zmmreg	AVX512,FUTURE	VPMOVUSQD mem256|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	xmmreg|mask|z,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQW xmm|mask|z, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	xmmreg|mask|z,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQW xmm|mask|z, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	xmmreg|mask|z,zmmreg	AVX512,FUTURE	VPMOVUSQW xmm|mask|z, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	mem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQW mem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	mem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPMOVUSQW mem64|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSQW	mem128|mask,zmmreg	AVX512,FUTURE	VPMOVUSQW mem128|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPMOVUSWB	xmmreg|mask|z,xmmreg	AVX512VL,AVX512BW,FUTURE	VPMOVUSWB xmm|mask|z, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	xmmreg|mask|z,ymmreg	AVX512VL,AVX512BW,FUTURE	VPMOVUSWB xmm|mask|z, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	ymmreg|mask|z,zmmreg	AVX512BW,FUTURE	VPMOVUSWB ymm|mask|z, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	mem64|mask,xmmreg	AVX512VL,AVX512BW,FUTURE	VPMOVUSWB mem64|mask, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	mem128|mask,ymmreg	AVX512VL,AVX512BW,FUTURE	VPMOVUSWB mem128|mask, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVUSWB	mem256|mask,zmmreg	AVX512BW,FUTURE	VPMOVUSWB mem256|mask, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVW2M	kreg,xmmreg	AVX512VL,AVX512BW,FUTURE	VPMOVW2M kreg, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVW2M	kreg,ymmreg	AVX512VL,AVX512BW,FUTURE	VPMOVW2M kreg, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVW2M	kreg,zmmreg	AVX512BW,FUTURE	VPMOVW2M kreg, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	xmmreg|mask|z,xmmreg	AVX512VL,AVX512BW,FUTURE	VPMOVWB xmm|mask|z, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	xmmreg|mask|z,ymmreg	AVX512VL,AVX512BW,FUTURE	VPMOVWB xmm|mask|z, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	ymmreg|mask|z,zmmreg	AVX512BW,FUTURE	VPMOVWB ymm|mask|z, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	mem64|mask,xmmreg	AVX512VL,AVX512BW,FUTURE	VPMOVWB mem64|mask, xmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	mem128|mask,ymmreg	AVX512VL,AVX512BW,FUTURE	VPMOVWB mem128|mask, ymm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMOVWB	mem256|mask,zmmreg	AVX512BW,FUTURE	VPMOVWB mem256|mask, zmm	TODO: AVX512VL,AVX512BW,FUTURE	
VPMULLQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512DQ,FUTURE	VPMULLQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMULLQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512DQ,FUTURE	VPMULLQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMULLQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512DQ,FUTURE	VPMULLQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512DQ,FUTURE	
VPMULTISHIFTQB	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512VBMI,FUTURE	VPMULTISHIFTQB xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPMULTISHIFTQB	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512VBMI,FUTURE	VPMULTISHIFTQB ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPMULTISHIFTQB	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512VBMI,FUTURE	VPMULTISHIFTQB zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512VBMI,FUTURE	
VPORD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPORD xmm|mask|z, xmm, xmm/m128|b32	Bitwise OR Int32 Vectors	
VPORD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPORD ymm|mask|z, ymm, ymm/m256|b32	Bitwise OR Int32 Vectors	
VPORD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPORD zmm|mask|z, zmm, zmm/m512|b32	Bitwise OR Int32 Vectors	
VPORQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPORQ xmm|mask|z, xmm, xmm/m128|b32	Bitwise OR Int64 Vectors	
VPORQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPORQ ymm|mask|z, ymm, ymm/m256|b32	Bitwise OR Int64 Vectors	
VPORQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPORQ zmm|mask|z, zmm, zmm/m512|b32	Bitwise OR Int64 Vectors	
VPROLD	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPROLD xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPROLD	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPROLD ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPROLD	zmmreg|mask|z,zmmrm512|b32,imm8	AVX512,FUTURE	VPROLD zmm|mask|z, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPROLQ	xmmreg|mask|z,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VPROLQ xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPROLQ	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPROLQ ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPROLQ	zmmreg|mask|z,zmmrm512|b64,imm8	AVX512,FUTURE	VPROLQ zmm|mask|z, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPROLVD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPROLVD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPROLVD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPROLVD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPROLVD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPROLVD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPROLVQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPROLVQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPROLVQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPROLVQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPROLVQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPROLVQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPRORD	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPRORD xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPRORD	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPRORD ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPRORD	zmmreg|mask|z,zmmrm512|b32,imm8	AVX512,FUTURE	VPRORD zmm|mask|z, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPRORQ	xmmreg|mask|z,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VPRORQ xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPRORQ	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPRORQ ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPRORQ	zmmreg|mask|z,zmmrm512|b64,imm8	AVX512,FUTURE	VPRORQ zmm|mask|z, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPRORVD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPRORVD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPRORVD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPRORVD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPRORVD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPRORVD zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPRORVQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPRORVQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPRORVQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPRORVQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPRORVQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPRORVQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERDD	xmem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPSCATTERDD xmem32|mask, xmm	Scatter Int32 Vector With Signed Dword Indices	
VPSCATTERDD	ymem32|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPSCATTERDD ymem32|mask, ymm	Scatter Int32 Vector With Signed Dword Indices	
VPSCATTERDD	zmem32|mask,zmmreg	AVX512,FUTURE	VPSCATTERDD zmem32|mask, zmm	Scatter Int32 Vector With Signed Dword Indices	
VPSCATTERDQ	xmem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPSCATTERDQ xmem64|mask, xmm	Scatter Int64 Vector With Signed Dword Indices	
VPSCATTERDQ	xmem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPSCATTERDQ xmem64|mask, ymm	Scatter Int64 Vector With Signed Dword Indices	
VPSCATTERDQ	ymem64|mask,zmmreg	AVX512,FUTURE	VPSCATTERDQ ymem64|mask, zmm	Scatter Int64 Vector With Signed Dword Indices	
VPSCATTERQD	xmem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPSCATTERQD xmem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQD	ymem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPSCATTERQD ymem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQD	zmem32|mask,ymmreg	AVX512,FUTURE	VPSCATTERQD zmem32|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQQ	xmem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VPSCATTERQQ xmem64|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQQ	ymem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VPSCATTERQQ ymem64|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VPSCATTERQQ	zmem64|mask,zmmreg	AVX512,FUTURE	VPSCATTERQQ zmem64|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VPSLLVW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSLLVW xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPSLLVW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSLLVW ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPSLLVW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSLLVW zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRAQ	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSRAQ xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	ymmreg|mask|z,ymmreg,xmmrm128	AVX512VL,AVX512,FUTURE	VPSRAQ ymm|mask|z, ymm, xmm/m128	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	zmmreg|mask|z,zmmreg,xmmrm128	AVX512,FUTURE	VPSRAQ zmm|mask|z, zmm, xmm/m128	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	xmmreg|mask|z,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VPSRAQ xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPSRAQ ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPSRAQ	zmmreg|mask|z,zmmrm512|b64,imm8	AVX512,FUTURE	VPSRAQ zmm|mask|z, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPSRAVQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPSRAVQ xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPSRAVQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPSRAVQ ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPSRAVQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPSRAVQ zmm|mask|z, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPSRAVW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSRAVW xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRAVW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSRAVW ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRAVW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSRAVW zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRLVW	xmmreg|mask|z,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPSRLVW xmm|mask|z, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRLVW	ymmreg|mask|z,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPSRLVW ymm|mask|z, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPSRLVW	zmmreg|mask|z,zmmreg,zmmrm512	AVX512BW,FUTURE	VPSRLVW zmm|mask|z, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPTERNLOGD	xmmreg|mask|z,xmmreg,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VPTERNLOGD xmm|mask|z, xmm, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGD	ymmreg|mask|z,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VPTERNLOGD ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGD	zmmreg|mask|z,zmmreg,zmmrm512|b32,imm8	AVX512,FUTURE	VPTERNLOGD zmm|mask|z, zmm, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGQ	xmmreg|mask|z,xmmreg,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VPTERNLOGQ xmm|mask|z, xmm, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGQ	ymmreg|mask|z,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VPTERNLOGQ ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPTERNLOGQ	zmmreg|mask|z,zmmreg,zmmrm512|b64,imm8	AVX512,FUTURE	VPTERNLOGQ zmm|mask|z, zmm, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VPTESTMB	kreg|mask,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPTESTMB kreg|mask, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMB	kreg|mask,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPTESTMB kreg|mask, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMB	kreg|mask,zmmreg,zmmrm512	AVX512BW,FUTURE	VPTESTMB kreg|mask, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMD	kreg|mask,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPTESTMD kreg|mask, xmm, xmm/m128|b32	Logical AND Int32 Vectors and Set Vector Mask	
VPTESTMD	kreg|mask,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPTESTMD kreg|mask, ymm, ymm/m256|b32	Logical AND Int32 Vectors and Set Vector Mask	
VPTESTMD	kreg|mask,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPTESTMD kreg|mask, zmm, zmm/m512|b32	Logical AND Int32 Vectors and Set Vector Mask	
VPTESTMQ	kreg|mask,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPTESTMQ kreg|mask, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPTESTMQ	kreg|mask,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPTESTMQ kreg|mask, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPTESTMQ	kreg|mask,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPTESTMQ kreg|mask, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPTESTMW	kreg|mask,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPTESTMW kreg|mask, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMW	kreg|mask,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPTESTMW kreg|mask, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTMW	kreg|mask,zmmreg,zmmrm512	AVX512BW,FUTURE	VPTESTMW kreg|mask, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMB	kreg|mask,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPTESTNMB kreg|mask, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMB	kreg|mask,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPTESTNMB kreg|mask, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMB	kreg|mask,zmmreg,zmmrm512	AVX512BW,FUTURE	VPTESTNMB kreg|mask, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMD	kreg|mask,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPTESTNMD kreg|mask, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMD	kreg|mask,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPTESTNMD kreg|mask, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMD	kreg|mask,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPTESTNMD kreg|mask, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMQ	kreg|mask,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPTESTNMQ kreg|mask, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMQ	kreg|mask,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPTESTNMQ kreg|mask, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMQ	kreg|mask,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPTESTNMQ kreg|mask, zmm, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VPTESTNMW	kreg|mask,xmmreg,xmmrm128	AVX512VL,AVX512BW,FUTURE	VPTESTNMW kreg|mask, xmm, xmm/m128	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMW	kreg|mask,ymmreg,ymmrm256	AVX512VL,AVX512BW,FUTURE	VPTESTNMW kreg|mask, ymm, ymm/m256	TODO: AVX512VL,AVX512BW,FUTURE	
VPTESTNMW	kreg|mask,zmmreg,zmmrm512	AVX512BW,FUTURE	VPTESTNMW kreg|mask, zmm, zmm/m512	TODO: AVX512VL,AVX512BW,FUTURE	
VPXORD	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VPXORD xmm|mask|z, xmm, xmm/m128|b32	Bitwise XOR Int32 Vectors	
VPXORD	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VPXORD ymm|mask|z, ymm, ymm/m256|b32	Bitwise XOR Int32 Vectors	
VPXORD	zmmreg|mask|z,zmmreg,zmmrm512|b32	AVX512,FUTURE	VPXORD zmm|mask|z, zmm, zmm/m512|b32	Bitwise XOR Int32 Vectors	
VPXORQ	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VPXORQ xmm|mask|z, xmm, xmm/m128|b32	Bitwise XOR Int64 Vectors	
VPXORQ	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VPXORQ ymm|mask|z, ymm, ymm/m256|b32	Bitwise XOR Int64 Vectors	
VPXORQ	zmmreg|mask|z,zmmreg,zmmrm512|b64	AVX512,FUTURE	VPXORQ zmm|mask|z, zmm, zmm/m512|b32	Bitwise XOR Int64 Vectors	
VRANGEPD	xmmreg|mask|z,xmmreg,xmmrm128|b64,imm8	AVX512VL,AVX512DQ,FUTURE	VRANGEPD xmm|mask|z, xmm, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPD	ymmreg|mask|z,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512DQ,FUTURE	VRANGEPD ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPD	zmmreg|mask|z,zmmreg,zmmrm512|b64|sae,imm8	AVX512DQ,FUTURE	VRANGEPD zmm|mask|z, zmm, zmm/m512|b32|sae, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPS	xmmreg|mask|z,xmmreg,xmmrm128|b32,imm8	AVX512VL,AVX512DQ,FUTURE	VRANGEPS xmm|mask|z, xmm, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPS	ymmreg|mask|z,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512DQ,FUTURE	VRANGEPS ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGEPS	zmmreg|mask|z,zmmreg,zmmrm512|b32|sae,imm8	AVX512DQ,FUTURE	VRANGEPS zmm|mask|z, zmm, zmm/m512|b32|sae, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VRANGESD	xmmreg|mask|z,xmmreg,xmmrm64|sae,imm8	AVX512DQ,FUTURE	VRANGESD xmm|mask|z, xmm, xmm/m64|sae, imm8	TODO: AVX512DQ,FUTURE	
VRANGESS	xmmreg|mask|z,xmmreg,xmmrm32|sae,imm8	AVX512DQ,FUTURE	VRANGESS xmm|mask|z, xmm, xmm/m32|sae, imm8	TODO: AVX512DQ,FUTURE	
VRCP14PD	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VRCP14PD xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PD	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VRCP14PD ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PD	zmmreg|mask|z,zmmrm512|b64	AVX512,FUTURE	VRCP14PD zmm|mask|z, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PS	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VRCP14PS xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PS	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VRCP14PS ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VRCP14PS	zmmreg|mask|z,zmmrm512|b32	AVX512,FUTURE	VRCP14PS zmm|mask|z, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VRCP14SD	xmmreg|mask|z,xmmreg,xmmrm64	AVX512,FUTURE	VRCP14SD xmm|mask|z, xmm, xmm/m64	TODO: AVX512,FUTURE	
VRCP14SS	xmmreg|mask|z,xmmreg,xmmrm32	AVX512,FUTURE	VRCP14SS xmm|mask|z, xmm, xmm/m32	TODO: AVX512,FUTURE	
VRCP28PD	zmmreg|mask|z,zmmrm512|b64|sae	AVX512ER,FUTURE	VRCP28PD zmm|mask|z, zmm/m512|b32|sae	TODO: AVX512ER,FUTURE	
VRCP28PS	zmmreg|mask|z,zmmrm512|b32|sae	AVX512ER,FUTURE	VRCP28PS zmm|mask|z, zmm/m512|b32|sae	TODO: AVX512ER,FUTURE	
VRCP28SD	xmmreg|mask|z,xmmreg,xmmrm64|sae	AVX512ER,FUTURE	VRCP28SD xmm|mask|z, xmm, xmm/m64|sae	TODO: AVX512ER,FUTURE	
VRCP28SS	xmmreg|mask|z,xmmreg,xmmrm32|sae	AVX512ER,FUTURE	VRCP28SS xmm|mask|z, xmm, xmm/m32|sae	TODO: AVX512ER,FUTURE	
VREDUCEPD	xmmreg|mask|z,xmmrm128|b64,imm8	AVX512VL,AVX512DQ,FUTURE	VREDUCEPD xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPD	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512DQ,FUTURE	VREDUCEPD ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPD	zmmreg|mask|z,zmmrm512|b64|sae,imm8	AVX512DQ,FUTURE	VREDUCEPD zmm|mask|z, zmm/m512|b32|sae, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPS	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512DQ,FUTURE	VREDUCEPS xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPS	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512DQ,FUTURE	VREDUCEPS ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCEPS	zmmreg|mask|z,zmmrm512|b32|sae,imm8	AVX512DQ,FUTURE	VREDUCEPS zmm|mask|z, zmm/m512|b32|sae, imm8	TODO: AVX512VL,AVX512DQ,FUTURE	
VREDUCESD	xmmreg|mask|z,xmmreg,xmmrm64|sae,imm8	AVX512DQ,FUTURE	VREDUCESD xmm|mask|z, xmm, xmm/m64|sae, imm8	TODO: AVX512DQ,FUTURE	
VREDUCESS	xmmreg|mask|z,xmmreg,xmmrm32|sae,imm8	AVX512DQ,FUTURE	VREDUCESS xmm|mask|z, xmm, xmm/m32|sae, imm8	TODO: AVX512DQ,FUTURE	
VRNDSCALEPD	xmmreg|mask|z,xmmrm128|b64,imm8	AVX512VL,AVX512,FUTURE	VRNDSCALEPD xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPD	ymmreg|mask|z,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VRNDSCALEPD ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPD	zmmreg|mask|z,zmmrm512|b64|sae,imm8	AVX512,FUTURE	VRNDSCALEPD zmm|mask|z, zmm/m512|b32|sae, imm8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPS	xmmreg|mask|z,xmmrm128|b32,imm8	AVX512VL,AVX512,FUTURE	VRNDSCALEPS xmm|mask|z, xmm/m128|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPS	ymmreg|mask|z,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VRNDSCALEPS ymm|mask|z, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALEPS	zmmreg|mask|z,zmmrm512|b32|sae,imm8	AVX512,FUTURE	VRNDSCALEPS zmm|mask|z, zmm/m512|b32|sae, imm8	TODO: AVX512VL,AVX512,FUTURE	
VRNDSCALESD	xmmreg|mask|z,xmmreg,xmmrm64|sae,imm8	AVX512,FUTURE	VRNDSCALESD xmm|mask|z, xmm, xmm/m64|sae, imm8	TODO: AVX512,FUTURE	
VRNDSCALESS	xmmreg|mask|z,xmmreg,xmmrm32|sae,imm8	AVX512,FUTURE	VRNDSCALESS xmm|mask|z, xmm, xmm/m32|sae, imm8	TODO: AVX512,FUTURE	
VRSQRT14PD	xmmreg|mask|z,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VRSQRT14PD xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PD	ymmreg|mask|z,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VRSQRT14PD ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PD	zmmreg|mask|z,zmmrm512|b64	AVX512,FUTURE	VRSQRT14PD zmm|mask|z, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PS	xmmreg|mask|z,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VRSQRT14PS xmm|mask|z, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PS	ymmreg|mask|z,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VRSQRT14PS ymm|mask|z, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14PS	zmmreg|mask|z,zmmrm512|b32	AVX512,FUTURE	VRSQRT14PS zmm|mask|z, zmm/m512|b32	TODO: AVX512VL,AVX512,FUTURE	
VRSQRT14SD	xmmreg|mask|z,xmmreg,xmmrm64	AVX512,FUTURE	VRSQRT14SD xmm|mask|z, xmm, xmm/m64	TODO: AVX512,FUTURE	
VRSQRT14SS	xmmreg|mask|z,xmmreg,xmmrm32	AVX512,FUTURE	VRSQRT14SS xmm|mask|z, xmm, xmm/m32	TODO: AVX512,FUTURE	
VRSQRT28PD	zmmreg|mask|z,zmmrm512|b64|sae	AVX512ER,FUTURE	VRSQRT28PD zmm|mask|z, zmm/m512|b32|sae	TODO: AVX512ER,FUTURE	
VRSQRT28PS	zmmreg|mask|z,zmmrm512|b32|sae	AVX512ER,FUTURE	VRSQRT28PS zmm|mask|z, zmm/m512|b32|sae	TODO: AVX512ER,FUTURE	
VRSQRT28SD	xmmreg|mask|z,xmmreg,xmmrm64|sae	AVX512ER,FUTURE	VRSQRT28SD xmm|mask|z, xmm, xmm/m64|sae	TODO: AVX512ER,FUTURE	
VRSQRT28SS	xmmreg|mask|z,xmmreg,xmmrm32|sae	AVX512ER,FUTURE	VRSQRT28SS xmm|mask|z, xmm, xmm/m32|sae	TODO: AVX512ER,FUTURE	
VSCALEFPD	xmmreg|mask|z,xmmreg,xmmrm128|b64	AVX512VL,AVX512,FUTURE	VSCALEFPD xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPD	ymmreg|mask|z,ymmreg,ymmrm256|b64	AVX512VL,AVX512,FUTURE	VSCALEFPD ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPD	zmmreg|mask|z,zmmreg,zmmrm512|b64|er	AVX512,FUTURE	VSCALEFPD zmm|mask|z, zmm, zmm/m512|b32|er	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPS	xmmreg|mask|z,xmmreg,xmmrm128|b32	AVX512VL,AVX512,FUTURE	VSCALEFPS xmm|mask|z, xmm, xmm/m128|b32	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPS	ymmreg|mask|z,ymmreg,ymmrm256|b32	AVX512VL,AVX512,FUTURE	VSCALEFPS ymm|mask|z, ymm, ymm/m256|b32	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFPS	zmmreg|mask|z,zmmreg,zmmrm512|b32|er	AVX512,FUTURE	VSCALEFPS zmm|mask|z, zmm, zmm/m512|b32|er	TODO: AVX512VL,AVX512,FUTURE	
VSCALEFSD	xmmreg|mask|z,xmmreg,xmmrm64|er	AVX512,FUTURE	VSCALEFSD xmm|mask|z, xmm, xmm/m64|er	TODO: AVX512,FUTURE	
VSCALEFSS	xmmreg|mask|z,xmmreg,xmmrm32|er	AVX512,FUTURE	VSCALEFSS xmm|mask|z, xmm, xmm/m32|er	TODO: AVX512,FUTURE	
VSCATTERDPD	xmem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VSCATTERDPD xmem64|mask, xmm	Scatter Float64 Vector With Signed Dword Indices	
VSCATTERDPD	xmem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VSCATTERDPD xmem64|mask, ymm	Scatter Float64 Vector With Signed Dword Indices	
VSCATTERDPD	ymem64|mask,zmmreg	AVX512,FUTURE	VSCATTERDPD ymem64|mask, zmm	Scatter Float64 Vector With Signed Dword Indices	
VSCATTERDPS	xmem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VSCATTERDPS xmem32|mask, xmm	Scatter Float32 Vector With Signed Dword Indices	
VSCATTERDPS	ymem32|mask,ymmreg	AVX512VL,AVX512,FUTURE	VSCATTERDPS ymem32|mask, ymm	Scatter Float32 Vector With Signed Dword Indices	
VSCATTERDPS	zmem32|mask,zmmreg	AVX512,FUTURE	VSCATTERDPS zmem32|mask, zmm	Scatter Float32 Vector With Signed Dword Indices	
VSCATTERPF0DPD	ymem64|mask	AVX512PF,FUTURE	VSCATTERPF0DPD ymem64|mask	TODO: AVX512PF,FUTURE	
VSCATTERPF0DPS	zmem32|mask	AVX512PF,FUTURE	VSCATTERPF0DPS zmem32|mask	Scatter Prefetch Float32 Vector With Signed Dword Indices Into L1	
VSCATTERPF0QPD	zmem64|mask	AVX512PF,FUTURE	VSCATTERPF0QPD zmem64|mask	TODO: AVX512PF,FUTURE	
VSCATTERPF0QPS	zmem32|mask	AVX512PF,FUTURE	VSCATTERPF0QPS zmem32|mask	TODO: AVX512PF,FUTURE	
VSCATTERPF1DPD	ymem64|mask	AVX512PF,FUTURE	VSCATTERPF1DPD ymem64|mask	TODO: AVX512PF,FUTURE	
VSCATTERPF1DPS	zmem32|mask	AVX512PF,FUTURE	VSCATTERPF1DPS zmem32|mask	Scatter Prefetch Float32 Vector With Signed Dword Indices Into L2	
VSCATTERPF1QPD	zmem64|mask	AVX512PF,FUTURE	VSCATTERPF1QPD zmem64|mask	TODO: AVX512PF,FUTURE	
VSCATTERPF1QPS	zmem32|mask	AVX512PF,FUTURE	VSCATTERPF1QPS zmem32|mask	TODO: AVX512PF,FUTURE	
VSCATTERQPD	xmem64|mask,xmmreg	AVX512VL,AVX512,FUTURE	VSCATTERQPD xmem64|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPD	ymem64|mask,ymmreg	AVX512VL,AVX512,FUTURE	VSCATTERQPD ymem64|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPD	zmem64|mask,zmmreg	AVX512,FUTURE	VSCATTERQPD zmem64|mask, zmm	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPS	xmem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VSCATTERQPS xmem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPS	ymem32|mask,xmmreg	AVX512VL,AVX512,FUTURE	VSCATTERQPS ymem32|mask, xmm	TODO: AVX512VL,AVX512,FUTURE	
VSCATTERQPS	zmem32|mask,ymmreg	AVX512,FUTURE	VSCATTERQPS zmem32|mask, ymm	TODO: AVX512VL,AVX512,FUTURE	
VSHUFF32X4	ymmreg|mask|z,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VSHUFF32X4 ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFF32X4	zmmreg|mask|z,zmmreg,zmmrm512|b32,imm8	AVX512,FUTURE	VSHUFF32X4 zmm|mask|z, zmm, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFF64X2	ymmreg|mask|z,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VSHUFF64X2 ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFF64X2	zmmreg|mask|z,zmmreg,zmmrm512|b64,imm8	AVX512,FUTURE	VSHUFF64X2 zmm|mask|z, zmm, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFI32X4	ymmreg|mask|z,ymmreg,ymmrm256|b32,imm8	AVX512VL,AVX512,FUTURE	VSHUFI32X4 ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFI32X4	zmmreg|mask|z,zmmreg,zmmrm512|b32,imm8	AVX512,FUTURE	VSHUFI32X4 zmm|mask|z, zmm, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFI64X2	ymmreg|mask|z,ymmreg,ymmrm256|b64,imm8	AVX512VL,AVX512,FUTURE	VSHUFI64X2 ymm|mask|z, ymm, ymm/m256|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
VSHUFI64X2	zmmreg|mask|z,zmmreg,zmmrm512|b64,imm8	AVX512,FUTURE	VSHUFI64X2 zmm|mask|z, zmm, zmm/m512|b32, imm8	TODO: AVX512VL,AVX512,FUTURE	
RDPKRU	none	X64,FUTURE	RDPKRU 	TODO: X64,FUTURE	
WRPKRU	none	X64,FUTURE	WRPKRU 	TODO: X64,FUTURE	
CLFLUSHOPT	mem	FUTURE	CLFLUSHOPT mem	TODO: FUTURE	
CLZERO	none	X64,FUTURE,AMD	CLZERO 	TODO: X64,FUTURE,AMD
